[
    {
        "title": "Few-Shot Learning for Dermatological Disease Diagnosis",
        "firstAuthor": "Viraj Prabhu",
        "url": null,
        "dateSubmitted": "2019-10-28",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We consider the problem of clinical image classi\ufb01cation for the purpose of aiding doctors in dermatological disease diagnosis. Diagnosis of dermatological conditions from images poses two major challenges for standard off-the-shelf techniques: First, the distribution of real-world dermatological datasets is typically long-tailed. Second, intra-class variability is large. To address the \ufb01rst issue, we formulate the problem as low-shot learning, where once deployed, a base classi\ufb01er must rapidly generalize to diagnose novel conditions given very few labeled examples. To model intra-class variability effectively, we propose Prototypical Clustering Networks (PCN), an extension to Prototypical Networks (Snell et al., 2017) that learns a mixture of \u201cprototypes\u201d for each class. Prototypes are initialized for each class via clustering and re\ufb01ned via an online update scheme. Classi\ufb01cation is performed by measuring similarity to a weighted combination of prototypes within a class, where the weights are the inferred cluster responsibilities. We demonstrate the strengths of our approach in effective diagnosis on a realistic dataset of dermatological conditions.",
        "paperId": "0000e6e3d378b80ece30cd6d2a1f4c8a4bd23cdc"
    },
    {
        "title": "ResAttr-GAN: Unpaired Deep Residual Attributes Learning for Multi-Domain Face Image Translation",
        "firstAuthor": "Rentuo Tao",
        "url": null,
        "dateSubmitted": "2019-09-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Facial attributes edit can be seen as an image-to-image translation problem, whose goal is to transfer images from the source domain to the target domain. Specially, facial attributes edit aims at changing some semantic attributes of a given face image while keeping the contents of unrelated area unchanged. The great challenge for this problem lies on the lacking of paired data, i.e. we do not have paired face images that only differ on particular attributes. Moreover, to train a good attributes editing model, there always needs a great amount of train data which labeled by hand. If the train data amount was reduced, then the editing performance would decrease accordingly. Strong intelligent systems should be able to learn knowledge from less data samples (similar idea with few-shot learning). To mitigate this limitation, in this paper, we proposed a Siamese-Network based residual attributes learning model to learn the attributes difference in the high-level latent space. Compared to existing models that perform attributes editing based on an attributes classifier, the proposed deep residual attributes learning model utilized relatively weaker information of attribute differences for face image translation. Sufficient qualitative and quantitative experiments conducted on CelebA dataset proved the effectiveness of our proposed method, moreover, we also adopt the proposed residual attributes learning model in two state-of-the-art models under different data usage percentage to show the effectiveness of the proposed model on boosting attribute editing performance under limited data usage. The experiment results proved that the proposed method can improve data utilization efficiency and thus can boost the editing performance when the train data was limited.",
        "paperId": "00039fb94e6c07a496ddef1360d2d6819fc79a0f"
    },
    {
        "title": "Few-shot relation classification based on the BERT model, hybrid attention and fusion networks",
        "firstAuthor": "Yibing Li",
        "url": null,
        "dateSubmitted": "2023-06-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "001dc098c4fac8c2b277546ace2be1dd55bea6e2"
    },
    {
        "title": "Exploring Example Selection for Few-shot Text-to-SQL Semantic Parsing",
        "firstAuthor": "Emmanouil Antonios",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We study example selection methods for few- 001 shot text-to-SQL tasks with unseen databases. 002 Annotating natural language questions with cor- 003 responding SQL queries is expensive, but we 004 can use abundant unlabeled questions to effi- 005 ciently select examples to annotate and then 006 use them to adapt models. Many previous 007 works only randomly sample a few instances 008 for few-shot learning, but this random selec- 009 tion is not sufficient to select representative and 010 informative examples that provide specific do- 011 main knowledge. We thus explore methods to 012 efficiently choose annotation examples. We 013 identify two important factors: the diversity of 014 selected instances and the dissimilarity to the 015 source training data if any. A diverse training 016 set contains more domain knowledge, while 017 dissimilar examples are selected to fill in the 018 domain gap between the source and target. We 019 show that our best example selection approach 020 substantially improves few-shot text-to-SQL 021 performance in both finetuning using T5 and 022 in-context learning with Codex: average execu- 023 tion accuracy gains of 8.7% and 4.3% over ran- 024 dom selection. Our extensive analysis demon- 025 strates the importance of the similarity metric 026 and the embedding method for example repre- 027 sentations. We also find that effective example 028 selection reduces syntax errors on the target 029 domains. Our results encourage future work to 030 further explore example selection for efficient 031 adaptation of text-to-SQL models. 1 032",
        "paperId": "002e6af90e7ae36fad7723356ad2f5dd880c2e90"
    },
    {
        "title": "Inductive Linear Probing for Few-shot Node Classification",
        "firstAuthor": "Hirthik Mathavan",
        "url": "http://arxiv.org/pdf/2306.08192",
        "dateSubmitted": "2023-06-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning has emerged as a powerful training strategy for few-shot node classification, demonstrating its effectiveness in the transductive setting. However, the existing literature predominantly focuses on transductive few-shot node classification, neglecting the widely studied inductive setting in the broader few-shot learning community. This oversight limits our comprehensive understanding of the performance of meta-learning based methods on graph data. In this work, we conduct an empirical study to highlight the limitations of current frameworks in the inductive few-shot node classification setting. Additionally, we propose a simple yet competitive baseline approach specifically tailored for inductive few-shot node classification tasks. We hope our work can provide a new path forward to better understand how the meta-learning paradigm works in the graph domain.",
        "paperId": "002fdac063820f90ea75f040a4f3a237a3b9d0d1"
    },
    {
        "title": "Masked Prompt Learning for Formal Analogies beyond Words",
        "firstAuthor": "Liyan Wang",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prompt learning, a recent thread in few-shot learning for pre-trained language models (PLMs), has been explored for completing word analogies in the extractive way. In this paper, we reformulate the analogy task as masked analogy completion task with the use of prompting to derive a generative model for analogies beyond words. We introduce a simple prompt-based fine-tuning paradigm for language modeling on answered prompts of analogies in the sequence-to-sequence framework. To convert discrete terms of analogies into linear sequences, we present a symbolic prompt template. The sequence-to-sequence model is fine-tuned to fill in the missing span of masked prompts deduced from different masking schemes on phrase analogies extracted from a small corpus. We analyze the out-of-distribution performance on sentence analogies which are unseen cases. Our experiments demonstrate that prompt-based fine-tuning with the objective of language modeling enables models to achieve significantly better performance on in-distribution cases than PLMs. Masked prompt learning with one-term masking exhibits the best out-of-distribution generalization on sentence analogies, with a difference of only 3 characters from references.",
        "paperId": "00541ef26fcdb73c4372b2f7fa9253524bc28c7c"
    },
    {
        "title": "Parasitic Resistance Effect Analysis in RRAM-based TCAM for Memory Augmented Neural Networks",
        "firstAuthor": "Yan Liao",
        "url": null,
        "dateSubmitted": "2020-05-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Memory augmented neural networks (MANNs) enable trained neural networks to rapidly learn new classes from few examples. However, content-based addressing is inefficient in conventional computer system due to the von Neumann bottleneck. Ternary content-addressable memories (TCAMs) based on resistive random access memory (RRAM) provide a promising approach to accelerate the addressing according to the Hamming distances (HDs) between the search vector and stored vectors. Generally, the HD is sensed from the discharge rate of a match line, exhibiting a linear dependence on the number of mismatched bits. However, parasitic resistance effect causes that the location of mismatched bits also determines the HD. This work proposes a compact model to evaluate the discharge rate of a match line. The impact of parasitic resistance effect in RRAM- based TCAMs is analyzed. Parasitic resistance effect is also incorporated into MANNs during few-shot learning. Remarkable accuracy losses are observed as parasitic line resistance and columns of TCAM increase. Our analyses provide valuable design guidelines of RRAM-based TCAM for future MANN systems.",
        "paperId": "005549b65c0cb362be9734bf48458f439bb35090"
    },
    {
        "title": "Few-shot Learning with Multi-scale Self-supervision",
        "firstAuthor": "Hongguang Zhang",
        "url": null,
        "dateSubmitted": "2020-01-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Learning concepts from the limited number of datapoints is a challenging task usually addressed by the so-called one- or few-shot learning. Recently, an application of second-order pooling in few-shot learning demonstrated its superior performance due to the aggregation step handling varying image resolutions without the need of modifying CNNs to fit to specific image sizes, yet capturing highly descriptive co-occurrences. However, using a single resolution per image (even if the resolution varies across a dataset) is suboptimal as the importance of image contents varies across the coarse-to-fine levels depending on the object and its class label e. g., generic objects and scenes rely on their global appearance while fine-grained objects rely more on their localized texture patterns. Multi-scale representations are popular in image deblurring, super-resolution and image recognition but they have not been investigated in few-shot learning due to its relational nature complicating the use of standard techniques. In this paper, we propose a novel multi-scale relation network based on the properties of second-order pooling to estimate image relations in few-shot setting. To optimize the model, we leverage a scale selector to re-weight scale-wise representations based on their second-order features. Furthermore, we propose to a apply self-supervised scale prediction. Specifically, we leverage an extra discriminator to predict the scale labels and the scale discrepancy between pairs of images. Our model achieves state-of-the-art results on standard few-shot learning datasets.",
        "paperId": "006ff9d09340ab6a9bda6caa5e6090c27f62ebd4"
    },
    {
        "title": "A Shallow-to-Deep Feature Fusion Network for VHR Remote Sensing Image Classification",
        "firstAuthor": "Sicong Liu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "With more detailed spatial information being represented in very-high-resolution (VHR) remote sensing images, stringent requirements are imposed on accurate image classification. Due to the diverse land objects with intraclass variation and interclass similarity, efficient and fine classification of VHR images especially in complex scenes are challenging. Even for some popular deep learning (DL) frameworks, geometric details of land objects may be lost in deep feature levels, so it is difficult to maintain the highly detailed spatial information (e.g., edges, small objects) only relying on the last high-level layer. Moreover, many of the newly developed DL methods require massive well-labeled samples, which inevitably deteriorates the model generalization ability under the few-shot learning. Therefore, in this article, a lightweight shallow-to-deep feature fusion network (SDF2N) is proposed for VHR image classification, where the traditional machine learning (ML) and DL schemes are integrated to learn rich and representative information to improve the classification accuracy. In particular, the shallow spectral\u2013spatial features are first extracted and then a novel triple-stage fusion (TSF) module is designed to learn the saliency and discriminative information at different levels for classification. The TSF module includes three feature fusion stages, that is, low-level spectral\u2013spatial feature fusion, middle-level multiscale feature fusion, and high-level multilayer feature fusion. The proposed SDF2N takes the advantage of the shallow-to-deep features, which can extract representative and complementary information from crossing layers. It is important to note that even with limited training samples, the SDF2N still can achieve satisfying classification performance. Experimental results obtained on three real VHR remote sensing datasets including two multispectral and one airborne hyperspectral images covering complex urban scenarios confirm the effectiveness of the proposed approach compared with the state-of-the-art methods.",
        "paperId": "008e123a6b7df2bd8b4e50377bf663d6094460d8"
    },
    {
        "title": "FHIST: A Benchmark for Few-shot Classification of Histological Images",
        "firstAuthor": "Fereshteh Shakeri",
        "url": "http://arxiv.org/pdf/2206.00092",
        "dateSubmitted": "2022-05-31",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning has recently attracted wide interest in image classification, but almost all the current public benchmarks are focused on natural images. The few-shot paradigm is highly relevant in medical-imaging applications due to the scarcity of labeled data, as annotations are expensive and require specialized expertise. However, in medical imaging, few-shot learning research is sparse, limited to private data sets and is at its early stage. In particular, the few-shot setting is of high interest in histology due to the diversity and fine granularity of cancer related tissue classification tasks, and the variety of data-preparation techniques. This paper introduces a highly diversified public benchmark, gathered from various public datasets, for few-shot histology data classification. We build few-shot tasks and base-training data with various tissue types, different levels of domain shifts stemming from various cancer sites, and different class-granularity levels, thereby reflecting realistic scenarios. We evaluate the performances of state-of-the-art few-shot learning methods on our benchmark, and observe that simple fine-tuning and regularization methods achieve better results than the popular meta-learning and episodic-training paradigm. Furthermore, we introduce three scenarios based on the domain shifts between the source and target histology data: near-domain, middle-domain and out-domain. Our experiments display the potential of few-shot learning in histology classification, with state-of-art few shot learning methods approaching the supervised-learning baselines in the near-domain setting. In our out-domain setting, for 5-way 5-shot, the best performing method reaches 60% accuracy. We believe that our work could help in building realistic evaluations and fair comparisons of few-shot learning methods and will further encourage research in the few-shot paradigm.",
        "paperId": "00a44bec8a36948d6f51365e6457eb2affd7a221"
    },
    {
        "title": "FS-HGR: Few-Shot Learning for Hand Gesture Recognition via Electromyography",
        "firstAuthor": "E. Rahimian",
        "url": null,
        "dateSubmitted": "2020-11-11",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This work is motivated by the recent advances in Deep Neural Networks (DNNs) and their widespread applications in human-machine interfaces. DNNs have been recently used for detecting the intended hand gesture through the processing of surface electromyogram (sEMG) signals. Objective: Although DNNs have shown superior accuracy compared to conventional methods when large amounts of data are available for training, their performance substantially decreases when data are limited. Collecting large datasets for training may be feasible in research laboratories, but it is not a practical approach for real-life applications. The main objective of this work is to design a modern DNN-based gesture detection model that relies on minimal training data while providing high accuracy. Methods: We propose the novel Few-Shot learning- Hand Gesture Recognition (FS-HGR) architecture. Few-shot learning is a variant of domain adaptation with the goal of inferring the required output based on just one or a few training observations. The proposed FS-HGR generalizes after seeing very few observations from each class by combining temporal convolutions with attention mechanisms. This allows the meta-learner to aggregate contextual information from experience and to pinpoint specific pieces of information within its available set of inputs. Data Source & Summary of Results: The performance of FS-HGR was tested on the second and fifth Ninapro databases, referred to as the DB2 and DB5, respectively. The DB2 consists of 50 gestures (rest included) from 40 healthy subjects. The Ninapro DB5 contains data from 10 healthy participants performing a total of 53 different gestures (rest included). The proposed approach for the Ninapro DB2 led to 85.94% classification accuracy on new repetitions with few-shot observation (5-way 5-shot), 81.29% accuracy on new subjects with few-shot observation (5-way 5-shot), and 73.36% accuracy on new gestures with few-shot observation (5-way 5-shot). Moreover, the proposed approach for the Ninapro DB5 led to 64.65% classification accuracy on new subjects with few-shot observation (5-way 5-shot).",
        "paperId": "00b275680fe3507df7895d25fe477f545c538e7d"
    },
    {
        "title": "CMT in TREC-COVID Round 2: Mitigating the Generalization Gaps from Web to Special Domain Search",
        "firstAuthor": "Chenyan Xiong",
        "url": null,
        "dateSubmitted": "2020-11-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Neural rankers based on deep pretrained language models (LMs) have been shown to improve many information retrieval benchmarks. However, these methods are affected by their the correlation between pretraining domain and target domain and rely on massive fine-tuning relevance labels. Directly applying pretraining methods to specific domains may result in suboptimal search quality because specific domains may have domain adaption problems, such as the COVID domain. This paper presents a search system to alleviate the special domain adaption problem. The system utilizes the domain-adaptive pretraining and few-shot learning technologies to help neural rankers mitigate the domain discrepancy and label scarcity problems. Besides, we also integrate dense retrieval to alleviate traditional sparse retrieval's vocabulary mismatch obstacle. Our system performs the best among the non-manual runs in Round 2 of the TREC-COVID task, which aims to retrieve useful information from scientific literature related to COVID-19. Our code is publicly available at this https URL.",
        "paperId": "00b36c57052f9cb2e6e39ed1106fd7a51920cec0"
    },
    {
        "title": "When Wafer Failure Pattern Classification Meets Few-shot Learning and Self-Supervised Learning",
        "firstAuthor": "Hao Geng",
        "url": null,
        "dateSubmitted": "2021-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Due to advances in semiconductor processing technologies, wafer failure pattern detection plays a key role in preventing yield loss excursion events for semiconductor manufacturing. In the recent semiconductor industry, visible surface defects are still mainly being inspected manually, which may result in inevitably erroneous classification. Many machine learning techniques-based pioneered arts in academia have been proposed to aid wafer failure pattern classification. However, few of these attach importance to unlabeled information and alleviate the data imbalanced issue. Based on these concerns, this paper designs an end-to-end wafer defect classifier that unites the few-shot learning and self-supervised learning algorithms. The aim of applying the few-shot learning paradigm is to learn representations that generalize well to the minority defect pattern classes where only a few wafer images are available, while the self-supervision information containing the intrinsic correlations of unlabeled wafer maps and their augmentations is expected to enhance the few-shot learner. The experimental results demonstrate the proposed framework has superior performance compared to cutting-edge wafer defect classification methods.",
        "paperId": "00b66bcebfedce47daf6cb4cac50bc192c804ac3"
    },
    {
        "title": "Rapid Model Architecture Adaption for Meta-Learning",
        "firstAuthor": "Yiren Zhao",
        "url": null,
        "dateSubmitted": "2021-09-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Network Architecture Search (NAS) methods have recently gathered much attention. They design networks with better performance and use a much shorter search time compared to traditional manual tuning. Despite their efficiency in model deployments, most NAS algorithms target a single task on a fixed hardware system. However, real-life few-shot learning environments often cover a great number of tasks (T ) and deployments on a wide variety of hardware platforms (H ). The combinatorial search complexity T times H creates a fundamental search efficiency challenge if one naively applies existing NAS methods to these scenarios. To overcome this issue, we show, for the first time, how to rapidly adapt model architectures to new tasks in a many-task many-hardware few-shot learning setup by integrating Model Agnostic Meta Learning (MAML) into the NAS flow. The proposed NAS method (H-Meta-NAS) is hardware-aware and performs optimisation in the MAML framework. H-Meta-NAS shows a Pareto dominance compared to a variety of NAS and manual baselines in popular few-shot learning benchmarks with various hardware platforms and constraints. In particular, on the 5-way 1-shot Mini-ImageNet classification task, the proposed method outperforms the best manual baseline by a large margin (5.21% in accuracy) using 60% less computation.",
        "paperId": "00e61a146906fedcd2f2872b1a51c88edbeb9e4c"
    },
    {
        "title": "Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders",
        "firstAuthor": "Edgar Sch\u00f6nfeld",
        "url": "https://arxiv.org/pdf/1812.01784",
        "dateSubmitted": "2018-12-05",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Many approaches in generalized zero-shot learning rely on cross-modal mapping between the image feature space and the class embedding space. As labeled images are expensive, one direction is to augment the dataset by generating either images or image features. However, the former misses fine-grained details and the latter requires learning a mapping associated with class embeddings. In this work, we take feature generation one step further and propose a model where a shared latent space of image features and class embeddings is learned by modality-specific aligned variational autoencoders. This leaves us with the required discriminative information about the image and classes in the latent features, on which we train a softmax classifier. The key to our approach is that we align the distributions learned from images and from side-information to construct latent features that contain the essential multi-modal information associated with unseen classes. We evaluate our learned latent features on several benchmark datasets, i.e. CUB, SUN, AWA1 and AWA2, and establish a new state of the art on generalized zero-shot as well as on few-shot learning. Moreover, our results on ImageNet with various zero-shot splits show that our latent features generalize well in large-scale settings.",
        "paperId": "00ffb4121cbd03d09ad4672a20eecd25703540ea"
    },
    {
        "title": "A Digital Health System for Disease Analytics",
        "firstAuthor": "C. Leung",
        "url": null,
        "dateSubmitted": "2021-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Data science, data mining and machine learning have been applied in numerous real-life applications and services including disease and healthcare analytics, such as identification and predictive analytics of coronavirus disease 2019 (COVID-19). Many of these existing works usually require large volumes of data train the classification and prediction models. However, these data (e.g., computed tomography (CT) scan images, viral/molecular test results) that can be expensive to produce and/or not easily accessible. For instance, partially due to privacy concerns and other factors, the volume of available disease data can be limited. Hence, in this paper, we present a digital health system for disease analytics. Specifically, the system make good use of autoencoder and few-shot learning to train the prediction model with only a few samples of more accessible and less expensive types of data (e.g., serology/antibody test results from blood samples), which helps to support prediction on classification of potential patients (e.g., potential COVID-19 patients). Moreover, the system also provides users (e.g., healthcare providers) with interpretable explanation of the prediction results, which increases their trust in the system. With this system, users could then focus and provide timely treatment to the true patients, thus preventing them for spreading the disease in the community. The system is helpful, especially for rural areas, when sophisticated equipment (e.g., CT scanners) may be unavailable. Evaluation results on a real-life datasets demonstrate the effectiveness of our digital health system in disease analytics, especially in classifying and explaining crucial information about patients.",
        "paperId": "0102cf6a9bc3d43ca415dc23f278152a3d9e7340"
    },
    {
        "title": "Few-Shot Pixel-Precise Document Layout Segmentation via Dynamic Instance Generation and Local Thresholding",
        "firstAuthor": "Axel De Nardin",
        "url": null,
        "dateSubmitted": "2023-07-28",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Over the years, the humanities community has increasingly requested the creation of artificial intelligence frameworks to help the study of cultural heritage. Document Layout segmentation, which aims at identifying the different structural components of a document page, is a particularly interesting task connected to this trend, specifically when it comes to handwritten texts. While there are many effective approaches to this problem, they all rely on large amounts of data for the training of the underlying models, which is rarely possible in a real-world scenario, as the process of producing the ground truth segmentation task with the required precision to the pixel level is a very time-consuming task and often requires a certain degree of domain knowledge regarding the documents at hand. For this reason, in this paper, we propose an effective few-shot learning framework for document layout segmentation relying on two novel components, namely a dynamic instance generation and a segmentation refinement module. This approach is able of achieving performances comparable to the current state of the art on the popular Diva-HisDB dataset, while relying on just a fraction of the available data.",
        "paperId": "0105ca9c7831f950148aad68eedcd7e24c2530d7"
    },
    {
        "title": "C LASS I MBALANCE IN F EW -S HOT L EARNING",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning aims to train models on a limited number of labeled samples from a support set in order to generalize to unseen samples from a query set. In the standard setup, the support set contains an equal amount of data points for each class. This assumption overlooks many practical considerations arising from the dynamic nature of the real world, such as class-imbalance. In this paper, we present a detailed study of few-shot class-imbalance along three axes: dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques. We extensively compare over 10 state-of-the-art few-shot learning methods using backbones of different depths on multiple datasets. Our analysis reveals that 1) compared to the balanced task, the performances of their class-imbalance counterparts always drop, by up to 18.0% for optimization-based methods, although feature-transfer and metric-based methods generally suffer less, 2) strategies used to mitigate imbalance in supervised learning can be adapted to the few-shot case resulting in better performances, 3) the effects of imbalance at the dataset level are less significant than the effects at the support set level. The code to reproduce the experiments is released under an open-source license.",
        "paperId": "01097e7369d858fb4f665221841630fbcaa16a50"
    },
    {
        "title": "MAD: Meta Adversarial Defense Benchmark",
        "firstAuthor": "Xiaoxu Peng",
        "url": null,
        "dateSubmitted": "2023-09-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Adversarial training (AT) is a prominent technique employed by deep learning models to defend against adversarial attacks, and to some extent, enhance model robustness. However, there are three main drawbacks of the existing AT-based defense methods: expensive computational cost, low generalization ability, and the dilemma between the original model and the defense model. To this end, we propose a novel benchmark called meta adversarial defense (MAD). The MAD benchmark consists of two MAD datasets, along with a MAD evaluation protocol. The two large-scale MAD datasets were generated through experiments using 30 kinds of attacks on MNIST and CIFAR-10 datasets. In addition, we introduce a meta-learning based adversarial training (Meta-AT) algorithm as the baseline, which features high robustness to unseen adversarial attacks through few-shot learning. Experimental results demonstrate the effectiveness of our Meta-AT algorithm compared to the state-of-the-art methods. Furthermore, the model after Meta-AT maintains a relatively high clean-samples classification accuracy (CCA). It is worth noting that Meta-AT addresses all three aforementioned limitations, leading to substantial improvements. This benchmark ultimately achieved breakthroughs in investigating the transferability of adversarial defense methods to new attacks and the ability to learn from a limited number of adversarial examples. Our codes and attacked datasets address will be available at https://github.com/PXX1110/Meta_AT.",
        "paperId": "011b2a2ad655cfb2c894aeef71278a1e4f0fb7c2"
    },
    {
        "title": "Label smoothing and task-adaptive loss function based on prototype network for few-shot learning",
        "firstAuthor": "Farong Gao",
        "url": null,
        "dateSubmitted": "2022-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "012180d1baada0c8b1fbb906ac11783188a7c223"
    },
    {
        "title": "Pareto Self-Supervised Training for Few-Shot Learning",
        "firstAuthor": "Zhengyu Chen",
        "url": "https://arxiv.org/pdf/2104.07841",
        "dateSubmitted": "2021-04-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "While few-shot learning (FSL) aims for rapid generalization to new concepts with little supervision, self-supervised learning (SSL) constructs supervisory signals directly computed from unlabeled data. Exploiting the complementarity of these two manners, few-shot auxiliary learning has recently drawn much attention to deal with few labeled data. Previous works benefit from sharing inductive bias between the main task (FSL) and auxiliary tasks (SSL), where the shared parameters of tasks are optimized by minimizing a linear combination of task losses. However, it is challenging to select a proper weight to balance tasks and reduce task conflict. To handle the problem as a whole, we propose a novel approach named as Pareto self-supervised training (PSST) for FSL. PSST explicitly decomposes the few-shot auxiliary problem into multiple constrained multi-objective subproblems with different trade-off preferences, and here a preference region in which the main task achieves the best performance is identified. Then, an effective preferred Pareto exploration is proposed to find a set of optimal solutions in such a preference region. Extensive experiments on several public benchmark datasets validate the effectiveness of our approach by achieving state-of-the-art performance.",
        "paperId": "01263f15e0724ed145f7ebd421702c883b0949b9"
    },
    {
        "title": "An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair",
        "firstAuthor": "Kai Huang",
        "url": null,
        "dateSubmitted": "2023-09-11",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The advent of large language models (LLMs) has opened up new opportunities for automated program repair (APR). In particular, some recent studies have explored how to leverage large language models of code (LLMCs) for program repair tasks and show promising results. However, most of them adopt the zero/few-shot learning paradigm for APR, which directly use LLMCs to generate the possibly correct code given its surrounding context. Though effective, the repair capabilities of LLMCs based on the fine-tuning paradigm have yet to be extensively explored. Also, it remains unknown whether LLMCs have the potential to repair more complicated bugs (e.g., multi-hunk bugs). To fill the gap, in this work, we conduct a comprehensive study on the program repair capability of LLMCs in the fine-tuning paradigm. We select 5 popular LLMCs with representative pre-training architectures, including CodeBERT, GraphCode-BERT, PLBART, CodeT5, and UniX coder. We consider 3 typical program repair scenarios (i.e., bugs, vulnerabilities, and errors) involving 3 programming languages (i.e., Java, $\\mathrm{C}/\\mathrm{C}++$, and JavaScript). Notably, we take both single-hunk and multi-hunk bugs/vulnerabilities into account. We then fine-tune them on widely-used datasets and compare them with existing state-of-the-art APR tools. We also investigate the impact of different design choices, which include code abstractions, code representations, and model evaluation metrics. Our experimental results show that LLMCs in the fine-tuning paradigm can significantly outperform previous state-of-the-art APR tools. Through in-depth analysis, we provide insights into choosing appropriate strategies to guide LLMCs for better performance. Lastly, we reveal several limitations of LLMCs for APR and make suggestions for future research on LLMC-based APR.",
        "paperId": "012a1885351785b62ab8273830197f1e759911ec"
    },
    {
        "title": "Meta-BN Net for few-shot learning",
        "firstAuthor": "Wei Gao",
        "url": null,
        "dateSubmitted": "2022-08-08",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "013007d3b3a31a469ebf1ed0f6b1d93937dc922c"
    },
    {
        "title": "Analysis and Applications of Deep Learning with Finite Samples in Full Life-Cycle Intelligence of Nuclear Power Generation",
        "firstAuthor": "Chenwei Tang",
        "url": null,
        "dateSubmitted": "2023-11-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The advent of Industry 4.0 has precipitated the incorporation of Artificial Intelligence (AI) methods within industrial contexts, aiming to realize intelligent manufacturing, operation as well as maintenance, also known as industrial intelligence. However, intricate industrial milieus, particularly those relating to energy exploration and production, frequently encompass data characterized by long-tailed class distribution, sample imbalance, and domain shift. These attributes pose noteworthy challenges to data-centric Deep Learning (DL) techniques, crucial for the realization of industrial intelligence. The present study centers on the intricate and distinctive industrial scenarios of Nuclear Power Generation (NPG), meticulously scrutinizing the application of DL techniques under the constraints of finite data samples. Initially, the paper expounds on potential employment scenarios for AI across the full life-cycle of NPG. Subsequently, we delve into an evaluative exposition of DL's advancement, grounded in the finite sample perspective. This encompasses aspects such as small-sample learning, few-shot learning, zero-shot learning, and open-set recognition, also referring to the unique data characteristics of NPG. The paper then proceeds to present two specific case studies. The first revolves around the automatic recognition of zirconium alloy metallography, while the second pertains to open-set recognition for signal diagnosis of machinery sensors. These cases, spanning the entirety of NPG's life-cycle, are accompanied by constructive outcomes and insightful deliberations. By exploring and applying DL methodologies within the constraints of finite sample availability, this paper not only furnishes a robust technical foundation but also introduces a fresh perspective toward the secure and efficient advancement and exploitation of this advanced energy source.",
        "paperId": "013721726d0204eb79ed47f06292abba5cae3d73"
    },
    {
        "title": "An Improved Prototype Network and Data Augmentation Algorithm for Few-Shot Structural Health Monitoring Using Guided Waves",
        "firstAuthor": "Fei Du",
        "url": null,
        "dateSubmitted": "2023-04-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The significance of implementing online structural health monitoring (SHM) for aerospace structures under harsh service environments cannot be overemphasized. Deep learning has demonstrated a promising and effective means to achieve accommodate such a need. However, as envisaged, the performance of deep learning-facilitated SHM heavily relies on the scale of training dataset, degrading the practicability of the approach. To address this, we propose an improved prototype network and data augmentation methods for few-shot SHM using guided waves. In the improved prototype network, the weighted Euclidean distance is used for damage classification. An attention module is established to predict the weight coefficients. The Davies\u2013Bouldin Index (DBI) is used in the loss function to better separate the embedding vectors of different classes. Time masking and frequency masking are proposed for data augmentation of guided wave signals. As bolt joints are widely used in aerospace structures, the proposed approach is experimentally validated by quantifying the degree of bolt loosening in multibolt connection structures. The results are compared against those obtained from other classical few-shot learning (FSL) methods.",
        "paperId": "0140f9cdf4c5a34d7ab2cbb065852021050ad67d"
    },
    {
        "title": "A Cross-domain Radar Emitter Recognition Method with Few-shot Learning",
        "firstAuthor": "Yixian Luo",
        "url": null,
        "dateSubmitted": "2023-08-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In many realistic scenarios, it is necessary but challenging to acquire a large number of annotated radar emitter samples for training a recognition model. This study proposes a cross-domain radar emitter recognition method with few-shot learning, which introduces model-agnostic meta-learning (MAML) to recognize radar emitter and improves it to adapt to various types of radar emitter in different domains without spending a lot of time and data to retrain the model. This method can learn an ideal initialization parameter with a few source domain samples, and then initialize with this parameter on a completely different target domain. It can obtain good generalization effect by fine-tuning with fewer samples, so as to realize cross-domain recognition of radar emitter. Simulation results show that the accuracy of the proposed method can reach more than 90% in high-noise target domains with completely different data distribution from the source domain, which shows its superiority in recognition performance and sample size compared with other radar emitter recognition methods.",
        "paperId": "0143c82e90d259532fa1455a253d680cea83ba93"
    },
    {
        "title": "A Generative Deep Recurrent Model for Exchangeable Data",
        "firstAuthor": "I. Korshunova",
        "url": null,
        "dateSubmitted": "2018-02-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We present a novel model architecture which leverages deep learning tools to perform exact Bayesian inference on sets of high dimensional, complex observations. Our model is provably exchangeable, meaning that the joint distribution over observations is invariant under permutation: this property lies at the heart of Bayesian inference. The model does not require variational approximations to train, and new samples can be generated conditional on previous samples, with cost linear in the size of the conditioning set. The advantages of our architecture are demonstrated on learning tasks requiring generalisation from short observed sequences while modelling sequence variability, such as conditional image generation, few-shot learning, set completion, and anomaly detection.",
        "paperId": "016099920f53a003a931f7919180635a601c3995"
    },
    {
        "title": "Extended Abstract: Concept Acquisition Through Meta-Learning",
        "firstAuthor": "Erin Grant",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We propose a novel method for few-shot learning of visual concepts from only a small number of positive examples. Our experiments on a large-scale visual concept dataset confirm that our gradient-based meta-learning method can learn new visual concepts strictly from positive examples, akin to how humans learn new concepts. Furthermore, we compare our method with human performance on a classic concept-learning task, showing that both are similarly impacted by the underlying taxonomic structure of the visual concept dataset.",
        "paperId": "01636bbd70cf207df8ff8eedbf3f9a4a7add6624"
    },
    {
        "title": "A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned, and Perspectives",
        "firstAuthor": "Nils Rethmeier",
        "url": "https://arxiv.org/pdf/2102.12982",
        "dateSubmitted": "2021-02-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Modern natural language processing (NLP) methods employ self-supervised pretraining objectives such as masked language modeling to boost the performance of various downstream tasks. These pretraining methods are frequently extended with recurrence, adversarial, or linguistic property masking. Recently, contrastive self-supervised training objectives have enabled successes in image representation pretraining by learning to contrast input-input pairs of augmented images as either similar or dissimilar. In NLP however, a single token augmentation can invert the meaning of a sentence during input-input contrastive learning, which led to input-output contrastive approaches that avoid the issue by instead contrasting over input-label pairs. In this primer, we summarize recent self-supervised and supervised contrastive NLP pretraining methods and describe where they are used to improve language modeling, zero to few-shot learning, pretraining data-efficiency, and specific NLP tasks. We overview key contrastive learning concepts with lessons learned from prior research and structure works by applications. Finally, we point to open challenges and future directions for contrastive NLP to encourage bringing contrastive NLP pretraining closer to recent successes in image representation pretraining.",
        "paperId": "01730636fe12bd3c15597e9439aba9b0b27ac150"
    },
    {
        "title": "Learn to Adapt to New Environments From Past Experience and Few Pilot Blocks",
        "firstAuthor": "Ouya Wang",
        "url": "https://ieeexplore.ieee.org/ielx7/6687307/10094251/09983851.pdf",
        "dateSubmitted": "2023-04-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In recent years, deep learning has been widely applied in communications and achieved remarkable performance improvement. Most of the existing works are based on data-driven deep learning, which requires a significant amount of training data for the communication model to adapt to new environments and results in huge computing resources for collecting data and retraining the model. In this paper, we will significantly reduce the required amount of training data for new environments by leveraging the learning experience from the known environments. Therefore, we introduce few-shot learning to enable the communication model to generalize to new environments, which is realized by an attention-based method. With the attention network embedded into the deep learning-based communication model, environments with different power delay profiles can be learnt together in the training process, which is called the learning experience. By exploiting the learning experience, the communication model only requires few pilot blocks to perform well in the new environment. Through an example of deep-learning-based channel estimation, we demonstrate that this novel design method achieves better performance than the existing data-driven approach designed for few-shot learning.",
        "paperId": "0195bf463b1e4359508c792b13687598e0b6b542"
    },
    {
        "title": "Few-Shot Classification of Skin Lesions from Dermoscopic Images by Meta-Learning Representative Embeddings",
        "firstAuthor": "Karthik Desingu",
        "url": "https://arxiv.org/pdf/2210.16954",
        "dateSubmitted": "2022-10-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Annotated images and ground truth for the diagnosis of rare and novel diseases are scarce. This is expected to prevail, considering the small number of affected patient population and limited clinical expertise to annotate images. Further, the frequently occurring long-tailed class distributions in skin lesion and other disease classification datasets cause conventional training approaches to lead to poor generalization due to biased class priors. Few-shot learning, and meta-learning in general, aim to overcome these issues by aiming to perform well in low data regimes. This paper focuses on improving meta-learning for the classification of dermoscopic images. Specifically, we propose a baseline supervised method on the meta-training set that allows a network to learn highly representative and generalizable feature embeddings for images, that are readily transferable to new few-shot learning tasks. We follow some of the previous work in literature that posit that a representative feature embedding can be more effective than complex meta-learning algorithms. We empirically prove the efficacy of the proposed meta-training method on dermoscopic images for learning embeddings, and show that even simple linear classifiers trained atop these representations suffice to outperform some of the usual meta-learning methods.",
        "paperId": "01a4f0a6aa4afd34e960c2c30812667f28e2a660"
    },
    {
        "title": "High-level semantic feature matters few-shot unsupervised domain adaptation",
        "firstAuthor": "Lei Yu",
        "url": "http://arxiv.org/pdf/2301.01956",
        "dateSubmitted": "2023-01-05",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In few-shot unsupervised domain adaptation (FS-UDA), most existing methods followed the few-shot learning (FSL) methods to leverage the low-level local features (learned from conventional convolutional models, e.g., ResNet) for classification. However, the goal of FS-UDA and FSL are relevant yet distinct, since FS-UDA aims to classify the samples in target domain rather than source domain. We found that the local features are insufficient to FS-UDA, which could introduce noise or bias against classification, and not be used to effectively align the domains. To address the above issues, we aim to refine the local features to be more discriminative and relevant to classification. Thus, we propose a novel task-specific semantic feature learning method (TSECS) for FS-UDA. TSECS learns high-level semantic features for image-to-class similarity measurement. Based on the high-level features, we design a cross-domain self-training strategy to leverage the few labeled samples in source domain to build the classifier in target domain. In addition, we minimize the KL divergence of the high-level feature distributions between source and target domains to shorten the distance of the samples between the two domains. Extensive experiments on DomainNet show that the proposed method significantly outperforms SOTA methods in FS-UDA by a large margin (i.e., ~10%).",
        "paperId": "01b14c1c3e2b5b4042d57f1a2be47d423c7fd68b"
    },
    {
        "title": "Multimodal Few-Shot Learning with Frozen Language Models",
        "firstAuthor": "Maria Tsimpoukelli",
        "url": null,
        "dateSubmitted": "2021-06-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "When trained at sufficient scale, auto-regressive language models exhibit the notable ability to learn a new language task after being prompted with just a few examples. Here, we present a simple, yet effective, approach for transferring this few-shot learning ability to a multimodal setting (vision and language). Using aligned image and caption data, we train a vision encoder to represent each image as a sequence of continuous embeddings, such that a pre-trained, frozen language model prompted with this prefix generates the appropriate caption. The resulting system is a multimodal few-shot learner, with the surprising ability to learn a variety of new tasks when conditioned on examples, represented as a sequence of multiple interleaved image and text embeddings. We demonstrate that it can rapidly learn words for new objects and novel visual categories, do visual question-answering with only a handful of examples, and make use of outside knowledge, by measuring a single model on a variety of established and new benchmarks.",
        "paperId": "01b5412f3d17e90e09226d7c40ad4d4468a1414d"
    },
    {
        "title": "Should I Look at the Head or the Tail? Dual-awareness Attention for Few-Shot Object Detection",
        "firstAuthor": "Tung-I Chen",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "While recent progress has significantly boosted few-shot classification (FSC) performance, few-shot object detection (FSOD) remains challenging for modern learning systems. Existing FSOD systems follow FSC approaches, neglect the problem of spatial misalignment and the risk of information entanglement, and result in low performance. Observing this, we propose a novel Dual-Awareness Attention (DAnA), which captures the pairwise spatial relationship cross the support and query images. The generated query-position-aware support features are robust to spatial misalignment and used to guide the detection network precisely. Our DAnA component is adaptable to various existing object detection networks and boosts FSOD performance by paying attention to specific semantics conditioned on the query. Experimental results demonstrate that DAnA significantly boosts (48% and 125% relatively) object detection performance on the COCO benchmark. By equipping DAnA, conventional object detection models, FasterRCNN and RetinaNet, which are not designed explicitly for few-shot learning, reach state-of-the-art performance.",
        "paperId": "01bb65416cc88506f07461abd96acb6746a09064"
    },
    {
        "title": "Device-free Location-independent Human Activity Recognition via Few-shot Learning",
        "firstAuthor": "Xue Ding",
        "url": null,
        "dateSubmitted": "2021-07-28",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Wi-Fi-based device-free human activity recognition has attracted widespread attention for its remarkable application value ranging from the Internet of Things (IoT) to Human-Computer Interaction (HCI). Empowering the wireless communication system with the ability for not only communication but also smart sensing is rather fascinating, which is known as Integrated Sensing, Computation and Communication (ISCC). Although the existing attempts have made great achievements, the generalization performance of the methods and systems is still a challenging issue. In practical applications, human activity recognition is seriously affected by the location variations, which is one of the prominent problems to be solved urgently. Previous solutions rely on sufficient data at different locations, which is labor-intensive and time-consuming. To address this concern, in this paper, we present a location-independent human activity recognition system with limited data based on Wi-Fi named WiLISensing. Specifically, inspired by few-shot learning, we propose a prototypical network-based method for activity recognition, which transfer the model well across positions with very few data samples. To fully validate the feasibility of the presented approach, extensive experiments have been conducted in a real office environment with 24 locations. The experimental results demonstrate that our method can achieve promising accuracy.",
        "paperId": "01c57fcbea9fa52549ee8bb4277ed02cefdc4a38"
    },
    {
        "title": "Learning discriminative representations to interpret image recognition models",
        "firstAuthor": "Yannis Avrithis",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "As for machine learning, computer vision has witnessed a fundamental change with the re-popularization of Deep Neural Networks (DNN) since 2012. Within a few years, DNN have been applied to various problems, such as image retrieval, object detection, instance segmentation, etc. These tasks benefit from the pre-training of networks on a large annotated corpus to obtain a superior visual representation that allows generalization and adaptation. A large number of methods are based on intermediate representation learning to better encapsulate variation in parts of the data. In fine-grained recognition for instance, part-like representations are largely used [9, 2] and are clearly outperforming other methods. Chen et al. [3] introduce Prototype-agnostic Scene Layout to model scenes. Several detection methods propose to learn deformable models based on parts [4]. Detection of object proposals can also be used to improve image representation for retrieval [5]. While many methods use additional annotation such as bounding boxes, semantic part location, etc, several methods use only imagelevel labels or no supervision at all [10, 8, 11]. An additional benefit of these part-based methods is that the learned representations can often be visualized to gain understanding about inner workings of complex models. Recently, Chen et al. [2] improved interpretability by showing the contribution of latent parts to the final classification prediction. This PhD aims at studying novel approaches to learn intermediate image representations. The objectives are to improve both recognition capabilities and interpretability of model predictions. While existing methods improve recognition and interpretability, several limitations remain: the computational cost, the inability to handle large datasets, complex optimization procedures, and the requirement for large amounts of annotation. A first objective of this PhD is to address these limitations. Specifically, simple and efficient end-to-end methods will be investigated. Unsupervised representation learning will be investigated, adapting methods from self-supervised learning [1]. These methods will then be investigated to address a number of tasks and supervision settings, such as semi-supervised learning, metric learning, open-set recognition [7], few-shot learning, instance retrieval, and object detection. A second objective is to produce better interpretation of model predictions. Several works enable interpretation, by using CAM [12] or grouping regions [6] for instance. Common part-based models already produce part-level information that can be linked to the classification prediction [2]. Following these works, improved methods will be investigated to learn intermediate representations that favour interpretability. Constraints will be considered on learned representations, so that these would be more discriminative, generative, binary, disentangled, etc. Such interpretation can help address other tasks with few or no labels and also help the user gain knowledge from data.",
        "paperId": "01cdbb4a48d46d7633e159e7526492dcb37c66aa"
    },
    {
        "title": "MICK: A Meta-Learning Framework for Few-shot Relation Classification with Little Training Data",
        "firstAuthor": "Xiaoqing Geng",
        "url": null,
        "dateSubmitted": "2020-04-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot relation classification describes a circumstance where a model is required to classify new-coming query instances after meeting only few support instances during testing. In this paper, we place a challenging restriction to conventional few-shot relation classification by additionally limiting the amount of training data. We also propose a few-shot learning framework for relation classification, which is particularly powerful when the training data is very small. In our framework, models not only strive to classify query instances, but also seek underlying knowledge within support instances to obtain better instance representations. The framework also includes a method for aggregating cross-domain knowledge into models by open-source task enrichment. Additionally, we construct a brand new dataset: the TinyRel-CM dataset, a few-shot relation classification dataset in health domain with limited training data and challenging relation classes. Experimental results demonstrate that our framework brings performance gains for most underlying classification models, and outperforms the state-of-the-art results given little training data (e.g., on TinyRel-CM dataset and FewRel-dataset [Han et al., 2018] with reduced training set), and achieves competitive results with sufficiently large training data (e.g., on FewRel dataset with full training data).",
        "paperId": "01cfa1a56af68fa1599f187e405b2db14baec18d"
    },
    {
        "title": "Learning Classifier Synthesis for Generalized Few-Shot Learning",
        "firstAuthor": "Han-Jia Ye",
        "url": null,
        "dateSubmitted": "2019-06-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Object recognition in real-world requires handling long-tailed or even open-ended data. An ideal visual system needs to reliably recognize the populated visual concepts and meanwhile efficiently learn about emerging new categories with a few training instances. Class-balanced many-shot learning and few-shot learning tackle one side of this problem, via either learning strong classifiers for populated categories or learning to learn few-shot classifiers for the tail classes. In this paper, we investigate the problem of generalized few-shot learning (GFSL) -- a model during the deployment is required to not only learn about \"tail\" categories with few shots, but simultaneously classify the \"head\" and \"tail\" categories. We propose the Classifier Synthesis Learning (CASTLE), a learning framework that learns how to synthesize calibrated few-shot classifiers in addition to the multi-class classifiers of \"head\" classes, leveraging a shared neural dictionary. CASTLE sheds light upon the inductive GFSL through optimizing one clean and effective GFSL learning objective. It demonstrates superior performances than existing GFSL algorithms and strong baselines on MiniImageNet and TieredImageNet data sets. More interestingly, it outperforms previous state-of-the-art methods when evaluated on standard few-shot learning.",
        "paperId": "01e50e14dd0670d491927155fb26e105b8c171e4"
    },
    {
        "title": "A Transductive Multi-Head Model for Cross-Domain Few-Shot Learning",
        "firstAuthor": "Jianan Jiang",
        "url": null,
        "dateSubmitted": "2020-06-08",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this paper, we present a new method, Transductive Multi-Head Few-Shot learning (TMHFS), to address the Cross-Domain Few-Shot Learning (CD-FSL) challenge. The TMHFS method extends the Meta-Confidence Transduction (MCT) and Dense Feature-Matching Networks (DFMN) method [2] by introducing a new prediction head, i.e, an instance-wise global classification network based on semantic information, after the common feature embedding network. We train the embedding network with the multiple heads, i.e,, the MCT loss, the DFMN loss and the semantic classifier loss, simultaneously in the source domain. For the few-shot learning in the target domain, we first perform fine-tuning on the embedding network with only the semantic global classifier and the support instances, and then use the MCT part to predict labels of the query set with the fine-tuned embedding network. Moreover, we further exploit data augmentation techniques during the fine-tuning and test stages to improve the prediction performance. The experimental results demonstrate that the proposed methods greatly outperform the strong baseline, fine-tuning, on four different target domains.",
        "paperId": "01e8405d5815df01bc3b9f91a9cd64045a93a569"
    },
    {
        "title": "MaskSplit: Self-supervised Meta-learning for Few-shot Semantic Segmentation",
        "firstAuthor": "Mustafa Sercan Amac",
        "url": "https://arxiv.org/pdf/2110.12207",
        "dateSubmitted": "2021-10-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Just like other few-shot learning problems, few-shot segmentation aims to minimize the need for manual annotation, which is particularly costly in segmentation tasks. Even though the few-shot setting reduces this cost for novel test classes, there is still a need to annotate the training data. To alleviate this need, we propose a self-supervised training approach for learning few-shot segmentation models. We first use unsupervised saliency estimation to obtain pseudo-masks on images. We then train a simple prototype based model over different splits of pseudo masks and augmentations of images. Our extensive experiments show that the proposed approach achieves promising results, highlighting the potential of self-supervised training. To the best of our knowledge this is the first work that addresses unsupervised few-shot segmentation problem on natural images.",
        "paperId": "01fc67cdddb64b49973fd56f7255a015c58c1691"
    },
    {
        "title": "Meta-Learning in Neural Networks: A Survey",
        "firstAuthor": "Timothy M. Hospedales",
        "url": "https://ieeexplore.ieee.org/ielx7/34/4359286/09428530.pdf",
        "dateSubmitted": "2020-04-11",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
        "paperId": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6"
    },
    {
        "title": "Boosting Few-Shot Classification with View-Learnable Contrastive Learning",
        "firstAuthor": "Xu Luo",
        "url": "https://arxiv.org/pdf/2107.09242",
        "dateSubmitted": "2021-07-05",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The goal of few-shot classification is to classify new categories with few labeled examples within each class. Nowadays, the excellent performance in handling few-shot classification problems is shown by metric-based meta-learning methods. However, it is very hard for previous methods to discriminate the fine-grained sub-categories in the embedding space without fine-grained labels. This may lead to unsatisfactory generalization to fine-grained sub-categories, and thus affects model interpretation. To tackle this problem, we introduce the contrastive loss into few-shot classification for learning latent fine-grained structure in the embedding space. Furthermore, to overcome the drawbacks of random image transformation used in current contrastive learning in producing noisy and inaccurate image pairs (i.e., views), we develop a learning-to-learn algorithm to automatically generate different views of the same image. Extensive experiments on standard few-shot learning benchmarks demonstrate the superiority of our method.",
        "paperId": "02262e27b1b31779e987bb1ca1f875ad52e6167d"
    },
    {
        "title": "Few-Shot Bearing Anomaly Detection Based on Model-Agnostic Meta-Learning",
        "firstAuthor": "S. Zhang",
        "url": null,
        "dateSubmitted": "2020-07-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The rapid development of artificial intelligence and deep learning technology has provided many opportunities to further enhance the safety, stability, and accuracy of industrial Cyber-Physical Systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing anomaly detection up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this paper, we propose a few-shot learning approach for bearing anomaly detection based on model-agnostic meta-learning (MAML), which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed method achieves an overall accuracy up to 25% higher than a Siamese-network-based benchmark study. Finally, the robustness of the generalization capability of MAML is further validated by case studies of applying the algorithm to identify real bearing damages using data from artificial damages.",
        "paperId": "023ebf16d65ebd482bb339d12549be90a818b3f7"
    },
    {
        "title": "Runoff Prediction in a Data Scarce Region Based on Few-Shot Learning",
        "firstAuthor": "Minghong Yang",
        "url": null,
        "dateSubmitted": "2022-07-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this study, we propose a new method (metric-LSTM fusion model) for runoff prediction in data scarce regions by combining few-shot learning and deep learning. To validate the effectiveness of the proposed model, taking the upper Yellow River basin as a case study, we compare its performance with that of four state-of-the-art data driven models (LSTM, SVR, RF, ANN) on monthly runoff prediction during 1970 to 1995. Results indicate that the proposed model performs well with the best NSE (Nash-Sutcliffe model efficiency coefficient) of 0.83, outperforming all the comparative models. Furthermore, the less the data used for model training, the more obvious the advance of the proposed model. Findings imply that the proposed model based on few-shot learning can provide an effective tool for runoff prediction in data-scarce regions.",
        "paperId": "0242b03ec5fee961a32621def7dc7df720b9708d"
    },
    {
        "title": "Generalized Reinforcement Meta Learning for Few-Shot Optimization",
        "firstAuthor": "R. Anantha",
        "url": null,
        "dateSubmitted": "2020-05-04",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We present a generic and flexible Reinforcement Learning (RL) based meta-learning framework for the problem of few-shot learning. During training, it learns the best optimization algorithm to produce a learner (ranker/classifier, etc) by exploiting stable patterns in loss surfaces. Our method implicitly estimates the gradients of a scaled loss function while retaining the general properties intact for parameter updates. Besides providing improved performance on few-shot tasks, our framework could be easily extended to do network architecture search. We further propose a novel dual encoder, affinity-score based decoder topology that achieves additional improvements to performance. Experiments on an internal dataset, MQ2007, and AwA2 show our approach outperforms existing alternative approaches by 21%, 8%, and 4% respectively on accuracy and NDCG metrics. On Mini-ImageNet dataset our approach achieves comparable results with Prototypical Networks. Empirical evaluations demonstrate that our approach provides a unified and effective framework.",
        "paperId": "02493726596c85a85cd3f1b1840d40ae4dfe171c"
    },
    {
        "title": "Semi-Supervised Few-Shot Learning from A Dependency-Discriminant Perspective",
        "firstAuthor": "Zejiang Hou",
        "url": null,
        "dateSubmitted": "2022-06-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We study the few-shot learning (FSL) problem, where a model learns to recognize new objects with extremely few labeled training data per category. Most of previous FSL approaches resort to the meta-learning paradigm, where the model accumulates inductive bias through learning from many training tasks, in order to solve new unseen few-shot tasks. In contrast, we propose a simple semi-supervised FSL approach to exploit unlabeled data accompanying the few-shot task to improve FSL performance. More exactly, to train a classifier, we propose a Dependency Maximization loss based on the Hilbert-Schmidt norm of the cross-covariance operator, which maximizes the statistical dependency between the embedded feature of the unlabeled data and their label predictions, together with the supervised loss over the support set. The obtained classifier is used to infer the pseudo-labels of the unlabeled data. Furthermore, we propose an Instance Discriminant Analysis to evaluate the credibility of the pseudo-labeled examples and select the faithful ones into an augmented support set, which is used to retrain the classifier. We iterate the process until the pseudo-labels of the unlabeled data becomes stable. Through extensive experiments on four widely used few-shot classification benchmarks, including mini-ImageNet, tiered-ImageNet, CUB, and CIFARFS, the proposed method outperforms previous state-of-the-art FSL methods.",
        "paperId": "02619d22acfd7172edd9f63e170953891a6023e0"
    },
    {
        "title": "Towards Fast Adaptation of Neural Architectures with Meta Learning",
        "firstAuthor": "Dongze Lian",
        "url": null,
        "dateSubmitted": "2020-04-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recently, Neural Architecture Search (NAS) has been successfully applied to multiple artificial intelligence areas and shows better performance compared with hand-designed networks. However, the existing NAS methods only target a specific task. Most of them usually do well in searching an architecture for single task but are troublesome for multiple datasets or multiple tasks. Generally, the architecture for a new task is either searched from scratch, which is neither efficient nor flexible enough for practical application scenarios, or borrowed from the ones searched on other tasks, which might be not optimal. In order to tackle the transferability of NAS and conduct fast adaptation of neural architectures, we propose a novel Transferable Neural Architecture Search method based on meta-learning in this paper, which is termed as T-NAS. T-NAS learns a meta-architecture that is able to adapt to a new task quickly through a few gradient steps, which makes the transferred architecture suitable for the specific task. Extensive experiments show that T-NAS achieves state-of-the-art performance in few-shot learning and comparable performance in supervised learning but with 50x less searching cost, which demonstrates the effectiveness of our method.",
        "paperId": "027d05ab0c9e3ad91103eec2fe6ee2d2951a1afa"
    },
    {
        "title": "Few-Shot Learning via Learning the Representation, Provably",
        "firstAuthor": "S. Du",
        "url": null,
        "dateSubmitted": "2020-02-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This paper studies few-shot learning via representation learning, where one uses $T$ source tasks with $n_1$ data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only $n_2 (\\ll n_1)$ data. Specifically, we focus on the setting where there exists a good \\emph{common representation} between source and target, and our goal is to understand how much of a sample size reduction is possible. First, we study the setting where this common representation is low-dimensional and provide a fast rate of $O\\left(\\frac{\\mathcal{C}\\left(\\Phi\\right)}{n_1T} + \\frac{k}{n_2}\\right)$; here, $\\Phi$ is the representation function class, $\\mathcal{C}\\left(\\Phi\\right)$ is its complexity measure, and $k$ is the dimension of the representation. When specialized to linear representation functions, this rate becomes $O\\left(\\frac{dk}{n_1T} + \\frac{k}{n_2}\\right)$ where $d (\\gg k)$ is the ambient input dimension, which is a substantial improvement over the rate without using representation learning, i.e. over the rate of $O\\left(\\frac{d}{n_2}\\right)$. Second, we consider the setting where the common representation may be high-dimensional but is capacity-constrained (say in norm); here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural network learning. Our results demonstrate representation learning can fully utilize all $n_1T$ samples from source tasks.",
        "paperId": "02841af780570666389643f2815460a10d9ae286"
    },
    {
        "title": "B-Pet: The PET Model with Parameter-Efficient Learning",
        "firstAuthor": "Qi Zheng",
        "url": null,
        "dateSubmitted": "2023-08-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In recent years, under the trend of training models in big data, Few-shot learning (FSL) which aims to learn models to solve problems with a few samples has also achieved good results on many data sets. In fact, acquiring high-quality training samples is expensive in many aspects, but FSL can save the overhead costs. Among FSL models, the PET model combines semi-supervised learning, prompt learning and knowledge distillation based on the pre-training language model. However, in fine-turning the PET model has the disadvantages that consumes a lot of resources and time and requires heavy costs of storage for model preservation. Therefore, this paper proposes the B-pet model, which freezes most of the training parameters and only trains bias parameters during fine-turning process, significantly reducing the storage consumption of the model for downstream tasks. We used six data sets with $\\vert \\tau \\vert=\\mathbf{10},\\ \\mathbf{50},\\ \\mathbf{100}$ and three different data training models respectively. The results show that four data sets on the B-pet model performed better than original PET model training. It is obvious that in the memory-constrained environment deployment, multitasking fine-tunes models have practical value. It also proved that most semi-supervised models with fixed parameters are realizable.",
        "paperId": "029b5d9dd6311850720eab9246e29545d63575e8"
    },
    {
        "title": "Physarum Powered Differentiable Linear Programming Layers and Applications",
        "firstAuthor": "Zihang Meng",
        "url": "https://ojs.aaai.org/index.php/AAAI/article/download/17081/16888",
        "dateSubmitted": "2020-04-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Consider a learning algorithm, which involves an internal call to an optimization routine such as a generalized eigenvalue problem, a cone programming problem or even sorting. Integrating such a method as a layer(s) within a trainable deep neural network (DNN) in an efficient and numerically stable way is not straightforward - for instance, only recently, strategies have emerged for eigendecomposition and differentiable sorting. We propose an efficient and differentiable solver for general linear programming problems which can be used in a plug and play manner within DNNs as a layer. Our development is inspired by a fascinating but not widely used link between dynamics of slime mold (physarum) and optimization schemes such as steepest descent. We describe our development and show the use of our solver in a video segmentation task and meta-learning for few-shot learning. We review the existing results and provide a technical analysis describing its applicability for our use cases. Our solver performs comparably with a customized projected gradient descent method on the first task and outperforms the differentiable CVXPY-SCS solver on the second task. Experiments show that our solver converges quickly without the need for a feasible initial point. Our proposal is easy to implement and can easily serve as layers whenever a learning procedure needs a fast approximate solution to a LP, within a larger network.",
        "paperId": "02ae998667e48ccd0b110dfe86f7ec7c3187356d"
    },
    {
        "title": "A Few-shot Learning Method Based on Bidirectional Encoder Representation from Transformers for Relation Extraction",
        "firstAuthor": "Yifei Gao",
        "url": null,
        "dateSubmitted": "2021-08-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Relation extraction is one of the fundamental subtasks of the information extraction. The purpose is to determine the implicit relation between two entities in a sentence. Therefore, Convolutional Neural Networks and Feature Attention-based Prototypical Networks (CNN-Proto-FATT), a typical few-shot learning method, is proposed and achieve competitive performance. However, convolutional neural networks suffer from the insufficient instances of relation in real scenes, leading to undesirable results. To extract long-distance features more comprehensively, the pre-trained model Bidirectional Encoder Representation from Transformers (BERT) is incorporated into CNN-Proto-FATT. In this model, named Bidirectional Encoder Representation from Transformers and Feature Attention-based Prototypical Networks (BERT-Proto-FATT), the multi-head attention helps the network extract semantic features cross long- and short-distance to enhance the encoded representations. Experimental results indicate that BERT-Proto-FATT demonstrates significant improvements on the FewRel dataset.",
        "paperId": "02af21d2b4a898e3dc8dcdec4fe6c6e6938fa506"
    },
    {
        "title": "Knowledge Guided Metric Learning for Few-Shot Text Classification",
        "firstAuthor": "Dianbo Sui",
        "url": "https://aclanthology.org/2021.naacl-main.261.pdf",
        "dateSubmitted": "2020-04-04",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Humans can distinguish new categories very efficiently with few examples, largely due to the fact that human beings can leverage knowledge obtained from relevant tasks. However, deep learning based text classification model tends to struggle to achieve satisfactory performance when labeled data are scarce. Inspired by human intelligence, we propose to introduce external knowledge into few-shot learning to imitate human knowledge. A novel parameter generator network is investigated to this end, which is able to use the external knowledge to generate different metrics for different tasks. Armed with this network, similar tasks can use similar metrics while different tasks use different metrics. Through experiments, we demonstrate that our method outperforms the SoTA few-shot text classification models.",
        "paperId": "02cce36fc58fd9a8682877435689eeef5c1a29fa"
    },
    {
        "title": "Information Diffusion for Few-Shot Learning in Robotic Residual Errors Compensation",
        "firstAuthor": "Zeyuan Yang",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "02e0b76b604bf8a6a335b3129d2bd7d4bf48a3f0"
    },
    {
        "title": "Few-Shot Learning with Visual Distribution Calibration and Cross-Modal Distribution Alignment",
        "firstAuthor": "Runqi Wang",
        "url": "https://arxiv.org/pdf/2305.11439",
        "dateSubmitted": "2023-05-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Pre-trained vision-language models have inspired much research on few-shot learning. However, with only a few training images, there exist two crucial problems: (1) the visual feature distributions are easily distracted by class-irrelevant information in images, and (2) the alignment between the visual and language feature distributions is difficult. To deal with the distraction problem, we propose a Selective Attack module, which consists of trainable adapters that generate spatial attention maps of images to guide the attacks on class-irrelevant image areas. By messing up these areas, the critical features are captured and the visual distributions of image features are calibrated. To better align the visual and language feature distributions that describe the same object class, we propose a cross-modal distribution alignment module, in which we introduce a vision-language prototype for each class to align the distributions, and adopt the Earth Mover's Distance (EMD) to optimize the prototypes. For efficient computation, the upper bound of EMD is derived. In addition, we propose an augmentation strategy to increase the diversity of the images and the text prompts, which can reduce overfitting to the few-shot training images. Extensive experiments on 11 datasets demonstrate that our method consistently outperforms prior arts in few-shot learning. The implementation code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/SADA.",
        "paperId": "02e376e249166b1981cb1bafa79e45ac26a41576"
    },
    {
        "title": "Cross-Domain Few-Shot Learning Approach for Lithium-Ion Battery Surface Defects Classification Using an Improved Siamese Network",
        "firstAuthor": "Ke Wu",
        "url": null,
        "dateSubmitted": "2022-06-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "It is difficult to detect the surface defects of a lithium battery with an aluminum/steel shell. The reflectivity, lack of 3D information on the battery surface, and the shortage of many datasets make the 2D detection method hard to apply in this field. In this paper, a cross-domain few-shot learning (FSL) approach for lithium-ion battery defect classification using an improved siamese network (BSR-SNet) is proposed. To obtain the critical 3D surface of the lithium-ion battery, a multiexposure-based structured light method is utilized. Then, the heights of the 3D cloud points are transferred to grayscale information and are saved as 8-bit 2D images. For the FSL task, the DAGM 2007 datasets are used as the source domain to pre-train the improved siamese model. To avoid negative mitigation in the target domain, batch spectral regularization (BSR) is added as a penalizer in the loss function. The accuracies of the experimental results are 93.3% for 10-shot batteries and 91.0% for 5-shot batteries, which means that our method can be used to classify the surface defects of lithium batteries well.",
        "paperId": "02ef204ce53f02ae828061799e0b3e96849b339e"
    },
    {
        "title": "Few-shot learning approach for 3D defect detection in lithium battery",
        "firstAuthor": "Ke Wu",
        "url": "https://iopscience.iop.org/article/10.1088/1742-6596/1884/1/012024/pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Detecting the surface defects in a lithium battery with an aluminium/steel shell is a difficult task. The effect of reflectivity, the limitation of acquiring the 3D information, and the shortage of massive amounts of labelled training data make the 2D detection method hard to classify surface defects. In this work, a few-shot learning approach for 3D defect detection in lithium batteries is proposed. The multi-exposure-based structured light method is introduced to reconstruct the 3D shape of the lithium battery. Then, the anomaly part of the 3D point cloud is transferred into 2D images by the height-gray transformation. The MiniImageNet datasets are used as the source domain to pretrain the Cross-Domain Few-Shot Learning (CD-FSL) model. The accuracy in our experiment result is 97.17%, which means that our method can be used to classify the surface defects of the lithium battery.",
        "paperId": "02feed51980d5631ae18ab4cf595a2be77b81974"
    },
    {
        "title": "Multi-task Learning for Cross-Lingual Sentiment Analysis",
        "firstAuthor": "Gaurish Thakkar",
        "url": "http://arxiv.org/pdf/2212.07160",
        "dateSubmitted": "2022-12-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This paper presents a cross-lingual sentiment analysis of news articles using zero-shot and few-shot learning. The study aims to classify the Croatian news articles with positive, negative, and neutral sentiments using the Slovene dataset. The system is based on a trilingual BERT-based model trained in three languages: English, Slovene, Croatian. The paper analyses different setups using datasets in two languages and proposes a simple multi-task model to perform sentiment classification. The evaluation is performed using the few-shot and zero-shot scenarios in single-task and multi-task experiments for Croatian and Slovene.",
        "paperId": "0319dc6f17f26a5c036782c0553c1b2ff4d81def"
    },
    {
        "title": "Reusability Report: Few-shot learning creates predictive models of drug response that translate from high-throughput screens to individual patients",
        "firstAuthor": "Emily So",
        "url": "https://www.biorxiv.org/content/biorxiv/early/2023/07/07/2023.07.06.547938.full.pdf",
        "dateSubmitted": "2023-07-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Machine learning (ML) and artificial intelligence (AI) methods are increasingly used in personalized medicine, including precision oncology. Ma et al. (Nature Cancer 2021) developed a new method c alled \u201cTransfer of Cell Line Response Prediction\u201d (TCRP) to train predictors of drug response in cancer cell lines and optimize their performance in higher complex cancer model systems via few-shot learning. TCRP was presented as a successful modeling approach in multiple case studies. Given the importance of this approach to assist clinicians in their treatment decision process, we sought to reproduce independently the authors\u2019 findings and improve the reusability of TCRP in new case studies, including validation in clinical trial datasets, a high bar for drug response prediction. Our results support the superiority of TCRP over established statistical and machine learning approaches in preclinical and clinical settings. We developed new resources to increase the reusability of the TCRP model for future improvements and validation studies.",
        "paperId": "0340f58b0d76e45b39c016931d8c0cfaa454932a"
    },
    {
        "title": "Class-Discriminative Feature Embedding For Meta-Learning based Few-Shot Classification",
        "firstAuthor": "Alireza Rahimpour",
        "url": null,
        "dateSubmitted": "2020-03-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Although deep learning-based approaches have been very effective in solving problems with plenty of labeled data, they suffer in tackling problems for which labeled data are scarce. In few-shot classification, the objective is to train a classifier from only a handful of labeled examples in a support set. In this paper, we propose a few-shot learning framework based on structured margin loss which takes into account the global structure of the support set in order to generate a highly discriminative feature space where the features from distinct classes are well separated in clusters. Moreover, in our meta-learning-based framework, we propose a context-aware query embedding encoder for incorporating support set context into query embedding and generating more discriminative and task-dependent query embeddings. The task-dependent features help the metalearner to learn a distribution over tasks more effectively. Extensive experiments based on few-shot, zero-shot and semi-supervised learning on three benchmarks show the advantages of the proposed model compared to state-of-the- art.",
        "paperId": "034cfd74bf49688decde034c81fa3f8b71b5b424"
    },
    {
        "title": "Few-shot Learning for Slot Tagging with Attentive Relational Network",
        "firstAuthor": "Cennet Oguz",
        "url": "https://aclanthology.org/2021.eacl-main.134.pdf",
        "dateSubmitted": "2021-03-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Metric-based learning is a well-known family of methods for few-shot learning, especially in computer vision. Recently, they have been used in many natural language processing applications but not for slot tagging. In this paper, we explore metric-based learning methods in the slot tagging task and propose a novel metric-based learning architecture - Attentive Relational Network. Our proposed method extends relation networks, making them more suitable for natural language processing applications in general, by leveraging pretrained contextual embeddings such as ELMO and BERT and by using attention mechanism. The results on SNIPS data show that our proposed method outperforms other state of the art metric-based learning methods.",
        "paperId": "0364102c8805bd1889467b5a1aaa6916764ffa0e"
    },
    {
        "title": "Meta-Learned Confidence for Few-shot Learning",
        "firstAuthor": "Seong Min Kye",
        "url": null,
        "dateSubmitted": "2020-02-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Transductive inference is an effective means of tackling the data deficiency problem in few-shot learning settings. A popular transductive inference technique for few-shot metric-based approaches, is to update the prototype of each class with the mean of the most confident query examples, or confidence-weighted average of all the query samples. However, a caveat here is that the model confidence may be unreliable, which may lead to incorrect predictions. To tackle this issue, we propose to meta-learn the confidence for each query sample, to assign optimal weights to unlabeled queries such that they improve the model's transductive inference performance on unseen tasks. We achieve this by meta-learning an input-adaptive distance metric over a task distribution under various model and data perturbations, which will enforce consistency on the model predictions under diverse uncertainties for unseen tasks. Moreover, we additionally suggest a regularization which explicitly enforces the consistency on the predictions across the different dimensions of a high-dimensional embedding vector. We validate our few-shot learning model with meta-learned confidence on four benchmark datasets, on which it largely outperforms strong recent baselines and obtains new state-of-the-art results. Further application on semi-supervised few-shot learning tasks also yields significant performance improvements over the baselines. The source code of our algorithm is available at this https URL.",
        "paperId": "036da0dc917fc9f02a081d24ad7d4babe8ce06fb"
    },
    {
        "title": "Zero- and Few-Shot NLP with Pretrained Language Models",
        "firstAuthor": "Iz Beltagy",
        "url": "https://aclanthology.org/2022.acl-tutorials.6.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The ability to efficiently learn from little-to-no data is critical to applying NLP to tasks where data collection is costly or otherwise difficult. This is a challenging setting both academically and practically\u2014particularly because training neutral models typically require large amount of labeled data. More recently, advances in pretraining on unlabelled data have brought up the potential of better zero-shot or few-shot learning (Devlin et al., 2019; Brown et al., 2020). In particular, over the past year, a great deal of research has been conducted to better learn from limited data using large-scale language models. In this tutorial, we aim at bringing interested NLP researchers up to speed about the recent and ongoing techniques for zero- and few-shot learning with pretrained language models. Additionally, our goal is to reveal new research opportunities to the audience, which will hopefully bring us closer to address existing challenges in this domain.",
        "paperId": "037110f8e99488f9b8f6e962da0a912d927695e5"
    },
    {
        "title": "Towards Answering Open-ended Ethical Quandary Questions",
        "firstAuthor": "Yejin Bang",
        "url": null,
        "dateSubmitted": "2022-05-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Considerable advancements have been made in various NLP tasks based on the impressive power of large language models (LLMs) and many NLP applications are deployed in our daily lives. In this work, we challenge the capability of LLMs with the new task of Ethical Quandary Generative Question Answering. Ethical quandary questions are more challenging to address because multiple conflicting answers may exist to a single quandary. We explore the current capability of LLMs in providing an answer with a deliberative exchange of different perspectives to an ethical quandary, in the approach of Socratic philosophy, instead of providing a closed answer like an oracle. We propose a model that searches for different ethical principles applicable to the ethical quandary and generates an answer conditioned on the chosen principles through prompt-based few-shot learning. We also discuss the remaining challenges and ethical issues involved in this task and suggest the direction toward developing responsible NLP systems by incorporating human values explicitly.",
        "paperId": "0376b7ff6bd5fd3df5dc766cb24f9ca8736ea34e"
    },
    {
        "title": "Few-shot Named Entity Recognition: Definition, Taxonomy and Research Directions",
        "firstAuthor": "V. Moscato",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3609483",
        "dateSubmitted": "2023-07-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent years have seen an exponential growth (+98% in 2022 w.r.t. the previous year) of the number of research articles in the few-shot learning field, which aims at training machine learning models with extremely limited available data. The research interest toward few-shot learning systems for Named Entity Recognition (NER) is thus at the same time increasing. NER consists in identifying mentions of pre-defined entities from unstructured text, and serves as a fundamental step in many downstream tasks, such as the construction of Knowledge Graphs, or Question Answering. The need for a NER system able to be trained with few-annotated examples comes in all its urgency in domains where the annotation process requires time, knowledge and expertise (e.g., healthcare, finance, legal), and in low-resource languages. In this survey, starting from a clear definition and description of the few-shot NER (FS-NER) problem, we take stock of the current state-of-the-art and propose a taxonomy which divides algorithms in two macro-categories according to the underlying mechanisms: model-centric and data-centric. For each category, we line-up works as a story to show how the field is moving toward new research directions. Eventually, techniques, limitations, and key aspects are deeply analyzed to facilitate future studies.",
        "paperId": "0379cfb16c1678bde9b889bb1c0ca39db2cb564a"
    },
    {
        "title": "Easter2.0: Improving convolutional models for handwritten text recognition",
        "firstAuthor": "Kartik Chaudhary",
        "url": "https://arxiv.org/pdf/2205.14879",
        "dateSubmitted": "2022-05-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Convolutional Neural Networks (CNN) have shown promising results for the task of Handwritten Text Recognition (HTR) but they still fall behind Recurrent Neural Networks (RNNs)/Transformer based models in terms of performance. In this paper, we propose a CNN based architecture that bridges this gap. Our work, Easter2.0, is composed of multiple layers of 1D Convolution, Batch Normalization, ReLU, Dropout, Dense Residual connection, Squeeze-and-Excitation module and make use of Connectionist Temporal Classification (CTC) loss. In addition to the Easter2.0 architecture, we propose a simple and effective data augmentation technique 'Tiling and Corruption (TACO)' relevant for the task of HTR/OCR. Our work achieves state-of-the-art results on IAM handwriting database when trained using only publicly available training data. In our experiments, we also present the impact of TACO augmentations and Squeeze-and-Excitation (SE) on text recognition accuracy. We further show that Easter2.0 is suitable for few-shot learning tasks and outperforms current best methods including Transformers when trained on limited amount of annotated data. Code and model is available at: https://github.com/kartikgill/Easter2",
        "paperId": "03b1c765501bc6fd58561688748641181c9a7a9d"
    },
    {
        "title": "Meta-Learning for Multi-Label Few-Shot Classification",
        "firstAuthor": "Christian Simon",
        "url": "https://arxiv.org/pdf/2110.13494",
        "dateSubmitted": "2021-10-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Even with the luxury of having abundant data, multi-label classification is widely known to be a challenging task to address. This work targets the problem of multi-label meta-learning, where a model learns to predict multiple labels within a query (e.g., an image) by just observing a few supporting examples. In doing so, we first propose a benchmark for Few-Shot Learning (FSL) with multiple labels per sample. Next, we discuss and extend several solutions specifically designed to address the conventional and single-label FSL, to work in the multi-label regime. Lastly, we introduce a neural module to estimate the label count of a given sample by exploiting the relational inference. We will show empirically the benefit of the label count module, the label propagation algorithm, and the extensions of conventional FSL methods on three challenging datasets, namely MS-COCO, iMaterialist, and Open MIC. Overall, our thorough experiments suggest that the proposed label-propagation algorithm in conjunction with the neural label count module (NLC) shall be considered as the method of choice.",
        "paperId": "03b97dde424510132470152a6e5fab70ce87b496"
    },
    {
        "title": "Additive Angular Margin for Few Shot Learning to Classify Clinical Endoscopy Images",
        "firstAuthor": "Sharib Ali",
        "url": "https://arxiv.org/pdf/2003.10033",
        "dateSubmitted": "2020-03-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "03c6691759a7a4ee7f6021be12cf9e1c448eb4d8"
    },
    {
        "title": "COVID-19 Surveillance through Twitter using Self-Supervised and Few Shot Learning",
        "firstAuthor": "Brandon Lwowski",
        "url": "https://aclanthology.org/2020.nlpcovid19-2.9.pdf",
        "dateSubmitted": "2020-08-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Public health surveillance and tracking virus via social media can be a useful digital tool for contact tracing and preventing the spread of the virus. Nowadays, large volumes of COVID-19 tweets can quickly be processed in real-time to offer information to researchers. Nonetheless, due to the absence of labeled data for COVID-19, the preliminary supervised classifier or semi-supervised self-labeled methods will not handle non-spherical data with adequate accuracy. With the seasonal influenza and novel Coronavirus having many similar symptoms, we propose using few shot learning to fine-tune a semi-supervised model built on unlabeled COVID-19 and previously labeled influenza dataset that can provide insights into COVID-19 that have not been investigated. The experimental results show the efficacy of the proposed model with an accuracy of 86%, identification of Covid-19 related discussion using recently collected tweets.",
        "paperId": "03c7326fe9a1e1160e5ccdf72ef389bfef3da942"
    },
    {
        "title": "AutoProtoNet: Interpretability for Prototypical Networks",
        "firstAuthor": "Pedro Sandoval Segura",
        "url": "http://arxiv.org/pdf/2204.00929",
        "dateSubmitted": "2022-04-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In meta-learning approaches, it is difficult for a practitioner to make sense of what kind of representations the model employs. Without this ability, it can be difficult to both understand what the model knows as well as to make meaningful corrections. To address these challenges, we introduce AutoProtoNet, which builds interpretability into Prototypical Networks by training an embedding space suitable for reconstructing inputs, while remaining convenient for few-shot learning. We demonstrate how points in this embedding space can be visualized and used to understand class representations. We also devise a prototype refinement method, which allows a human to debug inadequate classification parameters. We use this debugging technique on a custom classification task and find that it leads to accuracy improvements on a validation set consisting of in-the-wild images. We advocate for interpretability in meta-learning approaches and show that there are interactive ways for a human to enhance meta-learning algorithms.",
        "paperId": "03d2c7a30554f34ef3613d743fd14af68d4782a9"
    },
    {
        "title": "Local Stochastic Bilevel Optimization with Momentum-Based Variance Reduction",
        "firstAuthor": "Junyi Li",
        "url": "http://arxiv.org/pdf/2205.01608",
        "dateSubmitted": "2022-05-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Bilevel Optimization has witnessed notable progress recently with new emerging efficient algorithms and has been applied to many machine learning tasks such as data cleaning, few-shot learning, and neural architecture search. However, little attention has been paid to solve the bilevel problems under distributed setting. Federated learning (FL) is an emerging paradigm which solves machine learning tasks over distributed-located data. FL problems are challenging to solve due to the heterogeneity and communication bottleneck. However, it is unclear how these challenges will affect the convergence of Bilevel Optimization algorithms. In this paper, we study Federated Bilevel Optimization problems. Specifically, we first propose the FedBiO, a deterministic gradient-based algorithm and we show it requires $O(\\epsilon^{-2})$ number of iterations to reach an $\\epsilon$-stationary point. Then we propose FedBiOAcc to accelerate FedBiO with the momentum-based variance-reduction technique under the stochastic scenario. We show FedBiOAcc has complexity of $O(\\epsilon^{-1.5})$. Finally, we validate our proposed algorithms via the important Fair Federated Learning task. More specifically, we define a bilevel-based group fair FL objective. Our algorithms show superior performances compared to other baselines in numerical experiments.",
        "paperId": "03d6c7cd4e118d278ea692e5eb95ea645ea1d04d"
    },
    {
        "title": "Intriguing Properties of Vision Transformers",
        "firstAuthor": "Muzammal Naseer",
        "url": null,
        "dateSubmitted": "2021-05-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Vision transformers (ViT) have demonstrated impressive performance across various machine vision problems. These models are based on multi-head self-attention mechanisms that can flexibly attend to a sequence of image patches to encode contextual cues. An important question is how such flexibility in attending image-wide context conditioned on a given patch can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a) Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1 accuracy on ImageNet even after randomly occluding 80% of the image content. (b) The robust performance to occlusions is not due to a bias towards local textures, and ViTs are significantly less biased towards textures compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c) Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d) Off-the-shelf features from a single ViT model can be combined to create a feature ensemble, leading to high accuracy rates across a range of classification datasets in both traditional and few-shot learning paradigms. We show effective features of ViTs are due to flexible and dynamic receptive fields possible via the self-attention mechanism.",
        "paperId": "03db529f0bfae6d0b64b0feef565196327fe8d50"
    },
    {
        "title": "Few-Shot Video Classification via Temporal Alignment",
        "firstAuthor": "Kaidi Cao",
        "url": "https://arxiv.org/pdf/1906.11415",
        "dateSubmitted": "2019-06-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Difficulty in collecting and annotating large-scale video data raises a growing interest in learning models which can recognize novel classes with only a few training examples. In this paper, we propose the Ordered Temporal Alignment Module (OTAM), a novel few-shot learning framework that can learn to classify a previously unseen video. While most previous work neglects long-term temporal ordering information, our proposed model explicitly leverages the temporal ordering information in video data through ordered temporal alignment. This leads to strong data-efficiency for few-shot learning. In concrete, our proposed pipeline learns a deep distance measurement of the query video with respect to novel class proxies over its alignment path. We adopt an episode-based training scheme and directly optimize the few-shot learning objective. We evaluate OTAM on two challenging real-world datasets, Kinetics and Something-Something-V2, and show that our model leads to significant improvement of few-shot video classification over a wide range of competitive baselines and outperforms state-of-the-art benchmarks by a large margin.",
        "paperId": "03f33ad3f994e03b87ee2d1f711087c9efcd8cf6"
    },
    {
        "title": "Mitigating long tail effect in recommendations using few shot learning technique",
        "firstAuthor": "R. Sreepada",
        "url": null,
        "dateSubmitted": "2020-02-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "03fdd5aa02bc7dbd503fbfbbdcce949eff849c87"
    },
    {
        "title": "Triplet Siamese Network Model for Lithium-ion Battery Defects Classification Using Few-shot Learning Approach",
        "firstAuthor": "Ke Wu",
        "url": null,
        "dateSubmitted": "2021-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this paper, we propose a triplet siamese model for lithium-ion battery defects classification. It is a difficult task to detect the surface defects of lithium-ion batteries with stainless steel surface. The lack of three-dimensional information and the lack of marker datasets due to reflections prevent two-dimensional computer vision detection methods from meeting classification needs. In this work, the multiple exposure structured light method is utilized to obtain the three-dimensional shape of a lithium-ion battery with a stainless steel surface. The defect point cloud with three-dimensional information is obtained by this method, and then the 3D information of the defect point cloud is converted into grayscale information, and the grayscale image is used as the target domain data of the triplet siamese network. The public dataset MiniImageNet is utilized as the training data of the triplet siamese network model. The accuracies of the experimental results are 88.9%, 95.6%, and 97.8% for 1-shot, 5-shot, and 10-shot respectively. This result proves that our method can be used for lithium-ion battery defect detection.",
        "paperId": "0416bec016bbfc3455cf26f0af041395860214f9"
    },
    {
        "title": "FSG-Net: a Deep Learning model for Semantic Robot Grasping through Few-Shot Learning",
        "firstAuthor": "Leonardo Barcellona",
        "url": null,
        "dateSubmitted": "2023-05-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Robot grasping has been widely studied in the last decade. Recently, Deep Learning made possible to achieve remarkable results in grasp pose estimation, using depth and RGB images. However, only few works consider the choice of the object to grasp. Moreover, they require a huge amount of data for generalizing to unseen object categories. For this reason, we introduce the Few-shot Semantic Grasping task where the objective is inferring a correct grasp given only five labelled images of a target unseen object. We propose a new deep learning architecture able to solve the aforementioned problem, leveraging on a Few-shot Semantic Segmentation module. We have evaluated the proposed model both in the Graspnet dataset and in a real scenario. In Graspnet, we achieve 40,95% accuracy in the Few-shot Semantic Grasping task, outperforming baseline approaches. In the real experiments, the results confirmed the generalization ability of the network.",
        "paperId": "04276396d2f13adb80ed1c8dc0c65e023147f2ae"
    },
    {
        "title": "Adaptive few-shot learning with a fair priori distribution",
        "firstAuthor": "Xinke Zeng",
        "url": null,
        "dateSubmitted": "2022-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0428f9c0106d8e3bb7a342a3d3e48ab0c7694c48"
    },
    {
        "title": "A cross-modal deep metric learning model for disease diagnosis based on chest x-ray images",
        "firstAuthor": "Yufei Jin",
        "url": "https://link.springer.com/content/pdf/10.1007/s11042-023-14790-7.pdf",
        "dateSubmitted": "2023-03-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0429e9343424ded011eaa46547780c5c17f66fec"
    },
    {
        "title": "Bad Form: Comparing Context-Based and Form-Based Few-Shot Learning in Distributional Semantic Models",
        "firstAuthor": "Jeroen Van Hautte",
        "url": "https://www.aclweb.org/anthology/D19-6104.pdf",
        "dateSubmitted": "2019-10-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Word embeddings are an essential component in a wide range of natural language processing applications. However, distributional semantic models are known to struggle when only a small number of context sentences are available. Several methods have been proposed to obtain higher-quality vectors for these words, leveraging both this context information and sometimes the word forms themselves through a hybrid approach. We show that the current tasks do not suffice to evaluate models that use word-form information, as such models can easily leverage word forms in the training data that are related to word forms in the test data. We introduce 3 new tasks, allowing for a more balanced comparison between models. Furthermore, we show that hyperparameters that have largely been ignored in previous work can consistently improve the performance of both baseline and advanced models, achieving a new state of the art on 4 out of 6 tasks.",
        "paperId": "04374563c034ddfc54e710cc339d91d04835c205"
    },
    {
        "title": "A Few Shot Object Detection Method Based on Feature Pyramid Network and Graph Neural Network",
        "firstAuthor": "Xinlong Li",
        "url": null,
        "dateSubmitted": "2021-01-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few shot learning has become a research focus in the field of computer vision. Few shot detection method has a very crucial value in practice. But so far, only few results have been achieved in this field, and more research is required. In this paper, we proposed a few shot object detection method, which consists of two subnets. The first subnet is the object detection subnet, which is only responsible for the object positioning. We adopted an anchor box clustering method to produce the proper initial size of anchor boxes. Furthermore, a general class classification method was proposed to make the model learn the common features of different classes. Therefore, it could detect unseen classes when testing. The second subnet is the few shot classification subnet, which is designed to classify the detected objects. Images were preprocessed before input to the few shot detection subnet to remove redundant information. Finally, end-to-end experiments were designed on the ImageNet LOC dataset. Our method reached a high mAP of 80.76% in 5-way-10-shot experiments and significantly outperformed the benchmark method.",
        "paperId": "043ab1adaa38d3ebb275998e8b427934cd55d960"
    },
    {
        "title": "Teach machine to learn: hand-drawn multi-symbol sketch recognition in one-shot",
        "firstAuthor": "Chongyu Pan",
        "url": null,
        "dateSubmitted": "2020-03-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "04604dbe09deb5c064a59068bd43784ebb4c771e"
    },
    {
        "title": "Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning",
        "firstAuthor": "Mamshad Nayeem Rizve",
        "url": "https://arxiv.org/pdf/2103.01315",
        "dateSubmitted": "2021-03-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In many real-world problems, collecting a large number of labeled samples is infeasible. Few-shot learning (FSL) is the dominant approach to address this issue, where the objective is to quickly adapt to novel categories in presence of a limited number of samples. FSL tasks have been predominantly solved by leveraging the ideas from gradient-based meta-learning and metric learning approaches. However, recent works have demonstrated the significance of powerful feature representations with a simple embedding network that can outperform existing sophisticated FSL algorithms. In this work, we build on this insight and propose a novel training mechanism that simultaneously enforces equivariance and invariance to a general set of geometric transformations. Equivariance or invariance has been employed standalone in the previous works; however, to the best of our knowledge, they have not been used jointly. Simultaneous optimization for both of these contrasting objectives allows the model to jointly learn features that are not only independent of the input transformation but also the features that encode the structure of geometric transformations. These complementary sets of features help generalize well to novel classes with only a few data samples. We achieve additional improvements by incorporating a novel self-supervised distillation objective. Our extensive experimentation shows that even without knowledge distillation our proposed method can outperform current state-of-the-art FSL methods on five popular benchmark datasets.",
        "paperId": "04733e633493d5adc31f5f507ebf54a5e509fae4"
    },
    {
        "title": "Dlung: Unsupervised Few-Shot Diffeomorphic Respiratory Motion Modeling",
        "firstAuthor": "Peizhi Chen",
        "url": "https://link.springer.com/content/pdf/10.1007/s12204-022-2525-3.pdf",
        "dateSubmitted": "2022-11-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "047c636fbe8d12c136f36f3e8a9bb2e549f65428"
    },
    {
        "title": "Injecting Text and Cross-Lingual Supervision in Few-Shot Learning from Self-Supervised Models",
        "firstAuthor": "Matthew Wiesner",
        "url": "https://arxiv.org/pdf/2110.04863",
        "dateSubmitted": "2021-10-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Self-supervised model pretraining has recently garnered significant interest. However, using additional resources in fine-tuning these models has received less attention. We demonstrate how universal phoneset acoustic models can leverage cross-lingual supervision to improve transfer of pretrained self-supervised representations to new languages. We also show how target-language text can be used to enable and improve fine-tuning with the lattice-free maximum mutual information (LF-MMI) objective. In three low-resource languages these techniques greatly improved few-shot learning performance.",
        "paperId": "047ce1b1f4dfec2d5f53de955f5e0f645ddc929c"
    },
    {
        "title": "Exploring the Relations of Local Semantic Features with GNNs for Few-Shot Classification",
        "firstAuthor": "Jiaxing Chen",
        "url": null,
        "dateSubmitted": "2021-07-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In few-shot learning, methods based on graph neural network (GNN) are proposed for full exploitation of relations between samples. However, most GNN-based methods only explore a very rough relation among instances, ignoring that the relation between two samples is more complicated than a similarity value can convey. In this paper, we propose a model named GNN-based Relations Extraction for local features (GNN-RE in short) to explore the complex relations between instances. Specifically, we represent each image with multiple local semantic features, with each representing one type of semantic information. By exploring the relations among local semantic features in different images, we can learn more complex relations between images. To evaluate the effectiveness of the proposed GNN-RE, we conduct extensive experiments on two benchmark datasets. Our method achieves better or competitive performance comparing with previous work.",
        "paperId": "0480a33845c7ef024ab4f02ec84cea20bdf88bb5"
    },
    {
        "title": "Message Passing Neural Processes",
        "firstAuthor": "Ben Day",
        "url": null,
        "dateSubmitted": "2020-09-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Neural Processes (NPs) are powerful and flexible models able to incorporate uncertainty when representing stochastic processes, while maintaining a linear time complexity. However, NPs produce a latent description by aggregating independent representations of context points and lack the ability to exploit relational information present in many datasets. This renders NPs ineffective in settings where the stochastic process is primarily governed by neighbourhood rules, such as cellular automata (CA), and limits performance for any task where relational information remains unused. We address this shortcoming by introducing Message Passing Neural Processes (MPNPs), the first class of NPs that explicitly makes use of relational structure within the model. Our evaluation shows that MPNPs thrive at lower sampling rates, on existing benchmarks and newly-proposed CA and Cora-Branched tasks. We further report strong generalisation over density-based CA rule-sets and significant gains in challenging arbitrary-labelling and few-shot learning setups.",
        "paperId": "048ba309ce5c23ab6e57ff3de9cbcd890762e168"
    },
    {
        "title": "BSNet: Bi-Similarity Network for Few-shot Fine-grained Image Classification",
        "firstAuthor": "Xiaoxu Li",
        "url": "https://arxiv.org/pdf/2011.14311",
        "dateSubmitted": "2020-11-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning for fine-grained image classification has gained recent attention in computer vision. Among the approaches for few-shot learning, due to the simplicity and effectiveness, metric-based methods are favorably state-of-the-art on many tasks. Most of the metric-based methods assume a single similarity measure and thus obtain a single feature space. However, if samples can simultaneously be well classified via two distinct similarity measures, the samples within a class can distribute more compactly in a smaller feature space, producing more discriminative feature maps. Motivated by this, we propose a so-called Bi-Similarity Network (BSNet) that consists of a single embedding module and a bi-similarity module of two similarity measures. After the support images and the query images pass through the convolution-based embedding module, the bi-similarity module learns feature maps according to two similarity measures of diverse characteristics. In this way, the model is enabled to learn more discriminative and less similarity-biased features from few shots of fine-grained images, such that the model generalization ability can be significantly improved. Through extensive experiments by slightly modifying established metric/similarity based networks, we show that the proposed approach produces a substantial improvement on several fine-grained image benchmark datasets. Codes are available at: https://github.com/PRIS-CV/BSNet.",
        "paperId": "049692f8d58a5f4ae448fb87773a4aa6303a87c6"
    },
    {
        "title": "Combat data shift in few-shot learning with knowledge graph",
        "firstAuthor": "Yongchun Zhu",
        "url": "https://arxiv.org/pdf/2101.11354",
        "dateSubmitted": "2021-01-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "04b65f54570eaa3280f4c0b7461fc9ab99d852c4"
    },
    {
        "title": "Only Image Cosine Embedding for Few-Shot Learning",
        "firstAuthor": "Songyi Gao",
        "url": null,
        "dateSubmitted": "2019-12-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "04c0605b97a4d0d16d66cfb6ffbbdf94c70b8ede"
    },
    {
        "title": "Ranking Distance Calibration for Cross-Domain Few-Shot Learning",
        "firstAuthor": "Pan Li",
        "url": "https://arxiv.org/pdf/2112.00260",
        "dateSubmitted": "2021-12-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent progress in few-shot learning promotes a more realistic cross-domain setting, where the source and target datasets are in different domains. Due to the domain gap and disjoint label spaces between source and target datasets, their shared knowledge is extremely limited. This encourages us to explore more information in the target domain rather than to overly elaborate training strategies on the source domain as in many existing methods. Hence, we start from a generic representation pre-trained by a cross-entropy loss and a conventional distance-based classifier, along with an image retrieval view, to employ a re-ranking process to calibrate a target distance matrix by discovering the k-reciprocal neighbours within the task. Assuming the pre-trained representation is biased towards the source, we construct a non-linear subspace to minimise task-irrelevant features therewithin while keep more transferrable discriminative information by a hyperbolic tangent transformation. The calibrated distance in this target-aware non-linear sub-space is complementary to that in the pre-trained representation. To impose such distance calibration information onto the pre-trained representation, a Kullback-Leibler divergence loss is employed to gradually guide the model towards the calibrated distance-based distribution. Extensive evaluations on eight target domains show that this target ranking calibration process can improve conventional distance-based classifiers in few-shot learning.",
        "paperId": "04e5c5ff1c828c57baf299c1c66401caa5e9d42b"
    },
    {
        "title": "Meta-Learning with Latent Embedding Optimization",
        "firstAuthor": "Andrei A. Rusu",
        "url": null,
        "dateSubmitted": "2018-07-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.",
        "paperId": "04f739a0c29b75877243731aeead512bf0ed1dff"
    },
    {
        "title": "Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning",
        "firstAuthor": "Yun-ping Guan",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3583780.3614911",
        "dateSubmitted": "2023-10-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning excels in few-shot learning by extracting shared knowledge from the observed tasks. However, it needs the tasks to adhere to the i.i.d. constraint, which is challenging to achieve due to complex task relationships between data content. Current methods that create tasks in a one-dimensional structure and use meta-learning to learn all tasks flatly struggle with extracting shared knowledge from tasks with overlapping concepts. To address this issue, we propose further constructing tasks from the same environment into hyper-tasks. Since the distributions of hyper-tasks and tasks in a hyper-task can both be approximated as i.i.d. due to further summarization, the meta-learning algorithm can capture shared knowledge more efficiently. Based on the hyper-task, we propose a hierarchical meta-learning paradigm to meta-learn the meta-learning algorithm. The paradigm builds a customized meta-learner for each hyper-task, which makes meta-learners more flexible and expressive. We apply the paradigm to three classic meta-learning algorithms and conduct extensive experiments on public datasets, which confirm the superiority of hierarchical meta-learning in the few-shot learning setting. The code is released at https://github.com/tuantuange/H-meta-learning.",
        "paperId": "050dc39916e3b579f0d21ed758d44c7590831e20"
    },
    {
        "title": "Representative Local Feature Mining for Few-Shot Learning",
        "firstAuthor": "Kun Yan",
        "url": null,
        "dateSubmitted": "2021-06-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning aims to recognize unseen images of new classes with only a few training examples. While great progress has been made with deep learning technology, most metric-based works rely on the measurement based on global feature representation of images, which is sensitive to background factors due to the scarcity of training data. Given this, we propose a novel method that chooses representative local features to facilitate few-shot learning. Specifically, we propose a \"task-specific guided\" strategy to mine local features that are task-specific and discriminative. For each task, we first mine representative local features for labeled images by a loss guided mechanism. Then these local features are used to guide a classifier to mine representative local features for unlabeled images. In this way, task-specific representative local features can be selected for better classification. We empirically show our method can effectively alleviate the negative effect introduced by background factors. Extensive experiments on two few-shot benchmarks show the effectiveness of the proposed method.",
        "paperId": "0514416aa1f2ac2394a6e5c62ae4103dc8629440"
    },
    {
        "title": "Mapping Fluvial Landforms with Deep Similarity Learning",
        "firstAuthor": "P. Carbonneau",
        "url": null,
        "dateSubmitted": "2021-03-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "<p>Semantic image classification as practised in Earth Observation is poorly suited to mapping fluvial landforms which are often composed of multiple landcover types such as water, riparian vegetation and exposed sediment. Deep learning methods developed in the field of computer vision for the purpose of image classification (ie the attribution of a single label to an image such as cat/dog/etc) are in fact more suited to such landform mapping tasks. Notably, Convolutional Neural Networks (CNN) have excelled at the task of labelling images. However, CNN are notorious for requiring very large training sets that are laborious and costly to assemble. Similarity learning is a sub-field of deep learning and is better known for one-shot and few-shot learning methods. These approaches aim to reduce the need for large training sets by using CNN architectures to compare a single, or few, known examples of an instance to a new image and determining if the new image is similar to the provided examples. Similarity learning rests on the concept of image embeddings which are condensed higher-dimension vector representations of an image generated by a CNN. Ideally, and if a CNN is suitably trained, image embeddings will form clusters according to image classes, even if some of these classes were never used in the initial CNN training.</p><p>&#160;</p><p>In this paper, we use similarity learning for the purpose of fluvial landform mapping from Sentinel-2 imagery. We use the True Color Image product with a spatial resolution of 10 meters and begin by manually extracting tiles of 128x128 pixels for 4 classes: non-river, meandering reaches, anastomosing reaches and braiding reaches. We use the DenseNet121 CNN topped with a densely connected layer of 8 nodes which will produce embeddings as 8-dimension vectors. We then train this network with only 3 classes (non-river, meandering and anastomosing) using a categorical cross-entropy loss function. Our first result is that when applied to our image tiles, the embeddings produced by the trained CNN deliver 4 clusters. Despite not being used in the network training, the braiding river reach tiles have produced embeddings that form a distinct cluster. We then use this CNN to perform few-shot learning with a Siamese triplet architecture that will classify a new tile based on only 3 examples of each class. Here we find that tiles from the non-river, meandering and anastomising class were classified with F1 scores of 72%, 87% and 84%, respectively. The braiding river tiles were classified to an F1 score of 80%. Whilst these performances are lesser than the 90%+ performances expected from conventional CNN, the prediction of a new class of objects (braiding reaches) with only 3 samples to 80% F1 is unprecedented in river remote sensing. We will conclude the paper by extending the method to mapping fluvial landforms on entire Sentinel-2 tiles and we will show how we can use advanced cluster analyses of image embeddings to identify landform classes in an image without making a priori decisions on the classes that are present in the image.</p>",
        "paperId": "051b16931efb0ae43779214aa7a7858a06222013"
    },
    {
        "title": "Learning Classifiers for Domain Adaptation, Zero and Few-Shot Recognition Based on Learning Latent Semantic Parts.",
        "firstAuthor": "Pengkai Zhu",
        "url": null,
        "dateSubmitted": "2019-01-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In computer vision applications, such as domain adaptation (DA), few shot learning (FSL) and zero-shot learning (ZSL), we encounter new objects and environments, for which insufficient examples exist to allow for training \"models from scratch,\" and methods that adapt existing models, trained on the presented training environment, to the new scenario are required. We propose a novel visual attribute encoding method that encodes each image as a low-dimensional probability vector composed of prototypical part-type probabilities. The prototypes are learnt to be representative of all training data. At test-time we utilize this encoding as an input to a classifier. At test-time we freeze the encoder and only learn/adapt the classifier component to limited annotated labels in FSL; new semantic attributes in ZSL. We conduct extensive experiments on benchmark datasets. Our method outperforms state-of-art methods trained for the specific contexts (ZSL, FSL, DA).",
        "paperId": "0528eb3cf7398d0c5350cfdc227a0315853d77ca"
    },
    {
        "title": "Learning Class Prototypes Via Anisotropic Combination of Aligned Modalities for Few-Shot Learning",
        "firstAuthor": "Jieya Lian",
        "url": null,
        "dateSubmitted": "2020-07-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prototypical networks have shown their simplicity and effectiveness in few-shot learning. Recently, some works leverage cross-modal information to enhance the class prototype in few-shot learning. However, they seldom make use of structured information from textual space to optimize class prototype representation. And they either don\u2019t align textual modality to visual modality or align them too rigidly. We argue that proper alignment method is important to improve the performance of cross-modal methods, as query data only has visual information in the few-shot learning tasks. In this paper, we propose a cross-modal alignment method to optimize class prototypes with structured information from textual space. We further introduce an anisotropic combination method to enhance class prototypes with information from two modalities. Experiments show that the cross-modal alignment method and anisotropic combination method achieve state-of-the-art results on the miniImageNet and tieredImageNet benchmark in one-shot regime.",
        "paperId": "05389cd9b325aadc210fdb05adb4b48c197a092e"
    },
    {
        "title": "Comparative Analysis of Crop Disease Detection Based on Few-shot Learning",
        "firstAuthor": "Ruoyu Wang",
        "url": null,
        "dateSubmitted": "2022-10-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Disease is an important factor influencing crop yield and quality. In recent years, deep learning has made great progress in the field of crop disease detection, much superior to traditional methods. However, the excellent performance of deep learning needs a large number of training samples. In the field of plant science and biology, it is not easy to obtain a large amount of labeled data. So how to use a small number of samples for crop disease detection has become a topic that researchers are very concerned about. According to different learning methods, this study analyzes the researches on crop disease detection based on few-shot learning in recent years from four aspects: data augmentation, semi-supervised learning, metric learning, and meta-learning, we summarize the advantages and disadvantages of each method, and compare the performance of existing methods. On this basis, we discuss possible challenges in practical applications and proposes possible solutions. Finally, we analyzes and forecasts the future trends of crop disease detection based on few-shot learning.",
        "paperId": "053d8cf8e47fc51bfc940e2699455c6873c119a1"
    },
    {
        "title": "Max-margin learning with the Bayes factor",
        "firstAuthor": "R. G. Krishnan",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We propose a new way to answer probabilistic queries that span multiple datapoints. We formalize reasoning about the similarity of different datapoints as the evaluation of the Bayes Factor within a hierarchical deep generative model that enforces a separation between the latent variables used for representation learning and those used for reasoning. Under this model, we derive an intuitive estimator for the Bayes Factor that represents similarity as the amount of overlap in representation space shared by different points. The estimator we derive relies on a query-conditional latent reasoning network, that parameterizes a distribution over the latent space of the deep generative model. The latent reasoning network is trained to amortize the posterior-predictive distribution under a hierarchical model using supervised data and a maxmargin learning algorithm. We explore how the model may be used to focus the data variations captured in the latent space of the deep generative model and how this may be used to build new algorithms for few-shot learning.",
        "paperId": "0546d308fcdcaac940b133c9df3f7e2d0f88d525"
    },
    {
        "title": "Self-mentoring: A new deep learning pipeline to train a self-supervised U-net for few-shot learning of bio-artificial capsule segmentation",
        "firstAuthor": "Arnaud Deleruyelle",
        "url": "https://arxiv.org/pdf/2205.10840",
        "dateSubmitted": "2022-05-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0547f4b9710e99845438b750cf97a4b61a2c629f"
    },
    {
        "title": "Speakerbox: Few-Shot Learning for Speaker Identification with Transformers",
        "firstAuthor": "Eva Maxfield Brown",
        "url": "https://joss.theoj.org/papers/10.21105/joss.05132.pdf",
        "dateSubmitted": "2023-03-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "05555160ff32dc487ffb1ec5048a4f00b1709f79"
    },
    {
        "title": "Learning to Adapt With Memory for Probabilistic Few-Shot Learning",
        "firstAuthor": "Lei Zhang",
        "url": null,
        "dateSubmitted": "2021-01-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning has recently generated increasing popularity in machine learning, which addresses the fundamental yet challenging problem of learning to adapt to new tasks with the limited data. In this paper, we propose a new probabilistic framework that learns to fast adapt with external memory. We model the classifier parameters as distributions that are inferred from the support set and directly applied to the query set for prediction. The model is optimized by formulating as a variational inference problem. The probabilistic modeling enables better handling prediction uncertainty due to the limited data. We impose a discriminative constraint on the feature representations by exploring the class structure, which can improve the classification performance. We further introduce a memory unit to store task-specific information extracted from the support set and used for the query set to achieve explicit adaption to individual tasks. By episodic training, the model learns to acquire the capability of adapting to specific tasks, which guarantees its performance on new related tasks. We conduct extensive experiments on widely-used benchmarks for few-shot recognition. Our method achieves new state-of-the-art performance and largely surpassing previous methods by large margins. The ablation study further demonstrates the effectiveness of the proposed discriminative learning and memory unit.",
        "paperId": "05564dcad589f02db587d0b98f61cfda3e74ea7a"
    },
    {
        "title": "Meta-Learning GNN Initializations for Low-Resource Molecular Property Prediction",
        "firstAuthor": "Cuong Q. Nguyen",
        "url": null,
        "dateSubmitted": "2020-06-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Building in silico models to predict chemical properties and activities is a crucial step in drug discovery. However, limited labeled data often hinders the application of deep learning in this setting. Meanwhile advances in meta-learning have enabled state-of-the-art performances in few-shot learning benchmarks, naturally prompting the question: Can meta-learning improve deep learning performance in low-resource drug discovery projects? In this work, we assess the transferability of graph neural networks initializations learned by the Model-Agnostic Meta-Learning (MAML) algorithm - and its variants FO-MAML and ANIL - for chemical properties and activities tasks. Using the ChEMBL20 dataset to emulate low-resource settings, our benchmark shows that meta-initializations perform comparably to or outperform multi-task pre-training baselines on 16 out of 20 in-distribution tasks and on all out-of-distribution tasks, providing an average improvement in AUPRC of 11.2% and 26.9% respectively. Finally, we observe that meta-initializations consistently result in the best performing models across fine-tuning sets with $k \\in \\{16, 32, 64, 128, 256\\}$ instances.",
        "paperId": "05615a0c3bf6ae831a5df6dfa14a02de608fbbe0"
    },
    {
        "title": "Profiling Cryptocurrency Influencers with Few-Shot Learning Using Data Augmentation and ELECTRA",
        "firstAuthor": "Marco Siino",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0582177d4e96ed0071886fd18ea6a786f8dffb8b"
    },
    {
        "title": "Hyperbolic Feature Augmentation via Distribution Estimation and Infinite Sampling on Manifolds",
        "firstAuthor": "Zhi Gao",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Learning in hyperbolic spaces has attracted growing attention recently, owing to their capabilities in capturing hierarchical structures of data. However, existing learning algorithms in the hyperbolic space tend to overfit when limited data is given. In this paper, we propose a hyperbolic feature augmentation method that generates diverse and discriminative features in the hyperbolic space to combat overfitting. We employ a wrapped hyperbolic normal distribution to model augmented features, and use a neural ordinary differential equation module that benefits from meta-learning to estimate the distribution. This is to reduce the bias of estimation caused by the scarcity of data. We also derive an upper bound of the augmentation loss, which enables us to train a hyperbolic model by using an infinite number of augmentations. Experiments on few-shot learning and continual learning tasks show that our method significantly improves the performance of hyperbolic algorithms in scarce data regimes.",
        "paperId": "05832dfb1460b41f96885e705f183ceabc001563"
    },
    {
        "title": "An Open-set Recognition and Few-Shot Learning Dataset for Audio Event Classification in Domestic Environments",
        "firstAuthor": "Javier Naranjo-Alcazar",
        "url": null,
        "dateSubmitted": "2020-02-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The problem of training a deep neural network with a small set of positive samples is known as few-shot learning (FSL). It is widely known that traditional deep learning (DL) algorithms usually show very good performance when trained with large datasets. However, in many applications, it is not possible to obtain such a high number of samples. In the image domain, typical FSL applications are those related to face recognition. In the audio domain, music fraud or speaker recognition can be clearly benefited from FSL methods. This paper deals with the application of FSL to the detection of specific and intentional acoustic events given by different types of sound alarms, such as door bells or fire alarms, using a limited number of samples. These sounds typically occur in domestic environments where many events corresponding to a wide variety of sound classes take place. Therefore, the detection of such alarms in a practical scenario can be considered an open-set recognition (OSR) problem. To address the lack of a dedicated public dataset for audio FSL, researchers usually make modifications on other available datasets. This paper is aimed at providing the audio recognition community with a carefully annotated dataset for FSL and OSR comprised of 1360 clips from 34 classes divided into pattern sounds and unwanted sounds. To facilitate and promote research in this area, results with two baseline systems (one trained from scratch and another based on transfer learning), are presented.",
        "paperId": "05c34ed3c401ef35f4e26f4c585999a7a7a1f7c8"
    },
    {
        "title": "Adversarial Feature Hallucination Networks for Few-Shot Learning",
        "firstAuthor": "K. Li",
        "url": "https://arxiv.org/pdf/2003.13193",
        "dateSubmitted": "2020-03-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The recent flourish of deep learning in various tasks is largely accredited to the rich and accessible labeled data. Nonetheless, massive supervision remains a luxury for many real applications, boosting great interest in label-scarce techniques such as few-shot learning (FSL), which aims to learn concept of new classes with a few labeled samples. A natural approach to FSL is data augmentation and many recent works have proved the feasibility by proposing various data synthesis models. However, these models fail to well secure the discriminability and diversity of the synthesized data and thus often produce undesirable results. In this paper, we propose Adversarial Feature Hallucination Networks (AFHN) which is based on conditional Wasserstein Generative Adversarial networks (cWGAN) and hallucinates diverse and discriminative features conditioned on the few labeled samples. Two novel regularizers, i.e., the classification regularizer and the anti-collapse regularizer, are incorporated into AFHN to encourage discriminability and diversity of the synthesized features, respectively. Ablation study verifies the effectiveness of the proposed cWGAN based feature hallucination framework and the proposed regularizers. Comparative results on three common benchmark datasets substantiate the superiority of AFHN to existing data augmentation based FSL approaches and other state-of-the-art ones.",
        "paperId": "05ccac01939f5956fc332df838b879732933f50c"
    },
    {
        "title": "Transfer Learning for Power Outage Detection Task with Limited Training Data",
        "firstAuthor": "Olukunle O. Owolabi",
        "url": "http://arxiv.org/pdf/2305.17817",
        "dateSubmitted": "2023-05-28",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Early detection of power outages is crucial for maintaining a reliable power distribution system. This research investigates the use of transfer learning and language models in detecting outages with limited labeled data. By leveraging pretraining and transfer learning, models can generalize to unseen classes. Using a curated balanced dataset of social media tweets related to power outages, we conducted experiments using zero-shot and few-shot learning. Our hypothesis is that Language Models pretrained with limited data could achieve high performance in outage detection tasks over baseline models. Results show that while classical models outperform zero-shot Language Models, few-shot fine-tuning significantly improves their performance. For example, with 10% fine-tuning, BERT achieves 81.3% accuracy (+15.3%), and GPT achieves 74.5% accuracy (+8.5%). This has practical implications for analyzing and localizing outages in scenarios with limited data availability. Our evaluation provides insights into the potential of few-shot fine-tuning with Language Models for power outage detection, highlighting their strengths and limitations. This research contributes to the knowledge base of leveraging advanced natural language processing techniques for managing critical infrastructure.",
        "paperId": "05fab50acb26203a944a955131a2388c9731a8f7"
    },
    {
        "title": "Automated detection of COVID-19 on a small dataset of chest CT images using metric learning",
        "firstAuthor": "Shipra Madan",
        "url": null,
        "dateSubmitted": "2021-07-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Coronavirus disease has caused unprecedented chaos across the globe causing potentially fatal pneumonia, since the beginning of 2020. Researchers from different communities are working in conjunction with front-line doctors and policymakers to better understand the disease. The key to prevent the spread is a rapid diagnosis, prioritized isolation, and fastidious contact tracing. Recent studies have confirmed the presence of underlying patterns on chest CT for patients with COVID-19. We present a completely automated framework to detect COVID-19 using chest CT scans, only needing a small number of training samples. We present a few-shot learning technique based on the Triplet network in comparison to the conventional deep learning techniques which require a substantial amount of training examples. We used 140 chest CT images for training and the rest for testing from a total of 2482 images for both COVID-19 and non-COVID-19 cases from a publicly available dataset. The model trained with chest CT images achieves an AUC of 0.94, separates the two classes into distinct clusters; thereby giving correct prediction accuracy on the evaluation dataset.",
        "paperId": "05ff68da715769bf975a1bd847b1f4140f544d2f"
    },
    {
        "title": "Few-shot Learning with Data Enhancement and Transfer Learning for Underwater Target Recognition",
        "firstAuthor": "Feng Liu",
        "url": null,
        "dateSubmitted": "2021-07-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Due to the difficulty of acquiring underwater target data, the recognition of small samples of underwater acoustic targets has always been a difficult problem in the field of underwater acoustics. To solve this problem, this paper proposes a few-shot learning method based on data enhancement and transfer learning for underwater target recognition. This paper takes two-dimensional time-frequency spectrum as input, and uses a variety of data enhancement schemes, combined with transfer learning methods to achieve target classification. In terms of experiments, we used hydrophones to collect 3 times data in different sea areas as a data set for verification, including 10 types of targets. The experimental results show that our system could achieve the accuracy of 0.82.",
        "paperId": "06071e239ea4241754867548baa3bdbc9f4e22df"
    },
    {
        "title": "Learning to learn via Self-Critique",
        "firstAuthor": "Antreas Antoniou",
        "url": null,
        "dateSubmitted": "2019-05-24",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In few-shot learning, a machine learning system learns from a small set of labelled examples relating to a specific task, such that it can generalize to new examples of the same task. Given the limited availability of labelled examples in such tasks, we wish to make use of all the information we can. Usually a model learns task-specific information from a small training-set (support-set) to predict on an unlabelled validation set (target-set). The target-set contains additional task-specific information which is not utilized by existing few-shot learning methods. Making use of the target-set examples via transductive learning requires approaches beyond the current methods; at inference time, the target-set contains only unlabelled input data-points, and so discriminative learning cannot be used. In this paper, we propose a framework called Self-Critique and Adapt or SCA, which learns to learn a label-free loss function, parameterized as a neural network. A base-model learns on a support-set using existing methods (e.g. stochastic gradient descent combined with the cross-entropy loss), and then is updated for the incoming target-task using the learnt loss function. This label-free loss function is itself optimized such that the learnt model achieves higher generalization performance. Experiments demonstrate that SCA offers substantially reduced error-rates compared to baselines which only adapt on the support-set, and results in state of the art benchmark performance on Mini-ImageNet and Caltech-UCSD Birds 200.",
        "paperId": "06125bab53c6629ff24f2ea72080bb4ba59e2741"
    },
    {
        "title": "Continual few-shot learning with Hippocampal-inspired replay",
        "firstAuthor": "G. Kowadlo",
        "url": "http://arxiv.org/pdf/2209.07863",
        "dateSubmitted": "2022-08-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Continual learning and few-shot learning are important frontiers in the quest to improve Machine Learning. There is a growing body of work in each frontier, but very little combining the two. Recently however, Antoniou et al. arXiv:2004.11967 introduced a Continual Few-shot Learning framework, CFSL, that combines both. In this study, we extended CFSL to make it more comparable to standard continual learning experiments, where usually a much larger number of classes are presented. We also introduced an `instance test' to classify very similar specific instances - a capability of animal cognition that is usually neglected in ML. We selected representative baseline models from the original CFSL work and compared to a model with Hippocampal-inspired replay, as the Hippocampus is considered to be vital to this type of learning in animals. As expected, learning more classes is more difficult than the original CFSL experiments, and interestingly, the way in which they are presented makes a difference to performance. Accuracy in the instance test is comparable to the classification tasks. The use of replay for consolidation improves performance substantially for both types of tasks, particularly the instance test.",
        "paperId": "061494b439a0968af3f8b2886edf7f816796d362"
    },
    {
        "title": "Meta-augmented Prompt Tuning for Better Few-shot Learning",
        "firstAuthor": "Kaihang Pan",
        "url": "http://arxiv.org/pdf/2303.12314",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prompt tuning is a parameter-ef\ufb01cient method, which freezes all PLM parameters and only prepends some additional tunable tokens called soft prompts to the input text. However, soft prompts heavily rely on a better initialization and may easily result in over\ufb01tting under few-shot settings, which causes prompt-tuning performing much worse than \ufb01ne-tuning. To address the above issues, this paper proposes a novel S elf-s U pervised M eta-prompt learning framework with ME ta-gradient R egularization for few-shot generalization ( SUMMER ). We leverage self-supervised meta-learning to better initialize soft prompts and curriculum-based task augmentation is further proposed to enrich the meta-task distribution. Besides, a novel meta-gradient regularization method is integrated into the meta-prompt learning framework, which meta-learns to transform the raw gradient during few-shot learning into a domain- generalizable direction, thus alleviat-ing the problem of over\ufb01tting. Extensive experiments show that SUMMER achieves better performance for different few-shot downstream tasks, and also exhibits a stronger domain generalization ability.",
        "paperId": "0619de4ffded9cd19269c73cde22e6595133bade"
    },
    {
        "title": "Large-Scale Few-Shot Learning via Multi-modal Knowledge Discovery",
        "firstAuthor": "Shuo Wang",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "062a6f27a48374d1b53e272747cd9f5c389e768f"
    },
    {
        "title": "LGP: Few-Shot Class-Evolutionary Learning on Dynamic Graphs",
        "firstAuthor": "Tiancheng Huang",
        "url": null,
        "dateSubmitted": "2022-10-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Graph few-shot learning aims to learn how to quickly adapt to new tasks using only a few labeled data, which transfers learned knowledge of base classes to novel classes. Existing methods are mainly designed for static graphs, while many real-world graphs are dynamic and evolving over time, resulting in a phenomenon of structure and class evolutions. To address the challenges caused by the phenomenon, in this paper, we propose a novel algorithm named Learning to Generate Parameters (LGP) to deal with few-shot class-evolutionary learning on dynamic graphs. Specifically, for the structure evolution, LGP integrates ensemble learning into a backbone network to effectively learn invariant representation across different snapshots within a dynamic graph. For the class evolution, LGP adopts a meta-learning strategy that can learn to generate the classified parameters of novel classes via the parameters of the base classes. Therefore, LGP can quickly adapt to new tasks on a combination of base and novel classes. Besides, LGP utilizes an attention mechanism to capture the evolutionary pattern between the novel and based classes. Extensive experiments on a real-world dataset demonstrate the effectiveness of LGP.",
        "paperId": "062eb1b3bf8aff6abe66f5d601162c74931e25a1"
    },
    {
        "title": "Semantic Interaction Matching Network for Few-shot Knowledge Graph Completion",
        "firstAuthor": "Pengfei Luo",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3589557",
        "dateSubmitted": "2023-03-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The prosperity of knowledge graphs (KG), as well as related downstream applications, have raised the urgent request of knowledge graph completion techniques for fully supporting the KG reasoning tasks, especially under the circumstance of training data scarcity. Though large efforts have been made on solving this challenge via few-shot learning tools, they mainly focus on simply aggregating entity neighbors to represent few-shot references, while the enhancement from latent semantic correlation within neighbors has been largely ignored. To that end, in this paper, we propose a novel few-shot learning solution, named as Semantic Interaction Matching network (SIM), which applies Transformer framework to enhance the entity representation with capturing semantic interaction between entity neighbors. Specifically, we first design entity-relation fusion module to adaptively encode neighbors with incorporating relation representation. Along this line, Transformer layers are integrated to capture latent correlation within neighbors, as well as the semantic diversification of the support set. Finally, a similarity score is attentively estimated with attention mechanism. Extensive experiments on two public benchmark datasets demonstrate that our model outperforms a variety of state-of-the-art methods with a significant margin.",
        "paperId": "0640ba831eb2a6c4b57475d43f40a0e5ad010d50"
    },
    {
        "title": "Boosting Point-BERT by Multi-choice Tokens",
        "firstAuthor": "Kexue Fu",
        "url": "https://arxiv.org/pdf/2207.13226",
        "dateSubmitted": "2022-07-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Masked language modeling (MLM) has become one of the most successful self-supervised pre-training task. Inspired by its success, Point-BERT, as a pioneer work in point cloud, proposed masked point modeling (MPM) to pre-train point transformer on large scale unanotated dataset. Despite its great performance, we find the inherent difference between language and point cloud tends to cause ambiguous tokenization for point cloud. For point cloud, there doesn't exist a gold standard for point cloud tokenization. Point-BERT use a discrete Variational AutoEncoder (dVAE) as tokenizer, but it might generate different token ids for semantically-similar patches and generate the same token ids for semantically-dissimilar patches. To tackle above problem, we propose our McP-BERT, a pre-training framework with multi-choice tokens. Specifically, we ease the previous single-choice constraint on patch token ids in Point-BERT, and provide multi-choice token ids for each patch as supervision. Moreover, we utilitze the high-level semantics learned by transformer to further refine our supervision signals. Extensive experiments on point cloud classification, few-shot classification and part segmentation tasks demonstrate the superiority of our method, e.g., the pre-trained transformer achieves 94.1% accuracy on ModelNet40, 84.28% accuracy on the hardest setting of ScanObjectNN and new state-of-the-art performance on few-shot learning. We also demonstrate that our method not only improves the performance of Point-BERT on all downstream tasks, but also incurs almost no extra computational overhead. The code will be released in https://github.com/fukexue/McP-BERT.",
        "paperId": "0666eace5784006f5ea19cce49900589aade6ce9"
    },
    {
        "title": "A New Few-Shot Learning Method of Digital PCR Image Detection",
        "firstAuthor": "Zhang Beini",
        "url": "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09433537.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "With the global pandemic of infectious diseases, the demand for accurate nucleic acid detection is daily increasing. The traditional threshold-based algorithms are adopted as the mainstream for processing the images of digital polymerase chain reaction (dPCR) now, but they are facing huge challenges on complex problems such as irregular noise, uneven illumination, and the lack of data. So, this paper proposed a novel few-shot learning method based on our improved YOLOv3 model with fast processing speed and high accuracy to deal with complicated situations. Besides, to reduce the requirement of the large training dataset and annotation time of deep neural networks, we proposed the Random Background Transfer Method (RBTM) and Source Traceability Annotation Method (STAM) as the data augmentation and annotation method separately, which exploit the prior knowledge of the data and successfully realized the few-shot learning. Bases on the domain knowledge of dPCR images, our method could effectively augment images and reduce the labeling time by 70% while retaining the visually prominent features and improves the detection accuracy from 63.96% of the traditional threshold-based algorithm to as high as 98.98%. With the optimal processing speed and accuracy, our method is the state-of-art strategy for the detection of dPCR images now.",
        "paperId": "066970665ce9192dad3dc6f3f5225898fae4ff5d"
    },
    {
        "title": "Automated human cell classification in sparse datasets using few-shot learning",
        "firstAuthor": "Reece Walsh",
        "url": "https://www.nature.com/articles/s41598-022-06718-2.pdf",
        "dateSubmitted": "2021-07-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "06748b68c7fd9a7f28ca4601290da711f76b8229"
    },
    {
        "title": "Multi-scale kronecker-product relation networks for few-shot learning",
        "firstAuthor": "Mounir Abdelaziz",
        "url": null,
        "dateSubmitted": "2022-01-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "06758b2942e5862f5bf2e15f27b6d4349000f618"
    },
    {
        "title": "Parallel Multi-scale convolution based prototypical network for few-shot ECG beats classification",
        "firstAuthor": "Zicong Li",
        "url": null,
        "dateSubmitted": "2022-09-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The electrocardiogram (ECG) presents essential information of the electrical activity of the heart measured by electrodes placed on the body surface, forming an important approach to diagnosing cardiac arrhythmias. Although various deep-learning based models have been implemented for auto-classification of arrhythmias, limited clinical data still impedes the progress of auto-diagnosis. This study presented a parallel multi-scale convolution based prototypical network (PM-CNN ProtoNet) for processing the few-shot learning tasks of ECG beats classification. By evaluating the proposed model on the MIT-BIH arrhythmia database, the PM-CNN ProtoNet achieves a satisfying accuracy of 91.6% in a 2-way 10 shot task. The comparative results between the PM-CNN ProtoNet and other state-of-art models also demonstrate the efficiency of our proposed model. In conclusion, the PM-CNN structure can improve the classification performance of the prototypical network in few-shot learning tasks while having the potential for auto-classification under a small amount of medical data.",
        "paperId": "0678c90320aed830d873f4937ca40a807a5d809c"
    },
    {
        "title": "Learning speed equalization network for few-shot learning",
        "firstAuthor": "Cailing Wang",
        "url": null,
        "dateSubmitted": "2022-01-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Abstract. The core challenge of few-shot learning is the serious overfitting problem on new tasks because of the scarcity of labeled data. Self-supervision learning can mine powerful supervision signals from the data itself to enhance the generalization performance of the model. Thus a rotation self-supervision module has been directly integrated to a few-shot learning network to alleviate the overfitting problem. However, due to the level difference or convergence speed difference in the loss function for each task, the overall model can be alternately dominated or biased by a certain task during the training stages, which has disadvantages for the main task performance. Therefore, we design a network architecture with auxiliary task learning speed equalization (LSENet) for few-shot learning. The overall model improves the generalization capability using an auxiliary task. In addition, we design a speed equalization module to constrain the decline rate of the two tasks to achieve balanced learning. Our method alleviates the overfitting problem of few-shot learning and greatly improves classification accuracy. Extensive experiments are conducted on benchmark datasets to demonstrate the effectiveness of our method.",
        "paperId": "068b1b90bb5b1d8e0c380c28bca57ff1aae22482"
    },
    {
        "title": "Few-shot learning for classification of novel macromolecular structures in cryo-electron tomograms",
        "firstAuthor": "Ran Li",
        "url": "https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008227&type=printable",
        "dateSubmitted": "2020-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Cryo-electron tomography (cryo-ET) provides 3D visualization of subcellular components in the near-native state and at sub-molecular resolutions in single cells, demonstrating an increasingly important role in structural biology in situ. However, systematic recognition and recovery of macromolecular structures in cryo-ET data remain challenging as a result of low signal-to-noise ratio (SNR), small sizes of macromolecules, and high complexity of the cellular environment. Subtomogram structural classification is an essential step for such task. Although acquisition of large amounts of subtomograms is no longer an obstacle due to advances in automation of data collection, obtaining the same number of structural labels is both computation and labor intensive. On the other hand, existing deep learning based supervised classification approaches are highly demanding on labeled data and have limited ability to learn about new structures rapidly from data containing very few labels of such new structures. In this work, we propose a novel approach for subtomogram classification based on few-shot learning. With our approach, classification of unseen structures in the training data can be conducted given few labeled samples in test data through instance embedding. Experiments were performed on both simulated and real datasets. Our experimental results show that we can make inference on new structures given only five labeled samples for each class with a competitive accuracy (> 0.86 on the simulated dataset with SNR = 0.1), or even one sample with an accuracy of 0.7644. The results on real datasets are also promising with accuracy > 0.9 on both conditions and even up to 1 on one of the real datasets. Our approach achieves significant improvement compared with the baseline method and has strong capabilities of generalizing to other cellular components.",
        "paperId": "06980b0221ceddae35a9fabd2f46bdc80b654c39"
    },
    {
        "title": "Application of Metric Learning to Large-scale Image Classification Task",
        "firstAuthor": "Mykola Baranov",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deep learning has introduced a lot of successful approaches in a lot of supervised learning areas including computer vision. Modern neural network-based models have proved a human-level performance accuracy. The one limitation that has come along with deep learning is - the requirement of large-scale datasets to train such models. Despite the large-scale datasets like ImageNet or OpenImages, a huge amount of classes are left uncovered. In order to extend the existing model to one more class a lot of data collection and annotation is required. Few-shot learning approaches tackle the issue of large-scale dataset requirements. Most of the few-shot learning approaches tackle the problem of identity recognition (like face recognition etc). Novel object classification remains a challenging task. In this work, we built metric learning based deep learning model based on triplet loss. We explore how the triplet loss-driven model may be applicable to image recognition in a case of a lack of data. Our experiments show that such kind of model leads up to 83% accuracy using only a few samples per class.",
        "paperId": "06afdeb7c7878f29ba0d6b5e71d933d222f77571"
    },
    {
        "title": "Predicting hydrogen storage in nanoporous materials using meta-learning",
        "firstAuthor": "Yangzesheng Sun",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Discovering the optimal materials and conditions for hydrogen storage is crucial to the development of fuel cell vehicles. In this work, we present a method towards this goal by combining meta-learning and high-throughput molecular simulations. Our meta-learning model efficiently utilizes the datasets generated by high-throughput simulations and applies the physical domain knowledge of hydrogen storage. Comparing to training many small models each on a material, meta-learning showed more accurate prediction, higher data efficiency and improved generalization capability. Our meta-learning approach not only accelerates the workflow of computational materials discovery, but also introduces a practical application of meta-learning and few-shot learning in the physical sciences.",
        "paperId": "06bac995788732ee1bdd4e81e284cbeafd101b59"
    },
    {
        "title": "Self-Attention and Mutual-Attention for Few-Shot Hyperspectral Image Classification",
        "firstAuthor": "Kai Huang",
        "url": null,
        "dateSubmitted": "2021-07-11",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot classification of hyperspectral image (HSI) has been increasingly abstracted attention due to its superiority of adopting to new HSI classification with only a few labeled data available. However, insufficient feature expression still bothers the improvement of performance. To address this issue, a deep self-attention and mutual-attention few-shot learning (SMA-FSL) method is proposed for HSI few-shot classification. Specifically, a deep 3D convolutional feature embedding network is utilized to extract the spectral-spatial feature at first. Then, self-attention and mutual-attention are used to ally the feature of different samples with same class and expand the class prototypes for more stable feature expression. Finally, the predicted results are obtained by calculating the distance between query set and aligned class prototypes. The experimental results on two well-know HSI datasets demonstrate that the proposed method achieves better performance compared with other related methods.",
        "paperId": "06c741d4b8c0db8c4a7b13f302599afa43b13acf"
    },
    {
        "title": "A Few-Shot Learning-Based Reward Estimation for Mapless Navigation of Mobile Robots Using a Siamese Convolutional Neural Network",
        "firstAuthor": "Vernon Kok",
        "url": "https://www.mdpi.com/2076-3417/12/11/5323/pdf?version=1653445229",
        "dateSubmitted": "2022-05-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deep reinforcement learning-based approaches to mapless navigation have relied on the distance to the goal state being known a priori or that the distance to the goal can be obtained at each timestep. In artificial or simulated environments, obtaining the distance to the goal is considered a trivial task. Still, when applied to a real-world scenario, the distance must be obtained through complex localization techniques, and the use of localization techniques increases the complexity of the agent design. However, for agents navigating in unknown environments, using information about the goal to either form part of the state representation or act as the reward mechanism is usually expensive for both the robot design and for computing costs. This paper proposes using a pre-trained Siamese convolutional neural network (SCNN) to estimate the distance between an agent and its goal, thus enabling agents equipped with onboard cameras to navigate an unknown environment without needing localization sensors. This technique can be applied to environments where a goal location may be unknown, and the only information regarding the goal maybe a description of the goal state. Our experiments show that the Siamese network can learn the distance between the agent and its goal using relatively few training samples. Therefore, it is useful for mapless navigation using only visual state information and reduces the need for complex localization techniques.",
        "paperId": "06d58e96da614d4a6dba3730baf7aad2cf4ee914"
    },
    {
        "title": "A Dropout Style Model Augmentation for Cross Domain Few-Shot Learning",
        "firstAuthor": "Pei-Cheng Tu",
        "url": null,
        "dateSubmitted": "2021-12-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We focus on few-shot learning with cross-domain shift. While most existing few-shot learning assumed similar distributions between the source and target data, we aim to deal with the scenarios when we need to experience domain shift, the scenarios that fit to many real-world applications such as customization from lab-made toys to industrial products. More specifically, we consider the domain shift when we do not have much overlap between the source and the target domains, such as they do not have many overlapped classes or they do not have many common features. In fact, we experience significant improvement from existing work especially when we do not have much overlap between the source and the target domains. We propose a simple yet effective dropout-style method given a model that has been trained based on low-complexity concept from the source domain. The main idea is to sample several sub-networks by dropping neurons (or feature maps) to construct a bunch of models with diverse features for the target domain. Afterward, we choose the most suitable sub-networks to construct the ensemble for the target domain learning. The proposed method requires almost no external storage other than the original model for the source domain learning. As another advantage over other learning methods is the computation in the method is highly parallelizable for the purpose of efficiency. To evaluate the proposed method, we conduct experiments and show that the proposed method can be in cooperated with many metric-based few-shot learning base models, with consistent improvement under various settings.",
        "paperId": "06ddbe4affb617135c3f9edd77e5a6d67a14f45a"
    },
    {
        "title": "FGN: Fully Guided Network for Few-Shot Instance Segmentation",
        "firstAuthor": "Zhibo Fan",
        "url": "https://arxiv.org/pdf/2003.13954",
        "dateSubmitted": "2020-03-31",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot instance segmentation (FSIS) conjoins the few-shot learning paradigm with general instance segmentation, which provides a possible way of tackling instance segmentation in the lack of abundant labeled data for training. This paper presents a Fully Guided Network (FGN) for few-shot instance segmentation. FGN perceives FSIS as a guided model where a so-called support set is encoded and utilized to guide the predictions of a base instance segmentation network (i.e., Mask R-CNN), critical to which is the guidance mechanism. In this view, FGN introduces different guidance mechanisms into the various key components in Mask R-CNN, including Attention-Guided RPN, Relation-Guided Detector, and Attention-Guided FCN, in order to make full use of the guidance effect from the support set and adapt better to the inter-class generalization. Experiments on public datasets demonstrate that our proposed FGN can outperform the state-of-the-art methods.",
        "paperId": "06f047e1419ec24afb13d13b16fb4c70b648fd46"
    },
    {
        "title": "Task Agnostic Meta-Learning for Few-Shot Learning",
        "firstAuthor": "Muhammad Abdullah Jamal",
        "url": "https://arxiv.org/pdf/1805.07722",
        "dateSubmitted": "2018-05-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning approaches have been proposed to tackle the few-shot learning problem. Typically, a meta-learner is trained on a variety of tasks in the hopes of being generalizable to new tasks. However, the generalizability on new tasks of a meta-learner could be fragile when it is over-trained on existing tasks during meta-training phase. In other words, the initial model of a meta-learner could be too biased towards existing tasks to adapt to new tasks, especially when only very few examples are available to update the model. To avoid a biased meta-learner and improve its generalizability, we propose a novel paradigm of Task-Agnostic Meta-Learning (TAML) algorithms. Specifically, we present an entropy-based approach that meta-learns an unbiased initial model with the largest uncertainty over the output labels by preventing it from over-performing in classification tasks. Alternatively, a more general inequality-minimization TAML is presented for more ubiquitous scenarios by directly minimizing the inequality of initial losses beyond the classification tasks wherever a suitable loss can be defined. Experiments on benchmarked datasets demonstrate that the proposed approaches outperform compared meta-learning algorithms in both few-shot classification and reinforcement learning tasks.",
        "paperId": "06f0fe16fcb8f80bf88746c5ef6d3780531918ab"
    },
    {
        "title": "Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot Meta-Learning",
        "firstAuthor": "Nan Ding",
        "url": null,
        "dateSubmitted": "2021-05-28",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Despite recent advances in its theoretical understanding, there still remains a significant gap in the ability of existing PAC-Bayesian theories on meta-learning to explain performance improvements in the few-shot learning setting, where the number of training examples in the target tasks is severely limited. This gap originates from an assumption in the existing theories which supposes that the number of training examples in the observed tasks and the number of training examples in the target tasks follow the same distribution, an assumption that rarely holds in practice. By relaxing this assumption, we develop two PAC-Bayesian bounds tailored for the few-shot learning setting and show that two existing meta-learning algorithms (MAML and Reptile) can be derived from our bounds, thereby bridging the gap between practice and PAC-Bayesian theories. Furthermore, we derive a new computationally-efficient PACMAML algorithm, and show it outperforms existing meta-learning algorithms on several few-shot benchmark datasets.",
        "paperId": "06fa7347821e87b0200175eabd522a26dfb4bc10"
    },
    {
        "title": "Meta-Learning with Domain Adaptation for Few-Shot Learning under Domain Shift",
        "firstAuthor": "Doyen Sahoo",
        "url": null,
        "dateSubmitted": "2018-09-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0703dceb3d822f1925b2f770d135178af4b61400"
    },
    {
        "title": "Distillation of encoder-decoder transformers for sequence labelling",
        "firstAuthor": "M. Farina",
        "url": "http://arxiv.org/pdf/2302.05454",
        "dateSubmitted": "2023-02-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Driven by encouraging results on a wide range of tasks, the field of NLP is experiencing an accelerated race to develop bigger language models. This race for bigger models has also underscored the need to continue the pursuit of practical distillation approaches that can leverage the knowledge acquired by these big models in a compute-efficient manner. Having this goal in mind, we build on recent work to propose a hallucination-free framework for sequence tagging that is especially suited for distillation. We show empirical results of new state-of-the-art performance across multiple sequence labelling datasets and validate the usefulness of this framework for distilling a large model in a few-shot learning scenario.",
        "paperId": "0704a96e1c57c12031f1c3ca492a91dbed1f61ce"
    },
    {
        "title": "Joint Graph Learning and Model Fitting in Laplacian Regularized Stratified Models",
        "firstAuthor": "Ziheng Cheng",
        "url": "http://arxiv.org/pdf/2305.02573",
        "dateSubmitted": "2023-05-04",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Laplacian regularized stratified models (LRSM) are models that utilize the explicit or implicit network structure of the sub-problems as defined by the categorical features called strata (e.g., age, region, time, forecast horizon, etc.), and draw upon data from neighboring strata to enhance the parameter learning of each sub-problem. They have been widely applied in machine learning and signal processing problems, including but not limited to time series forecasting, representation learning, graph clustering, max-margin classification, and general few-shot learning. Nevertheless, existing works on LRSM have either assumed a known graph or are restricted to specific applications. In this paper, we start by showing the importance and sensitivity of graph weights in LRSM, and provably show that the sensitivity can be arbitrarily large when the parameter scales and sample sizes are heavily imbalanced across nodes. We then propose a generic approach to jointly learn the graph while fitting the model parameters by solving a single optimization problem. We interpret the proposed formulation from both a graph connectivity viewpoint and an end-to-end Bayesian perspective, and propose an efficient algorithm to solve the problem. Convergence guarantees of the proposed optimization algorithm is also provided despite the lack of global strongly smoothness of the Laplacian regularization term typically required in the existing literature, which may be of independent interest. Finally, we illustrate the efficiency of our approach compared to existing methods by various real-world numerical examples.",
        "paperId": "070a884761a6c00cfba907754e438e39a8ea4be3"
    },
    {
        "title": "Gaussian Prototype Rectification For Few-shot Image Recognition",
        "firstAuthor": "Jinfu Lin",
        "url": null,
        "dateSubmitted": "2021-07-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot Learning aims to recognize novel categories with scarce training data, which is a challenging problem in computer vision. Many single-point prototype-based methods are noise-vulnerable and deviate from the expected prototypes in a low-data regime. To address these issues, we firstly model the prototype as a multidimensional Gaussian distribution. Such a vanilla Gaussian prototype gains no significant performance improvement in complicated datasets (e.g., miniImageNet, tiered-ImageNet) due to weakly representativity of the latent vectors, this paper further proposes to rectify it by mutual information. In a nutshell, we use a multidimensional Gaussian distribution with local mutual information estimation and maximization to represent each prototype. The distribution estimation learns to construct a dimension and class-dependent distance metric while local mutual information maximization rectifies the prototype and guarantees the representation's suitability for few-shot classification. Besides, to solve prototype deviation in the low-data regime, we propose the transductive Kalman (t-Kalman) fusion method. To the best of our knowledge, we are the first to give the theoretical derivation of Kalman data fusion for few-shot scenario. Extensive experiments show our method outperforms previous methods on many benchmark datasets under various settings. Ablation study shows the mutual information and t-Kalman bring in significant improvement on miniImageNet (6.15% and 5.16%) and tieredImageNet (9.25% and 4.76%) under 1-shot and 5-shot task, demonstrating the effectiveness of the proposed Gaussian prototype rectification.",
        "paperId": "070dbd4dcca91c68dcfccd0c0282be9f2f65cf17"
    },
    {
        "title": "Few-Shot Learning for Small Impurities in Tobacco Stems With Improved YOLOv7",
        "firstAuthor": "Sheng Xue",
        "url": "https://ieeexplore.ieee.org/ielx7/6287639/10005208/10122545.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "With the increase of public concern about health and smoking, the authorities have gradually tightened the control of tar content in cigarettes, making reconstituted tobacco a growing concern for tobacco companies. Tobacco stems are used as the main raw material for reconstituted tobacco, but they contain a large number of small broken impurities mainly from cigarette butts, which are difficult to remove efficiently by air selection and manual methods. Detection schemes for cigarette butt impurities based on computer vision and deep learning are still difficult. The scarcity of images containing foreign impurities in cigarette butts and the small size of impurities limit the efficient application of deep learning algorithms. In view of the small impurities\u2019 characteristics, this paper optimizes the model structure of the YOLOv7 algorithm, and only retains the two detection head structures with high feature resolution, which reduces the model parameters by 29.68%. Using online data augmentation and transfer learning, the difficulty of small sample datasets is overcome. After the CutMix, Mosaic, Affine transformation, Copy-paste data augmentation in this paper, the model precision is increased by 6.95%, and the recall rate is increased by 10.51%. Detection FPS has been increased from 99 FPS to 111 FPS. Precision and recall rate reached 97.21% and 92.11%. Compared with YOLOv4_csp, the precision is in-creased by 11.58%, and the recall rate is increased by 0.48%. It shows that the improved YOLOv7xs model has the potential for wide application in small target recognition. At the same time, it has shown the potential to avoid the harm of toxic substances produced by cigarette impurities in the combustion process and promotes the application of computer vision and deep learning in industrial production.",
        "paperId": "071c7ff1d964d63cfb9fc4b458503c43c5cd64e8"
    },
    {
        "title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "firstAuthor": "Seungone Kim",
        "url": "http://arxiv.org/pdf/2305.14045",
        "dateSubmitted": "2023-05-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Language models (LMs) with less than 100B parameters are known to perform poorly on chain-of-thought (CoT) reasoning in contrast to large LMs when solving unseen tasks. In this work, we aim to equip smaller LMs with the step-by-step reasoning capability by instruction tuning with CoT rationales. In order to achieve this goal, we first introduce a new instruction-tuning dataset called the CoT Collection, which augments the existing Flan Collection (including only 9 CoT tasks) with additional 1.84 million rationales across 1,060 tasks. We show that CoT fine-tuning Flan-T5 (3B&11B) with CoT Collection enables smaller LMs to have better CoT capabilities on unseen tasks. On the BIG-Bench-Hard (BBH) benchmark, we report an average improvement of +4.34% (Flan-T5 3B) and +2.60% (Flan-T5 11B), in terms of zero-shot task accuracy. Furthermore, we show that instruction tuning with CoT Collection allows LMs to possess stronger few-shot learning capabilities on 4 domain-specific tasks, resulting in an improvement of +2.24% (Flan-T5 3B) and +2.37% (Flan-T5 11B), even outperforming ChatGPT utilizing demonstrations until the max length by a +13.98% margin. Our code, the CoT Collection data, and model checkpoints are publicly available.",
        "paperId": "0744580e75a74357e466a57082c85cb42f548aa9"
    },
    {
        "title": "Selecting Relevant Features from a Universal Representation for Few-shot Classification",
        "firstAuthor": "Nikita Dvornik",
        "url": null,
        "dateSubmitted": "2020-03-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Popular approaches for few-shot classification consist of first learning a generic data representation based on a large annotated dataset, before adapting the representation to new classes given only a few labeled samples. In this work, we propose a new strategy based on feature selection, which is both simpler and more effective than previous feature adaptation approaches. First, we obtain a multi-domain representation by training a set of semantically different feature extractors. Then, given a few-shot learning task, we use our multi-domain feature bank to automatically select the most relevant representations. We show that a simple non-parametric classifier built on top of such features produces high accuracy and generalizes to domains never seen during training, which leads to state-of-the-art results on MetaDataset and improved accuracy on mini-ImageNet.",
        "paperId": "074ce9a6b07211e4682046cd6f50678ff008a813"
    },
    {
        "title": "Technical Report - Competition Solution for Prompt Tuning using Pretrained Language Model",
        "firstAuthor": "Jiang-Long Song",
        "url": "http://arxiv.org/pdf/2212.06369",
        "dateSubmitted": "2022-12-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prompt tuning recently becomes a hot-spot in the applications of large pretrained language models on specific downstream tasks. Regarding the Language Model as a Service (LMaaS), black-box tuning using derivative-free optimization (DFO) provides a novel approach to expand the practical scenarios of pretrained models and enrich the researches of few-shot learning. In this report, we present our solution in this competition that is based on the LMaaS scenario. Our solution consists of several modifications to BBTv2, including multiple label words, selection of P0, rolling update strategy, multi-task loss from MLP classifier, and finally using the ensemble method to further improve generalization ability. We also shared some strategies that we tried but didn't use in the final submission for further discussion. In the end we raised a question about the SNLI dataset and the impact on the results, as well as our concerns about the competition.",
        "paperId": "075e16a0774b1a9d44a7d512c50b7f997e16befe"
    },
    {
        "title": "MetaRF: attention-based random forest for reaction yield prediction with a few trails",
        "firstAuthor": "Ke Chen",
        "url": "https://jcheminf.biomedcentral.com/counter/pdf/10.1186/s13321-023-00715-x",
        "dateSubmitted": "2023-04-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "077ab79d72699dee10c663feec0a40f41bc53115"
    },
    {
        "title": "QAmeleon: Multilingual QA with Only 5 Examples",
        "firstAuthor": "Priyanka Agrawal",
        "url": "https://arxiv.org/pdf/2211.08264",
        "dateSubmitted": "2022-11-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The availability of large, high-quality datasets has been one of the main drivers of recent progress in question answering (QA). Such annotated datasets however are difficult and costly to collect, and rarely exist in languages other than English, rendering QA technology inaccessible to underrepresented languages. An alternative to building large monolingual training datasets is to leverage pre-trained language models (PLMs) under a few-shot learning setting. Our approach, QAmeleon, uses a PLM to automatically generate multilingual data upon which QA models are trained, thus avoiding costly annotation. Prompt tuning the PLM for data synthesis with only five examples per language delivers accuracy superior to translation-based baselines, bridges nearly 60% of the gap between an English-only baseline and a fully supervised upper bound trained on almost 50,000 hand labeled examples, and always leads to substantial improvements compared to fine-tuning a QA model directly on labeled examples in low resource settings. Experiments on the TyDiQA-GoldP and MLQA benchmarks show that few-shot prompt tuning for data synthesis scales across languages and is a viable alternative to large-scale annotation.",
        "paperId": "0783c214623c18f6a8ad96b8eaf4a67a382e68ee"
    },
    {
        "title": "A novel few-shot learning based multi-modality fusion model for COVID-19 rumor detection from online social media",
        "firstAuthor": "Heng-yang Lu",
        "url": null,
        "dateSubmitted": "2021-08-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Background Rumor detection is a popular research topic in natural language processing and data mining. Since the outbreak of COVID-19, related rumors have been widely posted and spread on online social media, which have seriously affected people\u2019s daily lives, national economy, social stability, etc. It is both theoretically and practically essential to detect and refute COVID-19 rumors fast and effectively. As COVID-19 was an emergent event that was outbreaking drastically, the related rumor instances were very scarce and distinct at its early stage. This makes the detection task a typical few-shot learning problem. However, traditional rumor detection techniques focused on detecting existed events with enough training instances, so that they fail to detect emergent events such as COVID-19. Therefore, developing a new few-shot rumor detection framework has become critical and emergent to prevent outbreaking rumors at early stages. Methods This article focuses on few-shot rumor detection, especially for detecting COVID-19 rumors from Sina Weibo with only a minimal number of labeled instances. We contribute a Sina Weibo COVID-19 rumor dataset for few-shot rumor detection and propose a few-shot learning-based multi-modality fusion model for few-shot rumor detection. A full microblog consists of the source post and corresponding comments, which are considered as two modalities and fused with the meta-learning methods. Results Experiments of few-shot rumor detection on the collected Weibo dataset and the PHEME public dataset have shown significant improvement and generality of the proposed model.",
        "paperId": "078c17594276a382663337abfd367db1b252587c"
    },
    {
        "title": "MetaIoT: Few Shot Malicious Traffic Detection in Internet of Things Networks Based on HIN",
        "firstAuthor": "Hongwu Li",
        "url": null,
        "dateSubmitted": "2023-06-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Identification of abnormal and malicious traffic in the Internet-of-Things (IoT) network is critical for IoT security. However, it is worth noting that the majority of recent efforts demand a large amount of tagged traffic to train a machine-learning model. In this paper, we develop MetaIoT, an intelligent approach for identifying malicious traffic. MetaIoT is more accurate and more difficult for attackers to circumvent by taking into account both the local attributes of each traffic source and their global relationships. In MetaIoT, we begin by considering the heterogeneous and dynamic nature of traffic. Then, we introduce a heterogeneous graph (HG) to model the relationships between traffic and employ a relation-based heterogeneous graph attention network to learn node (i.e., traffic) representations over the built HG. Alternatively, MetaIoT addresses the issue of needing enough data for model training through the meta-learning technique. After conducting a comprehensive comparison with the baseline through experiments, our model demonstrated superior performance in few-shot learning scenarios, obtaining an accuracy score of 91.65% and an F1 score of 90.33%. When compared with current state-of-the-art IoT traffic detection models, our model showed the best results.",
        "paperId": "078d7f6226e106ae92fa34813b4d14d477b12788"
    },
    {
        "title": "Detec\u00e7\u00e3o de Pneumonia Causada por COVID-19 Utilizando Few-Shot Learning",
        "firstAuthor": "P. Le\u00e3o",
        "url": null,
        "dateSubmitted": "2022-06-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Dados radiol\u00f3gicos s\u00e3o importantes no diagn\u00f3stico e tratamento da COVID-19 e de doen\u00e7as relacionadas ao trato respirat\u00f3rio inferior, tais como a pneumonia. Considerando esse contexto, n\u00f3s apresentamos neste artigo um m\u00e9todo que utiliza uma Rede Siamesa que, por meio de uma estrat\u00e9gia de Few-Shot Learning, busca detectar pneumonia relacionada com COVID-19 em imagens de raio-x. A capacidade de generaliza\u00e7\u00e3o desse modelo \u00e9 avaliada utilizando dois conjuntos de dados de fontes diferentes, na forma de avalia\u00e7\u00e3o interna e externa. A parti\u00e7\u00e3o dos dados \u00e9 feita a partir de identificadores dos doentes. O modelo foi capaz de alcan\u00e7ar mais de 96% de acur\u00e1cia, precis\u00e3o, e sensibilidade na avalia\u00e7\u00e3o interna. Por\u00e9m, na avalia\u00e7\u00e3o externa o resultado foi abaixo do esperado. Por outro lado, observou-se que o modelo de Rede Siamesa com Few-Shot Learning supera uma CNN tradicional.",
        "paperId": "07a86476a28e4f3f59f76477fa5781d0f095ca87"
    },
    {
        "title": "The Sample Complexity of Meta Sparse Regression",
        "firstAuthor": "Zhanyu Wang",
        "url": null,
        "dateSubmitted": "2020-02-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This paper addresses the meta-learning problem in sparse linear regression with infinite tasks. We assume that the learner can access several similar tasks. The goal of the learner is to transfer knowledge from the prior tasks to a similar but novel task. For p parameters, size of the support set k , and l samples per task, we show that T \\in O (( k log(p) ) /l ) tasks are sufficient in order to recover the common support of all tasks. With the recovered support, we can greatly reduce the sample complexity for estimating the parameter of the novel task, i.e., l \\in O (1) with respect to T and p . We also prove that our rates are minimax optimal. A key difference between meta-learning and the classical multi-task learning, is that meta-learning focuses only on the recovery of the parameters of the novel task, while multi-task learning estimates the parameter of all tasks, which requires l to grow with T . Instead, our efficient meta-learning estimator allows for l to be constant with respect to T (i.e., few-shot learning).",
        "paperId": "07b03b5560a918a2364ed95759796115369b6d48"
    },
    {
        "title": "AdaptKeyBERT: An Attention-Based approach towards Few-Shot & Zero-Shot Domain Adaptation of KeyBERT",
        "firstAuthor": "Aman Priyanshu",
        "url": "http://arxiv.org/pdf/2211.07499",
        "dateSubmitted": "2022-11-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Keyword extraction has been an important topic for mod- ern natural language processing. With its applications rang-ing from ontology generation, fact veri\ufb01cation in summarized text, and recommendation systems. While it has had signi\ufb01cant data-intensive applications, it is often hampered when the data set is small. Downstream training for keyword extractors is a lengthy process and requires a signi\ufb01cant amount of data. Recently, Few-shot Learning (FSL) and Zero-Shot Learning (ZSL) have been proposed to tackle this problem. Therefore, we propose AdaptKeyBERT, a pipeline for training keyword extractors with LLM bases by incorporating the concept of regularized attention into a pre-training phase for downstream domain adaptation. As we believe our work has implications to be utilized in the pipeline of FSL/ZSL and keyword extraction, we open-source our code as well as pro- vide the \ufb01ne-tuning library of the same name AdaptKeyBERT at https://github.com/AmanPriyanshu/AdaptKeyBERT.",
        "paperId": "07b944e12c1a3509529d1c9ca3e076a783fb80d3"
    },
    {
        "title": "Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners",
        "firstAuthor": "Jihyeon Janel Lee",
        "url": "https://arxiv.org/pdf/2307.14856",
        "dateSubmitted": "2023-07-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In-context learning, which offers substantial advantages over fine-tuning, is predominantly observed in decoder-only models, while encoder-decoder (i.e., seq2seq) models excel in methods that rely on weight updates. Recently, a few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation. Inspired by these initial studies, we provide a first-ever extensive experiment comparing the in-context few-shot learning capabilities of decoder-only and encoder-decoder models on a broad range of tasks. Furthermore, we propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. Remarkably, our approach outperforms a decoder-only model that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a variety of settings. We posit that, with the right configuration and prompt design, seq2seq models can be highly effective few-shot learners for a wide spectrum of applications.",
        "paperId": "07bc02bd16f6fe78a7ea3bb8d966fcc6e3893195"
    },
    {
        "title": "A Spike Time-Dependent Online Learning Algorithm Derived From Biological Olfaction",
        "firstAuthor": "Ayon Borthakur",
        "url": "https://fjfsdata01prod.blob.core.windows.net/articles/files/452366/pubmed-zip/.versions/1/.package-entries/fnins-13-00656/fnins-13-00656.pdf?sv=2018-03-28&sr=b&sig=DIg%2FB%2F4Hb88IsiMUbJxhSF6n0xnDaptvrxBAb3oA4ak%3D&se=2021-02-22T06%3A44%3A18Z&sp=r&rscd=attachment%3B%20filename%2A%3DUTF-8%27%27fnins-13-00656.pdf",
        "dateSubmitted": "2019-06-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We have developed a spiking neural network (SNN) algorithm for signal restoration and identification based on principles extracted from the mammalian olfactory system and broadly applicable to input from arbitrary sensor arrays. For interpretability and development purposes, we here examine the properties of its initial feedforward projection. Like the full algorithm, this feedforward component is fully spike timing-based, and utilizes online learning based on local synaptic rules such as spike timing-dependent plasticity (STDP). Using an intermediate metric to assess the properties of this initial projection, the feedforward network exhibits high classification performance after few-shot learning without catastrophic forgetting, and includes a none of the above outcome to reflect classifier confidence. We demonstrate online learning performance using a publicly available machine olfaction dataset with challenges including relatively small training sets, variable stimulus concentrations, and 3 years of sensor drift.",
        "paperId": "07c5ad035b09445dc495d7c0a25e7b0355fcff83"
    },
    {
        "title": "Few-Shot Recognition of Multifunction Radar Modes via Refined Prototypical Random Walk Network",
        "firstAuthor": "Qihang Zhai",
        "url": null,
        "dateSubmitted": "2023-06-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Multifunctional radars (MFRs) can generate a variety of working modes for different tasks based on flexible modulation types and programmable parameters. The neural network has been widely used to recognize these fine-grained MFR modes. However, it requires a large number of samples with expert annotation in advance, which is hardly available in practical applications. Therefore, a few-shot learning method is used to learn \u201cgeneral information\u201d and transfer it into new tasks where only a small number of labeled samples are provided. In order to improve its effect, unlabeled samples are utilized to provide \u201cmanifold information\u201d that describes the distribution among data. This article proposes a framework of coding refined prototypical random walk network combining these two kinds of information. The whole framework is divided into three modules, i.e., preprocessing module, embedding module, and refined prototypical random walk module, which are, respectively, used to enhance the signal expression to adapt to nonideal situations, extract distinguishable features to compute prototypes, and utilize \u201cmanifold information\u201d for better classification. The experimental results and analysis show that the proposed method achieves excellent performance for MFR fine-grained mode recognition even under the condition of a small number of samples. In addition, the robustness of the proposed method is verified under the influence of different nonideal factors.",
        "paperId": "07c6c2e69f93ee98ed2c2b1ddcbb00c489e099b3"
    },
    {
        "title": "Compositional Affinity Propagation: When Clusters Have Compositional Structure",
        "firstAuthor": "J. Whitehill",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We consider a new kind of clustering problem in which clusters need not be independent of each other, but rather can have compositional relationships with other clusters (e.g., an image set consists of rectangles, circles, as well as combinations of rectangles and circles). This task is motivated by recent work in few-shot learning on compositional embedding models (Alfassy et al. 2019; Li, Mozer, and Whitehill 2021) that structure the embedding space to distinguish the label sets, not just the individual labels, assigned to the examples. To tackle this clustering problem, we propose a new algorithm called Compositional Affinity Propagation (CAP). In contrast to standard Affinity Propagation (Frey and Dueck 2007) as well as other algorithms for multi-view and hierarchical clustering, CAP can deduce compositionality among clusters automatically. We show promising results, compared to several existing clustering algorithms, on the MultiMNIST, OmniGlot, and LibriSpeech datasets. Our work has applications to multi-object image recognition and speaker diarization with simultaneous speech from multiple speakers.",
        "paperId": "07f49a3f49ca07011fbc0e797ec0c9190362bac7"
    },
    {
        "title": "Few-shot Natural Language Generation for Task-Oriented Dialog",
        "firstAuthor": "Baolin Peng",
        "url": "https://www.aclweb.org/anthology/2020.findings-emnlp.17.pdf",
        "dateSubmitted": "2020-02-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewshotWOZ, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewshotWOZ and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.",
        "paperId": "080872cc51dffa3b72d3870f968fc296d33922a7"
    },
    {
        "title": "Pretraining Representations for Bioacoustic Few-shot Detection using Supervised Contrastive Learning",
        "firstAuthor": "Ilyass Moummad",
        "url": "https://arxiv.org/pdf/2309.00878",
        "dateSubmitted": "2023-09-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deep learning has been widely used recently for sound event detection and classification. Its success is linked to the availability of sufficiently large datasets, possibly with corresponding annotations when supervised learning is considered. In bioacoustic applications, most tasks come with few labelled training data, because annotating long recordings is time consuming and costly. Therefore supervised learning is not the best suited approach to solve bioacoustic tasks. The bioacoustic community recasted the problem of sound event detection within the framework of few-shot learning, i.e. training a system with only few labeled examples. The few-shot bioacoustic sound event detection task in the DCASE challenge focuses on detecting events in long audio recordings given only five annotated examples for each class of interest. In this paper, we show that learning a rich feature extractor from scratch can be achieved by leveraging data augmentation using a supervised contrastive learning framework. We highlight the ability of this framework to transfer well for five-shot event detection on previously unseen classes in the training data. We obtain an F-score of 63.46\\% on the validation set and 42.7\\% on the test set, ranking second in the DCASE challenge. We provide an ablation study for the critical choices of data augmentation techniques as well as for the learning strategy applied on the training set.",
        "paperId": "0814b7d27155123ab260cf4d9aff4f162b9211d1"
    },
    {
        "title": "OptNCMiner: a deep learning approach for the discovery of natural compounds modulating disease-specific multi-targets",
        "firstAuthor": "Seo Hyun Shin",
        "url": "https://bmcbioinformatics.biomedcentral.com/counter/pdf/10.1186/s12859-022-04752-5",
        "dateSubmitted": "2022-06-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0832fe3f70c6df04a0f95e2a8e2b017efa20e089"
    },
    {
        "title": "Meta-Learning-Based Incremental Few-Shot Object Detection",
        "firstAuthor": "Mengjun Cheng",
        "url": null,
        "dateSubmitted": "2022-04-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent years have witnessed meaningful progress in the task of few-shot object detection. However, most of the existing models are not capable of incremental learning with a few samples, i.e., the detector can\u2019t detect novel-class objects by using only a few samples of novel classes (without revisiting the original training samples) while maintaining the performances on base classes. This is largely because of catastrophic forgetting, which is a general phenomenon in few-shot learning that the incorporation of the unseen information (e.g., novel-class objects) will lead to a serious loss of the knowledge learnt before (e.g., base-class objects). In this paper, a new model is proposed for incremental few-shot object detection, which takes CenterNet as the fundamental framework and redesigns it by introducing a novel meta-learning method to make the model adapted to unseen knowledge while overcoming forgetting to a great extent. Specifically, a meta-learner is trained with the base-class samples, providing the object locator of the proposed model with a good weight initialization, and thus the proposed model can be fine-tuned easily with few novel-class samples. On the other hand, the filters correlated to base classes are preserved when fine-tuning the proposed model with the few samples of novel classes, which is a simple but effective solution to mitigate the problem of forgetting. The experiments on the benchmark MS COCO and PASCAL VOC datasets demonstrate that the proposed model outperforms the state-of-the-art methods by a large margin in the detection performances on base classes and all classes while achieving best performances when detecting novel-class objects in most cases. The project page can be found in https://mic.tongji.edu.cn/e6/d5/c9778a190165/page.htm.",
        "paperId": "0833c6043ef6021203128588de84e98aec35e945"
    },
    {
        "title": "Empirical Evaluation of Topic Zero- and Few-Shot Learning for Stance Dissonance Detection",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We address stance dissonance detection , the 001 task of detecting con\ufb02icting stance between 002 two input statements. Computational models 003 for traditional stance detection have typically 004 been trained to indicate pro/con for a given tar- 005 get topic (e.g. gun control) and thus do not 006 generalize well to new topics. In this paper, 007 we systematically evaluate the generalizability 008 of this task to situations where examples of 009 the topic has not been seen at all (zero-shot) 010 or only a few times (few-shot). We \ufb01rst build 011 a large-scale dataset of stance dissonance de- 012 tection from an online debate platform, con- 013 sisting of 23.8k pairs of statements from 34 014 diverse topics. We show that stance disso- 015 nance detection models trained only on a small 016 number of non-target topics already perform 017 as well as those trained on a target topic. We 018 also show that adding more non-target topics 019 further boosts the performance, indicating the 020 generalizability of non-target topics to a target 021 topic in the stance dissonance detection task. 022",
        "paperId": "086469e12532668af7834f9b103179a6848791ef"
    },
    {
        "title": "Budget-aware Few-shot Learning via Graph Convolutional Network",
        "firstAuthor": "Shipeng Yan",
        "url": null,
        "dateSubmitted": "2022-01-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This paper tackles the problem of few-shot learning, which aims to learn new visual concepts from a few examples. A common problem setting in few-shot classification assumes random sampling strategy in acquiring data labels, which is inefficient in practical applications. In this work, we introduce a new budget-aware few-shot learning problem that not only aims to learn novel object categories, but also needs to select informative examples to annotate in order to achieve data efficiency. We develop a meta-learning strategy for our budget-aware few-shot learning task, which jointly learns a novel data selection policy based on a Graph Convolutional Network (GCN) and an example-based few-shot classifier. Our selection policy computes a context-sensitive representation for each unlabeled data by graph message passing, which is then used to predict an informativeness score for sequential selection. We validate our method by extensive experiments on the mini-ImageNet, tiered-ImageNet and Omniglot datasets. The results show our few-shot learning strategy outperforms baselines by a sizable margin, which demonstrates the efficacy of our method.",
        "paperId": "086865f95ad63cbe65f36bfb706697e950bc9a7c"
    },
    {
        "title": "Autonomous perception and adaptive standardization for few-shot learning",
        "firstAuthor": "Yourun Zhang",
        "url": null,
        "dateSubmitted": "2023-07-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "086c0ad6c63a17caabdbb7b4df6bdb9caa37ea46"
    },
    {
        "title": "Re-targeting self-supervised transformers for semantic segmentation without training",
        "firstAuthor": "Zeyu Yan",
        "url": null,
        "dateSubmitted": "2023-04-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Semantic segmentation is one of the fundamental problems in computer vision. Many learning paradigms have been proposed to alleviate the annotation burden for the semantic segmentation task, such as weakly-supervised learning, one-shot learning, and few-shot learning. However, these approaches still require collecting a large amount of labeled data for training. In this paper, we are motivated to release the model from collecting such training samples and propose to retarget on-the-shelf self-supervised models for semantic segmentation tasks. We observe that the self-supervised transformers have reasonable representations to evaluate the patch affinities and the semantic meanings. By leveraging the patch-level affinities, accurate segmentation masks can be obtained. Meanwhile, the semantic assignments can be obtained by comparing the pixel\u2019s representations with precomputed prototypes. Assembling them together, semantic segmentation results can be derived from the model without any finetuning. With only a single example per class, our approach achieves up to 51.4% mIoU on the challenging PASCAL VOC 2012 val set without any training using masks, demonstrating the effectiveness of the approach.",
        "paperId": "08872b81ce754602c19d533efa779a6826d7f440"
    },
    {
        "title": "CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study",
        "firstAuthor": "Zihan Guan",
        "url": "https://arxiv.org/pdf/2307.11346",
        "dateSubmitted": "2023-07-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Participant recruitment based on unstructured medical texts such as clinical notes and radiology reports has been a challenging yet important task for the cohort establishment in clinical research. Recently, Large Language Models (LLMs) such as ChatGPT have achieved tremendous success in various downstream tasks thanks to their promising performance in language understanding, inference, and generation. It is then natural to test their feasibility in solving the cohort recruitment task, which involves the classification of a given paragraph of medical text into disease label(s). However, when applied to knowledge-intensive problem settings such as medical text classification, where the LLMs are expected to understand the decision made by human experts and accurately identify the implied disease labels, the LLMs show a mediocre performance. A possible explanation is that, by only using the medical text, the LLMs neglect to use the rich context of additional information that languages afford. To this end, we propose to use a knowledge graph as auxiliary information to guide the LLMs in making predictions. Moreover, to further boost the LLMs adapt to the problem setting, we apply a chain-of-thought (CoT) sample selection strategy enhanced by reinforcement learning, which selects a set of CoT samples given each individual medical report. Experimental results and various ablation studies show that our few-shot learning method achieves satisfactory performance compared with fine-tuning strategies and gains superb advantages when the available data is limited. The code and sample dataset of the proposed CohortGPT model is available at: https://anonymous.4open.science/r/CohortGPT-4872/",
        "paperId": "089f6328085066263fedc083952624ca121ebbf3"
    },
    {
        "title": "Semi-Supervised Few-Shot Learning with Prototypical Random Walks",
        "firstAuthor": "A. Ayyad",
        "url": null,
        "dateSubmitted": "2019-09-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent progress has shown that few-shot learning can be improved with access to unlabelled data, known as semi-supervised few-shot learning(SS-FSL). We introduce an SS-FSL approach, dubbed as Prototypical Random Walk Networks(PRWN), built on top of Prototypical Networks (PN). We develop a random walk semi-supervised loss that enables the network to learn representations that are compact and well-separated. Our work is related to the very recent development on graph-based approaches for few-shot learning. However, we show that compact and well-separated class representations can be achieved by modeling our prototypical random walk notion without needing additional graph-NN parameters or requiring a transductive setting where collective test set is provided. Our model outperforms prior art in most benchmarks with significant improvements in some cases. For example, in a mini-Imagenet 5-shot classification task, we obtain 69.65$\\%$ accuracy to the 64.59$\\%$ state-of-the-art. Our model, trained with 40$\\%$ of the data as labelled, compares competitively against fully supervised prototypical networks, trained on 100$\\%$ of the labels, even outperforming it in the 1-shot mini-Imagenet case with 50.89$\\%$ to 49.4$\\%$ accuracy. We also show that our model is resistant to distractors, unlabeled data that does not belong to any of the training classes, and hence reflecting robustness to labelled/unlabelled class distribution mismatch. We also performed a challenging discriminative power test, showing a relative improvement on top of the baseline of $\\approx$14\\% on 20 classes on mini-Imagenet and $\\approx$60\\% on 800 classes on Omniglot. Code will be made available.",
        "paperId": "08d2a01979a273766178c734e1478c68910a8e2b"
    },
    {
        "title": "Evolving Deep Learning Models for Epilepsy Diagnosis in Data Scarcity Context: A Survey",
        "firstAuthor": "Raghdah Saem Aldahr",
        "url": null,
        "dateSubmitted": "2022-07-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recently, Epilepsy disorder has increasingly affected a large number of people worldwide, and it is a complex neurological condition characterized as recurrent, involuntary, paroxysmal seizure activity. Automated epilepsy diagnosis is vital to address the clinical gaps and impediments in epilepsy detection, prediction, and localization. Epilepsy diagnosis utilizes the EEG signals and adopts the Artificial Intelligence (AI) models to detect, predict, and localize seizure patterns in an automated manner. Even though deep neural networks have gained significant attention in epileptic seizure recognition, data scarcity is a primary constraint. Thus, this survey studies the emerging learning models that can address the scarcity of data on epilepsy diagnosis. In this context, to resolve the data scarcity, this work investigates the emerging learning models, including Few-shot Learning, Metric Learning, Self-Supervised Learning, Siamese Neural Networks, and Capsule Neural Networks. In particular, it reviews the epilepsy detection, prediction, and localization research works that address the data scarcity constraint on benchmark EEG datasets and possible solutions. Further, this survey concludes with research challenges, opportunities, and future research directions for building automated epilepsy diagnosis systems. As a result, this survey accentuates epilepsy researchers toward designing a reliable and robust epilepsy diagnosis model that efficiently works on EEG datasets with data scarcity.",
        "paperId": "08d5111d647c7e2ee0db5692248897b3c3c45414"
    },
    {
        "title": "Exploring lottery ticket hypothesis in few-shot learning",
        "firstAuthor": "Yu Xie",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "08da581d83a695ae17784b590f91ab10ecd00872"
    },
    {
        "title": "Sinc-based Multiplication-Convolution Network for Equipment Intelligent Edge Diagnosis under Small Samples",
        "firstAuthor": "Rui Liu",
        "url": null,
        "dateSubmitted": "2022-11-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Data-driven intelligent diagnosis models need massive monitoring data to train themselves for desired performance. However, in many engineering scenarios, collecting fault data is often expensive and time-consuming, which leads to few-shot learning becoming a valuable research hotspot for intelligent diagnosis. Inspired by mode characteristics and feature enhancement learning, this study propose a Sinc-based multiplication-convolution network (SincMCN) for intelligent fault diagnosis under small samples. It works in frequency domain, and consists of only three layers, including a feature separator, a feature extractor and a classifier. In the feature separator, a series of Sinc-based multiplication filtering kernels (SincMFKs) are designed for improving the utilization of fault information of spectrum samples. The products between SincMFKs and spectrum samples are stacked into activated mode spectrum images (AMSIs) with rich fault-related features retained. Since AMSIs are concise enough, this study employs only a 2D convolutional layer and a fully connected layer as the feature extractor and the classifier for achieving a fast and precise pattern recognition. Experimental results show SincMCN has better diagnosis accuracy and stronger potentials for few-shot diagnosis compared other cutting-edge models. Specially, analytic filtering kernels not only cut down the model parameters for edge diagnosis and provide powerful application potentials and engineering value for online monitoring of rotating machinery.",
        "paperId": "0919dbad920bd57762f321e2bb6aa43277f284b6"
    },
    {
        "title": "Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations",
        "firstAuthor": "Xinxi Lyu",
        "url": "http://arxiv.org/pdf/2212.09865",
        "dateSubmitted": "2022-12-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Although large language models can be prompted for both zero- and few-shot learning, performance drops significantly when no demonstrations are available. In this paper, we introduce Z-ICL, a new zero-shot method that closes the gap by constructing pseudo-demonstrations for a given test input using a raw text corpus. Concretely, pseudo-demonstrations are constructed by (1) finding the nearest neighbors to the test input from the corpus and pairing them with random task labels, and (2) applying a set of techniques to reduce the amount of direct copying the model does from the resulting demonstrations. Evaluation on nine classification datasets shows that Z-ICL outperforms previous zero-shot methods by a significant margin, and is on par with in-context learning with labeled training data in the few-shot setting. Overall, Z-ICL provides a significantly higher estimate of the zero-shot performance levels of a model, and supports future efforts to develop better pseudo-demonstrations that further improve zero-shot results.",
        "paperId": "0942bd8fad71282994ff4e9a779c09745da68edc"
    },
    {
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "firstAuthor": "Aakanksha Chowdhery",
        "url": null,
        "dateSubmitted": "2022-04-05",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.",
        "paperId": "094ff971d6a8b8ff870946c9b3ce5aa173617bfb"
    },
    {
        "title": "Deep Learning for Cross-Domain Few-Shot Visual Recognition: A Survey",
        "firstAuthor": "Huali Xu",
        "url": "http://arxiv.org/pdf/2303.08557",
        "dateSubmitted": "2023-03-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deep learning has been highly successful in computer vision with large amounts of labeled data, but struggles with limited labeled training data. To address this, Few-shot learning (FSL) is proposed, but it assumes that all samples (including source and target task data, where target tasks are performed with prior knowledge from source ones) are from the same domain, which is a stringent assumption in the real world. To alleviate this limitation, Cross-domain few-shot learning (CDFSL) has gained attention as it allows source and target data from different domains and label spaces. This paper provides a comprehensive review of CDFSL at the first time, which has received far less attention than FSL due to its unique setup and difficulties. We expect this paper to serve as both a position paper and a tutorial for those doing research in CDFSL. This review first introduces the definition of CDFSL and the issues involved, followed by the core scientific question and challenge. A comprehensive review of validated CDFSL approaches from the existing literature is then presented, along with their detailed descriptions based on a rigorous taxonomy. Furthermore, this paper outlines and discusses several promising directions of CDFSL that deserve further scientific investigation, covering aspects of problem setups, applications and theories.",
        "paperId": "095138d9207da38bce4914c569e2f312927213b5"
    },
    {
        "title": "Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer",
        "firstAuthor": "F. Guo",
        "url": "https://arxiv.org/pdf/2205.15290",
        "dateSubmitted": "2022-05-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Lung cancer is the leading cause of cancer-related death worldwide. Lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LUSC) are the most common histologic subtypes of non-small-cell lung cancer (NSCLC). Histology is an essential tool for lung cancer diagnosis. Pathologists make classifications according to the dominant subtypes. Although morphology remains the standard for diagnosis, significant tool needs to be developed to elucidate the diagnosis. In our study, we utilize the pre-trained Vision Transformer (ViT) model to classify multiple label lung cancer on histologic slices (from dataset LC25000), in both Zero-Shot and Few-Shot settings. Then we compare the performance of Zero-Shot and Few-Shot ViT on accuracy, precision, recall, sensitivity and specificity. Our study show that the pre-trained ViT model has a good performance in Zero-Shot setting, a competitive accuracy ($99.87\\%$) in Few-Shot setting ({epoch = 1}) and an optimal result ($100.00\\%$ on both validation set and test set) in Few-Shot seeting ({epoch = 5}).",
        "paperId": "0953ada119f384f328b6102e6b7963b3bde7cc9e"
    },
    {
        "title": "MDFS-Net: Multidomain Few Shot Classification for Hyperspectral Images With Support Set Reconstruction",
        "firstAuthor": "Ankit Jha",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deep neural networks are highly specialized for a given task and visual domain, which can limit their practical use. To address this issue, recent studies have proposed to learn universal feature extractors that can be used across multiple domains simultaneously, inspired by the success of transfer learning (TL). However, these universal features are still inferior to specialized networks. In the context of hyperspectral image (HSI) classification, the lack of labeled training samples due to high cost and the restriction to single-domain learning further complicates the problem. To overcome these challenges, we propose a solution that combines the problems of multidomain learning (MDL) and few-shot learning (FSL) for HSI classification. Our goal is to train a highly shareable network with all domains in the low-shot training regime. We call our network the multidomain few-shot network (MDFS-Net), which shares the majority of model parameters (specifically, convolution and dense layer parameters) across domains while keeping domain-specific batch-normalization layers separate to capture domain characteristics. To address the overfitting issue in few-shot models, we supplement the main classification task with an auxiliary self-supervised task. We test our proposed method on five benchmark HSI datasets and find that MDFS-Net consistently outperforms relevant baselines convincingly. Our approach offers a promising solution for HSI classification in remote sensing (RS) by enabling the design of a unified classification system that can work with multiple HSI sites (domains) and fewer labeled samples.",
        "paperId": "096c54aa19d39a073b32a7766664d0228ee63508"
    },
    {
        "title": "A Bridge Between Hyperparameter Optimization and Larning-to-learn",
        "firstAuthor": "Luca Franceschi",
        "url": null,
        "dateSubmitted": "2017-12-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We consider a class of a nested optimization problems involving inner and outer objectives. We observe that by taking into explicit account the optimization dynamics for the inner objective it is possible to derive a general framework that unifies gradient-based hyperparameter optimization and meta-learning (or learning-to-learn). Depending on the specific setting, the variables of the outer objective take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We show that some recently proposed methods in the latter setting can be instantiated in our framework and tackled with the same gradient-based algorithms. Finally, we discuss possible design patterns for learning-to-learn and present encouraging preliminary experiments for few-shot learning.",
        "paperId": "0971f1a538c2b69291a4bac8ee7710c89fb6df34"
    },
    {
        "title": "Overleaf Example",
        "firstAuthor": "A. Sathyamoorthy",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We propose a novel method for autonomous legged robot navigation in densely vegetated environments with a variety of pliable/traversable and non-pliable/untraversable vegetation. We present a novel few-shot learning classifier that can be trained on a few hundred RGB images to differentiate flora that can be navigated through, from the ones that must be circumvented. Using the vegetation classification and 2D lidar scans, our method constructs a vegetation-aware traversability cost map that accurately represents the pliable and non-pliable obstacles with lower, and higher traversability costs, respectively. Our cost map construction accounts for misclassifications of the vegetation and further lowers the risk of collisions, freezing and entrapment in vegetation during navigation. Furthermore, we propose holonomic recovery behaviors for the robot for scenarios where it freezes, or gets physically entrapped in dense, pliable vegetation. We demonstrate our method on a Boston Dynamics Spot robot in real-world unstructured environments with sparse and dense tall grass, bushes, trees, etc. We observe an increase of 25-90% in success rates, 10-90% decrease in freezing rate, and up to 65% decrease in the false positive rate compared to existing methods.",
        "paperId": "0975241e605761306e370c13f2cba8d3bb212a8b"
    },
    {
        "title": "Application of New Sensor Technology and Few-Shot Learning in Education Based on IoT Era",
        "firstAuthor": "Jianwen Feng",
        "url": "https://downloads.hindawi.com/journals/cin/2022/3965416.pdf",
        "dateSubmitted": "2022-07-04",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In recent years, with the rapid development of emerging Internet of Things technology and short-range wireless communication technology, smart healthcare monitoring network technology has become a research hotspot. It provides convenience for people and enhances the development of people's own healthcare awareness. This paper aims to study how to make its application in the field of smart healthcare education more applicable through the use of related technologies in the Internet of Things era and few-shot learning. For this reason, this paper proposes to optimize and improve the new sensor technology and the algorithm of few-shot learning, and to adjust some parameters as a whole. At the same time, related experiments and analysis are designed for the improved algorithm to study and understand its performance. The experimental results in this paper show that the improved algorithm improves its application effect by 36.9% and is relatively more applicable than the unimproved algorithm.",
        "paperId": "09794b810fd43f6d3f8b05eb7e390105f2f78477"
    },
    {
        "title": "Detecting Hate Speech with GPT-3",
        "firstAuthor": "Ke-Li Chiu",
        "url": null,
        "dateSubmitted": "2021-03-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Sophisticated language models such as OpenAI's GPT-3 can generate hateful text that targets marginalized groups. Given this capacity, we are interested in whether large language models can be used to identify hate speech and classify text as sexist or racist. We use GPT-3 to identify sexist and racist text passages with zero-, one-, and few-shot learning. We find that with zero- and one-shot learning, GPT-3 can identify sexist or racist text with an average accuracy between 55 per cent and 67 per cent, depending on the category of text and type of learning. With few-shot learning, the model's accuracy can be as high as 85 per cent. Large language models have a role to play in hate speech detection, and with further development they could eventually be used to counter hate speech.",
        "paperId": "098370508aaf56f718a472511987ac2072d0f917"
    },
    {
        "title": "Edge-Labeling Graph Neural Network for Few-Shot Learning",
        "firstAuthor": "Jongmin Kim",
        "url": "https://arxiv.org/pdf/1905.01436",
        "dateSubmitted": "2019-05-04",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this paper, we propose a novel edge-labeling graph neural network (EGNN), which adapts a deep neural network on the edge-labeling graph, for few-shot learning. The previous graph neural network (GNN) approaches in few-shot learning have been based on the node-labeling framework, which implicitly models the intra-cluster similarity and the inter-cluster dissimilarity. In contrast, the proposed EGNN learns to predict the edge-labels rather than the node-labels on the graph that enables the evolution of an explicit clustering by iteratively updating the edge-labels with direct exploitation of both intra-cluster similarity and the inter-cluster dissimilarity. It is also well suited for performing on various numbers of classes without retraining, and can be easily extended to perform a transductive inference. The parameters of the EGNN are learned by episodic training with an edge-labeling loss to obtain a well-generalizable model for unseen low-data problem. On both of the supervised and semi-supervised few-shot image classification tasks with two benchmark datasets, the proposed EGNN significantly improves the performances over the existing GNNs.",
        "paperId": "098b138f58e43338248e3bc35cb36adfed8008d1"
    },
    {
        "title": "Few-shot Image Recognition with Manifolds",
        "firstAuthor": "Debasmit Das",
        "url": "https://arxiv.org/pdf/2010.12084",
        "dateSubmitted": "2020-10-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "098d671d74fc83f4293cd602660ca18893a3c448"
    },
    {
        "title": "Long-tail learning with attributes",
        "firstAuthor": "Dvir Samuel",
        "url": null,
        "dateSubmitted": "2020-04-05",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Learning to classify images with unbalanced class distributions is challenged by two effects: It is hard to learn tail classes that have few samples, and it is hard to adapt a single model to both richly-sampled and poorly-sampled classes. To address few-shot learning of tail classes, it is useful to fuse additional information in the form of semantic attributes and classify based on multi-modal information. Unfortunately, as we show below, unbalanced data leads to a \"familiarity bias\", where classifiers favor sample-rich classes. This bias and lack of calibrated predictions make it hard to fuse correctly information from multiple modalities like vision and attributes. Here we describe DRAGON, a novel modular architecture for long-tail learning designed to address these biases and fuse multi-modal information in face of unbalanced data. Our architecture is based on three classifiers: a vision expert, a semantic attribute expert that excels on the tail classes, and a debias-and-fuse module to combine their predictions. We present the first benchmark for long-tail learning with attributes and use it to evaluate DRAGON. DRAGON outperforms state-of-the-art long-tail learning models and Generalized Few-Shot-Learning with attributes (GFSL-a) models. DRAGON also obtains SoTA in some existing benchmarks for single-modality GFSL.",
        "paperId": "099585892d4ec871a9cef371e8698c314e361dd6"
    },
    {
        "title": "Federated Few-Shot Learning with Adversarial Learning",
        "firstAuthor": "Chenyou Fan",
        "url": "https://arxiv.org/pdf/2104.00365",
        "dateSubmitted": "2021-04-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We are interested in developing a unified machine learning framework for effectively training machine learning models from many small data sources such as mobile devices. This is a commonly encountered situation in mobile computing scenarios, where data is scarce and distributed while the tasks are distinct. In this paper, we propose a federated few-shot learning (FedFSL) framework to learn a few-shot classification model that can classify unseen data classes with only a few labeled samples. With the federated learning strategy, FedFSL can utilize many data sources while keeping data privacy and communication efficiency. To tackle the issue of obtaining misaligned decision boundaries produced by client models, we propose to regularize local updates by minimizing the divergence of client models. We also formulate the training in an adversarial fashion and optimize the client models to produce a discriminative feature space that can better represent unseen data samples. We demonstrate the intuitions and conduct experiments to show our approaches outperform baselines by more than 10% in learning benchmark vision tasks and 5% in language tasks.",
        "paperId": "09a19c117eb3f928426c5c4aace4f3cdd85ecf9f"
    },
    {
        "title": "Unified Vision and Language Prompt Learning",
        "firstAuthor": "Yuhang Zang",
        "url": "http://arxiv.org/pdf/2210.07225",
        "dateSubmitted": "2022-10-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prompt tuning, a parameter- and data-efficient transfer learning paradigm that tunes only a small number of parameters in a model's input space, has become a trend in the vision community since the emergence of large vision-language models like CLIP. We present a systematic study on two representative prompt tuning methods, namely text prompt tuning and visual prompt tuning. A major finding is that none of the unimodal prompt tuning methods performs consistently well: text prompt tuning fails on data with high intra-class visual variances while visual prompt tuning cannot handle low inter-class variances. To combine the best from both worlds, we propose a simple approach called Unified Prompt Tuning (UPT), which essentially learns a tiny neural network to jointly optimize prompts across different modalities. Extensive experiments on over 11 vision datasets show that UPT achieves a better trade-off than the unimodal counterparts on few-shot learning benchmarks, as well as on domain generalization benchmarks. Code and models will be released to facilitate future research.",
        "paperId": "09b7338021fff3200c2098b19824aecc83a66cb5"
    },
    {
        "title": "A hybrid approach with optimization-based and metric-based meta-learner for few-shot learning",
        "firstAuthor": "Duo Wang",
        "url": null,
        "dateSubmitted": "2019-07-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "09c132a39bd924e887944b768cb6f9a98148f2f1"
    },
    {
        "title": "Meta-Learning Divergences of Variational Inference",
        "firstAuthor": "Ruqi Zhang",
        "url": null,
        "dateSubmitted": "2020-07-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Variational inference (VI) plays an essential role in approximate Bayesian inference due to its computational efficiency and broad applicability. Crucial to the performance of VI is the selection of the associated divergence measure, as VI approximates the intractable distribution by minimizing this divergence. In this paper we propose a meta-learning algorithm to learn the divergence metric suited for the task of interest, automating the design of VI methods. In addition, we learn the initialization of the variational parameters without additional cost when our method is deployed in the few-shot learning scenarios. We demonstrate our approach outperforms standard VI on Gaussian mixture distribution approximation, Bayesian neural network regression, image generation with variational autoencoders and recommender systems with a partial variational autoencoder.",
        "paperId": "0a099b36dbda4c9c242f47df4a4f7c2666a68e61"
    },
    {
        "title": "On Codex Prompt Engineering for OCL Generation: An Empirical Study",
        "firstAuthor": "Seif Abukhalaf",
        "url": "https://arxiv.org/pdf/2303.16244",
        "dateSubmitted": "2023-03-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to Meta-Object Facility (MOF) models. OCL can provide precision and conciseness to UML models. Nevertheless, the unfamiliar syntax of OCL has hindered its adoption by software practitioners. LLMs, such as GPT-3, have made significant progress in many NLP tasks, such as text generation and semantic parsing. Similarly, researchers have improved on the downstream tasks by fine-tuning LLMs for the target task. Codex, a GPT-3 descendant by OpenAI, has been fine-tuned on publicly available code from GitHub and has proven the ability to generate code in many programming languages, powering the AI-pair programmer Copilot. One way to take advantage of Codex is to engineer prompts for the target downstream task. In this paper, we investigate the reliability of the OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications from various educational resources. We manually crafted a prompt template with slots to populate with the UML information and the target task in the prefix format to complete the template with the generated OCL constraint. We used both zero- and few-shot learning methods in the experiments. The evaluation is reported by measuring the syntactic validity and the execution accuracy metrics of the generated OCL constraints. Moreover, to get insight into how close or natural the generated OCL constraints are compared to human-written ones, we measured the cosine similarity between the sentence embedding of the correctly generated and human-written OCL constraints. Our findings suggest that by enriching the prompts with the UML information of the models and enabling few-shot learning, the reliability of the generated OCL constraints increases. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex.",
        "paperId": "0a0d6a98bd246a82aaaa9d33ec0eadf4ceae69dc"
    },
    {
        "title": "Exploiting Language Model Prompts Using Similarity Measures: A Case Study on the Word-in-Context Task",
        "firstAuthor": "Mohsen Tabasi",
        "url": "https://aclanthology.org/2022.acl-short.36.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "As a recent development in few-shot learning, prompt-based techniques have demonstrated promising potential in a variety of natural language processing tasks. However, despite proving competitive on most tasks in the GLUE and SuperGLUE benchmarks, existing prompt-based techniques fail on the semantic distinction task of the Word-in-Context (WiC) dataset. Specifically, none of the existing few-shot approaches (including the in-context learning of GPT-3) can attain a performance that is meaningfully different from the random baseline.Trying to fill this gap, we propose a new prompting technique, based on similarity metrics, which boosts few-shot performance to the level of fully supervised methods. Our simple adaptation shows that the failure of existing prompt-based techniques in semantic distinction is due to their improper configuration, rather than lack of relevant knowledge in the representations. We also show that this approach can be effectively extended to other downstream tasks for which a single prompt is sufficient.",
        "paperId": "0a0e48c469b124c9a03d4bc841311f59424e97f2"
    },
    {
        "title": "Multi-level Feature Representation and Multi-layered Fusion Contrast for Few-Shot Classification",
        "firstAuthor": "Wenqian Qin",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "\u2014Training a model that can quickly adapt to new tasks keeps a crucial challenge for few-shot learning. Approaches based on metric-learning are very popular and promising. However, the existing such approaches usually only rely on the feature information obtained in the last layer of the feature extraction backbone for similarity metric, and do not consider that the feature information obtained in multi-layered can be fully utilized. Furthermore, the targeted differentiation of features and the selection and construction of loss functions are usually ignored by these approaches, which will become important factors that limit the performance of the model. Therefore, a few-shot learning approach MFR-MFC with attention mechanism based on multi-level feature representation and multi-layered fusion contrast is proposed in this paper. First, multi-level feature representations are introduced when extracting features, feature information of multi-layers are used to perform information fusion, and then this information is utilized for subsequent metric. Then, when training the model, multi-level features are also used to introduce multi-layered fusion contrast. Additionally, an attention module is introduced in the feature extraction process to make the model obtain more discriminative information. Experiments have shown that the approach proposed in this paper has achieved excellent performance in few-shot classification and has significant advantages compared with advanced technologies.",
        "paperId": "0a14a30c1e454f445c897cf0c462af619a3e04bd"
    },
    {
        "title": "Multi-Modal Fusion by Meta-Initialization",
        "firstAuthor": "M. Jackson",
        "url": "http://arxiv.org/pdf/2210.04843",
        "dateSubmitted": "2022-10-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "When experience is scarce, models may have insufficient information to adapt to a new task. In this case, auxiliary information - such as a textual description of the task - can enable improved task inference and adaptation. In this work, we propose an extension to the Model-Agnostic Meta-Learning algorithm (MAML), which allows the model to adapt using auxiliary information as well as task experience. Our method, Fusion by Meta-Initialization (FuMI), conditions the model initialization on auxiliary information using a hypernetwork, rather than learning a single, task-agnostic initialization. Furthermore, motivated by the shortcomings of existing multi-modal few-shot learning benchmarks, we constructed iNat-Anim - a large-scale image classification dataset with succinct and visually pertinent textual class descriptions. On iNat-Anim, FuMI significantly outperforms uni-modal baselines such as MAML in the few-shot regime. The code for this project and a dataset exploration tool for iNat-Anim are publicly available at https://github.com/s-a-malik/multi-few .",
        "paperId": "0a30893af0dcc58147ea98de688902ddb7902fe0"
    },
    {
        "title": "SMAE: Few-shot Learning for HDR Deghosting with Saturation-Aware Masked Autoencoders",
        "firstAuthor": "Qingsen Yan",
        "url": "https://arxiv.org/pdf/2304.06914",
        "dateSubmitted": "2023-04-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Generating a high-quality High Dynamic Range (HDR) image from dynamic scenes has recently been extensively studied by exploiting Deep Neural Networks (DNNs). Most DNNs-based methods require a large amount of training data with ground truth, requiring tedious and time-consuming work. Few-shot HDR imaging aims to generate satisfactory images with limited data. However, it is difficult for modern DNNs to avoid overfitting when trained on only a few images. In this work, we propose a novel semi-supervised approach to realize few-shot HDR imaging via two stages of training, called SSHDR. Unlikely previous methods, directly recovering content and removing ghosts simultaneously, which is hard to achieve optimum, we first generate content of saturated regions with a self-supervised mechanism and then address ghosts via an iterative semi-supervised learning framework. Concretely, considering that saturated regions can be regarded as masking Low Dynamic Range (LDR) input regions, we design a Saturated Mask AutoEncoder (SMAE) to learn a robust feature representation and reconstruct a non-saturated HDR image. We also propose an adaptive pseudo-label selection strategy to pick high-quality HDR pseudo-labels in the second stage to avoid the effect of mislabeled samples. Experiments demonstrate that SSHDR outperforms state-of-the-art methods quantitatively and qualitatively within and across different datasets, achieving appealing HDR visualization with few labeled samples.",
        "paperId": "0a32ba84d37bdcfab87791be8c162e8725dbb214"
    },
    {
        "title": "Emotion recognition from facial expressions for 3D videos using siamese network",
        "firstAuthor": "Divina Lawrance",
        "url": null,
        "dateSubmitted": "2021-06-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this work, we have proposed STLEV (Siamese Neural Network with Triplet Loss and Long Short-Term Memory for Emotion recognition in Videos) a method for emotion recognition in videos. This method is beneficial for cognitive Human-Computer interaction. Emotion recognition from video is a challenging task as only few frames of a video will contain relevant information for recognizing emotions. Also identifying the apex frame is challenging. Emotion recognition from videos involves extracting the features from the frames of a video and classifying the sequence of features. For feature extraction we have used Siamese Neural Network (SNN) which is metric based meta-learning model. SNN is trained with triplet loss. For classification, Long Shot-Term Memory (LSTM) model is used. In this work we have used spatial and temporal aspects of video. Spatial features are extracted using SNN and temporal features using LSTM. Deep learning models need large amount of data for good accuracy. We have addressed this problem by leveraging few shot learning aspects of metric meta-learning so that fewer samples are needed for training the model used for feature extraction. Experiments done using BU-4DFE dataset achieved an accuracy of 87.5% which demonstrates the efficiency of the method STLEV.",
        "paperId": "0a3ce81792bddd1ae6b54a88f6c651c32954fc20"
    },
    {
        "title": "\u7269\u4f53\u3089\u3057\u3055\u3092\u7528\u3044\u305fFew-Shot Learning\u306e\u305f\u3081\u306e\u30c7\u30fc\u30bf\u5897\u5f37\u30a2\u30d7\u30ed\u30fc\u30c1\u306e\u691c\u8a0e",
        "firstAuthor": "\u9032 \u677e\u898b",
        "url": null,
        "dateSubmitted": "2020-02-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0a405019e3281fe74d98b92b8765a8cc2d78fc2c"
    },
    {
        "title": "Prospectivity Mapping of Tungsten Mineralization in Southern Jiangxi Province Using Few-Shot Learning",
        "firstAuthor": "Kai Zhou",
        "url": "https://www.mdpi.com/2075-163X/13/5/669/pdf?version=1683967360",
        "dateSubmitted": "2023-05-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The development of mineral prospectivity mapping (MPM), which aims to outline and prioritize mineral exploration targets, has been spurred by advances in data-driven machine learning algorithms. Supervised data-driven MPM is a typical few-shot task, suffering from a scarcity of labeled data, the over-fitting of models and an uncertainty of predictions. The main objective of this contribution is to propose a robust framework of few-shot learning (FSL), combining data augmentation and transfer learning to enable the generation of prospectivity models with excellent predictive efficiency and low uncertainty. The mineral systems approach was used to transfer a conceptual mineral system into mappable exploration criteria. Synthetic minority over-sampling technique (SMOTE) was employed to augment and balance the labeled dataset, allowing for model pre-training with the large synthetic training dataset of a source domain. The knowledge derived from pre-trained models was then transferred to the target domain by fine-tuning, and the prospectivity model was generated in light of over-fitting and uncertainty assessments. The proposed FSL framework was applied to tungsten prospectivity mapping in southern Jiangxi Province. The results indicated that the SMOTE-ed balanced dataset boosted the classification accuracy in the training process. The FSL models yielded an arch-shaped prediction point pattern which was favorable for focusing potential targets with high probability and low uncertainty. The FSL models achieved a high predictive performance (test AUC = 0.9172) and the lowest quantitative over-fitting value compared to the models derived from the benchmark algorithms of random forest and support vector machine. Four levels of potential targeting zones, considering both predictive efficiency and uncertainty, were extracted from the resulting FSL prospectivity map. The final high-potential and low-risk exploration targets only cover 4.27% of the area, but capture 41.53% of known tungsten deposits, thus achieving a superior predictive performance. This study highlights the capability of FSL framework to control over-fitting and generate high-confidence exploration targets with low levels of uncertainty.",
        "paperId": "0a4598da57b5aa259acd8aac3da45596bff6fa7c"
    },
    {
        "title": "State of health estimation for lithium-ion batteries on few-shot learning",
        "firstAuthor": "Shuxin Zhang",
        "url": null,
        "dateSubmitted": "2023-04-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0a4d4f3655d2e945e5f343c5ef3da5521283ef72"
    },
    {
        "title": "Exploiting the Matching Information in the Support Set for Few Shot Event Classification",
        "firstAuthor": "Viet Dac Lai",
        "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-47436-2_18.pdf",
        "dateSubmitted": "2020-02-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0a525eee04c67072508117e9d4c2d80972c1180d"
    },
    {
        "title": "ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning",
        "firstAuthor": "Yi Rong",
        "url": "http://arxiv.org/pdf/2304.13287",
        "dateSubmitted": "2023-04-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and the transformed one. With this definition, the ESPT-augmented FSL objective promotes learning more transferable feature representations that capture the local spatial features of different images and their inter-relational structural information in each input episode, thus enabling the model to generalize better to new categories with only a few samples. Extensive experiments indicate that our ESPT method achieves new state-of-the-art performance for few-shot image classification on three mainstay benchmark datasets. The source code will be available at: https://github.com/Whut-YiRong/ESPT.",
        "paperId": "0a52f77490300be671942909e09b4ee87e7f23a0"
    },
    {
        "title": "Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning",
        "firstAuthor": "Shaohua Wu",
        "url": null,
        "dateSubmitted": "2021-10-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent work like GPT-3 has demonstrated excellent performance of Zero-Shot and Few-Shot learning on many natural language processing (NLP) tasks by scaling up model size, dataset size and the amount of computation. However, training a model like GPT-3 requires huge amount of computational resources which makes it challengeable to researchers. In this work, we propose a method that incorporates large-scale distributed training performance into model architecture design. With this method, Yuan 1.0, the current largest singleton language model with 245B parameters, achieves excellent performance on thousands GPUs during training, and the state-of-the-art results on NLP tasks. A data processing method is designed to efficiently filter massive amount of raw data. The current largest high-quality Chinese corpus with 5TB high quality texts is built based on this method. In addition, a calibration and label expansion method is proposed to improve the Zero-Shot and Few-Shot performance, and steady improvement is observed on the accuracy of various tasks. Yuan 1.0 presents strong capacity of natural language generation, and the generated articles are difficult to distinguish from the human-written ones.",
        "paperId": "0ab41d455d676542b37ca1499bb19ea6a5d1cf79"
    },
    {
        "title": "FeLMi : Few shot Learning with hard Mixup",
        "firstAuthor": "A. Roy",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0abae4f143c00f0a18f1920c73bca1cfb550f1c5"
    },
    {
        "title": "Hyperspectral Classification of Frost Damage Stress in Tomato Plants Based on Few-Shot Learning",
        "firstAuthor": "Shiwei Ruan",
        "url": "https://www.mdpi.com/2073-4395/13/9/2348/pdf?version=1694248497",
        "dateSubmitted": "2023-09-09",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Early detection and diagnosis of crop anomalies is crucial for enhancing crop yield and quality. Recently, the combination of machine learning and deep learning with hyperspectral images has significantly improved the efficiency of crop detection. However, acquiring a large amount of properly annotated hyperspectral data on stressed crops requires extensive biochemical experiments and specialized knowledge. This limitation poses a challenge to the construction of large-scale datasets for crop stress analysis. Meta-learning is a learning approach that is capable of learning to learn and can achieve high detection accuracy with limited training samples. In this paper, we introduce meta-learning to hyperspectral imaging and crop detection for the first time. In addition, we gathered 88 hyperspectral images of drought-stressed tomato plants and 68 images of freeze-stressed tomato plants. The data related to drought serve as the source domain, while the data related to frost damage serve as the target domain. Due to the difficulty of obtaining target domain data from real-world testing scenarios, only a limited amount of target domain data and source domain data are used for model training. The results indicated that meta-learning, with a minimum of eight target domain samples, achieved a detection accuracy of 69.57%, precision of 59.29%, recall of 66.32% and F1-score of 62.61% for classifying the severity of frost stress, surpassing other methods with a target domain sample size of 20. Moreover, for determining whether the plants were under stress, meta-learning, with a minimum of four target domain samples, achieved a detection accuracy of 89.1%, precision of 89.72%, recall of 93.08% and F1-score of 91.37% outperforming other methods at a target domain sample size of 20. The results show that meta-learning methods require significantly less data across different domains compared to other methods. The performance of meta-learning techniques thoroughly demonstrates the feasibility of rapidly detecting crop stress without the need for collecting a large amount of target stress data. This research alleviates the data annotation pressure for researchers and provides a foundation for detection personnel to anticipate and prevent potential large-scale stress damage to crops.",
        "paperId": "0acabdcce3f1f64740b9feb068ca11108b84e369"
    },
    {
        "title": "Distribution Consistency Based Covariance Metric Networks for Few-Shot Learning",
        "firstAuthor": "Wenbin Li",
        "url": "https://ojs.aaai.org/index.php/AAAI/article/download/4885/4758",
        "dateSubmitted": "2019-07-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning aims to recognize new concepts from very few examples. However, most of the existing few-shot learning methods mainly concentrate on the first-order statistic of concept representation or a fixed metric on the relation between a sample and a concept. In this work, we propose a novel end-to-end deep architecture, named Covariance Metric Networks (CovaMNet). The CovaMNet is designed to exploit both the covariance representation and covariance metric based on the distribution consistency for the few-shot classification tasks. Specifically, we construct an embedded local covariance representation to extract the second-order statistic information of each concept and describe the underlying distribution of this concept. Upon the covariance representation, we further define a new deep covariance metric to measure the consistency of distributions between query samples and new concepts. Furthermore, we employ the episodic training mechanism to train the entire network in an end-to-end manner from scratch. Extensive experiments in two tasks, generic few-shot image classification and fine-grained fewshot image classification, demonstrate the superiority of the proposed CovaMNet. The source code can be available from https://github.com/WenbinLee/CovaMNet.git.",
        "paperId": "0ae1c3d49952f33df628f5d8476fed692e5f6027"
    },
    {
        "title": "Variational Inference on Decomposition of Conceptual Knowledge for Few-Shot Learning",
        "firstAuthor": "Lei Su",
        "url": null,
        "dateSubmitted": "2022-11-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning (FSL) aims at learning a model to generalize well on new tasks with limited training examples. In this paper, we propose a new FSL model called Variational Conceptual Decomposition Network (VCDNet) that learns to decompose the image representation from the conceptual level for maintaining both generalization and discrimination capabilities when adapting to new data. Specifically, the decomposition is accomplished by variational inference on the disentanglement of a frame feature and a salient feature that represent the conceptual structure and the discriminative detailed information for generating the distribution over the images, respectively. In addition, we introduce an adversarial classification method to further guide the decomposition conducted on the conceptual knowledge level. Our experiments on the CIFAR-FS dataset demonstrate that the proposed VCDNet outperforms many competitive baselines.",
        "paperId": "0aed186b989d6e236df0b12603127168b1e0e535"
    },
    {
        "title": "Few-shot learning for image-based bridge damage detection",
        "firstAuthor": "Yan Gao",
        "url": null,
        "dateSubmitted": "2023-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0aefa69e41012dffa7ddbac1cd1f1547276a7076"
    },
    {
        "title": "Key Phrases Annotation in Medical Documents: MEDDOCAN 2019 Anonymization Task",
        "firstAuthor": "Alicia Lara-Clares",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "There is a vast amount of digitized information about medical records, treatments and diseases, that used to be in an unstructured or semi-structured format. In order to take advantage of all the potential data that can be extracted from this information, it is necessary to deploy systems capable of converting it into annotated and structured information. In the context of the MEDDOCAN shared task of IberLEF2019, we use a Few-Shot Learning approach for Named Entity Recognition (NER) in medical documents to identify and classify key phrases in a document. The architecture of the system is an hybrid Bi-LSTM and CNN model with four input layers that can recognize multi-word entities using the BIO encoding format for the labels.",
        "paperId": "0b083d574f5248cad493cd157e036a7f67df2ef8"
    },
    {
        "title": "Episode Difficulty Based Sampling Method for Few-Shot Classification",
        "firstAuthor": "Hochang Rhee",
        "url": null,
        "dateSubmitted": "2022-10-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Most methods in few-shot learning adopt episodic training, where classes for generating episodes are randomly sampled. Here, most of the episodes are easily solvable, i.e., the dataset in terms of the episodes becomes biased towards easy ones. In this paper, we propose a novel sampling method named Episode Difficulty Based Sampling (EDBS) that aims to remove the dataset bias in terms of episode difficulty. We define the episode difficulty to be proportional to the similarity between the classes composing the episode. Then we determine an episode as easy or hard depending on their episode difficulty and design a balanced episode dataset in terms of the difficulty. Through our EDBS, few-shot networks become less biased to the easy episodes and learn detailed features necessary for solving challenging episodes. Experiments demonstrate that our sampling method is widely applicable and achieves state-of-the-art performance in the benchmarks.",
        "paperId": "0b09950a6f4c48277d04c4754d70daa3b0712f70"
    },
    {
        "title": "Task-distribution-aware Meta-learning for Cold-start CTR Prediction",
        "firstAuthor": "Tianwei Cao",
        "url": null,
        "dateSubmitted": "2020-10-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Nowadays, click-through rate (CTR) prediction has achieved great success in online advertising. However, making desirable predictions for unseen ads is still challenging, which is known as the cold-start problem. To address such a problem in CTR prediction, meta-learning methods have recently emerged as a popular direction. In these approaches, the predictions for each user/item are regarded as individual tasks, then training a meta-learner on them to implement zero-shot/few-shot learning for unknown tasks. Though these approaches have effectively alleviated the cold-start problem, two facts are not paid enough attention, 1) the diversity of the task difficulty and 2) the perturbation of the task distribution. In this paper, we propose an adaptive loss that ensures the consistency between the task weight and difficulty. Interestingly, the loss function can also be viewed as a description of the worst-case performance under distribution perturbation. Moreover, we develop an algorithm, under the framework of gradient descent with max-oracle (GDmax), to minimize such an adaptive loss. Then we prove the algorithm can return to a stationary point of the adaptive loss. Finally, we implement our method on top of the meta-embedding framework and conduct experiments on three real-world datasets. The experiments show that our proposed method significantly improves the predictions in the cold-start scenario.",
        "paperId": "0b0e3d74d9cc7da18f3653ba0f7c070ded31dab9"
    },
    {
        "title": "Few-Shot Link Prediction with Domain-Agnostic Graph Embedding",
        "firstAuthor": "Hao Zhu",
        "url": null,
        "dateSubmitted": "2022-12-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Real-world link prediction problems often deal with data from multiple domains, where data may be highly skewed and imbalanced. Computer vision research has studied similar issues under the Few-Shot Learning (FSL) umbrella. However, this problem has rarely been addressed and explored in the graph domain, specifically for link prediction. In this work, we propose an adversarial training-based framework that aims at improving link prediction for highly skewed and imbalanced graphs from different domains by generating domain agnostic embedding. We introduce a domain discriminator on pairs of graph-level embedding. We then use the discriminator to improve the model in an adversarial way, such that the graph embedding generated by the model are domain agnostic. We test our ideas on one large real-world user-business-review dataset and three benchmark datasets. Our results demonstrate that when domain differences exist, our method creates better graph embedding that are more evenly distributed across domains and generate better prediction outcomes. In the absence of domain differences, our method is on par with state-of-the-art.",
        "paperId": "0b103b507c5c602dc0d99b1e2f3d07f397600d49"
    },
    {
        "title": "MFNet: Multiclass Few-Shot Segmentation Network With Pixel-Wise Metric Learning",
        "firstAuthor": "Miao Zhang",
        "url": "https://arxiv.org/pdf/2111.00232",
        "dateSubmitted": "2021-10-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In visual recognition tasks, few-shot learning requires the ability to learn object categories with few support examples. Its re-popularity in light of the deep learning development is mainly in image classification. This work focuses on few-shot semantic segmentation, which is still a largely unexplored field. A few recent advances are often restricted to single-class few-shot segmentation. In this paper, we first present a novel multi-way (class) encoding and decoding architecture which effectively fuses multi-scale query information and multi-class support information into one query-support embedding. Multi-class segmentation is directly decoded upon this embedding. For better feature fusion, a multi-level attention mechanism is proposed within the architecture, which includes the attention for support feature modulation and attention for multi-scale combination. Last, to enhance the embedding space learning, an additional pixel-wise metric learning module is introduced with triplet loss formulated on the pixel-level of the query-support embedding. Extensive experiments on standard benchmarks PASCAL-<inline-formula> <tex-math notation=\"LaTeX\">$5^{i}$ </tex-math></inline-formula> and COCO-<inline-formula> <tex-math notation=\"LaTeX\">$20^{i}$ </tex-math></inline-formula> show clear benefits of our method over the state of the art in multi-class few-shot segmentation.",
        "paperId": "0b107fc7243033160634955816710fd545c51c49"
    },
    {
        "title": "Data Distributional Properties Drive Emergent Few-Shot Learning in Transformers",
        "firstAuthor": "Stephanie C. Y. Chan",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Large transformer-based language models are able to perform few-shot learning (also known as in-context learning), without having been explicitly trained for it. We hypothesized that speci\ufb01c distributional properties of natural language might drive this emergent phenomenon, as these characteristics might lead to a kind of interpolation between few-shot meta-training (designed to elicit rapid few-shot learning) and standard supervised training (designed to elicit gradual in-weights learning). We also hypothesized that these distributional properties could lead to emergent few-shot learning in domains outside of language. Inspired by this idea, we ran a series of experiments on a standard image-based few-shot dataset. We discovered that a number of data properties did indeed promote the emergence of few-shot learning in transformer models. All of these properties are present in natural language \u2013 burstiness, long-tailedness, and many-to-one or one-to-many label mappings. The data in\ufb02uenced whether models were biased towards either few-shot learning vs. memorizing information in their weights; models could generally perform well at only one or the other. However, we discovered that an additional distributional property could allow the two capabilities to co-exist in the same model \u2013 a skewed, Zip\ufb01an distribution over classes \u2013 which occurs in language as well. Notably, training data that could elicit few-shot learning in transformers were unable to elicit few-shot learning in recurrent models. In sum, we \ufb01nd that few-shot learning emerges only from applying the right architecture to the right data distribution; neither component is su\ufb03cient on its own. However, if we train on skewed distributions, there is a sweet spot where both few-shot learning and in-weights memorization can be maintained at a high level in the same model (Zipf exponent = 1, for this particular training regime). Intriguingly, a Zipf exponent of 1 corresponds approximately to the skew in many natural languages. Rare items from training are never memorized (performance is at chance for all Zipf exponents) (e).",
        "paperId": "0b18c6f168e1a6d2f16eaa317747748c5c4c5b63"
    },
    {
        "title": "Momentum memory contrastive learning for transfer-based few-shot classification",
        "firstAuthor": "Runliang Tian",
        "url": null,
        "dateSubmitted": "2022-04-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0b2b9cda21217e1b61112927f535b0700f91e48d"
    },
    {
        "title": "A Patch-as-Filter Method for Same-Different Problems with Few-Shot Learning",
        "firstAuthor": "Yining Hu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Convolutional Neural Network (CNN) has undergone tremendous advancements in recent years, but visual reasoning tasks are still a huge undertaking, particularly in few-shot learning cases. Little is known, especially in solving the Same-Different (SD) task, which is a type of visual reasoning task that requires seeking pattern repetitions in a single image. In this thesis, we propose a patch-as-filter method focusing on solving the SD tasks with few-shot learning. Firstly, a patch in an individual image is detected. Then, transformations are learned to create sample-specific convolutional filters. After applying these filters on the original input images, we, lastly, acquire feature maps indicating the duplicate segments. We show experimentally that our approach achieves the state-of-the-art few-shot performance on the Synthetic Visual Reasoning Test (SVRT) SD tasks by accuracy going up above 30% on average, with only ten training samples. Besides that, to further evaluate the effectiveness of our approach, SVRT-like tasks are generated with more difficult visual reasoning concepts. The results suggest that the average accuracy is increased by approximately 10% compared to several popular few-shot algorithms. The method we suggest here has shed new light upon new CNN approaches in solving the SD tasks with few-shot learning.",
        "paperId": "0b39b0712670481cb9241893d301492ea6e3be3f"
    },
    {
        "title": "Plug-and-Play Multilingual Few-shot Spoken Words Recognition",
        "firstAuthor": "Aaqib Saeed",
        "url": "http://arxiv.org/pdf/2305.03058",
        "dateSubmitted": "2023-05-03",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "As technology advances and digital devices become prevalent, seamless human-machine communication is increasingly gaining significance. The growing adoption of mobile, wearable, and other Internet of Things (IoT) devices has changed how we interact with these smart devices, making accurate spoken words recognition a crucial component for effective interaction. However, building robust spoken words detection system that can handle novel keywords remains challenging, especially for low-resource languages with limited training data. Here, we propose PLiX, a multilingual and plug-and-play keyword spotting system that leverages few-shot learning to harness massive real-world data and enable the recognition of unseen spoken words at test-time. Our few-shot deep models are learned with millions of one-second audio clips across 20 languages, achieving state-of-the-art performance while being highly efficient. Extensive evaluations show that PLiX can generalize to novel spoken words given as few as just one support example and performs well on unseen languages out of the box. We release models and inference code to serve as a foundation for future research and voice-enabled user interface development for emerging devices.",
        "paperId": "0b413633f14ec7f96948067abf1d4ca930fa38a1"
    },
    {
        "title": "Improving graph prototypical network using active learning",
        "firstAuthor": "Mona Solgi",
        "url": "https://link.springer.com/content/pdf/10.1007/s13748-022-00293-3.pdf",
        "dateSubmitted": "2022-10-10",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0b496e20dec12c87030d898daf8c795d3985a377"
    },
    {
        "title": "Channel-spatial attention network for fewshot classification",
        "firstAuthor": "Y. Zhang",
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0225426&type=printable",
        "dateSubmitted": "2019-12-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Learning a powerful representation for a class with few labeled samples is a challenging problem. Although some state-of-the-art few-shot learning algorithms perform well based on meta-learning, they only focus on novel network architecture and fail to take advantage of the knowledge of every classification task. In this paper, to accomplish this goal, it proposes to combine the channel attention and spatial attention module (C-SAM), the C-SAM can mine deeply more effective information using samples of different classes that exist in different tasks. The residual network is used to alleviate the loss of the underlying semantic information when the network is deeper. Finally, a relation network including a C-SAM is applied to act as a classifier, which avoids learning more redundant information and compares the relation between difference samples. The experiment was carried out using the proposed method on six datasets, such as miniimagenet, Omniglot, Caltech-UCSD Birds, describable textures dataset, Stanford Dogs and Stanford Cars. The experimental results show that the C-SAM outperforms many state-of-the-art few-shot classification methods.",
        "paperId": "0b554078c227bb883c10b17599f076390eb9cac0"
    },
    {
        "title": "Regularization with Multiple Feature Combination for Few-Shot Learning",
        "firstAuthor": "Su Been Lee",
        "url": null,
        "dateSubmitted": "2021-01-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning solves problems with a limited amount of labeled examples. Our analysis shows the existing metric-based methods concentrate on highly discriminative features while not fully utilizing whole capacity. In this work, we propose a novel regularization technique that constrains the model to exploit whole capacity by distinguishing data with multiple feature combinations. Our approach achieves state-of the-art performance in several public benchmarks compared to the existing metric-based methods.",
        "paperId": "0b5e29d41fb374dd11193d598c9b18b9c99f5bac"
    },
    {
        "title": "TAdaNet: Task-Adaptive Network for Graph-Enriched Meta-Learning",
        "firstAuthor": "Qiuling Suo",
        "url": null,
        "dateSubmitted": "2020-08-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Annotated data samples in real-world applications are often limited. Meta-learning, which utilizes prior knowledge learned from related tasks and generalizes to new tasks of limited supervised experience, is an effective approach for few-shot learning. However, standard meta-learning with globally shared knowledge cannot handle the task heterogeneity problem well, i.e., tasks lie in different distributions. Recent advances have explored several ways to trigger task-dependent initial parameters or metrics, in order to customize task-specific information. These approaches learn task contextual information from data, but ignore external domain knowledge that can help in the learning process. In this paper, we propose a task-adaptive network (TAdaNet) that makes use of a domain-knowledge graph to enrich data representations and provide task-specific customization. Specifically, we learn a task embedding that characterizes task relationships and tailors task-specific parameters, resulting in a task-adaptive metric space for classification. Experimental results on a few-shot image classification problem show the effectiveness of the proposed method. We also apply it on a real-world disease classification problem, and show promising results for clinical decision support.",
        "paperId": "0b5ed48c8b98950518061a1bb385cb176aec61e0"
    },
    {
        "title": "Deep few-shot learning for bi-temporal building change detection",
        "firstAuthor": "M. Khoshboresh-Masouleh",
        "url": "https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIV-M-3-2021/99/2021/isprs-archives-XLIV-M-3-2021-99-2021.pdf",
        "dateSubmitted": "2021-08-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Abstract. In real-world applications (e.g., change detection), annotating images is very expensive. To build effective deep learning models in these applications, deep few-shot learning methods have been developed and prove to be a robust approach in small training data. The study of building change detection from high spatial resolution satellite observations is important to research in remote sensing, photogrammetry, and computer vision nowadays, which can be widely used in a variety of real-world applications, such as map generation and updating. As manual high-resolution image interpretation is expensive and time-consuming, building change detection methods are of high interest. The interest in developing building change detection approaches from optical remote sensing images is rapidly increasing due to larger coverages, and lower costs of optical images. In this study, we focus on building change detection analysis on a small set of building changes from different regions that sit in several cities. In this paper, a new deep few-shot learning method is proposed for building change detection using Monte Carlo dropout and remote sensing observations. The setup is based on a small dataset, including bitemporal optical images labelled for building change detection.\n",
        "paperId": "0b614bf2be15248797559a823493546bc760e845"
    },
    {
        "title": "Multi-task learning of perceptive feature for thyroid malignant probability prediction",
        "firstAuthor": "Zixiong Gao",
        "url": null,
        "dateSubmitted": "2021-02-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In recent years many computer-aided diagnosis systems (CAD) using deep learning (DL) were developed for thyroid classification. However, most DL approaches have flawed clinical interpretation and often need a large amount of supervised data to ensure performance. For medical images, the costs of obtaining labeled data are relatively high, making the problem of few-shot learning (FSL) more common. We proposed a multi-task learning network for thyroid malignant probability prediction using perceptive interpretable features to overcome these limitations. With IRB approval, 1588 cases were collected with perceptive features diagnosed by experienced radiologists. The hard parameter sharing network was trained using perceptive features and pathological results as ground truth. Prior knowledge was embedded into the network by multi-task learning of perceptive features, which is how radiologists diagnose from ultrasound images. We trained the models using the 1345 cases and tested them with 243 cases. It was found that the improvement of the classifier with the proposed network (AUC of 0.879) to the baseline CNN (AUC of 0.779) was statistically significant (p <0.001).",
        "paperId": "0b6f9c8b6d29ddb156f268a2dbe98e68f51307cd"
    },
    {
        "title": "Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts",
        "firstAuthor": "Mohna Chakraborty",
        "url": "http://arxiv.org/pdf/2305.15689",
        "dateSubmitted": "2023-05-25",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent studies have demonstrated that natural-language prompts can help to leverage the knowledge learned by pre-trained language models for the binary sentence-level sentiment classification task. Specifically, these methods utilize few-shot learning settings to fine-tune the sentiment classification model using manual or automatically generated prompts. However, the performance of these methods is sensitive to the perturbations of the utilized prompts. Furthermore, these methods depend on a few labeled instances for automatic prompt generation and prompt ranking. This study aims to find high-quality prompts for the given task in a zero-shot setting. Given a base prompt, our proposed approach automatically generates multiple prompts similar to the base prompt employing positional, reasoning, and paraphrasing techniques and then ranks the prompts using a novel metric. We empirically demonstrate that the top-ranked prompts are high-quality and significantly outperform the base prompt and the prompts generated using few-shot learning for the binary sentence-level sentiment classification task.",
        "paperId": "0b71af0bf02ab58b8d8e342c1c803322cfede603"
    },
    {
        "title": "External-Memory Networks for Low-Shot Learning of Targets in Forward-Looking-Sonar Imagery",
        "firstAuthor": "I. Sledge",
        "url": null,
        "dateSubmitted": "2021-07-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We propose a memory-based framework for real-time, data-efficient target analysis in forward-looking-sonar (FLS) imagery. Our framework relies on first removing non-discriminative details from the imagery using a small-scale DenseNet-inspired network. Doing so simplifies ensuing analyses and permits generalizing from few labeled examples. We then cascade the filtered imagery into a novel NeuralRAM-based convolutional matching network, NRMN, for low-shot target recognition. We employ a small-scale FlowNet, LFN to align and register FLS imagery across local temporal scales. LFN enables target label consensus voting across images and generally improves target detection and recognition rates. We evaluate our framework using real-world FLS imagery with multiple broad target classes that have high intra-class variability and rich sub-class structure. We show that few-shot learning, with anywhere from ten to thirty class-specific exemplars, performs similarly to supervised deep networks trained on hundreds of samples per class. Effective zero-shot learning is also possible. High performance is realized from the inductive-transfer properties of NRMNs when distractor elements are removed.",
        "paperId": "0bada5c36357836b541cad9fbbabfe9ed74a41e8"
    },
    {
        "title": "vMF Loss: Exploring a Scattered Intra-class Hypersphere for Few-Shot Learning",
        "firstAuthor": "Xin Liu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0bc17828f79ab91688b4efbbce9a7288b075e282"
    },
    {
        "title": "Leveraging Continuous Prompt for Few-Shot Named Entity Recognition in Electric Power Domain with Meta-Learning",
        "firstAuthor": "Yu Yang",
        "url": "https://direct.mit.edu/dint/article-pdf/doi/10.1162/dint_a_00202/2072381/dint_a_00202.pdf",
        "dateSubmitted": "2023-02-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "\n Conventional named entity recognition methods usually assume that the model can be trained with sufficient annotated data to obtain good recognition results. However, in Chinese named entity recognition in the electric power domain, existing methods still face the challenges of lack of annotated data and new entities of unseen types. To address these challenges, this paper proposes a meta-learning-based continuous cue adjustment method. A generative pre-trained language model is used so that it does not change its own model structure when dealing with new entity types. To guide the pre-trained model to make full use of its own latent knowledge, a vector of learnable parameters is set as a cue to compensate for the lack of training data. In order to further improve the model's few-shot learning capability, a meta-learning strategy is used to train the model. Experimental results show that the proposed approach achieves the best results in a few-shot electric Chinese power named entity recognition dataset compared to several traditional named entity approaches.",
        "paperId": "0bde9e1f40895e0a92de030cbd540a707a75e835"
    },
    {
        "title": "MAML and ANIL Provably Learn Representations",
        "firstAuthor": "Liam Collins",
        "url": null,
        "dateSubmitted": "2022-02-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent empirical evidence has driven conventional wisdom to believe that gradient-based meta-learning (GBML) methods perform well at few-shot learning because they learn an expressive data representation that is shared across tasks. However, the mechanics of GBML have remained largely mysterious from a theoretical perspective. In this paper, we prove that two well-known GBML methods, MAML and ANIL, as well as their first-order approximations, are capable of learning common representation among a set of given tasks. Specifically, in the well-known multi-task linear representation learning setting, they are able to recover the ground-truth representation at an exponentially fast rate. Moreover, our analysis illuminates that the driving force causing MAML and ANIL to recover the underlying representation is that they adapt the final layer of their model, which harnesses the underlying task diversity to improve the representation in all directions of interest. To the best of our knowledge, these are the first results to show that MAML and/or ANIL learn expressive representations and to rigorously explain why they do so.",
        "paperId": "0becd3c7bd0208fe9e611061947c8797f14517d1"
    },
    {
        "title": "Meta-Transfer Learning Through Hard Tasks",
        "firstAuthor": "Qianru Sun",
        "url": null,
        "dateSubmitted": "2019-10-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, typical meta-learning models use shallow neural networks, thus limiting its effectiveness. In order to achieve top performance, some recent works tried to use the DNNs pre-trained on large-scale datasets but mostly in straight-forward manners, e.g., (1) taking their weights as a warm start of meta-training, and (2) freezing their convolutional layers as the feature extractor of base-learners. In this paper, we propose a novel approach called meta-transfer learning (MTL), which learns to transfer the weights of a deep NN for few-shot learning tasks. Specifically, meta refers to training multiple tasks, and transfer is achieved by learning scaling and shifting functions of DNN weights (and biases) for each task. To further boost the learning efficiency of MTL, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum of few-shot classification tasks. We conduct experiments for five-class few-shot classification tasks on three challenging benchmarks, miniImageNet, tieredImageNet, and Fewshot-CIFAR100 (FC100), in both supervised and semi-supervised settings. Extensive comparisons to related works validate that our MTL approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.",
        "paperId": "0beceb58bf35073bf4abe1e0d9116c8525530179"
    },
    {
        "title": "Prompt-Guided Few-Shot Event Detection",
        "firstAuthor": "Prafulla Dhariwal",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Practical applications of event extraction sys- 001 tems have long been hindered by their need 002 for heavy human annotation. In order to scale 003 up to new domains and event types, models 004 must learn to cope with limited supervision, 005 as in few-shot learning settings. To this end, 006 the major challenge is to let the model master 007 the semantic of event types, without requiring 008 abundant event mention annotations. In our 009 study, we employ cloze prompts to elicit event- 010 related knowledge from pretrained language 011 models and further use event definitions and 012 keywords to pinpoint the trigger word. By for- 013 mulating the event detection task as an identify- 014 then-localize procedure, we minimize the num- 015 ber of type-specific parameters, enabling our 016 model to quickly adapt to event detection tasks 017 for new types. Experiments on three event de- 018 tection benchmark datasets (ACE, FewEvent, 019 MAVEN) show that our proposed method per- 020 forms favorably under fully supervised settings 021 and surpasses existing few-shot methods by 022 16% F1 on the FewEvent dataset and 23% on 023 the MAVEN dataset when only 5 examples are 024 provided for each event type. 1 025",
        "paperId": "0bf03af786d13cca86ff8a5543c26502bf2728b0"
    },
    {
        "title": "Skip Residual Pairwise Networks With Learnable Comparative Functions for Few-Shot Learning",
        "firstAuthor": "A. Mehrotra",
        "url": null,
        "dateSubmitted": "2019-01-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this work we consider the ubiquitous Siamese network architecture and hypothesize that having an end-to-end learnable comparative function instead of an arbitrarily fixed one used commonly in practice (such as dot product) would allow the network to learn a final representation more suited to the task at hand and generalize better with very small quantities of data. Based on this we propose Skip Residual Pairwise Networks (SRPN) for few-shot learning based on residual Siamese networks. We validate our hypothesis by evaluating the proposed model for few-shot learning on Omniglot and mini-Imagenet datasets. Our model outperforms the residual Siamese design of equal depth and parameters. We also show that our model is competitive with state-of-the-art meta-learning based methods for few-shot learning on the challenging mini-Imagenet dataset whilst being a much simpler design, obtaining 54.4% accuracy on the five-way few-shot learning task with only a single example per class and over 70% accuracy with five examples per class. We further observe that the network weights in our model are much smaller compared to an equivalent residual Siamese Network under similar regularization, thus validating our hypothesis that our model design allows for better generalization. We also observe that our asymmetric, non-metric SRPN design automatically learns to approximate natural metric learning priors such as a symmetry and the triangle inequality.",
        "paperId": "0bfc4988d39624b220776935cacea48dee9b0f48"
    },
    {
        "title": "Mind the Gap: On Bridging the Semantic Gap between Machine Learning and Malware Analysis",
        "firstAuthor": "Michael R. Smith",
        "url": null,
        "dateSubmitted": "2020-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Machine learning (ML) techniques are being used to detect increasing amounts of malware and variants. Despite successful applications of ML, we hypothesize that the full potential of ML is not realized in malware analysis (MA) due to a semantic gap between the ML and MA communities---as demonstrated in the data that is used. Due in part to the available data, ML has primarily focused on detection whereas MA is also interested in identifying behaviors. We review existing open-source malware datasets used in ML and find a lack of behavioral information that could facilitate stronger impact by ML in MA. As a first step in bridging this gap, we label existing data with behavioral information using open-source MA reports---1) altering the analysis from identifying malware to identifying behaviors, 2)~aligning ML better with MA, and 3)~allowing ML models to generalize to novel malware in a zero/few-shot learning manner. We classify the behavior of a malware family not seen during training using transfer learning from a state-of-the-art model for malware family classification and achieve 57% - 84% accuracy on behavioral identification but fail to outperform the baseline set by a majority class predictor. This highlights opportunities for improvement on this task related to the data representation, the need for malware specific ML techniques, and a larger training set of malware samples labeled with behaviors.",
        "paperId": "0c126f64df4e7f0c9b6c9f43fbe306b5aa8df8e1"
    },
    {
        "title": "Few-Shot Learning for Deformable Medical Image Registration With Perception-Correspondence Decoupling and Reverse Teaching",
        "firstAuthor": "Yuting He",
        "url": null,
        "dateSubmitted": "2021-07-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Deformable medical image registration estimates corresponding deformation to align the regions of interest (ROIs) of two images to a same spatial coordinate system. However, recent unsupervised registration models only have correspondence ability without perception, making misalignment on blurred anatomies and distortion on task-unconcerned backgrounds. Label-constrained (LC) registration models embed the perception ability via labels, but the lack of texture constraints in labels and the expensive labeling costs causes distortion internal ROIs and overfitted perception. We propose the first few-shot deformable medical image registration framework, Perception-Correspondence Registration (PC-Reg), which embeds perception ability to registration models only with few labels, thus greatly improving registration accuracy and reducing distortion. 1) We propose the Perception-Correspondence Decoupling which decouples the perception and correspondence actions of registration to two CNNs. Therefore, independent optimizations and feature representations are available avoiding interference of the correspondence due to the lack of texture constraints. 2) For few-shot learning, we propose Reverse Teaching which aligns labeled and unlabeled images to each other to provide supervision information to the structure and style knowledge in unlabeled images, thus generating additional training data. Therefore, these data will reversely teach our perception CNN more style and structure knowledge, improving its generalization ability. Our experiments on three datasets with only five labels demonstrate that our PC-Reg has competitive registration accuracy and effective distortion-reducing ability. Compared with LC-VoxelMorph($\\lambda =1$), we achieve the 12.5%, 6.3% and 1.0% Reg-DSC improvements on three datasets, revealing our framework with great potential in clinical application.",
        "paperId": "0c1442a38ede09cfa8de8000d6d824a863385f11"
    },
    {
        "title": "When Does Self-supervision Improve Few-shot Learning?",
        "firstAuthor": "Jong-Chyi Su",
        "url": "https://arxiv.org/pdf/1910.03560",
        "dateSubmitted": "2019-10-08",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0c1513b21d703e7e0d5a1d99a2ad5f6614a2706d"
    },
    {
        "title": "CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP",
        "firstAuthor": "Runnan Chen",
        "url": "https://arxiv.org/pdf/2301.04926",
        "dateSubmitted": "2023-01-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Contrastive Language-Image Pre-training (CLIP) achieves promising results in 2D zero-shot and few-shot learning. Despite the impressive performance in 2D, applying CLIP to help the learning in 3D scene understanding has yet to be explored. In this paper, we make the first attempt to investigate how CLIP knowledge benefits 3D scene understanding. We propose CLIP2Scene, a simple yet effective framework that transfers CLIP knowledge from 2D image-text pre-trained models to a 3D point cloud network. We show that the pre-trained 3D network yields impressive performance on various downstream tasks, i.e., annotation-free and fine-tuning with labelled data for semantic segmentation. Specifically, built upon CLIP, we design a Semantic-driven Cross-modal Contrastive Learning framework that pre-trains a 3D network via semantic and spatial-temporal consistency regularization. For the former, we first leverage CLIP's text semantics to select the positive and negative point samples and then employ the contrastive loss to train the 3D network. In terms of the latter, we force the consistency between the temporally coherent point cloud features and their corresponding image features. We conduct experiments on SemanticKITTI, nuScenes, and ScanNet. For the first time, our pre-trained network achieves annotation-free 3D semantic segmentation with 20.8% and 25.08% mIoU on nuScenes and ScanNet, respectively. When fine-tuned with 1% or 100% labelled data, our method significantly outperforms other self-supervised methods, with improvements of 8% and 1% mIoU, respectively. Furthermore, we demonstrate the generalizability for handling cross-domain datasets. Code is publicly available11https://github.com/runnanchen/CLIP2Scene..",
        "paperId": "0c17326565266c40a02b230fac3b405a4d3220b9"
    },
    {
        "title": "An Agenda for Multimodal Foundation Models for Earth Observation",
        "firstAuthor": "P. Dias",
        "url": null,
        "dateSubmitted": "2023-07-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Archives of remote sensing (RS) data are increasing swiftly as new sensing modalities with enhanced spatiotemporal resolution become operational. While promising new breakthroughs, the sheer volume of RS archives stretches the limits of human analysts and existing AI tools, as most models are: i) limited to single data modalities; ii) task-specific; iii) heavily reliant on labeled data. The emerging Foundation Models (FMs) have the potential to address these limitations. Trained on vast unlabeled datasets through self-supervised learning, FMs enable generic feature extraction that facilitate specialization to a wide variety of downstream tasks. This paper describes a vision towards an FM for multimodal Earth Observation data (FM4EO), discussing key building blocks and open challenges. We put particular emphasis on multimodal reasoning, a topic underexplored in EO. Our ultimate goal is a practical path toward FM4EO with capacity to unlock breakthroughs in few-shot learning scenarios, multimodal geographic knowledge integration, synthesis, and hypothesis generation.",
        "paperId": "0c20ecc34e5a1e74806a6f890c17613339788775"
    },
    {
        "title": "Revisiting Mid-Level Patterns for Cross-Domain Few-Shot Recognition",
        "firstAuthor": "Yixiong Zou",
        "url": "https://arxiv.org/pdf/2008.03128",
        "dateSubmitted": "2020-08-07",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Existing few-shot learning (FSL) methods usually assume base classes and novel classes are from the same domain (in-domain setting). However, in practice, it may be infeasible to collect sufficient training samples for some special domains to construct base classes. To solve this problem, cross-domain FSL (CDFSL) is proposed very recently to transfer knowledge from general-domain base classes to special-domain novel classes. Existing CDFSL works mostly focus on transferring between near domains, while rarely consider transferring between distant domains, which is in practical need as any novel classes could appear in real-world applications, and is even more challenging. In this paper, we study a challenging subset of CDFSL where the novel classes are in distant domains from base classes, by revisiting the mid-level features, which are more transferable yet under-explored in main stream FSL work. To boost the discriminability of mid-level features, we propose a residual-prediction task to encourage mid-level features to learn discriminative information of each sample. Notably, such mechanism also benefits the in-domain FSL and CDFSL in near domains. Therefore, we provide two types of features for both cross- and in-domain FSL respectively, under the same training framework. Experiments under both settings on six public datasets, including two challenging medical datasets, validate the our rationale and demonstrate state-of-the-art performance. Code will be released.",
        "paperId": "0c2507955b7931abd55496ad35e9ebd0eea1fb12"
    },
    {
        "title": "Few-Shot and Prompt Training for Text Classification in German Doctor's Letters",
        "firstAuthor": "Phillip Richter-Pechanski",
        "url": "https://ebooks.iospress.nl/pdf/doi/10.3233/SHTI230275",
        "dateSubmitted": "2023-05-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "To classify sentences in cardiovascular German doctor's letters into eleven section categories, we used pattern-exploiting training, a prompt-based method for text classification in few-shot learning scenarios (20, 50 and 100 instances per class) using language models with various pre-training approaches evaluated on CARDIO:DE, a freely available German clinical routine corpus. Prompting improves results by 5-28% accuracy compared to traditional methods, reducing manual annotation efforts and computational costs in a clinical setting.",
        "paperId": "0c409f7b605ea5bbccfd50d3200a287697102fc3"
    },
    {
        "title": "Deepfake: Creation and Detection using Deep Learning",
        "firstAuthor": "Prof. Shashi Rekha G",
        "url": null,
        "dateSubmitted": "2023-05-31",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Abstract: The aim of this study is to develop customizedphoto-realistic talking head models, which refers to the creation of systems capable of generating believable video sequences that mimic the speech expressions and facial movements of a specific person. The authors propose a system that can produce talking head models using just a few photographs, a technique known as \"few-shot learning,\" and with minimal training time. This system is capable of generating a plausible outcome using just one photograph, and additional photographs enhance the level of personalization. The authors present a system that can perform few-shot learning by conducting meta-learning on a vast collection of videos, which allows it to address the neural talking head models of new and unseen individuals as adversarial training problems with high-capacity generators and discriminators. The system can personalize both the generator and the discriminator's parameters based on each person, enabling training to be performed quickly with only a few images, despite the need to fine-tune millions of parameters.",
        "paperId": "0c49d9a0167a53087493155e95bcad123543b334"
    },
    {
        "title": "Automated Classification of Inherited Retinal Diseases in Optical Coherence Tomography Images Using Few-shot Learning.",
        "firstAuthor": "Qi Zhao",
        "url": null,
        "dateSubmitted": "2023-05-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Objective\nTo develop a few-shot learning (FSL) approach for classifying optical coherence tomography (OCT) images in patients with inherited retinal disorders (IRDs).\n\n\nMethods\nIn this study, an FSL model based on a student-teacher learning framework was designed to classify images. 2,317 images from 189 participants were included. Of these, 1,126 images revealed IRDs, 533 were normal samples, and 658 were control samples.\n\n\nResults\nThe FSL model achieved a total accuracy of 0.974-0.983, total sensitivity of 0.934-0.957, total specificity of 0.984-0.990, and total F1 score of 0.935-0.957, which were superior to the total accuracy of the baseline model of 0.943-0.954, total sensitivity of 0.866-0.886, total specificity of 0.962-0.971, and total F1 score of 0.859-0.885. The performance of most subclassifications also exhibited advantages. Moreover, the FSL model had a higher area under curves (AUC) of the receiver operating characteristic (ROC) curves in most subclassifications.\n\n\nConclusion\nThis study demonstrates the effective use of the FSL model for the classification of OCT images from patients with IRDs, normal, and control participants with a smaller volume of data. The general principle and similar network architectures can also be applied to other retinal diseases with a low prevalence.",
        "paperId": "0c66c57abdc1da11297960ac239e8ff76348961e"
    },
    {
        "title": "Meta-Style: Few-Shot Learning Dataset for Social Media Field",
        "firstAuthor": "Yuncong Peng",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0c67695d20da15c88c6eae086675347fba5c1820"
    },
    {
        "title": "An evaluation of GPT models for phenotype concept recognition",
        "firstAuthor": "T. Groza",
        "url": "https://arxiv.org/pdf/2309.17169",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Objective: Clinical deep phenotyping plays a critical role in both the diagnosis of patients with rare disorders as well as in building care coordination plans. The process relies on modelling and curating patient profiles using ontology concepts, usually from the Human Phenotype Ontology. Machine learning methods have been widely adopted to support this phenotype concept recognition task. With the significant shift in the use of large language models (LLMs) for most NLP tasks, herewithin, we examine the performance of the latest Generative Pre-trained Transformer (GPT) models underpinning ChatGPT in clinical deep phenotyping. Materials and Methods: The experimental setup of the study included seven prompts of various levels of specificity, two GPT models (gpt-3.5 and gpt-4.0) and an established gold standard for phenotype recognition. Results: Our results show that, currently, these models have not yet achieved state of the art performance. The best run, using few-shots learning, achieved 0.41 F1 score, compared to a 0.62 F1 score achieved by the current best in class tool. Conclusion: The non-deterministic nature of the outcomes and the lack of concordance between different runs using the same prompt and input makes the use of these LLMs in clinical settings problematic.",
        "paperId": "0c75cda2bb0812217bf0e5460e910212ad512944"
    },
    {
        "title": "Unsupervised Task Design to Meta-Train Medical Image Classifiers",
        "firstAuthor": "Gabriel Maicas",
        "url": "https://arxiv.org/pdf/1907.07816",
        "dateSubmitted": "2019-07-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-training has been empirically demonstrated to be the most effective pre-training method for few-shot learning of medical image classifiers (i.e., classifiers modeled with small training sets). However, the effectiveness of meta-training relies on the availability of a reasonable number of hand-designed classification tasks, which are costly to obtain, and consequently rarely available. In this paper, we propose a new method to unsupervisedly design a large number of classification tasks to meta-train medical image classifiers. We evaluate our method on a breast dynamically contrast enhanced magnetic resonance imaging (DCE-MRI) data set that has been used to benchmark few-shot training methods of medical image classifiers. Our results show that the proposed unsupervised task design to meta-train medical image classifiers builds a pre-trained model that, after fine-tuning, produces better classification results than other unsupervised and supervised pre-training methods, and competitive results with respect to meta-training that relies on hand-designed classification tasks.",
        "paperId": "0c7e7ae49bd745cb53902bf76389ee2a83d5aa3a"
    },
    {
        "title": "Few-shot Classification with First-order Task Agnostic Meta-learning",
        "firstAuthor": "Xiaoxiao Yang",
        "url": null,
        "dateSubmitted": "2022-05-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning approaches are typically used to solve few-shot learning tasks by training on a variety of data in the hopes of developing generalization abilities that can be applied to new tasks. Model-Agnostic Meta-Learning (MAML) is one of the popular ways for few-shot learning currently. However, the generalizability is impacted when the meta-learner is over-trained in the meta-training, leading to a bias toward existing tasks. Besides, MAML involves a second-order gradient, which costs a lot. In this paper, we propose a First-order Task-agnostic Meta-learning algorithm (TA-Reptile). Our entropy-based method utilizes a first-order gradient update to learn an unbiased model with a fine set of initialization parameters, aiming to address the difficulty of overperforming in classification tasks. Experiments on benchmark datasets illustrate that TA-Reptile has competitive performance in few-shot classification tasks.",
        "paperId": "0c869ea9348df81aad7655940faeb6f986e90519"
    },
    {
        "title": "Few-Shot SAR Target Recognition Through Meta-Adaptive Hyperparameters\u2019 Learning for Fast Adaptation",
        "firstAuthor": "Zhiqiang Zeng",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In synthetic aperture radar automatic target recognition (SAR-ATR), the limitations of imaging environment and observation conditions make it challenging to acquire a substantial amount of high-value targets, resulting in a severe shortage of datasets. This scarcity leads to poor performance and instability in few-shot SAR target recognition. To address these shortcomings, this article proposes meta-adaptive stochastic gradient descent (Mada-SGD), a novel inner loop parameter update approach based on meta-adaptive hyperparameter learning. By considering the correlation information between multiple update steps, Mada-SGD learns the weight distribution information of initialization parameters across previous and current update steps, akin to a memory mechanism. This approach enhances feature extraction and representation ability for few-shot SAR targets. In addition, an adaptive hyperparameter update strategy is introduced to simultaneously learn the initialization, weight factor, update factor, and update direction in the meta-learner. This effectively resolves parameter updating issues in meta-learning models while improving fast adaptation for few-shot SAR targets. Experimental results on the specialized moving and stationary target acquisition and recognition few-shot learning (MSTAR-FSL) dataset demonstrate that Mada-SGD outperforms the latest few-shot SAR target recognition model in terms of SAR target recognition performance, validating its advancement and superiority.",
        "paperId": "0c8f589444fe94105c6a05f0bd23b28d5cf166d4"
    },
    {
        "title": "MetaModulation: Learning Variational Feature Hierarchies for Few-Shot Learning with Fewer Tasks",
        "firstAuthor": "Wen-Jin Sun",
        "url": "http://arxiv.org/pdf/2305.10309",
        "dateSubmitted": "2023-05-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning algorithms are able to learn a new task using previously learned knowledge, but they often require a large number of meta-training tasks which may not be readily available. To address this issue, we propose a method for few-shot learning with fewer tasks, which we call MetaModulation. The key idea is to use a neural network to increase the density of the meta-training tasks by modulating batch normalization parameters during meta-training. Additionally, we modify parameters at various network levels, rather than just a single layer, to increase task diversity. To account for the uncertainty caused by the limited training tasks, we propose a variational MetaModulation where the modulation parameters are treated as latent variables. We also introduce learning variational feature hierarchies by the variational MetaModulation, which modulates features at all layers and can consider task uncertainty and generate more diverse tasks. The ablation studies illustrate the advantages of utilizing a learnable task modulation at different levels and demonstrate the benefit of incorporating probabilistic variants in few-task meta-learning. Our MetaModulation and its variational variants consistently outperform state-of-the-art alternatives on four few-task meta-learning benchmarks.",
        "paperId": "0c9a1fe4bc47b72706af36053cd10cbb189d4338"
    },
    {
        "title": "MULTILINGUAL TEXT CLASSIFIER USING PRE-TRAINED UNIVERSAL SENTENCE ENCODER MODEL",
        "firstAuthor": "O. V. Orlovskiy",
        "url": "http://ric.zntu.edu.ua/article/download/265730/261778",
        "dateSubmitted": "2022-10-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Context. Online platforms and environments continue to generate ever-increasing content. The task of automating the moderation of user-generated content continues to be relevant. Of particular note are cases in which, for one reason or another, there is a very small amount of data to teach the classifier. To achieve results under such conditions, it is important to involve the classifier pre-trained models, which were trained on a large amount of data from a wide range. This paper deals with the use of the pre-trained multilingual Universal Sentence Encoder (USE) model as a component of the developed classifier and the affect of hyperparameters on the classification accuracy when learning on a small data amount (~ 0.05% of the dataset). \nObjective. The goal of this paper is the investigation of the pre-trained multilingual model and optimal hyperparameters influence for learning the text data classifier on the classification result. \nMethod. To solve this problem, a relatively new approach to few-shot learning has recently been used \u2013 learning with a relatively small number of examples. Since text data is still the dominant way of transmitting information, the study of the possibilities of constructing a classifier of text data when learning from a small number of examples (~ 0.002\u20130.05% of the data set) is an actual problem. \nResults. It is shown that even with a small number of examples for learning (36 per class) due to the use of USE and optimal configuration in learning can achieve high accuracy of classification on English and Russian data, which is extremely important when it is impossible to collect your own large data set. The influence of the approach using USE and a set of different configurations of hyperparameters on the result of the text data classifier on the example of English and Russian data sets is evaluated. \nConclusions. During the experiments, a significant degree of relevance of the correct selection of hyperparameters is shown. In particular, this paper considered the batch size, optimizer, number of learning epochs and the percentage of data from the set taken to train the classifier. In the process of experimentation, the optimal configuration of hyperparameters was selected, according to which 86.46% accuracy of classification on the Russian-language data set and 91.13% on the English-language data, respectively, can be achieved in ten seconds of training (training time can be significantly affected by technical means used).",
        "paperId": "0ce5afadf43cef02253872cba7e8b5e7d5935ada"
    },
    {
        "title": "F EW -S HOT L EARNING BY D IMENSIONALITY R EDUCTION IN G RADIENT S PACE",
        "firstAuthor": "M. Gauch",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We introduce SubGD, a novel few-shot learning method which is based on the recent finding that stochastic gradient descent updates tend to live in a low-dimensional parameter subspace. In experimental and theoretical analyses, we show that models confined to a suitable predefined subspace generalize well for few-shot learning. A suitable subspace fulfills three criteria across the given tasks: it (a) allows to reduce the training error by gradient flow, (b) leads to models that generalize well",
        "paperId": "0d0853959bba595f503cb53c3ff9ae6870585d4f"
    },
    {
        "title": "Measuring Dataset Granularity",
        "firstAuthor": "Yin Cui",
        "url": null,
        "dateSubmitted": "2019-12-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Despite the increasing visibility of fine-grained recognition in our field, \"fine-grained'' has thus far lacked a precise definition. In this work, building upon clustering theory, we pursue a framework for measuring dataset granularity. We argue that dataset granularity should depend not only on the data samples and their labels, but also on the distance function we choose. We propose an axiomatic framework to capture desired properties for a dataset granularity measure and provide examples of measures that satisfy these properties. We assess each measure via experiments on datasets with hierarchical labels of varying granularity. When measuring granularity in commonly used datasets with our measure, we find that certain datasets that are widely considered fine-grained in fact contain subsets of considerable size that are substantially more coarse-grained than datasets generally regarded as coarse-grained. We also investigate the interplay between dataset granularity with a variety of factors and find that fine-grained datasets are more difficult to learn from, more difficult to transfer to, more difficult to perform few-shot learning with, and more vulnerable to adversarial attacks.",
        "paperId": "0d08f9d9a5efc227d17665e3a23ce0353f915fd2"
    },
    {
        "title": "In-Context Learning for Few-Shot Molecular Property Prediction",
        "firstAuthor": "Christopher Fifty",
        "url": "https://arxiv.org/pdf/2310.08863",
        "dateSubmitted": "2023-10-13",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In-context learning has become an important approach for few-shot learning in Large Language Models because of its ability to rapidly adapt to new tasks without fine-tuning model parameters. However, it is restricted to applications in natural language and inapplicable to other domains. In this paper, we adapt the concepts underpinning in-context learning to develop a new algorithm for few-shot molecular property prediction. Our approach learns to predict molecular properties from a context of (molecule, property measurement) pairs and rapidly adapts to new properties without fine-tuning. On the FS-Mol and BACE molecular property prediction benchmarks, we find this method surpasses the performance of recent meta-learning algorithms at small support sizes and is competitive with the best methods at large support sizes.",
        "paperId": "0d09c569477457c32637f9e866727cc4623b1165"
    },
    {
        "title": "Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University Meta-transfer learning for few-shot learning Meta-transfer learning for few-shot learning",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Meta-learning has been proposed as a framework to ad-dress the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to over\ufb01t using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks . Speci\ufb01cally, meta refers to training multiple tasks, and transfer is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy 1 .",
        "paperId": "0d09fffe4ca9dbde56d3af4650d4bae910425bac"
    },
    {
        "title": "LLM4SGG: Large Language Model for Weakly Supervised Scene Graph Generation",
        "firstAuthor": "Kibum Kim",
        "url": null,
        "dateSubmitted": "2023-10-16",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard, studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However, they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions, where fine-grained predicates in captions are undesirably converted into coarse-grained predicates, resulting in a long-tailed predicate distribution, and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest, where many triplets are discarded and not used in training, leading to insufficient supervision. To tackle the two issues, we propose a new approach, i.e., Large Language Model for weakly-supervised SGG (LLM4SGG), where we mitigate the two issues by leveraging the LLM's in-depth understanding of language and reasoning ability during the extraction of triplets from captions and alignment of entity/predicate classes with target data. To further engage the LLM in these processes, we adopt the idea of Chain-of-Thought and the in-context few-shot learning strategy. To validate the effectiveness of LLM4SGG, we conduct extensive experiments on Visual Genome and GQA datasets, showing significant improvements in both Recall@K and mean Recall@K compared to the state-of-the-art WSSGG methods. A further appeal is that LLM4SGG is data-efficient, enabling effective model training with a small amount of training images.",
        "paperId": "0d298db9e71999192fdf048780f004cc3be02b41"
    },
    {
        "title": "Semi-Supervised Few-Shot Learning with Prototypical Networks",
        "firstAuthor": "Rinu Boney",
        "url": null,
        "dateSubmitted": "2017-11-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We consider the problem of semi-supervised few-shot classification (when the few labeled samples are accompanied with unlabeled data) and show how to adapt the Prototypical Networks to this problem. We first show that using larger and better regularized prototypical networks can improve the classification accuracy. We then show further improvements by making use of unlabeled data.",
        "paperId": "0d557a49ead061ec4eee669cc122e67842c07625"
    },
    {
        "title": "COVID-19 Multi-Targeted Drug Repurposing Using Few-Shot Learning",
        "firstAuthor": "Yang Liu",
        "url": "https://www.frontiersin.org/articles/10.3389/fbinf.2021.693177/pdf",
        "dateSubmitted": "2021-06-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The life-threatening disease COVID-19 has inspired significant efforts to discover novel therapeutic agents through repurposing of existing drugs. Although multi-targeted (polypharmacological) therapies are recognized as the most efficient approach to system diseases such as COVID-19, computational multi-targeted compound screening has been limited by the scarcity of high-quality experimental data and difficulties in extracting information from molecules. This study introduces MolGNN, a new deep learning model for molecular property prediction. MolGNN applies a graph neural network to computational learning of chemical molecule embedding. Comparing to state-of-the-art approaches heavily relying on labeled experimental data, our method achieves equivalent or superior prediction performance without manual labels in the pretraining stage, and excellent performance on data with only a few labels. Our results indicate that MolGNN is robust to scarce training data, and hence a powerful few-shot learning tool. MolGNN predicted several multi-targeted molecules against both human Janus kinases and the SARS-CoV-2 main protease, which are preferential targets for drugs aiming, respectively, at alleviating cytokine storm COVID-19 symptoms and suppressing viral replication. We also predicted molecules potentially inhibiting cell death induced by SARS-CoV-2. Several of MolGNN top predictions are supported by existing experimental and clinical evidence, demonstrating the potential value of our method.",
        "paperId": "0d706bd885d2ec41e2a2fbce49e3b901ee868dc6"
    },
    {
        "title": "Attention-based Few-Shot Person Re-identification Using Meta Learning",
        "firstAuthor": "Alireza Rahimpour",
        "url": null,
        "dateSubmitted": "2018-06-24",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this paper, we investigate the challenging task of person re-identification from a new perspective and propose an end-to-end attention-based architecture for few-shot re-identification through meta-learning. The motivation for this task lies in the fact that humans, can usually identify another person after just seeing that given person a few times (or even once) by attending to their memory. On the other hand, the unique nature of the person re-identification problem, i.e., only few examples exist per identity and new identities always appearing during testing, calls for a few shot learning architecture with the capacity of handling new identities. Hence, we frame the problem within a meta-learning setting, where a neural network based meta-learner is trained to optimize a learner i.e., an attention-based matching function. Another challenge of the person re-identification problem is the small inter-class difference between different identities and large intra-class difference of the same identity. In order to increase the discriminative power of the model, we propose a new attention-based feature encoding scheme that takes into account the critical intra-view and cross-view relationship of images. We refer to the proposed Attention-based Re-identification Metalearning model as ARM. Extensive evaluations demonstrate the advantages of the ARM as compared to the state-of-the-art on the challenging PRID2011, CUHK01, CUHK03 and Market1501 datasets.",
        "paperId": "0d7810ba414b746b0d4f73aa94042bb0ea8f324d"
    },
    {
        "title": "Hybrid Attention Deep Adaptive Residual Graph Convolution Network for Few-shot Classification",
        "firstAuthor": "Guangyi Liu",
        "url": null,
        "dateSubmitted": "2023-03-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning is a challenging task in the field of machine learning that aims to acknowledge novel class with a few amount of labeled samples. To address this problem, researchers have proposed several methods, with metric-based methods being one of the most effective approaches. These methods learn a transferable embedding space for classification by computing the similarity between samples. In this context, Graph Neural Networks (GNNs) have been employed to describe the association among support samples and query samples. However, existing GNN-based methods face limitations in their capability to achieve deeper layers, which restricts their ability to effectively transport information from the support images to the query images. To overcome the limitation, we propose a deep adaptive residual graph convolution network with deeper layers that better explores the relationship between support and query sets. Additionally, we design a hybrid attention module to learn the metric distributions, which helps to alleviate the over-fitting problem that can occur with few samples. The proposed method has been shown to be effective through comprehensive experimentation on five benchmark datasets.",
        "paperId": "0d9104755fbf55e6e9968b306596d9a81c505ed1"
    },
    {
        "title": "How to train your MAML",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.",
        "paperId": "0dae167ba55d7f9dfd140de9e6533b995c4eb7eb"
    },
    {
        "title": "Towards a Chatbot for Creating Trigger-Action Rules based on ChatGPT and Rasa",
        "firstAuthor": "Simone Gallo",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In this paper, we propose a novel approach for building a conversational agent for creating trigger-action rules and controlling smart objects inside smart environments, such as a smart home. Our approach integrates ChatGPT, a state-of-the-art pre-trained language model for open-domain dialogue generation, with Rasa, a popular open-source framework for developing task-oriented chatbots. We leverage ChatGPT's abilities to perform Natural Language Processing tasks through prompting and few-shot learning, and Rasa Open Source's features to handle intents, entities, forms, and execute actions. We design Rasa custom actions that invoke ChatGPT's API to process complex customization rules, manage conversational breakdowns and answer questions about the smart environment.",
        "paperId": "0dc1f8366a10d249977d945abe100cc07835684f"
    },
    {
        "title": "A Conceptual Framework for Lifelong Learning",
        "firstAuthor": "C. Ling",
        "url": null,
        "dateSubmitted": "2019-11-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Humans can learn a variety of concepts and skills incrementally over the course of their lives while exhibiting many desirable properties, such as continual learning without forgetting, forward transfer and backward transfer of knowledge, and learning a new concept or task with only a few examples. Several lines of machine learning research, such as lifelong learning, few-shot learning, and transfer learning, attempt to capture these properties. However, most previous approaches can only demonstrate subsets of these properties, often by different complex mechanisms. In this work, we propose a simple yet powerful unified framework that supports almost all of these properties and approaches through one central mechanism. We also draw connections between many peculiarities of human learning (such as memory loss and \"rain man\") and our framework. While we do not present any state-of-the-art results, we hope that this conceptual framework provides a novel perspective on existing work and proposes many new research directions.",
        "paperId": "0de97a5ac2327fd06ffaa51eaf9251bcca5ab81c"
    },
    {
        "title": "Application of Artificial Intelligence in Diagnosis of Craniopharyngioma",
        "firstAuthor": "Caijie Qin",
        "url": "https://www.frontiersin.org/articles/10.3389/fneur.2021.752119/pdf",
        "dateSubmitted": "2022-01-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Craniopharyngioma is a congenital brain tumor with clinical characteristics of hypothalamic-pituitary dysfunction, increased intracranial pressure, and visual field disorder, among other injuries. Its clinical diagnosis mainly depends on radiological examinations (such as Computed Tomography, Magnetic Resonance Imaging). However, assessing numerous radiological images manually is a challenging task, and the experience of doctors has a great influence on the diagnosis result. The development of artificial intelligence has brought about a great transformation in the clinical diagnosis of craniopharyngioma. This study reviewed the application of artificial intelligence technology in the clinical diagnosis of craniopharyngioma from the aspects of differential classification, prediction of tissue invasion and gene mutation, prognosis prediction, and so on. Based on the reviews, the technical route of intelligent diagnosis based on the traditional machine learning model and deep learning model were further proposed. Additionally, in terms of the limitations and possibilities of the development of artificial intelligence in craniopharyngioma diagnosis, this study discussed the attentions required in future research, including few-shot learning, imbalanced data set, semi-supervised models, and multi-omics fusion.",
        "paperId": "0deb78b717bc998a3ae4c16a3b0f03f354c3a229"
    },
    {
        "title": "Few-shot Learning for Trajectory-based Mobile Game Cheating Detection",
        "firstAuthor": "Yueyang Su",
        "url": null,
        "dateSubmitted": "2022-08-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "With the emerging of smartphones, mobile games have attracted billions of players and occupied most of the share for game companies. On the other hand, mobile game cheating, aiming to gain improper advantages by using programs that simulate the players' inputs, severely damages the game's fairness and harms the user experience. Therefore, detecting mobile game cheating is of great importance for mobile game companies. Many PC game-oriented cheating detection methods have been proposed in the past decades, however, they can not be directly adopted in mobile games due to the concern of privacy, power, and memory limitations of mobile devices. Even worse, in practice, the cheating programs are quickly updated, leading to the label scarcity for novel cheating patterns. To handle such issues, we in this paper introduce a mobile game cheating detection framework, namely FCDGame, to detect the cheats under the few-shot learning framework. FCDGame only consumes the screen sensor data, recording users' touch trajectories, which is less sensitive and more general for almost all mobile games. Moreover, a Hierarchical Trajectory Encoder and a Cross-pattern Meta Learner are designed in FCDGame to capture the intrinsic characters of mobile games and solve the label scarcity problem, respectively. Extensive experiments on two real online games show that FCDGame achieves almost 10% improvements in detection accuracy with only few fine-tuned samples.",
        "paperId": "0dff3933892ea82234233a278685ff537d997e7a"
    },
    {
        "title": "Cross-Domain Few-Shot Micro-Expression Recognition Incorporating Action Units",
        "firstAuthor": "Yi Dai",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Micro-expression, different from ordinary facial expressions, is an involuntary, spontaneous, and subtle facial movement that reveals true emotions which people intend to conceal. As it usually occurs within a fraction of a second (less than 1/2 second) with a low action intensity, capturing micro-expressions among facial movements in a video is difficult. Moreover, when a micro-expression recognition system works in cold-start conditions, it has to recognize novel classes of micro-expressions in a new scenario, suffering from the lack of sufficient labeled samples. Inconsistency in micro-expression labeling criteria makes it difficult to use existing labeled datasets in other scenarios. To tackle the challenges, we present a micro-expression recognizer, which on one hand leverages the knowledge of facial action units (AU) to enhance facial representations, and on the other hand performs cross-domain few-shot learning to transfer knowledge acquired from other domains with different data labeling protocols and feature distribution to overcome the scarcity of labeled samples in the cold-starting scenario. In particular, we draw inspirations from the correlation between micro-expression and facial action units (AUs), and design an action unit module, aiming to extract subtle AU-related features from videos. We then fuse AU-related features and general features extracted by optical-flow facial images. Through fine-tuning, we transfer knowledge from datasets in different domains to the target domain. The experimental results on two datasets show that: (1) the proposed recognizer can effectively learn to recognize new categories of micro-expressions in different domains with a very few labeled samples with the UF1 score of 0.544 on CASME dataset, outperforming the state-of-the-art methods by 0.089; (2) the performance of the recognizer is more competitive when it distinguishes micro-expression videos of more categories; and (3) the action unit module enables to improve the recognition performance by 0.072 and 0.047 on CASME and SMIC, respectively.",
        "paperId": "0dffb975890993aa088e5a1ac2af67e212f8311f"
    },
    {
        "title": "How to train your MAML",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.",
        "paperId": "0e02c39a88eaf97accc00fc61ac02c70d3bfe295"
    },
    {
        "title": "Few-Shot Remote Sensing Scene Classification with Multi-Metric Fusion",
        "firstAuthor": "Zichen Wang",
        "url": null,
        "dateSubmitted": "2022-09-23",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot remote sensing scene classification is one of the research topics in the field of computer vision and few-shot learning, aiming to classify remote sensing scene through few training samples. The current methods of few-shot remote sensing scene classification use single metric, thus the classification accuracy is affected for the features cannot be effectively extracted. Therefore, we propose multi-metric fusion networks (MMFN) to address the problem via assembling a feature map multi encoder (FMME) and relation attention networks (RAN) to extract the features effectively and improve the classification accuracy. The FMME is designed to further encode the feature map which is extracted in the embedding phase to get different meaningful features. The RAN is aiming to calculate the similarity between features via fusing results of multiple methods based on image attention mechanism. Experimental results on three remote sensing data sets show that the multi-metric fusion method can extract meaningful features and effectively improve the classification performance of few-shot remote sensing scene.",
        "paperId": "0e0ef392058f5f0bd52643b0aa6fbae053217320"
    },
    {
        "title": "Mapping Underwater Aquatic Vegetation Using Foundation Models With Air- and Space-Borne Images: The Case of Polyphytos Lake",
        "firstAuthor": "Leonidas Alagialoglou",
        "url": "https://www.mdpi.com/2072-4292/15/16/4001/pdf?version=1691827396",
        "dateSubmitted": "2023-08-12",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Mapping underwater aquatic vegetation (UVeg) is crucial for understanding the dynamics of freshwater ecosystems. The advancement of artificial intelligence (AI) techniques has shown great potential in improving the accuracy and efficiency of UVeg mapping using remote sensing data. This paper presents a comparative study of the performance of classical and modern AI tools, including logistic regression, random forest, and a visual-prompt-tuned foundational model, the Segment Anything model (SAM), for mapping UVeg by analyzing air- and space-borne images in the few-shot learning regime, i.e., using limited annotations. The findings demonstrate the effectiveness of the SAM foundation model in air-borne imagery (GSD = 3\u20136 cm) with an F1 score of 86.5%\u00b14.1% when trained with as few as 40 positive/negative pairs of pixels, compared to 54.0%\u00b19.2% using the random forest model and 42.8%\u00b16.2% using logistic regression models. However, adapting SAM to space-borne images (WorldView-2 and Sentinel-2) remains challenging, and could not outperform classical pixel-wise random forest and logistic regression methods in our task. The findings presented provide valuable insights into the strengths and limitations of AI models for UVeg mapping, aiding researchers and practitioners in selecting the most suitable tools for their specific applications.",
        "paperId": "0e13c3db536ca8916aa60a151783a21db4224595"
    },
    {
        "title": "Ferroelectric ternary content-addressable memory for one-shot learning",
        "firstAuthor": "K. Ni",
        "url": null,
        "dateSubmitted": "2019-11-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0e22d8a86c17c415d9c1f737fb8cb7ada5e75656"
    },
    {
        "title": "Few Shots Is All You Need: A Progressive Few Shot Learning Approach for Low Resource Handwriting Recognition",
        "firstAuthor": "Mohamed Ali Souibgui",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Handwritten text recognition in low resource scenarios, such as manuscripts with rare alphabets, is a challenging problem. The main difficulty comes from the very few annotated data and the limited linguistic information (e.g. dictionaries and language models). Thus, we propose a few-shot learning-based handwriting recognition approach that significantly reduces the human labor annotation process, requiring only few images of each alphabet symbol. First, our model detects all symbols of a given alphabet in a textline image, then a decoding step maps the symbol similarity scores to the final sequence of transcribed symbols. Our model is first pretrained on synthetic line images generated from any alphabet, even though different from the target domain. A second training step is then applied to diminish the gap between the source and target data. Since this retraining would require annotation of thousands of handwritten symbols together with their bounding boxes, we propose to avoid such human effort through an unsupervised progressive learning approach that automatically assigns pseudo-labels to the non-annotated data. The evaluation on different manuscript datasets show that our model can lead to competitive results with a significant reduction in human effort. \u00a9 2021 Elsevier Ltd. All rights reserved.",
        "paperId": "0e537d6ac2bdd84082d1e83c5c1c63e6862acd73"
    },
    {
        "title": "Active meta-learning for predicting and selecting perovskite crystallization experiments.",
        "firstAuthor": "Venkateswaran Shekar",
        "url": null,
        "dateSubmitted": "2021-10-27",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Autonomous experimentation systems use algorithms and data from prior experiments to select and perform new experiments in order to meet a specified objective. In most experimental chemistry situations, there is a limited set of prior historical data available, and acquiring new data may be expensive and time consuming, which places constraints on machine learning methods. Active learning methods prioritize new experiment selection by using machine learning model uncertainty and predicted outcomes. Meta-learning methods attempt to construct models that can learn quickly with a limited set of data for a new task. In this paper, we applied the model-agnostic meta-learning (MAML) model and the Probabilistic LATent model for Incorporating Priors and Uncertainty in few-Shot learning (PLATIPUS) approach, which extends MAML to active learning, to the problem of halide perovskite growth by inverse temperature crystallization. Using a dataset of 1870 reactions conducted using 19 different organoammonium lead iodide systems, we determined the optimal strategies for incorporating historical data into active and meta-learning models to predict reaction compositions that result in crystals. We then evaluated the best three algorithms (PLATIPUS and active-learning k-nearest neighbor and decision tree algorithms) with four new chemical systems in experimental laboratory tests. With a fixed budget of 20 experiments, PLATIPUS makes superior predictions of reaction outcomes compared to other active-learning algorithms and a random baseline.",
        "paperId": "0e7281d0bc3a296187b413ea816ddaec3c83d0c7"
    },
    {
        "title": "Self-Supervised Point Cloud Learning in Few-Shot Scenario by Point Up-Sampling and Mutual Information Neural Estimation",
        "firstAuthor": "Jiawei Li",
        "url": null,
        "dateSubmitted": "2022-04-22",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Point cloud data is hard to obtain and time-consuming to be labelled. Self-supervised methods can utilize data without label, but it still needs large amount of data. The key to self-supervised methods lies in the design of pretext tasks. In this work, we propose a new self-supervised pretext task in few-shot learning scenario to further alleviate the data scarcity problem. Our self-supervised method learns by training the network to restore the original point cloud from the down-sampled point cloud. Although our point up-sampling pretext task as a kind of reconstruction task can ensure the learned representation contains sufficient information, it cannot guarantee its distinguishability. Thus, we introduce a Mutual Information Estimation and Maximization task to increase the distinguishability of the learned representation. Classification and segmentation results have shown that our method can learn efficient feature and increase the performance of down-stream models.",
        "paperId": "0e740d21e60c17ceaca52f2db819e97d4c443104"
    },
    {
        "title": "N-Omniglot: a Large-scale Dataset for Spatio-Temporal Sparse Few-shot Learning",
        "firstAuthor": "Yang Li",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning (learning with a few samples) is one of the most important capacities of the human brain. However, the current artificial intelligence systems meet difficulties in achieving this ability, so as the biologically plausible spiking neural networks (SNNs). Datasets for traditional few-shot learning domains provide few amounts of temporal information. And the absence of the neuromorphic datasets has hindered the development of few-shot learning for SNNs. Here, we provide the first neuromorphic dataset: N-Omniglot, using the Dynamic Vision Sensor (DVS). It contains 1623 categories of handwritten characters, with only 20 samples per class. N-Omniglot eliminates the need for a neuromorphic dataset for SNNs with high spareness and tremendous temporal coherence. Additionally, the dataset provides a powerful challenge and a suitable benchmark for developing SNNs algorithm in the few-shot learning domain due to the chronological information of strokes. We also provide the improved nearest neighbor, convolutional network, SiameseNet, and meta-learning algorithm in spiking version for verification. Background & Summary In recent years, the large scale datasets and increased computing power make machine learning, especially deep learning, reach the level of human-like performance in many areas1\u20133. However, compared with the human brain, artifical neural networks(ANN) lack of biological characteristic and interpretability, for its floating-point-based calculation and gradient-based algorithm4. Combining computer technology and computational neuroscience related knowledge can effectively improve the current deep learning technology. Spiking neural networks (SNNs) are considered to be the third generation of artificial neural networks5, by simulating the similar calculations and representations in the human brain, which shows strong biological interpretability. Only neurons that fire spikes will participate in the calculation of the network. Meanwhile, the sparse spike activity greatly reduces the network\u2019s energy consumption6. However, the lack of datasets for SNNs burden the development of SNN algorithm. The success of deep learning can largely attribute to the introduction of datasets such as ImageNet7 and COCO8. However, the currently widely used datasets are not suitable for SNNs. SNNs need to encode the static data into spike trains and then put them into the network9. As a result, the information will be missing, and it will be not fair to compare with the artificial neural networks. Dynamic Vision Sensor (DVS)10 is a new neuromorphic camera. DVS only generates 0/1 events on pixels with different light intensities to achieve low latency, low redundancy, and high time resolution, which is different from the ar X iv :2 11 2. 13 23 0v 1 [ cs .N E ] 2 5 D ec 2 02 1 frame-based cameras. In addition, DVS simulates the human visual nervous system in principle so that SNNs can make full use of the temporal information provided by such sensors. To promote the development of SNNs, researchers used DVS to provide many neuromorphic datasets. N-MNIST11, N-caltech101, DVS-CIFAR1012 are obtained through the picture or camera jitter, captured from traditional classification datasets, avoiding the damage to original image information during the encoding process. In addition to the conversion of static images, more researchers tend to obtain event data from natural environments, such as DVS-Gesture13, N-Cars14, etc. But the existed datasets, such as those mentioned above, have very low temporal correlation and cannot fully reflect the temporal information processing capabilities of SNN. All the characteristics are shown in Table 1. In addition to sparse coding15 to reduce energy consumption, learning new concepts rapidly from a few samples is also one of the important capabilities of the human brains. While it is an open problem in spike-based machine learning. The few-shot learning16, 17 imposes tremendous challenges to the current learning methodologies of SNNs due to the lack of neuromorphic datasets18 for training and evaluating the learning ability of a few samples. Dataset # of classes Sparsity Difference Object N-MNIST 10 Low Low Image N-Caltech101 100 Low Low Image DVS-CIFAR10 10 Low Low Image N-Cars 2 Low Mid Gesture DVS-Gesture 11 Low Mid Cars N-Omniglot 1623 High High Stroke Table 1. The Characteristics of the neuromorphic datasets. To tackle the problems and fulfill this gap, we propose the first neuromorphic dataset for few-shot learning: N-Omniglot. The original Omniglot dataset19 is the most commonly used dataset in the field of few-shot learning. It consists of 1623 handwritten characters from 50 different languages. Each character has only 20 different samples. It is usually recognized as a static character image, while the rich temporal information of the writing process is ignored. Therefore, we reconstruct the Figure 1. Some examples of N-Omniglot. High temporal correlation and spatio-temporal sparsity can be seen in these examples.",
        "paperId": "0e887315f733ba44ea37cac0f813db113ad18592"
    },
    {
        "title": "Semi-Supervised Exaggeration Detection of Health Science Press Releases",
        "firstAuthor": "Dustin Wright",
        "url": "https://aclanthology.org/2021.emnlp-main.845.pdf",
        "dateSubmitted": "2021-08-30",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Public trust in science depends on honest and factual communication of scientific papers. However, recent studies have demonstrated a tendency of news media to misrepresent scientific papers by exaggerating their findings. Given this, we present a formalization of and study into the problem of exaggeration detection in science communication. While there are an abundance of scientific papers and popular media articles written about them, very rarely do the articles include a direct link to the original paper, making data collection challenging, and necessitating the need for few-shot learning. We address this by curating a set of labeled press release/abstract pairs from existing expert annotated studies on exaggeration in press releases of scientific papers suitable for benchmarking the performance of machine learning models on the task. Using limited data from this and previous studies on exaggeration detection in science, we introduce MT-PET, a multi-task version of Pattern Exploiting Training (PET), which leverages knowledge from complementary cloze-style QA tasks to improve few-shot learning. We demonstrate that MT-PET outperforms PET and supervised learning both when data is limited, as well as when there is an abundance of data for the main task.",
        "paperId": "0e96b7f20eff4144851869fed0b7924db91e3010"
    },
    {
        "title": "Supplemental Material: JointFontGAN: JointGeometry-ContentGAN for FontGeneration via Few-Shot Learning",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0e9f8d0c842ae6c50c14b7d6f7ab5af85d5c1d1f"
    },
    {
        "title": "A GNN-based Few-shot learning model on the Credit Card Fraud detection",
        "firstAuthor": "Rongrong Jing",
        "url": null,
        "dateSubmitted": "2021-07-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In the era of big data, large-scale data can be very effective in improving model performance. However, in the real world, high-quality data is usually difficult to acquire due to privacy or cost. Especially when it comes to credit card fraud, the fraud samples are quite rare. Detecting card fraud with few samples is a meaningful task. Graph neural network (GNN) is a good way to deal with few samples because an advantage of GNN is that information can be disseminated through connections between nodes. However, the data structure of credit cards cannot be applied by the GNN-based method directly. In this paper, we proposed a GNN-based few-shot learning method which can detect credit card fraud with few samples effectively. We constructed a learnable parametric adjacency matrix method relying on the similarity of features to pass messages and utilized the GCN layer to extract node features. We compared our method with classical machine learning algorithms and other graph neural networks on the real-world data set. Our experimental results show that our proposed model can perform better extremely with fewer training samples than baselines.",
        "paperId": "0ea96b7db3b776b184a06a8f5b1b41d584a3b1ab"
    },
    {
        "title": "Preliminary Study on Adapting ProtoPNet to Few-Shot Learning Using MAML",
        "firstAuthor": "Yapu Zhao",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0eb64e30771b4cd3b5733c01b7e4c7e504bd147d"
    },
    {
        "title": "Exploring Neuromodulation for Dynamic Learning",
        "firstAuthor": "A. Daram",
        "url": null,
        "dateSubmitted": "2020-09-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "A continual learning system requires the ability to dynamically adapt and generalize to new tasks with access to only a few samples. In the central nervous system, across species, it is observed that continual and dynamic behavior in learning is an active result of a mechanism known as neuromodulation. Therefore, in this work, neuromodulatory plasticity is embedded with dynamic learning architectures as a first step toward realizing power and area efficient few shot learning systems. An inbuilt modulatory unit regulates learning based on the context and internal state of the system. This renders the system an ability to self modify its weights. In one of the proposed architectures, ModNet, a modulatory layer is introduced in a random projection framework. ModNet's learning capabilities are enhanced by integrating attention along with compartmentalized plasticity mechanisms. Moreover, to explore modulatory mechanisms in conjunction with backpropagation in deeper networks, a modulatory trace learning rule is introduced. The proposed learning rule, uses a time dependent trace to modify the synaptic connections as a function of ongoing states and activations. The trace itself is updated via simple plasticity rules thus reducing the demand on resources. The proposed ModNet and learning rules demonstrate the ability to learn from few samples, train quickly, and perform few-shot image classification in a computationally efficient manner. The simple ModNet and the compartmentalized ModNet architecture learn benchmark image classification tasks in just 2 epochs. The network with modulatory trace achieves an average accuracy of 98.8%\u00b11.16 on the omniglot dataset for five-way one-shot image classification task while requiring 20x fewer trainable parameters in comparison to other state of the art models.",
        "paperId": "0ebaa64023a3e79323c02384db1de5b4535c4bd4"
    },
    {
        "title": "How to train your MAML",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.",
        "paperId": "0ec94e734e23228c680d22b162460b008ef09e4f"
    },
    {
        "title": "Leveraging Natural Language Processing for a Consistency Checking Toolchain of Automotive Requirements",
        "firstAuthor": "Vincent Bertram",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In the automotive industry, specifications often consist of a large number of textual requirements. These requirements are linguistically ambiguous and written in informal language. Utilizing Structured English for requirements eliminates ambiguity, improves data quality, and supports further automated processing while maintaining readability. The recent development of large language models enables a fully automated translation approach using few-shot learning. To deal with the limited context size of large language models, an improved algorithm, OptKATE, is presented to find an ideal set of requirements for few-shot learning. Structured English can be used as a basis for further formalization. This capability is key in creating an interface between natural language processing and verification, in our case, consistency analysis using the Z3 SMT solver. We implemented a grammar for translating Structured English into TCTL using the MontiCore workbench. Furthermore, since SMT-based methods currently rely on manual precondition satisfaction and do not tackle conflicting preconditions automatically, we propose a scenario generation algorithm that generates potential scenarios using the specification and checks the requirements against them. Through this approach, we can better identify and resolve conflicting preconditions, ultimately improving the consistency of requirements. Our toolchain is evaluated using an automotive requirements dataset provided by former Daimler AG.",
        "paperId": "0ede2854648bf3bde6b316792b78f16333278aa2"
    },
    {
        "title": "Few-Shot Learning Based Balanced Distribution Adaptation for Heterogeneous Defect Prediction",
        "firstAuthor": "Aili Wang",
        "url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/08999527.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Heterogeneous defect prediction (HDP) aims to predict the defect tendency of modules in one project using heterogeneous data collected from other projects. It sufficiently incorporates the two characteristics of the defect prediction data: (1) datasets could have different metrics and distribution, and (2) data could be highly imbalanced. In this paper, we propose a few-shot learning based balanced distribution adaptation (FSLBDA) approach for heterogeneous defect prediction, which takes into consideration the two characteristics of the defect prediction data. Class imbalance of the defect datasets can be solved with undersampling, but the scale of the training datasets will be smaller. Specifically, we first remove redundant metrics of datasets with extreme gradient boosting. Then, we reduce the data difference between the source domain and the target domain with the balanced distribution adaptation. It considers the marginal distribution and the probability of conditional distribution differences and adaptively assigns different weights to them. Finally, we use adaptive boosting to relieve the influence caused by the size of the training dataset is smaller, which can improve the accuracy of the defect prediction model. We conduct experiments on 17 projects from 4 datasets using 3 indicators (i.e., AUC, G-mean, F-measure). Compared to three classic approaches, the experimental results show that FSLBDA can effectively improve the prediction performance.",
        "paperId": "0ee0b3f2fac1bb5703bcbdce5faca0264ca8219b"
    },
    {
        "title": "Few-shot Learning for Multi-Modality Tasks",
        "firstAuthor": "Jie Chen",
        "url": null,
        "dateSubmitted": "2021-10-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent deep learning methods rely on a large amount of labeled data to achieve high performance. These methods may be impractical in some scenarios, where manual data annotation is costly or the samples of certain categories are scarce (e.g., tumor lesions, endangered animals and rare individual activities). When only limited annotated samples are available, these methods usually suffer from the overfitting problem severely, which degrades the performance significantly. In contrast, humans can recognize the objects in the images rapidly and correctly with their prior knowledge after exposed to only a few annotated samples. To simulate the learning schema of humans and relieve the reliance on the large-scale annotation benchmarks, researchers start shifting towards the few-shot learning problem: they try to learn a model to correctly recognize novel categories with only a few annotated samples.",
        "paperId": "0eea2c7bd7231ccab326d2c70f83dd4d52aa2865"
    },
    {
        "title": "A Revision of Neural Tangent Kernel-based Approaches for Neural Networks",
        "firstAuthor": "Kyungsu Kim",
        "url": null,
        "dateSubmitted": "2020-07-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recent theoretical works based on the neural tangent kernel (NTK) have shed light on the optimization and generalization of over-parameterized networks, and partially bridge the gap between their practical success and classical learning theory. Especially, using the NTK-based approach, the following three representative results were obtained: (1) A training error bound was derived to show that networks can fit any finite training sample perfectly by reflecting a tighter characterization of training speed depending on the data complexity. (2) A generalization error bound invariant of network size was derived by using a data-dependent complexity measure (CMD). It follows from this CMD bound that networks can generalize arbitrary smooth functions. (3) A simple and analytic kernel function was derived as indeed equivalent to a fully-trained network. This kernel outperforms its corresponding network and the existing gold standard, Random Forests, in few shot learning. For all of these results to hold, the network scaling factor $\\kappa$ should decrease w.r.t. sample size n. In this case of decreasing $\\kappa$, however, we prove that the aforementioned results are surprisingly erroneous. It is because the output value of trained network decreases to zero when $\\kappa$ decreases w.r.t. n. To solve this problem, we tighten key bounds by essentially removing $\\kappa$-affected values. Our tighter analysis resolves the scaling problem and enables the validation of the original NTK-based results.",
        "paperId": "0eef135c44c00f72e649d06dd3894410ddcc9cdb"
    },
    {
        "title": "SSL-DC: Improving Transductive Few-Shot Learning via Self-Supervised Learning and Distribution Calibration",
        "firstAuthor": "Huayi Yang",
        "url": null,
        "dateSubmitted": "2022-08-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning, aiming to distinguish unseen classes by training with few labeled samples, is still challenged by the overfitting problem. The transductive few-shot learning paradigm enables us to reduce overfitting by training a highly discriminative feature representation via self-supervised learning since the entire unlabeled samples are allowed to be accessed. In this paper, we propose a simple but efficient approach based on self-supervised pre-training and nearest class prototype search, which can obtain a significant improvement in the performance of transductive few-shot learning tasks without external samples. However, since the class prototype is obtained through limited support samples, it is easily affected by biased samples. Therefore, we propose to train a conditional generative adversarial network to estimate the distribution of features instead of assuming it follows Gaussian distribution as previous arts. Thus, we can generate features that are closed to real features from the estimated distribution to calibrate the distribution of the class prototype. Finally, more detailed experiments show that our method can exceed plenty of recent transductive few-shot learning methods significantly and achieve 9.83% and 4.38% improvements over the existing best method under the transductive 5-way 1-shot and 5-shot settings with ResNet-12 on the miniImageNet.",
        "paperId": "0f2a646ccc57b48c08e48ef4ceace53bd987d8f7"
    },
    {
        "title": "SEE&TELL: Controllable Narrative Generation from Images",
        "firstAuthor": "S. Lukin",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We propose a visual storytelling framework with a distinction between what is present and observable in the visual storyworld, and what story is ultimately told. We implement a model that tells a story from an image using three affordances: 1) a fixed set of visual properties in an image that constitute a holistic representation its contents, 2) a variable stage direction that establishes the story setting, and 3) incremental questions about character goals. The generated narrative plans are then realized as expressive texts using few-shot learning. Following this approach, we generated 64 visual stories and measured the preservation, loss, and gain of visual information throughout the pipeline, and the willingness of a reader to take action to read more. We report different proportions of visual information preserved and lost depending upon the phase of the pipeline and the stage direction\u2019s apparent relatedness to the image, and report 83% of stories were found to be interesting.",
        "paperId": "0f307d1361d6f967d9a67195f85b522ae40f6501"
    },
    {
        "title": "Multimodal learning of noncoding variant effects using genome sequence and chromatin structure",
        "firstAuthor": "Wuwei Tan",
        "url": null,
        "dateSubmitted": "2022-12-21",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Motivation A growing amount of noncoding genetic variants, including single-nucleotide polymorphisms (SNPs), are found to be associated with complex human traits and diseases. Their mechanistic interpretation is relatively limited and can use the help from computational prediction of their effects on epigenetic profiles. However, current models often focus on local, 1D genome sequence determinants and disregard global, 3D chromatin structure that critically affects epigenetic events. Results We find that noncoding variants of unexpected high similarity in epigenetic profiles, with regards to their relatively low similarity in local sequences, can be largely attributed to their proximity in chromatin structure. Accordingly we have developed a multimodal deep learning scheme that incorporates both data of 1D genome sequence and 3D chromatin structure for predicting noncoding variant effects. Specifically, we have integrated convolutional and recurrent neural networks for sequence embedding and graph neural networks for structure embedding despite the resolution gap between the two types of data, while utilizing recent DNA language models. Numerical results show that our models outperform competing sequence-only models in predicting epigenetic profiles and their use of long-range interactions complement sequence-only models in extracting regulatory motifs. They prove to be excellent predictors for noncoding variant effects in gene expression and pathogenicity, whether in unsupervised \u201czero-shot\u201d learning or supervised \u201cfew-shot\u201d learning. Availability Codes and data access can be found at https://github.com/Shen-Lab/ncVarPred-1D3D Contact yshen@tamu.edu Supplementary information Supplementary data are available at Bioinformatics online.",
        "paperId": "0f4c792150018f4c8f8c6c362a8b4cf38e46b09f"
    },
    {
        "title": "Human in the loop: How to effectively create coherent topics by manually labeling only a few documents per class",
        "firstAuthor": "Anton Thielmann",
        "url": "http://arxiv.org/pdf/2212.09422",
        "dateSubmitted": "2022-12-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot methods for accurate modeling under sparse label-settings have improved significantly. However, the applications of few-shot modeling in natural language processing remain solely in the field of document classification. With recent performance improvements, supervised few-shot methods, combined with a simple topic extraction method pose a significant challenge to unsupervised topic modeling methods. Our research shows that supervised few-shot learning, combined with a simple topic extraction method, can outperform unsupervised topic modeling techniques in terms of generating coherent topics, even when only a few labeled documents per class are used.",
        "paperId": "0f4c9d858cb38330f2f0f78d9d05ca097537b59d"
    },
    {
        "title": "Latent Weights Generating for Few Shot Learning Using Information Theory",
        "firstAuthor": "Zongyang Li",
        "url": null,
        "dateSubmitted": "2020-08-24",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0f65d2b373c212ea5495a6d29229cc327f9f8d3c"
    },
    {
        "title": "Boosting Transductive Few-Shot Fine-tuning with Margin-based Uncertainty Weighting and Probability Regularization",
        "firstAuthor": "R. Tao",
        "url": null,
        "dateSubmitted": "2023-06-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-Shot Learning (FSL) has been rapidly developed in recent years, potentially eliminating the requirement for significant data acquisition. Few-shot fine-tuning has been demonstrated to be practically efficient and helpful, especially for out-of-distribution datum [7, 13, 17, 29]. In this work, we first observe that the few-shot fine-tuned methods are learned with the imbalanced class marginal distribution, leading to imbalanced per-class testing accuracy. This observation further motivates us to propose the Transductive Fine-tuning with Margin-based uncertainty weighting and Probability regularization (TF-MP), which learns a more balanced class marginal distribution as shown in Fig. 1. We first conduct sample weighting on unlabeled testing data with margin-based uncertainty scores and fur-ther regularize each test sample's categorical probability. TF-MP achieves state-of-the-art performance on in-/out-of-distribution evaluations of Meta- Dataset [31] and sur-passes previous transductive methods by a large margin.",
        "paperId": "0f6debcbabb27effcf5d2a8d74e5d96bf2f0a310"
    },
    {
        "title": "Robust Task Clustering for Deep Many-Task Learning",
        "firstAuthor": "Mo Yu",
        "url": null,
        "dateSubmitted": "2017-08-26",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "We investigate task clustering for deep-learning based multi-task and few-shot learning in a many-task setting. We propose a new method to measure task similarities with cross-task transfer performance matrix for the deep learning scenario. Although this matrix provides us critical information regarding similarity between tasks, its asymmetric property and unreliable performance scores can affect conventional clustering methods adversely. Additionally, the uncertain task-pairs, i.e., the ones with extremely asymmetric transfer scores, may collectively mislead clustering algorithms to output an inaccurate task-partition. To overcome these limitations, we propose a novel task-clustering algorithm by using the matrix completion technique. The proposed algorithm constructs a partially-observed similarity matrix based on the certainty of cluster membership of the task-pairs. We then use a matrix completion algorithm to complete the similarity matrix. Our theoretical analysis shows that under mild constraints, the proposed algorithm will perfectly recover the underlying \"true\" similarity matrix with a high probability. Our results show that the new task clustering method can discover task clusters for training flexible and superior neural network models in a multi-task learning setup for sentiment classification and dialog intent classification tasks. Our task clustering approach also extends metric-based few-shot learning methods to adapt multiple metrics, which demonstrates empirical advantages when the tasks are diverse.",
        "paperId": "0f84e1781b8eddd4b559a7178217b2a9fb14e477"
    },
    {
        "title": "Comprehensive Analysis of Few-shot Image Classification Method Using Triplet Loss",
        "firstAuthor": "Mykola Baranov",
        "url": "https://science.lpnu.ua/sites/default/files/journal-paper/2022/jun/28146/220364ismverstka1-105-111.pdf",
        "dateSubmitted": "2022-06-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Image classification task is a very important problem of a computer vision area. The first approaches to image classification tasks belong to a classic straightforward algorithm. Despite the successful applications of such algorithms a lot of image classification tasks had not been solved until machine learning approaches were involved in a computer vision area. An early successful result of machine learning applications helps researchers with extracted features classification which was not available without machine learning models. But handcrafter features were required which left the most complicated classification task impossible to solve. Recent success in deep learning allows researchers to implement automatic trainable feature extraction. This gave significant progress in the computer vision area last but not least. Processing large-scale datasets bring researchers great progress in automatic feature extraction thus combining such features with precious approaches led to groundbreaking in computer vision. But a new limitation has come - dependency on large amounts of data. Deep learning approaches to image classification task usually requires large-scale datasets. Moreover, modern models lead to unexpected behavior in distribution datasets. A few-shot learning approach of deep learning models allows us to dramatically reduce the amount of required data while keeping the same promising results. Despite reduced datasets, there is still a tradeoff between the amount of available data and trained model performance. In this paper, we implemented a siamese network based on triplet loss. Then, we investigate a relationship between the amount of available data and few-shot model performances. We compare the models obtained by metric-learning with baselines models trained using large-scale datasets.",
        "paperId": "0f9e552bf04d65e725c1bf4ed9ef9cf2d5917c99"
    },
    {
        "title": "Few-shot malicious traffic classification based on Siamese Neural Network",
        "firstAuthor": "Kailin Wu",
        "url": null,
        "dateSubmitted": "2021-12-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The process of learning good features for machine learning applications can be computationally expensive, and can prove difficult when there is little data available. A typical example is few-shot learning. In this case, we must make predictions correctly and only give a few examples of each class. In this article, we propose a method based on a one-dimensional convolutional siamese neural network, which uses a unique structure to naturally rank the similarities between inputs. Once the network is adjusted, we can use powerful discriminative features to extend the network's predictive capabilities to new data, and to new categories from unknown distributions. Using the convolutional architecture, we can achieve powerful results that exceed other deep learning models, and have close to the most advanced performance on few-shot classification tasks. The results show that this method can obtain higher recognition accuracy than the traditional methods of smote and GAN generated data training.",
        "paperId": "0fab974a050ad7a5018ed3a0e77fd2f9e06fa4fe"
    },
    {
        "title": "Rapid and flexible segmentation of electron microscopy data using few-shot machine learning",
        "firstAuthor": "Sarah Akers",
        "url": "https://www.nature.com/articles/s41524-021-00652-z.pdf",
        "dateSubmitted": "2021-11-17",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "0fc9f67c487a48bd77e36b81e8302017f930a9af"
    },
    {
        "title": "Comparing Pretrained Image-Net CNN with a Siamese Architecture for Few-Shot Learning Applications in Radar Systems",
        "firstAuthor": "Cesar Martinez Melgoza",
        "url": null,
        "dateSubmitted": "2022-06-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Over the years, the increase in electronic devices and innovation towards technological capabilities have resulted in an increase in traffic in the electromagnetic spectrum, thus making it harder for radar systems to distinguish multiple emitters with added interference. Traditional methods for classification, such as machine learning, prove to be a suitable solution for this problem, however these models require an enormous amount of data to train and evaluate. This experiment implements a Few-Shot learning framework and evaluates the performance of different Neural Network Architectures such as a standard Convolutional Neural Network, and a Siamese Network from a previous experiment. The experiment will utilize different kinds of hardware equipment. This includes the ZCU104 FPGA board, AD-FMCOMMS2-EBZ RF module, the Jetson TX2, and NVIDIA Titan RTX. The hardware equipment will be evaluated using performance metrics such as hardware acceleration, to find the best medium between computational power, acceleration speed, and evaluation accuracy.",
        "paperId": "0fd2a69650923177a3348fd5be671792a387d079"
    },
    {
        "title": "Discriminative Hallucination for Multi-Modal Few-Shot Learning",
        "firstAuthor": "Frederik Pahde",
        "url": null,
        "dateSubmitted": "2018-10-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "State-of-the-art deep learning algorithms yield remarkable results in many visual recognition tasks. However, they still catastrophically struggle in low data scenarios. To a certain extent, the lack of visual data can be compensated by multimodal information. Information missing in one modality (e.g. image) due to the limited data can be included in the other modality (e.g. text). In this paper, we propose a benchmark for few-shot learning with multi-modal data which can be used by other researchers. We also introduced a method for few-shot fine-grained recognition, utilizing textual descriptions of the visual data. We developed a two-stage framework built upon the idea of cross-modal data hallucination. For each visual category, we first generate a set of images by conditioning on the textual description of the category using StackGANs. Next, we rank the generated images based on their class-discriminativeness and only pick the most discriminative images to extend the dataset. Lastly, a classifier invariant to our framework can be trained using an extended training set. We show the results of our proposed discriminative hallucinated method for 1-, 2-, and 5-shot learning on the CUB dataset, where the accuracy is improved by employing the multi-modal data.",
        "paperId": "0fe72746f1f58d68f06580a7c97f9aa4497a4887"
    },
    {
        "title": "R EVISIT F INETUNING STRATEGY FOR F EW -S HOT L EARN - ING TO T RANSFER THE E MDEDDINGS",
        "firstAuthor": "Revisit Finetuning",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-Shot Learning (FSL) aims to learn a simple and effective bias on limited novel samples. Recently, many methods have been focused on re-training a randomly initialized linear classifier to adapt it to the novel features extracted by a pre-trained feature extractor (called Linear-Probing-based methods). These methods typically assumed the pre-trained feature extractor was robust enough, i.e., finetuning was not needed, and hence the pre-trained feature extractor does not be adapted to the novel samples. However, the unadapted pre-trained feature extractor distorts the features of novel samples because the robustness assumption may not hold, especially on the out-of-distribution samples. To extract the undistorted features, we designed Linear-Probing-Finetuning with Firth-Bias (LP-FT-FB) to yield an accurate bias on the limited samples for better finetuning the pre-trained feature extractor, providing stronger transferring ability. In LP-FT-FB, we further proposed inverse Firth Bias Reduction (i-FBR) to regularize the over-parameterized feature extractor on which FBR does not work well. The proposed i-FBR effectively alleviates the over-fitting problem of the feature extractor in the process of finetuning and helps extract undistorted novel features. To show the effectiveness of the designed LP-FT-FB, we conducted comprehensive experiments on the commonly used FSL datasets under different backbones for in-domain and cross-domain FSL tasks. The experimental results show that the proposed FT-LP-FB outperforms the SOTA FSL methods. The code is available at https://github.com/whzyf951620/ LinearProbingFinetuningFirthBias.",
        "paperId": "0fea9c29b7be31608831f2a84ae4f21fe390252e"
    },
    {
        "title": "Zero-Shot Learning in Named-Entity Recognition with External Knowledge",
        "firstAuthor": "Nguyen Van Hoang",
        "url": null,
        "dateSubmitted": "2021-11-15",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "A significant shortcoming of current state-of-the-art (SOTA) named-entity recognition (NER) systems is their lack of generalization to unseen domains, which poses a major problem since obtaining labeled data for NER in a new domain is expensive and time-consuming. We propose ZERO, a model that performs zero-shot and few-shot learning in NER to generalize to unseen domains by incorporating pre-existing knowledge in the form of semantic word embeddings. ZERO first obtains contextualized word representations of input sentences using the model LUKE, reduces their dimensionality, and compares them directly with the embeddings of the external knowledge, allowing ZERO to be trained to recognize unseen output entities. We find that ZERO performs well on unseen NER domains with an average macro F1 score of 0.23, outperforms LUKE in few-shot learning, and even achieves competitive scores on an in-domain comparison. The performance across source-target domain pairs is shown to be inversely correlated with the pairs' KL divergence.",
        "paperId": "10133f50939dac23fbb1f5f6f289f4aec9c85f3f"
    },
    {
        "title": "A New Diagnosis Method with Few-shot Learning Based on a Class-rebalance Strategy for Scarce Faults in Industrial Processes",
        "firstAuthor": "Xin Xu",
        "url": null,
        "dateSubmitted": "2023-02-18",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "101795ca290cd876736a0962e3037453a4201836"
    },
    {
        "title": "Few-shot Learning for Topic Modeling",
        "firstAuthor": "Tomoharu Iwata",
        "url": null,
        "dateSubmitted": "2021-04-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Topic models have been successfully used for analyzing text documents. However, with existing topic models, many documents are required for training. In this paper, we propose a neural network-based few-shot learning method that can learn a topic model from just a few documents. The neural networks in our model take a small number of documents as inputs, and output topic model priors. The proposed method trains the neural networks such that the expected test likelihood is improved when topic model parameters are estimated by maximizing the posterior probability using the priors based on the EM algorithm. Since each step in the EM algorithm is differentiable, the proposed method can backpropagate the loss through the EM algorithm to train the neural networks. The expected test likelihood is maximized by a stochastic gradient descent method using a set of multiple text corpora with an episodic training framework. In our experiments, we demonstrate that the proposed method achieves better perplexity than existing methods using three real-world text document sets.",
        "paperId": "101bbfb1686f806c94ab8cc49ee94945b0f05cf7"
    },
    {
        "title": "A Unified Two-Stage Spatial and Spectral Network With Few-Shot Learning for Pansharpening",
        "firstAuthor": "Zhi Sheng",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recently, pansharpening methods based on deep learning (DL) have achieved state-of-the-art results. However, current existing DL-based pansharpening methods need to be trained repetitively for different satellite sensors to obtain satisfactory fusion performance and therefore require a large number of training images for each satellite. To deal with these issues, in this article, we propose a unified two-stage spatial and spectral network (UTSN) for pansharpening. A branch of networks is constructed for each different satellite, in which the spatial enhancement network (SEN) is shared to improve the spatial details in the fused images from different satellites. A spectral adjustment network (SAN) is employed to capture the spectral characteristics of the specific satellite. Through SAN, the spectral information in the intermediate image from SEN is refined to produce the final fusion results. Such a framework can integrate the datasets from different satellites together for sufficient training of SEN. The proposed method is able to achieve promising pansharpening results also for a new satellite with limited training images by only learning a new SAN on the few-shot datasets due to the simple but efficient structure of SAN. The experimental results show that the proposed method can produce state-of-the-art fusion results in both the standard and few-shot cases. The source code is publicly available at https://github.com/RSMagneto/UTSN.",
        "paperId": "10256e7ffde4fe2d658cb3f1c5988dece579a274"
    },
    {
        "title": "Exploiting Contactless Side Channels in Wireless Charging Power Banks for User Privacy Inference via Few-shot Learning",
        "firstAuthor": "Tao Ni",
        "url": null,
        "dateSubmitted": "2023-10-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Recently, power banks for smartphones have begun to support wireless charging. Although these wireless charging power banks appear to be immune to most reported vulnerabilities in either power banks or wireless charging, we have found a new contactless wireless charging side channel in these power banks that leaks user privacy from their wireless charging smartphones without compromising either power banks or victim smartphones. We have proposed BankSnoop to demonstrate the practicality of the newly discovered wireless charging side channel in power banks. Specifically, it leverages the coil whine and magnetic field disturbance emitted by a power bank when wirelessly charging a smartphone and adopts the few-shot learning to recognize the app running on the smartphone and uncover keystrokes. We evaluate the effectiveness of BankSnoop using commodity wireless charging power banks and smartphones, and the results show it achieves over 90% accuracy on average in recognizing app launching and keystrokes. It also presents high adaptability when apply to different smartphone models, power banks, etc., achieving over 85% accuracy with 10-shot learning.",
        "paperId": "1027be65f649dd00bc0c21722d50c32ffef19223"
    },
    {
        "title": "Non-episodic Variational Weight Imprinting for Few-Shot Learning",
        "firstAuthor": "V. Padma",
        "url": "https://link.springer.com/content/pdf/10.1007/s42979-023-01732-1.pdf",
        "dateSubmitted": "2023-03-31",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "103084da0b16d93325bb93103bce83b5a5c8a513"
    },
    {
        "title": "Few-shot Text Classification with Saliency-equivalent Concatenation",
        "firstAuthor": "Ying-Jia Lin",
        "url": null,
        "dateSubmitted": "2022-09-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In few-shot text classification, the lack of significant features limits models from generalizing to data not included in the training set. Data augmentation is a solution to the classification tasks; however, the standard augmentation methods in natural language processing are not feasible in few-shot learning. In this study, we explore data augmentation in few-shot text classification. We propose saliency-equivalent concatenation (SEC)11Our code is available at https://github.com/IKMLab/SEC.. The core concept of SEC is to append additional key information to an input sentence to help a model understand the sentence easier. In the proposed method, we first leverage a pre-trained language model to generate several novel sentences for each sample in datasets. Then we leave the most relevant one and concatenate it with the original sentence as additional information for each sample. Our experiments on the two few-shot text classification tasks verified that the proposed method can boost the performance of meta-learning models and outperform the previous unsupervised data augmentation methods.",
        "paperId": "1039237871a7b65833dc433690d4adaa6f973c27"
    },
    {
        "title": "Measuring the Robustness of Natural Language Processing Models to Domain Shifts",
        "firstAuthor": "Nitay Calderon",
        "url": "http://arxiv.org/pdf/2306.00168",
        "dateSubmitted": "2023-05-31",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Existing research on Domain Robustness (DR) suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we pose a fundamental question: What is the state of affairs of the DR challenge in the era of Large Language Models (LLMs)? To this end, we construct a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We explore the DR challenge of fine-tuned and few-shot learning models in natural domain shift settings and devise two diagnostic metrics of Out-of-Distribution (OOD) performance degradation: The commonly used Source Drop (SD) and the overlooked Target Drop (TD). Our findings reveal important insights: First, despite their capabilities, zero-to-few shot LLMs and fine-tuning approaches still fail to meet satisfactory performance in the OOD context; Second, TD approximates better than SD the average OOD degradation; Third, in a significant proportion of domain shifts, either SD or TD is positive, but not both, and therefore disregarding one can lead to incorrect DR conclusions.",
        "paperId": "104c878d17a179e86ba094b221993cfdd3277943"
    },
    {
        "title": "FEW-SHOT LEARNING WITH WEAK SUPERVISION",
        "firstAuthor": "Ali Ghadirzadeh",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot meta-learning methods aim to learn the common structure shared across a set of tasks to facilitate learning new tasks with small amounts of data. However, provided only a few training examples, many tasks are ambiguous. Such ambiguity can be mitigated with side information in terms of weak labels which is often readily available. In this paper, we propose a Bayesian gradient-based metalearning algorithm that can incorporate weak labels to reduce task ambiguity and improve performance. Our approach is cast in the framework of amortized variational inference and trained by optimizing a variational lower bound. The proposed method is competitive to state-of-the-art methods and achieves significant performance gains in settings where weak labels are available.",
        "paperId": "105aefdc812c469971f1355475cf913e98a27f02"
    },
    {
        "title": "miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings",
        "firstAuthor": "T. Klein",
        "url": "http://arxiv.org/pdf/2211.04928",
        "dateSubmitted": "2022-11-09",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "This paper presents miCSE, a mutual information-based contrastive learning framework that significantly advances the state-of-the-art in few-shot sentence embedding.The proposed approach imposes alignment between the attention pattern of different views during contrastive learning. Learning sentence embeddings with miCSE entails enforcing the structural consistency across augmented views for every sentence, making contrastive self-supervised learning more sample efficient. As a result, the proposed approach shows strong performance in the few-shot learning domain. While it achieves superior results compared to state-of-the-art methods on multiple benchmarks in few-shot learning, it is comparable in the full-shot scenario. This study opens up avenues for efficient self-supervised learning methods that are more robust than current contrastive methods for sentence embedding.",
        "paperId": "106551b32cc73db6561cfd2be61aa522be5154a7"
    },
    {
        "title": "Towards Practical Few-shot Federated NLP",
        "firstAuthor": "Dongqi Cai",
        "url": "https://arxiv.org/pdf/2212.00192",
        "dateSubmitted": "2022-12-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Transformer-based pre-trained models have emerged as the predominant solution for natural language processing (NLP). Fine-tuning such pre-trained models for downstream tasks often requires a considerable amount of labeled private data. In practice, private data is often distributed across heterogeneous mobile devices and may be prohibited from being uploaded. Moreover, well-curated labeled data is often scarce, presenting an additional challenge. To address these challenges, we first introduce a data generator for federated few-shot learning tasks, which encompasses the quantity and skewness of scarce labeled data in a realistic setting. Subsequently, we propose AUG-FedPrompt, a prompt-based federated learning system that exploits abundant unlabeled data for data augmentation. Our experiments indicate that AUG-FedPrompt can perform on par with full-set fine-tuning with a limited amount of labeled data. However, such competitive performance comes at a significant system cost.",
        "paperId": "10717aefce06cc41465619ec8c956f4b0b0fa6e1"
    },
    {
        "title": "Few-Shot and Many-Shot Fusion Learning in Mobile Visual Food Recognition",
        "firstAuthor": "Heng Zhao",
        "url": null,
        "dateSubmitted": "2019-05-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Mobile visual food recognition is emerging as an important application in food logging and dietary monitoring in recent years. Existing food recognition methods use conventional many-shot learning to train a large backbone network, which refers to the use of sufficient number of training data to train the network. However, these methods firstly do not consider the cases where certain food categories have limited training data. Therefore, they cannot use the conventional training using many-shot learning. Further, existing solutions focus on improving the food recognition performance by implementing state-of-the-art large full networks, and do not pay much attention to reduce the size and computational cost of the network. As a result, they are not amenable for deployment on mobile devices. In this paper, we address these issues by proposing a new few-shot and many-shot fusion learning for mobile visual food recognition, it has a compact framework and is able to learn from existing dataset categories, and also new food categories given only a few sample images. We construct a new Indian food dataset called NTU-IndianFood107 in order to evaluate the performance of the proposed method. The dataset has two parts: (i) a Base Dataset of 83 classes of Indian food images with over 600 images per class to perform many-shot learning, and (ii) a Food Diary of 24 classes captured in restaurants with limited number to simulate the few-shot learning on new food categories. The proposed fusion method achieves a Top-1 classification accuracy of 72.0% on the new dataset.",
        "paperId": "10721e5ec34d8072b619f4f7975c32fc7c202cd5"
    },
    {
        "title": "Weakly-supervised Object Localization for Few-shot Learning and Fine-grained Few-shot Learning.",
        "firstAuthor": "Xiaojian He",
        "url": null,
        "dateSubmitted": "2020-12-14",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Few-shot learning (FSL) aims to learn novel visual categories from very few samples, which is a challenging problem in real-world applications. Many methods of few-shot classification work well on general images to learn global representation. However, they can not deal with fine-grained categories well at the same time due to a lack of subtle and local information. We argue that localization is an efficient approach because it directly provides the discriminative regions, which is critical for both general classification and fine-grained classification in a low data regime. In this paper, we propose a Self-Attention Based Complementary Module (SAC Module) to fulfill the weakly-supervised object localization, and more importantly produce the activated masks for selecting discriminative deep descriptors for few-shot classification. Based on each selected deep descriptor, Semantic Alignment Module (SAM) calculates the semantic alignment distance between the query and support images to boost classification performance. Extensive experiments show our method outperforms the state-of-the-art methods on benchmark datasets under various settings, especially on the fine-grained few-shot tasks. Besides, our method achieves superior performance over previous methods when training the model on miniImageNet and evaluating it on the different datasets, demonstrating its superior generalization capacity. Extra visualization shows the proposed method can localize the key objects more interval.",
        "paperId": "1085908abbb8ea6b04984315a506309f364ae563"
    },
    {
        "title": "MetaHistoSeg: A Python Framework for Meta Learning in Histopathology Image Segmentation",
        "firstAuthor": "Zheng Yuan",
        "url": "https://arxiv.org/pdf/2109.14754",
        "dateSubmitted": "2021-09-29",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "1085aa8d267c4fa4fc16f43f734eceddfa661362"
    },
    {
        "title": "A Systematic Review of Few-Shot Learning in Medical Imaging",
        "firstAuthor": "Eva Pachetti",
        "url": "https://arxiv.org/pdf/2309.11433",
        "dateSubmitted": "2023-09-20",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets. Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis, especially with meta-learning. This systematic review gives a comprehensive overview of few-shot learning in medical imaging. We searched the literature systematically and selected 80 relevant articles published from 2018 to 2023. We clustered the articles based on medical outcomes, such as tumour segmentation, disease classification, and image registration; anatomical structure investigated (i.e. heart, lung, etc.); and the meta-learning method used. For each cluster, we examined the papers' distributions and the results provided by the state-of-the-art. In addition, we identified a generic pipeline shared among all the studies. The review shows that few-shot learning can overcome data scarcity in most outcomes and that meta-learning is a popular choice to perform few-shot learning because it can adapt to new tasks with few labelled samples. In addition, following meta-learning, supervised learning and semi-supervised learning stand out as the predominant techniques employed to tackle few-shot learning challenges in medical imaging and also best performing. Lastly, we observed that the primary application areas predominantly encompass cardiac, pulmonary, and abdominal domains. This systematic review aims to inspire further research to improve medical image analysis and patient care.",
        "paperId": "10952bd6ede413a389c66fb32d7c29ab295dbebf"
    },
    {
        "title": "Studying and Improving Extrapolation and Generalization of Non-Parametric and Optimization-Based Meta-Learners",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In case of few-shot learners, the ability of the algorithms to generalize beyond the training tasks and datasets it sees is of utmost importance. However, little is known about individual extrapolation properties of non-parametric few-shot learning algorithms on unknown out-of-distribution tasks. Next to examining the generalization and extrapolation performance of the raw and unmodified non-parametric few-shot learners we explore and propose bespoke regularization methods that can help reduce initial training task overfitting. In this context we examine the corresponding out-of-distribution performances of regularized learners. Finn and Levine [2018] compare the gradient based-optimization learners (MAML) to black-box (recurrent) meta-learners on out-of-distribution tasks. Yet it is still unclear how generalization and extrapolation properties of non-parametric fewshot learners compare to MAML and recurrent learners. Given the competitive performance of proto-nets on, e.g., the Omniglot dataset (see Snell et al. [2017] and Vinyals et al. [2017]), it is important to extend the analysis to non-parametric-type models. Further, recent research shows that 'in-domain' task distributions are typically well captured by state of the art few-shot learning approaches such that the models are robust towards mild in-domain distributional shifts (Finn and Levine [2018]). To assess the cross-domain robustness of meta-learners, Triantafillou et al. [2020] introduce a meta-dataset comprised of several sub-datasets suitable for few-shot learning. The authors show that the performance of meta-learners trained on a subset of datasets and tested on different datasets deteriorates considerably. Hence, few-shot learning models do not generalize well to out-of-domain data and in this respect fall short of the ambition to match humanoid performance. Various approaches were proposed to mitigate the initial overfitting in meta-learning. Recent examples of regularization procedures for meta-learning are given in Zintgraf et al. [2019], Lee et al. [2020], Zhang et al. [2018], Guiroy et al. [2019] and Jamal et al. [2018]. In contrast to the traditional approaches, Finn and Levine [2018] address the problem of meta-overfitting in the context of non-mutually exclusive tasks. The primary aim of our study is to empirically assess the out-of-distribution (OOD) generalization properties of non-parametric and optimization-based meta-learning. We assess the generalization on both perturbed test data from the domain under consideration (in-domain generalization) and also on tasks drawn from other unrelated datasets (out-of-domain) taken from a meta dataset. The latter test can certainly be seen as the tougher stress test for few-shot learners. Second, our approach builds on the premise that few meta-learning studies are explicitly concerned with regularization for generalizing across domains. To better control the trade-off between in sample / in-domain fit and the ability of a model to generalize we investigate the use of regularization techniques for this purpose. Our main findings show that non-parametric meta-learners as represented by ProtoNets generalize better than optimization-based meta-learners such as MAML and ANIL. This finding holds for both distributional shifts of in-domain data and cross-domain data taken from a meta-dataset, i.e. a dataset of datasets. In addition, our experiments suggest that regularizing the image embedding layers is beneficial to both MAML/ANIL and ProtoNets. In specific, we find that the metaregularization proposed in Yin et al. [2020] can slightly improve the accuracies achieved with ANIL while facilitating trainability. Further, a combination of the meta-regularization and dropout seems well suited for regularizing ProtoNets. Future work can directly adapt to our results. A promising path is to assess the generalization properties of the ProtoMAML model introduced by Triantafillou et al. [2020] which was shown to be successful in cross-domain exercises. All regularization techniques applied in our study directly carry over to the ProtoMAML. Apart from regularizing the image embedding layers, Zhou et al. [2020] is a recent approach in meta-learning aiming to learn equivariances from data. Equivariances are immune to certain shifts of the data input and hence a model based on encoded equivariances should generalize well.",
        "paperId": "1095343b5869c3968bff4c1a10a920d4e94c3a19"
    },
    {
        "title": "Neural Data Augmentation via Example Extrapolation",
        "firstAuthor": "Kenton Lee",
        "url": null,
        "dateSubmitted": "2021-02-02",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "In many applications of machine learning, certain categories of examples may be underrepresented in the training data, causing systems to underperform on such\"few-shot\"cases at test time. A common remedy is to perform data augmentation, such as by duplicating underrepresented examples, or heuristically synthesizing new examples. But these remedies often fail to cover the full diversity and complexity of real examples. We propose a data augmentation approach that performs neural Example Extrapolation (Ex2). Given a handful of exemplars sampled from some distribution, Ex2 synthesizes new examples that also belong to the same distribution. The Ex2 model is learned by simulating the example generation procedure on data-rich slices of the data, and it is applied to underrepresented, few-shot slices. We apply Ex2 to a range of language understanding tasks and significantly improve over state-of-the-art methods on multiple few-shot learning benchmarks, including for relation extraction (FewRel) and intent classification + slot filling (SNIPS).",
        "paperId": "10b15a695f837fbdc2babe0c38f8702c10af7bfb"
    },
    {
        "title": "Cascade Graph Neural Networks for Few-Shot Learning on Point Clouds",
        "firstAuthor": "Yangfan Li",
        "url": null,
        "dateSubmitted": "2023-08-01",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Point cloud data, a flexible 3D object representation, is critical for various applications such as autonomous driving, robotics and remote sensing. Despite the recent success of deep neural networks (DNNs) on supervised point cloud analysis tasks, they still rely on tedious manual annotation of point clouds and cannot make predictions for new classes. Unlike few-shot learning for 2D images with the advantages of large-scale datasets and high-quality deep pre-trained models like ResNet, for 3D few-shot learning, obtaining discriminative representations of unseen classes with high intra-class similarity and inter-class difference is very challenging. To address this issue, this work proposes a novel cascade graph neural network for few-shot learning on point clouds, termed as CGNN, in which two cascade GNNs are adopted to extract the intra-object topological information and learn the inter-object relations respectively. To further increase the discriminability of point cloud features, we first design a novel discriminative edge label to model the intra-class similarity and inter-class dissimilarity based on channel-wise feature variance and class consistency. Second, we propose a novel few-shot circle loss which classifies the nodes into two subsets, i.e., support to support pairs and support to query pairs, and optimizes the pair-wise similarity on two subsets independently. Extensive experiments on benchmark CAD and real LiDAR point cloud datasets have demonstrated that CGNN improves accuracy by 5.98% over the state-of-the-art GNN-based few-shot classification methods.",
        "paperId": "10be1384ac1030b0be5cda9fd2c161a6133af5be"
    },
    {
        "title": "Few-shot cotton leaf spots disease classification based on metric learning",
        "firstAuthor": "Xihuizi Liang",
        "url": "https://plantmethods.biomedcentral.com/track/pdf/10.1186/s13007-021-00813-7",
        "dateSubmitted": "2021-08-06",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": null,
        "paperId": "10dcbdc9e2cd8065f1e5af67fb8e5c0423de08f0"
    },
    {
        "title": "Few-shot Insider Threat Detection",
        "firstAuthor": "Shuhan Yuan",
        "url": null,
        "dateSubmitted": "2020-10-19",
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Insiders cause significant cyber-security threats to organizations. Due to a very limited number of insiders, most of the current studies adopt unsupervised learning approaches to detect insiders by analyzing the audit data that record information about employees' activities. However, in practice, we do observe a small number of insiders. How to make full use of these few observed insiders to improve a classifier for insider threat detection is a key challenge. In this work, we propose a novel framework combining the idea of self-supervised pre-training and metric-based few-shot learning to detect insiders. Experimental results on insider threat datasets demonstrate that our model outperforms the existing anomaly detection approaches by only using a few insiders.",
        "paperId": "10e0303e00c0f5f8582f5097ff5e113298babc6f"
    },
    {
        "title": "HG-Meta: Graph Meta-learning over Heterogeneous Graphs",
        "firstAuthor": "Qiannan Zhang",
        "url": "https://repository.kaust.edu.sa/bitstream/10754/678229/1/SDM22.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "few-shot learning"
        ],
        "abstract": "Prevailing supervised graph neural networks su\ufb00er from po-tential performance degradation in the label sparsity case. Though increasing attention has been paid to graph few-shot learning methods for learning e\ufb00ective graph embeddings under the scarcity of labeled data, most existing works study homogeneous graphs while ignoring the ubiquitous-ness of heterogeneous graphs (HG), where multi-typed nodes are interconnected by multi-typed edges. To this end, we propose to tackle few-shot learning on HG and develop a novel model for H eterogeneous G raph Meta -learning (a.k.a. HG-Meta ). Regarding the graph heterogeneity, HG-Meta \ufb01rstly builds a graph encoder to aggregate heterogeneous neighbors information from multiple semantic contexts (gen-erated by meta-paths). Secondly, to train the graph encoder with meta-learning in a few-shot scenario, HG-Meta tackles meta-task di\ufb00erences produced from meta-task sampling procedure on HG with a task feature scaling module and a degree based task attention module. To further alleviate low-data problem, HG-Meta leverages unlabelled information in HG with auxiliary self-supervised learning task alongside the meta-optimization process to facilitate node embedding. Extensive experiments on two HG datasets demonstrate that HG-Meta outperforms state-of-the-art methods for multiple few-shot node classi\ufb01cation tasks.",
        "paperId": "10e390b725a95ddae3cf780fa9bcd1a5bc13fd52"
    }
]