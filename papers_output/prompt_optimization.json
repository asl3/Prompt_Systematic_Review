[
    {
        "title": "Improving Short Text Classification With Augmented Data Using GPT-3",
        "firstAuthor": "Salvador Balkus",
        "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/4F23066E3F0156382190BD76DA9A7BA5/S1351324923000438a.pdf/div-class-title-improving-short-text-classification-with-augmented-data-using-gpt-3-div.pdf",
        "dateSubmitted": "2022-05-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "\n GPT-3 is a large-scale natural language model developed by OpenAI that can perform many different tasks, including topic classification. Although researchers claim that it requires only a small number of in-context examples to learn a task, in practice GPT-3 requires these training examples to be either of exceptional quality or a higher quantity than easily created by hand. To address this issue, this study teaches GPT-3 to classify whether a question is related to data science by augmenting a small training set with additional examples generated by GPT-3 itself. This study compares two augmented classifiers: the Classification Endpoint with an increased training set size and the Completion Endpoint with an augmented prompt optimized using a genetic algorithm. We find that data augmentation significantly increases the accuracy of both classifiers, and that the embedding-based Classification Endpoint achieves the best accuracy of about 76%, compared to human accuracy of 85%. In this way, giving large language models like GPT-3 the ability to propose their own training examples can improve short text classification performance.",
        "paperId": "0008b1e49c3d4afe2cfffe82ea88be147b618504"
    },
    {
        "title": "Automatic Prompt Rewriting for Personalized Text Generation",
        "firstAuthor": "Cheng Li",
        "url": "https://arxiv.org/pdf/2310.00152",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Facilitated by large language models (LLMs), personalized text generation has become a rapidly growing research direction. Most existing studies focus on designing specialized models for a particular domain, or they require fine-tuning the LLMs to generate personalized text. We consider a typical scenario in which the large language model, which generates personalized output, is frozen and can only be accessed through APIs. Under this constraint, all one can do is to improve the input text (i.e., text prompts) sent to the LLM, a procedure that is usually done manually. In this paper, we propose a novel method to automatically revise prompts for personalized text generation. The proposed method takes the initial prompts generated by a state-of-the-art, multistage framework for personalized generation and rewrites a few critical components that summarize and synthesize the personal context. The prompt rewriter employs a training paradigm that chains together supervised learning (SL) and reinforcement learning (RL), where SL reduces the search space of RL and RL facilitates end-to-end training of the rewriter. Using datasets from three representative domains, we demonstrate that the rewritten prompts outperform both the original prompts and the prompts optimized via supervised learning or reinforcement learning alone. In-depth analysis of the rewritten prompts shows that they are not only human readable, but also able to guide manual revision of prompts when there is limited resource to employ reinforcement learning to train the prompt rewriter, or when it is costly to deploy an automatic prompt rewriter for inference.",
        "paperId": "04892382200a9d48ad5f8d3cb3cd3d63a8206a01"
    },
    {
        "title": "Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation",
        "firstAuthor": "Zonghai Yao",
        "url": null,
        "dateSubmitted": "2023-11-16",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "This study examines the effect of prompt engineering on the performance of Large Language Models (LLMs) in clinical note generation. We introduce an Automatic Prompt Optimization (APO) framework to refine initial prompts and compare the outputs of medical experts, non-medical experts, and APO-enhanced GPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in standardizing prompt quality across clinical note sections. A human-in-the-loop approach shows that experts maintain content quality post-APO, with a preference for their own modifications, suggesting the value of expert customization. We recommend a two-phase optimization process, leveraging APO-GPT4 for consistency and expert input for personalization.",
        "paperId": "0544cad023bf49bbf51d69f44f8280dc63b20f57"
    },
    {
        "title": "An Impact of Use the Artificial Neural Networks in Analysis of Electrical Power Stability at Meharde Plant (Hama-Syria)",
        "firstAuthor": "A. Alzakkar",
        "url": null,
        "dateSubmitted": "2021-09-05",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "The administration of power system has gotten more troublesome than before in light of the fact that power systems are worked nearer as far as possible, ecological requirements limit the development of transmission network, the requirement for significant distance power transfers has increased and less administrators are occupied with the management and activity of power systems. Voltage instability has become a significant worry in many power systems and numerous power outages have been accounted for, where the explanation has been voltage instability. In the current work, the electric voltage stability in Meharde station in Syria has concentrated during the typical and up ordinary loading state. The outcomes in this examination were getting from fake neural network, which is comprising from three layers (input-hidden-output), where this network described by the speed and accuracy in preparing before the failure and cease the providing engine which may prompt practical problems. This investigation has been done through two unique examples of generating in this station (single, double and four) generators. The accomplishment of this network comprises of two phases: preparing Stage (disconnected) and testing Stage (on-line) to make an examination between the preparation stage and testing stage which prompting optimization the load in testing cases relying upon preparing data.",
        "paperId": "05a49c195c282dcfd8bfc3dfa8cb8d7ea5f5b90d"
    },
    {
        "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
        "firstAuthor": "Mingkai Deng",
        "url": "http://arxiv.org/pdf/2205.12548",
        "dateSubmitted": "2022-05-25",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Prompting has shown impressive success in enabling large pre-trained language models (LMs) to perform diverse NLP tasks, especially with only few downstream data. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning *soft* prompts (e.g., embeddings) which fall short of interpretability, reusability across LMs, and applicability when gradients are not accessible. *Discrete* prompts, on the other hand, are difficult to optimize, and are often created by \u201cenumeration (e.g., paraphrasing)-then-selection\u201d heuristics that do not explore the prompt space systematically. This paper proposes RLPrompt, an efficient discrete prompt optimization approach with reinforcement learning (RL). RLPrompt formulates a parameter-efficient policy network that generates the optimized discrete prompt after training with reward. To harness the complex and stochastic reward signals from the large LM environment, we incorporate effective reward stabilization that substantially enhances training efficiency. RLPrompt is flexibly applicable to different types of LMs, such as masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both classification and generation tasks. Experiments on few-shot classification and unsupervised text style transfer show superior performance over a wide range of existing fine-tuning or prompting methods. Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns.",
        "paperId": "07759a84f27e43cfa5bc8d579f8227c96e6ae1dc"
    },
    {
        "title": "Home energy management system internetworking with advanced metering infrastructure",
        "firstAuthor": "Jeong-In Lee",
        "url": null,
        "dateSubmitted": "2012-12-24",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Smart grid attempts to predict and intelligently respond to the advanced metering infrastructure and smart meters in home place. It is prompting optimization of energy management. The present of HEMS is possible to real-time monitoring of information regarding energy consumption by advanced metering infrastructures (AMI) and smart meter. In this paper, we build a set of an application program interface (API) for controlling and monitoring energy devices connected with HEMS and AMI.",
        "paperId": "08646d239689997cc04291c1b948088ee5b84f91"
    },
    {
        "title": "MultiPrompter: Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning",
        "firstAuthor": "Dong-Ki Kim",
        "url": null,
        "dateSubmitted": "2023-10-25",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Recently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL). This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models. However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence. This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters which take turns composing a prompt together. Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts. We test our method on the text-to-image task and show its ability to generate higher-quality images than baselines.",
        "paperId": "0887b3324d64c4c9ee35593a2260002089658572"
    },
    {
        "title": "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL",
        "firstAuthor": "Hao Sun",
        "url": "https://arxiv.org/pdf/2309.06553",
        "dateSubmitted": "2023-09-13",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In this study, we aim to enhance the arithmetic reasoning ability of Large Language Models (LLMs) through zero-shot prompt optimization. We identify a previously overlooked objective of query dependency in such optimization and elucidate two ensuing challenges that impede the successful and economical design of prompt optimization techniques. One primary issue is the absence of an effective method to evaluate prompts during inference when the golden answer is unavailable. Concurrently, learning via interactions with the LLMs to navigate the expansive natural language prompting space proves to be resource-intensive. To address this, we introduce Prompt-OIRL, which harnesses offline inverse reinforcement learning to draw insights from offline prompting demonstration data. Such data exists as by-products when diverse prompts are benchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependent prompt optimization objective is achieved by first learning an offline reward model. This model can evaluate any query-prompt pairs without accessing LLMs. Subsequently, a best-of-N strategy is deployed to recommend the optimal prompt. Our experimental evaluations across various LLM scales and arithmetic reasoning datasets underscore both the efficacy and economic viability of the proposed approach.",
        "paperId": "0ad677b4172e5aef8b18bc6832145d1a03e11da4"
    },
    {
        "title": "Temporally-Extended Prompts Optimization for SAM in Interactive Medical Image Segmentation",
        "firstAuthor": "Chuyun Shen",
        "url": "http://arxiv.org/pdf/2306.08958",
        "dateSubmitted": "2023-06-15",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "The Segmentation Anything Model (SAM) has recently emerged as a foundation model for addressing image segmentation. Owing to the intrinsic complexity of medical images and the high annotation cost, the medical image segmentation (MIS) community has been encouraged to investigate SAM's zero-shot capabilities to facilitate automatic annotation. Inspired by the extraordinary accomplishments of interactive medical image segmentation (IMIS) paradigm, this paper focuses on assessing the potential of SAM's zero-shot capabilities within the IMIS paradigm to amplify its benefits in the MIS domain. Regrettably, we observe that SAM's vulnerability to prompt forms (e.g., points, bounding boxes) becomes notably pronounced in IMIS. This leads us to develop a framework that adaptively offers suitable prompt forms for human experts. We refer to the framework above as temporally-extended prompts optimization (TEPO) and model it as a Markov decision process, solvable through reinforcement learning. Numerical experiments on the standardized benchmark BraTS2020 demonstrate that the learned TEPO agent can further enhance SAM's zero-shot capability in the MIS context.",
        "paperId": "0da5adf32fe7501a5b98eb6549b2c42af08ee094"
    },
    {
        "title": "Preoperative and postoperative predictors of early and delayed extubation after coronary artery bypass surgery.",
        "firstAuthor": "Lynn V. Doering",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "OBJECTIVE\nTo identify preoperative, intraoperative, and postoperative predictors of early (6 hours or less after surgery) and delayed (more than 6 hours) extubation after coronary artery bypass graft surgery.\n\n\nMETHODS\nThe sample for this prospective nonrandomized study consisted of 116 consecutive patients in a 12-bed cardiothoracic ICU who had coronary artery bypass graft surgery in a 6-month period and were followed up prospectively until transfer to an observation unit.\n\n\nRESULTS\nAge and the presence of early hemodynamic instability (within the first 3 hours after ICU admission) were independent predictors of intubation times of more than 6 hours when each was considered in separate multivariate models of preoperative, intraoperative, and postoperative variables. In a combined model, when considered with age and ejection fraction, the presence of early hemodynamic instability increased the odds by 4.7 times that extubation would occur more than 6 hours after surgery. For every 1 year increase in age, the odds of extubation occurring more than 6 hours after surgery increased by 6.5%.\n\n\nCONCLUSIONS\nOlder age and the presence of early hemodynamic instability are associated with postoperative intubation periods of more than 6 hours after coronary artery bypass graft surgery. Clinicians should evaluate extubation goals in older patients carefully. Clinical management of hemodynamic instability should be aimed at prompt optimization of myocardial oxygen supply to limit ischemia and its sequelae.",
        "paperId": "129e53a2025b341375a2148765c6093c67c513f3"
    },
    {
        "title": "Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models",
        "firstAuthor": "Paul Youssef",
        "url": null,
        "dateSubmitted": "2023-10-25",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich in world knowledge. This fact has sparked the interest of the community in quantifying the amount of factual knowledge present in PLMs, as this explains their performance on downstream tasks, and potentially justifies their use as knowledge bases. In this work, we survey methods and datasets that are used to probe PLMs for factual knowledge. Our contributions are: (1) We propose a categorization scheme for factual probing methods that is based on how their inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of the datasets used for factual probing; (3) We synthesize insights about knowledge retention and prompt optimization in PLMs, analyze obstacles to adopting PLMs as knowledge bases and outline directions for future work.",
        "paperId": "18d18d4ffdc070868ce06f216a2a8d040d42a4cb"
    },
    {
        "title": "Medical Students\u2019 Perspectives on an Assessment of Reflective Portfolios [Response to Letter]",
        "firstAuthor": "S. Kassab",
        "url": "https://www.dovepress.com/getfile.php?fileID=59764",
        "dateSubmitted": "2020-07-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Salah Eldin Kassab 1 Mubarak Bidmos 1 Michail Nomikos 1 Suhad Daher-Nashif 2 Tanya Kane 2 Srikant Sarangi Marwan Abu-Hijleh 1 1Department of Basic Medical Sciences, College of Medicine, QU Health, Qatar University, Doha, Qatar; 2Department of Population Medicine, College of Medicine, QU Health, Qatar University, Doha, Qatar; 3Danish Institute of Humanities and Medicine (DIHM), Aalborg University, Aalborg, Denmark Dear editor We thank Forenc et al for their interest in our study titled Construct Validity of an Instrument for Assessment of Reflective Writing-Based Portfolios of Medical Students. In their Letter to Editor, their main critique concerned the extent to which the nonanonymity of reflective portfolios and the lack of reflection prompts to students may have affected the G-theory analysis. In their view, these two aspects will have reduced the percentage variance of the object of measurement (students) and thus influenced the variance attributed to the study facets. In addition, they draw attention that the study instrument might not be replicable for clinical students, due to increased complexity of the learning environment. We address their concerns in turn. It is important to clarify that there are currently no universal guidelines for explaining the magnitude of variance related to each component in G-theory analysis. Of course, any researcher would aim to get the maximum percentage of variance attributed to differences between the object of measurement compared with other facets in the measurement plan. However, the main determinant of what represents large or small variance is the purpose of the study and the identified sources of variance. For example, we have recently reported an acceptable reliability coefficient with only 27% variance due to the object of measurement, because the study aimed to measure \u201csoft skills\u201d, which are considered difficult to measure. Given that reflection is an enigmatic and complex construct, we believe that the 46.6% variance attributed to the object of measurement in our study was reasonably grounded. We fully acknowledge that anonymity in reflective writing\u2013based portfolios could have reduced the variance in student\u2013rater interaction and thus bias in assessment. However, the decision concerning whether to provide students with reflection prompts or not is a tradeoff between scaffolding a structured, guided reflection process or affording the unbounded freedom of personal reflections deriving from a rich and varied array of lived experiences. We firmly believe that the absence of reflection prompts optimizes the conditions for individually unique, authentic reflections, which must be preferred to (re)acting reflectively to a checklist of activities triggered by a set of predetermined prompts. Here, maintaining a distinction between \u201creflection for learning\u201d and \u201creflection for assessment\u201d is useful: although prompts are a good device for learning purposes, they are not relevant for assessment purposes. In the latter context, what students choose to Correspondence: Salah Eldin Kassab Physiology and Medical Education, College of Medicine, QU Health, Qatar University, PO Box 2713, Doha, Qatar Tel +974 4403 7843 Email skassab@qu.edu.qa Advances in Medical Education and Practice Dovepress open access to scientific and medical research",
        "paperId": "1960aa27ec7fd799941a6905c086d32ffa0214ce"
    },
    {
        "title": "Identification of Hydroxamic Acid Based Selective HDAC1 Inhibitors: Computer Aided Drug Design Studies.",
        "firstAuthor": "P. Patel",
        "url": null,
        "dateSubmitted": "2019-03-31",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "BACKGROUND\nOverexpression of Histone deacetylase 1 (HDAC1) is responsible for carcinogenesis by promoting epigenetic silence of tumour suppressor genes. Thus, HDAC1 inhibitors have emerged as the potential therapeutic leads against multiple human cancers, as they can block the activity of particular HDACs, renovate the expression of several tumour suppressor genes and bring about cell differentiation, cell cycle arrest and apoptosis.\n\n\nMETHODS\nThe present research work comprises atom-based 3D-QSAR, docking, molecular dynamic simulations and DFT (density functional theory) studies on a diverse series of hydroxamic acid derivatives as selective HDAC1 inhibitors. Two pharmacophoric models were generated and validated by calculating the enrichment factors with the help of the decoy set. The Four different 3D-QSAR models i.e., PLS (partial least square) model, MLR (multiple linear regression) model, Field-based model and GFA (Genetic function approximation) model were developed using 'PHASE' v3.4 (Schr\u00f6dinger) and Discovery Studio (DS) 4.1 software and validated using different statistical parameters like internal and external validation.\n\n\nRESULTS AND DISCUSSION\nThe results showed that the best PLS model has R2=0.991 and Q2=0.787, the best MLR model has R2= 0.993 and Q2= 0.893, the best Field-based model has R2= 0.974 and Q2= 0.782 and the best GFA model has R2= 0.868 and Q2= 0.782. Cross-validated coefficients, (rcv 2) of 0.967, 0.926, 0.966 and 0.829 was found for PLS model, MLR, Field based and GFA model, respectively, indicated the satisfactory correlativity and prediction. The docking studies were accomplished to find out the conformations of the molecules and their essential binding interactions with the target protein. The trustworthiness of the docking results was further confirmed by molecular dynamics (MD) simulations studies. Density Functional Theory (DFT) study was performed which promptly optimizes the geometry, stability and reactivity of the molecule during receptor-ligand interaction.\n\n\nCONCLUSION\nThus, the present research work provides spatial fingerprints which would be beneficial for the development of potent HDAC1 inhibitors.",
        "paperId": "1ce8295a9917bc3dc580704891daac8fdfae841d"
    },
    {
        "title": "ATT3D: Amortized Text-to-3D Object Synthesis",
        "firstAuthor": "Jonathan Lorraine",
        "url": "http://arxiv.org/pdf/2306.07349",
        "dateSubmitted": "2023-06-06",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Text-to-3D modelling has seen exciting progress by combining generative text-to-image models with image-to-3D methods like Neural Radiance Fields. DreamFusion recently achieved high-quality results but requires a lengthy, per-prompt optimization to create 3D objects. To address this, we amortize optimization over text prompts by training on many prompts simultaneously with a unified model, instead of separately. With this, we share computation across a prompt set, training in less time than per-prompt optimization. Our framework - Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to generalize to unseen setups and smooth interpolations between text for novel assets and simple animations.",
        "paperId": "1e8403af2e1e7a8f803d8df9e8daac584f99c2a0"
    },
    {
        "title": "PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization",
        "firstAuthor": "Xinyuan Wang",
        "url": null,
        "dateSubmitted": "2023-10-25",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Highly effective, task-specific prompts are often heavily engineered by experts to integrate detailed instructions and domain insights based on a deep understanding of both instincts of large language models (LLMs) and the intricacies of the target task. However, automating the generation of such expert-level prompts remains elusive. Existing prompt optimization methods tend to overlook the depth of domain knowledge and struggle to efficiently explore the vast space of expert-level prompts. Addressing this, we present PromptAgent, an optimization method that autonomously crafts prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm, rooted in Monte Carlo tree search, to strategically navigate the expert-level prompt space. Inspired by human-like trial-and-error exploration, PromptAgent induces precise expert-level insights and in-depth instructions by reflecting on model errors and generating constructive error feedback. Such a novel framework allows the agent to iteratively examine intermediate prompts (states), refine them based on error feedbacks (actions), simulate future rewards, and search for high-reward paths leading to expert prompts. We apply PromptAgent to 12 tasks spanning three practical domains: BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing it significantly outperforms strong Chain-of-Thought and recent prompt optimization baselines. Extensive analyses emphasize its capability to craft expert-level, detailed, and domain-insightful prompts with great efficiency and generalizability.",
        "paperId": "1eb1a8c7f88de27af224153f43ecdd41774600f2"
    },
    {
        "title": "Ultrasound Imaging of the Subcoracoid Space in the Shoulder: Brachial Plexus Nearby?",
        "firstAuthor": "V. Ricci",
        "url": null,
        "dateSubmitted": "2019-12-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Shoulder disorders are commonplace in musculoskeletal medicine and, currently, ultrasound (US) imaging is an established tool to promptly optimize the diagnosis 1 and guided interventions 2 in their management. Among others, the SASD (subacromial-subdeltoid) bursa is considered as one of the most common pain-generators in the shoulder. In this sense, specific ultrasonographic patterns of bursitis and/or adhesive bursopathy have been clearly described in the pertinent literature.",
        "paperId": "1f61fc6632b81333980265a0cb56324b05d76206"
    },
    {
        "title": "Home telemonitoring of respiratory activity and heart rate variability in chronic heart failure patients: the challenge of the home or hospital in heart failure project",
        "firstAuthor": "G. Pinna",
        "url": "http://www.cinc.org/Proceedings/2003/pdf/197.pdf",
        "dateSubmitted": "2003-12-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Nocturnal respiratory disorders and depressed heart rate variability are known predictors of poor prognosis in chronic heart failure (CHF) patients. Intermittent monitoring of cardiorespiratory signals while the patient is at home might thus allow early identification of clinical deterioration and prompt optimization of treatment, leading to reduced hospitalizations and mortality and improved quality of life. Within the European Community multicenter trial HHH (Home or Hospital in Heart Failure), we are testing a novel low-cost system for 24-hour recording of cardiorespiratory signals, suitable to be self-managed by the patient at home, with transmission of acquired data through standard telephone lines to the medical/nursing staff. Preliminary results from 24 CHF patients enrolled so far indicate that monthly home telemonitoring is feasible and the compliance is high.",
        "paperId": "21d1465ca2a9514e26b1b368c653f10c48d6e9fc"
    },
    {
        "title": "Predicting Treatment Response in Inflammatory Bowel Diseases: Cross-Sectional Imaging Markers",
        "firstAuthor": "I. Mignini",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Therapeutic options for inflammatory bowel diseases (IBD) have largely expanded in the last decades, both in Crohn\u2019s disease and ulcerative colitis, including multiple biological drugs targeting different inflammation pathways. However, choosing the best treatment and timing for each patient is still an undeniable challenge for IBD physicians due to the marked heterogeneity among patients and disease behavior. Therefore, early prediction of the response to biological drugs becomes of utmost importance, allowing prompt optimization of therapeutic strategies and thus paving the way towards precision medicine. In such a context, researchers have recently focused on cross-sectional imaging techniques (intestinal ultrasound, computed tomography, and magnetic resonance enterography) in order to identify predictive markers of response or non-response to biologic therapies. In this review, we aim to summarize data about imaging factors that may early predict disease behavior during biological treatment, potentially helping to define more precise and patient-tailored strategies.",
        "paperId": "2389f8d454f00fc7271556e8e01ef3cf2575205f"
    },
    {
        "title": "Topological Data Analysis Guided Segment Anything Model Prompt Optimization for Zero-Shot Segmentation in Biological Imaging",
        "firstAuthor": "R. Glatt",
        "url": "http://arxiv.org/pdf/2306.17400",
        "dateSubmitted": "2023-06-30",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Emerging foundation models in machine learning are models trained on vast amounts of data that have been shown to generalize well to new tasks. Often these models can be prompted with multi-modal inputs that range from natural language descriptions over images to point clouds. In this paper, we propose topological data analysis (TDA) guided prompt optimization for the Segment Anything Model (SAM) and show preliminary results in the biological image segmentation domain. Our approach replaces the standard grid search approach that is used in the original implementation and finds point locations based on their topological significance. Our results show that the TDA optimized point cloud is much better suited for finding small objects and massively reduces computational complexity despite the extra step in scenarios which require many segmentations.",
        "paperId": "294b4613b21abf1e9ba499de274569360093b107"
    },
    {
        "title": "P411 Early ultrasound assessment predicts therapy response: an easy tool for clinical decision making",
        "firstAuthor": "E. Calabrese PhD",
        "url": "https://academic.oup.com/ecco-jcc/article-pdf/17/Supplement_1/i540/48953571/jjac190.0541.pdf",
        "dateSubmitted": "2023-01-30",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "\n \n \n Intestinal ultrasound (IUS) is an effective and easy-to-use tool in monitoring Crohn\u2019s disease (CD) lesions during different biological therapies. Aim of our study was to evaluate whether lesion improvement during biological therapy could predict transmural healing.\n \n \n \n We performed a prospective study enrolling CD patients (pts) with indication to biological therapies. IUS and doppler US parameters at baseline, at 3 and 12 months were: bowel wall thickening (BWT), lesion length, echopattern, complications, blood flow according to Limberg\u2019 score. Transmural healing (TH) was defined as normalization of all parameters; IUS responders were defined as pts with improvement of BWT associated with decreased lesion length, Limberg\u2019 score improvement, and no worsening of the other parameters. Delta (\u0394) signified the difference between IUS parameters at baseline and at 3 months. Changes in parameters and in \u0394 values at baseline and after 3 months were analyzed using Mann Whitney test; the area under (a ROC) curve was calculated. Differences between combination of parameters were tested by Chi-square test.\n \n \n \n One hundred and fifteen CD pts were enrolled (63.5% males; median age 37 years; median disease duration 96 months). Forty-nine per cent of pts had L1, 9% had L2, 42% had L3 according to the Montreal criteria. TH rate at 12 months was 20% and IUS responder rate was 43%. At baseline, no statistical differences in terms of BWT were observed between pts achieving TH vs no TH. Similarly, no differences were observed in pts defined as IUS responders vs non responders. Patients achieving TH at 12 months had a higher \u0394BWT than patient without TH (p=0.0004). On ROC curve, \u0394BWT improvement of 1.25 mm showed sensitivity and specificity of 73% and 61%, respectively, in predicting pts who achieved TH. Similarly, IUS responder group at 12 months had a higher \u0394BWT than patients IUS non-responder group (p<0.0001). On ROC curve, \u0394BWT improvement of 1.25 mm showed sensitivity and specificity of 83% and 57%, respectively, in predicting IUS responders. A combination of a \u0394BWT (\u22651 mm) and Limberg\u2019 score improvement (1 point) was associated with a higher risk of TH at 12 months (p=0.0007; OR 5.1; 95% CI, 1.8-12.8). A combination of a \u0394BWT (\u22651 mm) and Limberg\u2019 score improvement (1 point) was associated with a higher risk of IUS responders at 12 months (p<0.0001; OR 15.7; 95% CI, 4.5-52).\n \n \n \n An early \u0394BWT, and a combination of a \u0394BWT and Limberg\u2019 score improvement showed high diagnostic accuracy in predicting pts who achieved TH and IUS responder at 12 months. This information may help clinical decision making in terms of prompt optimization or switching/swapping therapies in CD.\n",
        "paperId": "2a2285593e042230dda4c2461cb2b0a13c124e6d"
    },
    {
        "title": "DeltaEdit: Exploring Text-free Training for Text-Driven Image Manipulation",
        "firstAuthor": "Yueming Lyu",
        "url": "https://arxiv.org/pdf/2303.06285",
        "dateSubmitted": "2023-03-11",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Text-driven image manipulation remains challenging in training or inference flexibility. Conditional generative models depend heavily on expensive annotated training data. Meanwhile, recent frameworks, which leverage pre-trained vision-language models, are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. In this work, we propose a novel framework named DeltaEdit to address these problems. Our key idea is to investigate and identify a space, namely delta image and text space that has well-aligned distribution between CLIP visual feature differences of two images and CLIP textual embedding differences of source and target texts. Based on the CLIP delta space, the DeltaEdit network is designed to map the CLIP visual features differences to the editing directions of StyleGAN at training phase. Then, in inference phase, DeltaEdit predicts the StyleGAN's editing directions from the differences of the CLIP textual features. In this way, DeltaEdit is trained in a text-free manner. Once trained, it can well generalize to various text prompts for zero-shot inference without bells and whistles. Code is available at https://github.com/Yueming6568/DeltaEdit.",
        "paperId": "2a48f4a1ec3381600cd97235071f86566ecbfecc"
    },
    {
        "title": "Bioinformatics in Plant Breeding and Research on Disease Resistance",
        "firstAuthor": "Huiying Mu",
        "url": "https://www.mdpi.com/2223-7747/11/22/3118/pdf?version=1668520760",
        "dateSubmitted": "2022-11-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In the context of plant breeding, bioinformatics can empower genetic and genomic selection to determine the optimal combination of genotypes that will produce a desired phenotype and help expedite the isolation of these new varieties. Bioinformatics is also instrumental in collecting and processing plant phenotypes, which facilitates plant breeding. Robots that use automated and digital technologies to collect and analyze different types of information to monitor the environment in which plants grow, analyze the environmental stresses they face, and promptly optimize suboptimal and adverse growth conditions accordingly, have helped plant research and saved human resources. In this paper, we describe the use of various bioinformatics databases and algorithms and explore their potential applications in plant breeding and for research on plant disease resistance.",
        "paperId": "2c2b40b4f1967dc1fb640c7c4bec140110dbf2cf"
    },
    {
        "title": "Early Diagnostic Markers of Late-Onset Neonatal Sepsis",
        "firstAuthor": "Preslava Gatseva",
        "url": "https://www.mdpi.com/2036-7503/15/3/50/pdf?version=1695182872",
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Objective: Early diagnosis of nosocomial infections in newborns is a great challenge, because in the initial phase of systemic infection, clinical symptoms are often non-specific, and routinely used hematological markers are not sufficiently informative. The aim of this study was to determine the potential of early inflammatory markers to diagnose late-onset neonatal sepsis\u2014procalcitonin (PCT), interleukin 6 (IL-6), interleukin 8 (IL-8) and endocan (ESM-1). Material and methods: A prospective clinical\u2013epidemiological study was conducted in a third-level NICU in Pleven, Bulgaria. Patients with suspected late-onset sepsis and healthy controls were tested. A sandwich ELISA method was used to measure the serum concentrations of biomarkers. Results: Sixty newborns were included, of which 35% symptomatic and infected, 33.3% symptomatic but uninfected and 31.7% asymptomatic controls. The mean values of PCT, IL-6, I/T index and PLT differ significantly in the three groups. For ESM-1, IL-8 and CRP, the difference was statistically insignificant. The best sensitivity (78%) and negative predictive value (84%) was found for IL-6. The combinations of PCT + IL-6 and PCT + IL-6+ I/T+ PLT showed very good diagnostic potential. Conclusion: The introduction into the routine practice of indicators such as PCT and IL-6 may provide an opportunity to promptly optimize the diagnostic and therapeutic approach to LOS.",
        "paperId": "2e536dcd013be93dc1841dd0e7a0a87b2846f341"
    },
    {
        "title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media",
        "firstAuthor": "Chuanbo Hu",
        "url": "https://arxiv.org/pdf/2307.03699",
        "dateSubmitted": "2023-07-07",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Social media platforms such as Instagram and Twitter have emerged as critical channels for drug marketing and illegal sale. Detecting and labeling online illicit drug trafficking activities becomes important in addressing this issue. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose \\emph{knowledge-informed prompts}, which serve as the interface that humans can interact with and use LLMs to perform the detection task. Additionally, we design a Monte Carlo dropout based prompt optimization method to further to improve performance and interpretability. Our experimental findings demonstrate that the proposed framework outperforms other baseline language models in terms of drug trafficking detection accuracy, showing a remarkable improvement of nearly 12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can effectively identify and label drug trafficking activities on social networks, even in the presence of deceptive language and euphemisms used by drug dealers to evade detection. The implications of our research extend to social networks, emphasizing the importance of incorporating prior knowledge and scenario-based prompts into analytical tools to improve online security and public safety.",
        "paperId": "2e588fe7e07948cb9112c37d5e9dcc3a13b1bd0f"
    },
    {
        "title": "Automatic Data Transformation Using Large Language Model: An Experimental Study on Building Energy Data",
        "firstAuthor": "Ankita Sharma",
        "url": "https://arxiv.org/pdf/2309.01957",
        "dateSubmitted": "2023-09-05",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Existing approaches to automatic data transformation are insufficient to meet the requirements in many real-world scenarios, such as the building sector. First, there is no convenient interface for domain experts to provide domain knowledge easily. Second, they require significant training data collection overheads. Third, the accuracy suffers from complicated schema changes. To bridge this gap, we present a novel approach that leverages the unique capabilities of large language models (LLMs) in coding, complex reasoning, and zero-shot learning to generate SQL code that transforms the source datasets into the target datasets. We demonstrate the viability of this approach by designing an LLM-based framework, termed SQLMorpher, which comprises a prompt generator that integrates the initial prompt with optional domain knowledge and historical patterns in external databases. It also implements an iterative prompt optimization mechanism that automatically improves the prompt based on flaw detection. The key contributions of this work include (1) pioneering an end-to-end LLM-based solution for data transformation, (2) developing a benchmark dataset of 105 real-world building energy data transformation problems, and (3) conducting an extensive empirical evaluation where our approach achieved 96% accuracy in all 105 problems. SQLMorpher demonstrates the effectiveness of utilizing LLMs in complex, domain-specific challenges, highlighting the potential of their potential to drive sustainable solutions.",
        "paperId": "3120c2763edab339b937ddbe76991ebdfe0e01e6"
    },
    {
        "title": "85. Plasma Cell Free Deoxyribonucleic Acid (cfDNA) Fungal Polymerase Chain Reaction (PCR): a Non-Invasive Diagnostic for Invasive Fungal Disease Evaluation in At-Risk Pediatric Oncology and Stem Cell Transplant Patients",
        "firstAuthor": "L. Kushner",
        "url": "https://academic.oup.com/ofid/article-pdf/9/Supplement_2/ofac492.010/47889531/ofac492.010.pdf",
        "dateSubmitted": "2022-12-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Abstract Background Molecular diagnostics appear promising for early, non-invasive detection of invasive fungal disease (IFD) in immunocompromised patients. Our clinical lab developed and validated cell free DNA (cfDNA) fungal polymerase chain reaction (PCR) assays (Table 1), which have been in clinical use since November 2020 and were recently included in an institutional pediatric clinical care pathway for prolonged febrile neutropenia. We aimed to evaluate the performance of these plasma cfDNA fungal PCR assays in pediatric oncology and hematopoietic stem cell transplant (HSCT) patients with clinical concern for IFD.Table 1: Summary of available cfDNA fungal PCR assays and their targetsAbbreviations: cfDNA: cell free deoxyribonucleic acid; PCR: polymerase chain reaction. Methods We initiated an observational study of inpatient oncology and HSCT patients who had plasma mold panel (+/- Candida panel) cfDNA fungal PCR obtained as part of an IFD evaluation at our freestanding quaternary care children\u2019s hospital. The primary outcome was IFD clinical diagnosis (proven, probable, possible, unlikely) as per EORTC/MSG\u2020 definitions within one month of the cfDNA fungal PCR, which was assigned independently by two physicians, with a third physician utilized in cases of discrepancy. Patient demographics, hospital course, imaging results, and clinical laboratory data were abstracted and maintained in an encrypted REDCap\u00a9 database. Results In a preliminary analysis of October 2021-March 2022 data, there were 21 IFD evaluations for 18 patients (Table 2). Most oncology evaluations were for prolonged febrile neutropenia, while many HSCT were non-neutropenic, but on enhanced immunosuppression with new clinical concerns (e.g., respiratory symptoms, persistent fever). Plasma cfDNA detected a mold or yeast consistent with the clinical presentation in 100% of the five proven/probable cases (Figures 1 & 2). All 14 possible IFD cases had a negative cfDNA fungal PCR.Table 2: Baseline characteristics for Oncology & Hematopoietic Stem Cell Transplant (HSCT) patient evaluations\u2020Included hemophagocytic lymphohistiocytosis, hereditary osteopetrosis, STAT1 gain-of-function.*Oncology clinical concern: 2 (17%) with new oral/sinus concern and 2 (17%) with new respiratory symptoms and new diffuse skin lesions.**HSCT clinical concern: 5 (56%) evaluations were for new respiratory symptoms and/or oxygen requirement with abnormal imaging. Additional reasons included lab abnormality, new oral/sinus concern, new rash, and persistent fevers in absence of neutropenia.\u2021Note: Several patients underwent more than one procedure.Abbreviations: ANC: absolute neutrophil count (units are cells per microliter, cells/ul); ENT: ear nose throat / otolaryngology; HSCT: hematopoietic stem cell transplant; IFD: invasive fungal disease; IQR: interquartile range.Figure 1: Clinical diagnoses for the 21 patient evaluations for invasive fungal disease by patient groupThe cell free DNA (cfDNA) fungal polymerase chain reaction (PCR) was positive in all five proven/probable cases (*), but negative in all remaining cases.* Designates a patient with positive cfDNA fungal PCR.Abbreviations: HSCT: Hematopoietic stem cell transplant; IFD: invasive fungal disease.Figure 2: Clinical characteristics of the five proven/probable cases of invasive fungal disease Proven cases are designated with blue icon, while the probable case is orange. All five cases were in oncology patients who did not have history of hematopoietic stem cell transplant. Cell free DNA (cfDNA) fungal polymerase chain reaction (PCR) results include the organism identified, followed by the cycle threshold (Ct) in parenthesis. Maximum Ct for the assay is 45. Abbreviations: AG: Aspergillus galactomannan index (Ref <0.5); ALL: acute lymphoblastic leukemia. BAL: bronchoalveolar lavage; 1,3-BDG: 1,3-beta-D-glucan (Ref <60 pg/ml); cfDNA: cell free deoxyribonucleic acid; CNS: central nervous system; EORTC/MSG: European Organization for Research and Treatment of Cancer/Invasive Fungal Infections Cooperative Group & the National Institute of Allergy & Infectious Diseases Mycoses Study Group; L-AmB: liposomal amphotericin B; SARS-CoV-2: severe acute respiratory syndrome associated with coronavirus 2. Conclusion Upfront plasma cfDNA fungal PCR successfully detected a relevant mold or yeast with short turnaround time in 100% of cases that were later classified as proven/probable. This appears promising for early, noninvasive diagnosis that enables prompt optimization of antifungal and surgical management, particularly for mucormycosis cases. Additional data may permit consideration of Mucorales agents PCR as a new EORTC/MSG mycologic criteria. Disclosures Lauren E. Kushner, MD, Roman: Client of my husband's business..",
        "paperId": "31c855da5e3598879ff920ee97f90654a6fdb808"
    },
    {
        "title": "PROPANE: Prompt design as an inverse problem",
        "firstAuthor": "Rimon Melamed",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Carefully-designed prompts are key to inducing desired behavior in Large Language Models (LLMs). As a result, great effort has been dedicated to engineering prompts that guide LLMs toward particular behaviors. In this work, we propose an automatic prompt optimization framework, PROPANE, which aims to find a prompt that induces semantically similar outputs to a fixed set of examples without user intervention. We further demonstrate that PROPANE can be used to (a) improve existing prompts, and (b) discover semantically obfuscated prompts that transfer between models.",
        "paperId": "394ade86b0aee8f2b0ab09128eb8743bac1193d1"
    },
    {
        "title": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts",
        "firstAuthor": "Moxin Li",
        "url": null,
        "dateSubmitted": "2023-05-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Large Language Model (LLM) has demonstrated significant ability in various Natural Language Processing tasks. However, their effectiveness is highly dependent on the phrasing of the task prompt, leading to research on automatic prompt optimization using labeled task data. We reveal that these prompt optimization techniques are vulnerable to distribution shifts such as subpopulation shifts, which are common for LLMs in real-world scenarios such as customer reviews analysis. In this light, we propose a new problem of robust prompt optimization for LLMs against distribution shifts, which requires the prompt optimized over the labeled source group can simultaneously generalize to an unlabeled target group. To solve this problem, we propose Generalized Prompt Optimization framework, which incorporates the unlabeled data from the target group into prompt optimization. Extensive experimental results demonstrate the effectiveness of the proposed framework with significant performance improvement on the target group and comparable performance on the source group.",
        "paperId": "3b0c49ca5ac0f441c302c9ca4def4804253552d5"
    },
    {
        "title": "Automated Extraction and Visualization of Metabolic Networks from Biomedical Literature Using a Large Language Model",
        "firstAuthor": "Thiptanawat Phongwattana",
        "url": "https://www.biorxiv.org/content/biorxiv/early/2023/06/29/2023.06.27.546560.full.pdf",
        "dateSubmitted": "2023-06-29",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "The rapid growth of biomedical literature presents a significant challenge for researchers to extract and analyze relevant information efficiently. In this study, we explore the application of GPT, the large language model to automate the extraction and visualization of metabolic networks from a corpus of PubMed abstracts. Our objective is to provide a valuable tool for biomedical researchers to explore and understand the intricate metabolic interactions discussed in scientific literature. We begin by splitting a ton of the tokens within the corpus, as the GPT-3.5-Turbo model has a token limit of 4,000 per analysis. Through iterative prompt optimization, we successfully extract a comprehensive list of metabolites, enzymes, and proteins from the abstracts. To validate the accuracy and completeness of the extracted entities, our biomedical data domain experts compare them with the provided abstracts and ensure a fully matched result. Using the extracted entities, we generate a directed graph that represents the metabolic network including 3 types of metabolic events that consist of metabolic consumption, metabolic reaction, and metabolic production. The graph visualization, achieved through Python and NetworkX, offers a clear representation of metabolic pathways, highlighting the relationships between metabolites, enzymes, and proteins. Our approach integrates language models and network analysis, demonstrating the power of combining automated information extraction with sophisticated visualization techniques. The research contributions are twofold. Firstly, we showcase the ability of GPT-3.5-Turbo to automatically extract metabolic entities, streamlining the process of cataloging important components in metabolic research. Secondly, we present the generation and visualization of a directed graph that provides a comprehensive overview of metabolic interactions. This graph serves as a valuable tool for further analysis, comparison with existing pathways, and updating or refining metabolic networks. Our findings underscore the potential of large language models and network analysis techniques in extracting and visualizing metabolic information from scientific literature. This approach enables researchers to gain insights into complex biological systems, advancing our understanding of metabolic pathways and their components.",
        "paperId": "439c2a5c4883b421ca316617b1306583cc1d706c"
    },
    {
        "title": "Inflammation\u2010inducible anti\u2010TNF gene expression mediated by intra\u2010articular injection of serotype 5 adeno\u2010associated virus reduces arthritis",
        "firstAuthor": "M. Khoury",
        "url": null,
        "dateSubmitted": "2007-07-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "The tumor necrosis factor (TNF)\u2010\u03b1 plays a central role in rheumatoid arthritis (RA) and current biotherapies targeting TNF\u2010\u03b1 have a major impact on RA treatment. The long\u2010term safety concerns associated with the repetitive TNF blockade prompt optimization of therapeutic anti\u2010TNF approaches. Since we recently demonstrated that intra\u2010articular gene transfer using a recombinant adeno\u2010associated virus serotype 5 (rAAV5) efficiently transduces arthritic joints, we evaluate its effect on collagen\u2010induced arthritis (CIA) when encoding TNF antagonists.",
        "paperId": "4e54122e3895ca688f8b9b3cf5320509f72ed3bd"
    },
    {
        "title": "In-context Examples Selection for Machine Translation",
        "firstAuthor": "Sweta Agrawal",
        "url": "https://arxiv.org/pdf/2212.02437",
        "dateSubmitted": "2022-12-05",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model. For Machine Translation (MT), these examples are typically randomly sampled from the development dataset with a similar distribution as the evaluation set. However, it is unclear how the choice of these in-context examples and their ordering impacts the output translation quality. In this work, we aim to understand the properties of good in-context examples for MT in both in-domain and out-of-domain settings. We show that the translation quality and the domain of the in-context examples matter and that 1-shot noisy unrelated example can have a catastrophic impact on output quality. While concatenating multiple random examples reduces the effect of noise, a single good prompt optimized to maximize translation quality on the development dataset can elicit learned information from the pre-trained language model. Adding similar examples based on an n-gram overlap with the test source significantly and consistently improves the translation quality of the outputs, outperforming a strong kNN-MT baseline in 2 out of 4 out-of-domain datasets.",
        "paperId": "515cf674fcdced5a7d5bb156dd5fcc1f5290e79b"
    },
    {
        "title": "Hypoxemia during veno-venous extracorporeal membrane oxygenation. When two is not better than one",
        "firstAuthor": "A. Tralh\u00e3o",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Unwittingly, hypoxemia may persist or even supervene after a patient is placed on veno-venous extracorporeal membrane lung oxygenation (VV-ECMO) for refractory hypoxemia. According to Extracorporeal Life Support Organization (ELSO) guidelines, the threshold for adequate arterial O2 saturation is > 80 85%,(1) while a value > 88% has been considered the threshold in other guidelines.(2) Although the exact incidence is difficult to ascertain and the definition itself may vary, hypoxemia during VV-ECMO requires both systematic assessment and prompt optimization of modifiable variables, as it has been associated with increased mortality.(3) To fully understand why hypoxemia still occurs, one has to consider the principles underpinning the ability of ECMO to ensure adequate oxygen (O2) transfer across the membrane lung and into the patient\u2019s blood. First, there is a fraction of oxygen in the fresh sweep gas that can be set, usually at 1.0. Second, a membrane lung, with an appropriate surface area available for gas exchange, needs to be working properly, allowing unimpeded blood flow around the gas-containing polymer microfibers. Third, the absolute amount of blood flowing through the oxygenator (QECMO) and its relative proportion to the patient\u2019s own cardiac output (Qpatient) need to be considered. Finally, the fraction of oxygenated blood flowing through ECMO that does not go into the pulmonary circulation but instead recirculates into the drainage cannula impacts the oxygenating efficacy of VV-ECMO.(4) In a concept study, Schmidt et al. clearly demonstrated that blood flow through the ECMO circuit is the key determinant of blood oxygenation.(5) Furthermore, as a higher proportion of deoxygenated venous blood goes through the patient\u2019s right heart than through the ECMO circuit, the QECMO/Qpatient quotient falls below the boundary of 0.6, and the O2 content of arterial blood will drop even if the absolute blood flow through the membrane lung is appropriate to the body surface area.(5) This is especially important if the degree of pulmonary shunt is such that any residual lung function contributing to oxygenation is negligible, which frequently occurs in patients being considered for VV-ECMO.(4) To overcome persistent hypoxemia, different strategies have been devised. Among them, the most immediate would be to increase the QECMO/Qpatient ratio. Typical ECMO rated flows, which is the maximal flow at which hemoglobin [12g/ dL] is fully saturated at the membrane outlet, are ~7L/minute. In these extreme situations, when a patient with no lung contribution and very high cardiac output has persistent severe hypoxemia or hypercarbia, adding a second oxygenator to the extracorporeal circuit, whether in parallel or in series, might be an intuitive option. In this issue of the Revista Brasileira de Terapia Intensiva, Melro et al.,(6) using a porcine model, evaluated the impact on blood oxygenation of these two circuit configurations. Additionally, decarboxylation efficacy, as well as pressure and resistance changes to the circuit imposed by the \u201cvirtual\u201d presence of a second oxygenator, were analyzed. To achieve this goal, the authors built on their own previous work(7) by using a validated mathematical model to calculate peripheral arterial oxygen saturation, postoxygenator O2 content and arterial partial pressure of carbon dioxide (PaCO2) for different ECMO flows while keeping the remaining variables constant (pulmonary shunt fraction, ventilator fraction of inspired oxygen [FiO2], cardiac output, sweep gas flow, O2 fraction of sweep gas flow, hemoglobin concentration, O2 consumption and CO2 production). Ant\u00f3nio Tralh\u00e3o1 , Philip Fortuna2",
        "paperId": "57584db1e2e698963c8aed2601b1a91420f5ab6d"
    },
    {
        "title": "The wavefront sensing making-of for THEMIS solar telescope",
        "firstAuthor": "M. Tallon",
        "url": null,
        "dateSubmitted": "2019-06-09",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "An adaptive optics system with a single deformable mirror is being implemented on the THEMIS 90cm solar telescope. This system is designed to operate in the visible and is required to be as robust as possible in order to deliver the best possible correction in any atmospheric conditions, even if wavefronts are sensed on some low-contrast solar granulation. In extreme conditions, the images given by the subapertures of the Shack-Hartmann wavefront sensor get randomly blurred in space, in the set of subapertures, and the distribution of blurred images is rapidly changing in time, some of them possibly fading away. The algorithms we have developed for such harsh conditions rely on inverse problem approach. As an example, with the gradients of the wavefronts, the wavefront sensor also estimates their errors, including their covariance. This information allows the control loop to promptly optimize itself to the fast varying conditions, both in space (wavefront reconstruction) and in time. A major constraint is to fit the calculations in a low-cost multi-core CPU. An overview of the algorithms in charge of implementing this strategy is presented, focusing on wavefront sensing.",
        "paperId": "5821d5637fd4b1d9d588e8626998d6f0ca77522c"
    },
    {
        "title": "MLLM-DataEngine: An Iterative Refinement Approach for MLLM",
        "firstAuthor": "Zhiyuan Zhao",
        "url": "https://arxiv.org/pdf/2308.13566",
        "dateSubmitted": "2023-08-25",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental dataset based on the benchmarking results. For quality, we resort to GPT-4 to generate high-quality data with each given data type. For correctness, prompt design is critical for the data generation results. Rather than previous hand-crafted prompt, we propose an Interactive Prompt Optimization strategy, which optimizes the prompt with the multi-round interaction between human and GPT, and improve the correctness of generated data greatly. Through extensive experiments, we find our MLLM-DataEngine could boost the MLLM capability in a targeted and automatic manner, with only a few human participation. We hope it could be a general solution for the following MLLMs building. The MLLM-DataEngine has been open-sourced and is now available at https://github.com/opendatalab/MLLM-DataEngine.",
        "paperId": "58a282c89864f35bff1741f5ab439222da6bb3ec"
    },
    {
        "title": "Clinical trials: A transparent future for clinical trial reporting",
        "firstAuthor": "F. Karassa",
        "url": null,
        "dateSubmitted": "2015-05-05",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": null,
        "paperId": "5c2eb222b529aedbe84244f18b29ec0f3e848481"
    },
    {
        "title": "A framework for enabling an integrated and proactive decision making in airport systems",
        "firstAuthor": "A. Napolitano",
        "url": null,
        "dateSubmitted": "2012-07-16",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Airport systems stands for one of most important and essential asset within the transport system of a country. The air transport liberalization has promoted the air traffic growth with a consequential cost reduction to the passengers and air carriers. In turn, this growth is moving the main airports towards the saturation, affecting the performance and quality of the services provided to the passengers. Some analyses, indeed, foresee that the capacity of the airports, in the management of the aircrafts and passengers, will likely be the bottleneck of the air transport growth. Hence, airport capacity needs to be improved. The common and agreed view for succeeding to this goal moves to the optimization and orchestration of the available resources within the airport. To do that, the interoperability and cooperation among stakeholders, operating in the airport, often with different purposes, has to be rethought, along with the development of novel technological systems enabling and supporting this process. To this aim, the paper proposes a new framework that enabling the information interoperability on the top of classic data interoperability among heterogeneous stakeholders (often legacy systems) operating both in airside and landside area and provides a net-centric orchestration service capable of forecasting and promptly optimizing the choices of the stakeholders with the aim addressed to the airport performance as a whole.",
        "paperId": "5cec39e77af461f737a8c78a2d4d6f48c47fd387"
    },
    {
        "title": "Conformational Properties of \u03b1- or \u03b2-(1\u21926)-Linked Oligosaccharides: Hamiltonian Replica Exchange MD Simulations and NMR Experiments",
        "firstAuthor": "Dhilon S. Patel",
        "url": "https://pubs.acs.org/doi/pdf/10.1021/jp412051v",
        "dateSubmitted": "2014-02-19",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Conformational sampling for a set of 10 \u03b1- or \u03b2-(1\u21926)-linked oligosaccharides has been studied using explicit solvent Hamiltonian replica exchange (HREX) simulations and NMR spectroscopy techniques. Validation of the force field and simulation methodology is done by comparing calculated transglycosidic J coupling constants and proton\u2013proton distances with the corresponding NMR data. Initial calculations showed poor agreement, for example, with >3 Hz deviation of the calculated 3J(H5,H6R) values from the experimental data, prompting optimization of the \u03c9 torsion angle parameters associated with (1\u21926)-linkages. The resulting force field is in overall good agreement (i.e., within \u223c0.5 Hz deviation) from experimental 3J(H5,H6R) values, although some small limitations are evident. Detailed hydrogen bonding analysis indicates that most of the compounds lack direct intramolecular H-bonds between the two monosaccharides; however, minor sampling of the O6\u00b7\u00b7\u00b7HO2\u2032 hydrogen bond is present in three compounds. The results verify the role of the gauche effect between O5 and O6 atoms in gluco- and manno-configured pyranosides causing the \u03c9 torsion angle to sample an equilibrium between the gt and gg rotamers. Conversely, galacto-configured pyranosides sample a population distribution in equilibrium between gt and tg rotamers, while the gg rotamer populations are minor. Water radial distribution functions suggest decreased accessibility to the O6 atom in the (1\u21926)-linkage as compared to the O6\u2032 atom in the nonreducing sugar. The role of bridging water molecules between two sugar moieties on the distributions of \u03c9 torsion angles in oligosaccharides is also explored.",
        "paperId": "5e2b1deb2cbb7bb816a77a5a26bc21ab5425b60d"
    },
    {
        "title": "Getting MoRE out of Mixture of Language Model Reasoning Experts",
        "firstAuthor": "Chenglei Si",
        "url": null,
        "dateSubmitted": "2023-05-24",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "While recent large language models (LLMs) improve on various question answering (QA) datasets, it remains difficult for a single model to generalize across question types that require distinct reasoning abilities. We provide empirical evidence that state-of-the-art LLMs suffer from poor generalizability on reasoning types beyond those seen in the prompt. To remedy this, we propose a Mixture-of-Reasoning-Experts (MoRE) framework that ensembles diverse specialized language models. We specialize the backbone language model with prompts optimized for different reasoning categories, including factual, multihop, mathematical, and commonsense reasoning. Our key insight is to leverage agreement among the specialized experts to select the best answer for each question, or to abstain from answering. This gives MoRE higher accuracy than any single specialized model on a collection of 12 QA datasets from four reasoning types. Beyond generalizability, the interpretable design of MoRE improves selective question answering results compared to baselines without incorporating inter-expert agreement. This framework is also more interpretable and useful to human consumers of QA outputs. Our human study confirms that presenting expert predictions and the answer selection process helps annotators more accurately calibrate when to trust the system's output. We release all code and data to facilitate future work.",
        "paperId": "643e4e9beed8b14656eadfa214b8106858dbb27c"
    },
    {
        "title": "\u041c\u043e\u0434\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u043d\u043e\u0433\u043e\u043c\u043e\u0434\u043e\u0432\u043e\u0433\u043e \u0434\u0432\u0443\u0445\u0437\u0430\u0437\u043e\u0440\u043d\u043e\u0433\u043e \u0440\u0435\u0437\u043e\u043d\u0430\u0442\u043e\u0440\u0430 \u0434\u043b\u044f \u043c\u0438\u043d\u0438\u0430\u0442\u044e\u0440\u043d\u044b\u0445 \u043c\u043d\u043e\u0433\u043e\u043b\u0443\u0447\u0435\u0432\u044b\u0445 \u043f\u0440\u0438\u0431\u043e\u0440\u043e\u0432",
        "firstAuthor": "\u0410. \u0418. \u041c\u0438\u0440\u043e\u0448\u043d\u0438\u0447\u0435\u043d\u043a\u043e",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In the article a double-gap cavity with anti-phase excitation that has wide application in designs of floating-drift klystrons is considered. One of the ways of reduction of time during machine design of klystron\u2019s cavity is using of the simple analytical expression, allowing to determine the main klystron electrodynamic parameters with a sufficient accuracy for practice. In the article we presented the results of physical and mathematical modeling of the double-gap cavity, the corrected mathematical models were introduced that can be utilized in programs of a prompt optimization of klystron's type devices. The technique of creation of approximate mathematical model in this case was reduced to definition of basic analytical function, and the subsequent approximation between experimental and calculated data by means of a method of planned experiment. In presented work the analysis of adequacy was carry out. Analysis revealed inaccuracy of a resonance frequency of an anti-phase type in chosen ranges of change of influencing factors doesn\u2019t exceed 1%, characteristic impedance5%. The received analytical ratios allow carrying out quickly calculation of parameters of the cavity, without labor-consuming and expensive experiments and calculations.",
        "paperId": "6d7f3d4e9dd6194ee15c2b7d7720916e39525982"
    },
    {
        "title": "Transient Ischemic Attack (tia) Guideline Knowledge And Perceived Barriers To Implementation Amongst Emergency Department Health Care Providers In A Rural State",
        "firstAuthor": "C. Ingvoldstad",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Transient Ischemic Attack (TIA) is a prominent risk factor for subsequent stroke, and its associated morbidity, mortality, and health care costs. Studies have demonstrated up to 80% reductions in subsequent stroke rate with prompt, optimized protocols for rapid TIA evaluation and treatment. National Stroke Association (NSA) and American Heart Association (AHA) guidelines have recommended institution of protocols assuring timely completion of the recommended testing, and evaluation by a stroke expert within 48 hours. However, limited literature exists on the implementation of guideline-based care in rural regions, and the few studies related to TIA suggest that barriers including difficulty accessing services and poorly updated TIA knowledge amongst rural, nonneurologist providers exist despite national guidelines. Behavior change theories have suggested that evaluating factors hindering or motivating behavior change may aid in tailoring implementation of guideline-based practices. This descriptive study sought to understand ED health care providers\u2019 perceived barriers to implementation of NSA/AHA TIA guidelines in a rural state. All healthcare providers in each of the state\u2019s emergency departments were invited by email to complete an online anonymous survey assessing knowledge of present TIA guidelines and perceived barriers to implementation of these guidelines in their practice setting using a modified Barriers and Facilitators Assessment Instrument (BFAI). After completing the knowledge based questions, respondents were presented a brief educational overview of the guidelines to ensure adequate familiarity with the TIA guidelines to complete the BFAI. Thirty-nine respondents completed the survey. Twenty-seven worked at regional or academic medical centers, and 12 worked at critical access hospitals representing the more rural regions of the state. Consistent with prior work, the most notable finding of this study was a low awareness of the present TIA guidelines amongst ED providers, with none of the survey respondents correctly identifying all items consistent with the evaluation guidelines for TIA. In addition to a low awareness of the guidelines, a number of perceived barriers to implementation were identified, which may inform efforts at implementation, and/or offer a model for similar barrier assessment elsewhere.",
        "paperId": "6e7aa4b8be2fc7fcbb3ec13251c4dff1087e8b7d"
    },
    {
        "title": "InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image",
        "firstAuthor": "Jianhui Li",
        "url": null,
        "dateSubmitted": "2023-11-06",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "With the success of Neural Radiance Field (NeRF) in 3D-aware portrait editing, a variety of works have achieved promising results regarding both quality and 3D consistency. However, these methods heavily rely on per-prompt optimization when handling natural language as editing instructions. Due to the lack of labeled human face 3D datasets and effective architectures, the area of human-instructed 3D-aware editing for open-world portraits in an end-to-end manner remains under-explored. To solve this problem, we propose an end-to-end diffusion-based framework termed InstructPix2NeRF, which enables instructed 3D-aware portrait editing from a single open-world image with human instructions. At its core lies a conditional latent 3D diffusion process that lifts 2D editing to 3D space by learning the correlation between the paired images' difference and the instructions via triplet data. With the help of our proposed token position randomization strategy, we could even achieve multi-semantic editing through one single pass with the portrait identity well-preserved. Besides, we further propose an identity consistency module that directly modulates the extracted identity signals into our diffusion process, which increases the multi-view 3D identity consistency. Extensive experiments verify the effectiveness of our method and show its superiority against strong baselines quantitatively and qualitatively.",
        "paperId": "743f9c1ce97f44f3034f80f850d3f5f447f8f94d"
    },
    {
        "title": "Task-driven Prompt Evolution for Foundation Models",
        "firstAuthor": "R. Sathish",
        "url": null,
        "dateSubmitted": "2023-10-26",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Promptable foundation models, particularly Segment Anything Model (SAM), have emerged as a promising alternative to the traditional task-specific supervised learning for image segmentation. However, many evaluation studies have found that their performance on medical imaging modalities to be underwhelming compared to conventional deep learning methods. In the world of large pre-trained language and vision-language models, learning prompt from downstream tasks has achieved considerable success in improving performance. In this work, we propose a plug-and-play Prompt Optimization Technique for foundation models like SAM (SAMPOT) that utilizes the downstream segmentation task to optimize the human-provided prompt to obtain improved performance. We demonstrate the utility of SAMPOT on lung segmentation in chest X-ray images and obtain an improvement on a significant number of cases ($\\sim75\\%$) over human-provided initial prompts. We hope this work will lead to further investigations in the nascent field of automatic visual prompt-tuning.",
        "paperId": "78e19186c577cf6fbc24a3d87cb7f95fbbdb6e96"
    },
    {
        "title": "Adaptive Automatic Route Shortening in DSR for Ad Hoc Network",
        "firstAuthor": "L. Hongyan",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In an Ad Hoc network,DSR is a common ondemand source routing algorithm,It is widely discussed and a number of optimizations that improve the performance of the protocol have been defined.In this paper, we analyzed a optimization named automatic route shortening, The method allow source routes in use to be shortened when possible,but it can\u2032t guarantee the quality of the new shortented route.Then we proposed the adaptive automatic route shortening as the prompted approach which will bring more efficient shortened route. The simulation results show that, compared with original optimization,DSR benefits more from our prompted optimization.",
        "paperId": "7f252e69f1814ea9a409272c80e133adcc2fbcbe"
    },
    {
        "title": "AutoHint: Automatic Prompt Optimization with Hint Generation",
        "firstAuthor": "Hong Sun",
        "url": "https://arxiv.org/pdf/2307.07415",
        "dateSubmitted": "2023-07-13",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induction dataset for both zero-shot and few-short prompts, where experiments demonstrate our method is able to significantly boost accuracy for multiple tasks.",
        "paperId": "838e1317454724a9bb758d05d97e6058e11a8251"
    },
    {
        "title": "Rvoice Studio and Activeprompts",
        "firstAuthor": "Peter Rutten",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "ActivePrompts are a new technology from Rhetorical, designed to offer a quicker and cheaper alternative to using voice talents and recording studios for the creation of an application-specific prompt library. Most speech user interfaces optimize the quality of their speech output by using pre-recorded prompts. In these applications, TTS is often considered to be a fall-back technology to generate speech for the variable content of messages. Although pre-recorded prompts optimize the quality of the static part of messages, they are expensive to create, depend on the availability of a speaker and recording studio, and can be difficult to combine with TTS. As an alternative to pre-recorded prompts, Rhetorical Systems has developed the technology to create prompts by using the rVoice TTS engine. This technology exploits the fact that rVoice contains a large unit selection database, that can be used to synthesize a large number of alternative versions of a same sentence. Given an appropriate interface to rVoice, it is generally possible to find the sequence of speech units that result in synthetic speech that can pass as a pre-recorded prompt. We coined the name \u2019ActivePrompt\u2019 for prompts that are created from the rVoice speech unit database. They are different from recorded prompts in the way they can be used in the application. Instead of being a speech file, that is concatenated with speech that is synthesized, they can be stored as a sequence of speech unit identifiers that should be used to synthesize a particular text in a particular context.",
        "paperId": "888a067abe5a2b4c2e49cdea11366e515d30fbb3"
    },
    {
        "title": "Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers",
        "firstAuthor": "Qingyan Guo",
        "url": "https://arxiv.org/pdf/2309.08532",
        "dateSubmitted": "2023-09-15",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3.5 and Alpaca, on 9 datasets spanning language understanding and generation tasks. EvoPrompt significantly outperforms human-engineered prompts and existing methods for automatic prompt generation by up to 25% and 14% respectively. Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs creates synergies, which could inspire further research on the combination of LLMs and conventional algorithms.",
        "paperId": "8d17234680db76f99efd22fbcb169f45d2d79d93"
    },
    {
        "title": "Dynamic ultrasound imaging of the posterior capsule in the shoulder: Tips and tricks",
        "firstAuthor": "Ricci Vincenzo",
        "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/kjm2.12190",
        "dateSubmitted": "2020-02-12",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Shoulder disorders are commonplace in clinical practice of musculoskeletal physicians. Currently, ultrasound (US) imaging is an established tool to promptly optimize their diagnoses and guided interventions. Herein, different from the \u201ccommon\u201d pain generators of the shoulder which are usually evaluated during a routine US examination (eg, subacromial-subdeltoid bursa, long head of the biceps tendon, rotator cuff), the glenohumeral capsule is usually overlooked due to the technical difficulty in distinguishing it from the overlying",
        "paperId": "8ee4b6928d7fc47665eb5ad7236cff181d676603"
    },
    {
        "title": "Emerging technology in acute resuscitation monitoring",
        "firstAuthor": "M. Tichauer",
        "url": "http://www.scirp.org/journal/PaperDownload.aspx?paperID=24794",
        "dateSubmitted": "2012-11-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Fluid optimization in the resuscitation of shock became the mainstay of treatment following the advent of Early Goal-Directed Therapy (EGDT) by Rivers et al. in 2001 [1]. Patients presenting in shock require prompt optimization of volume status and cardiac out- put to ensure adequate perfusion. Poor optimization may be associated with prolonged hospital and intensive care unit stays. The prior gold standard, pulmonary artery catheterization, is rarely available in the emergency department setting and its invasive nature has led to recent re-evaluation of its clinical utility. However, there are new monitoring technologies that are being studied in the intensive care unit setting that may soon be available in emergency departments to aid in nursing and physician decision making to improve acute resuscitation.",
        "paperId": "93e09c5feb9b2ffc8926b4edff13b3d8e02e41de"
    },
    {
        "title": "Diversity-Aware Meta Visual Prompting",
        "firstAuthor": "Qidong Huang",
        "url": "https://arxiv.org/pdf/2303.08138",
        "dateSubmitted": "2023-03-14",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "We present Diversity-Aware Meta Visual Prompting (DAM-VP), an efficient and effective prompting method for transferring pre-trained models to downstream tasks with frozen backbone. A challenging issue in visual prompting is that image datasets sometimes have a large data diversity whereas a per-dataset generic prompt can hardly handle the complex distribution shift toward the original pretraining data distribution properly. To address this issue, we propose a dataset Diversity-Aware prompting strategy whose initialization is realized by a Meta-prompt. Specifically, we cluster the downstream dataset into small homogeneity subsets in a diversity-adaptive way, with each subset has its own prompt optimized separately. Such a divide-and-conquer design reduces the optimization difficulty greatly and significantly boosts the prompting performance. Furthermore, all the prompts are initialized with a meta-prompt, which is learned across several datasets. It is a bootstrapped paradigm, with the key observation that the prompting knowledge learned from previous datasets could help the prompt to converge faster and perform better on a new dataset. During inference, we dynamically select a proper prompt for each input, based on the feature distance between the input and each subset. Through extensive experiments, our DAM-VP demonstrates superior efficiency and effectiveness, clearly surpassing previous prompting methods in a series of downstream datasets for different pretraining models. Our code is available at: https://github.com/shikiw/DAM-VP.",
        "paperId": "943d42ce1c8983251c227e9b995dc069c477aa90"
    },
    {
        "title": "Recombinant hemagglutinin displaying on yeast reshapes congenital lymphocyte subsets to prompt optimized systemic immune protection against avian influenza infection",
        "firstAuthor": "Han Zhang",
        "url": "https://www.frontiersin.org/articles/10.3389/fmicb.2023.1153922/pdf",
        "dateSubmitted": "2023-05-31",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Introduction Prophylactic vaccination is regarded as the most effective means to control avian flu infection. Currently, there is a need for a universal vaccine that provides broad and long-lasting protection against influenza virus. Meanwhile, although yeast-based vaccines have been used in clinic, studies are still required to further understand the molecular mechanism of yeast-based vaccines under physiological conditions. Methods We generated a yeast-based vaccine against influenza hemagglutinin (HA) of H5, H7 and H9 using surface displaying technology and evaluated the protective efficacy of chickens after exposure to H9N2 influenza virus. Results Oral yeast vaccine provided less clinical syndrome, reduced viral loading and alleviated airway damage significantly. Compared to the commercial inactivated vaccine, yeast vaccine stimulated the activation of splenic NK and APCs cells and boosted TLR7-IRF7-IFN signaling in spleen. Meanwhile, \u03b3\u03b4 T cells in the bursa of Fabricius were activated and the innate lymphoid cells (ILCs) in the bursa of Fabricius promoted the CILPs to differentiate to ILC3 cells in oral yeast birds. Moreover, the reshaped gut microbiota and a suppressed Th17-IL17-mediated inflammation in intestine was observed in oral yeast chickens, which might facilitate the recovery of intestinal mucosal immunity upon virus infection. Collectively, our findings suggest that oral yeast based multivalent bird flu vaccines provide an attractive strategy to update host defense function via reshapes of multi-systemic immune homeostasis.",
        "paperId": "98090bbc7b784a1f64d4522c5e1987b196863fd0"
    },
    {
        "title": "Unnatural language processing: How do language models handle machine-generated prompts?",
        "firstAuthor": "Corentin Kervadec",
        "url": null,
        "dateSubmitted": "2023-10-24",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Language model prompt optimization research has shown that semantically and grammatically well-formed manually crafted prompts are routinely outperformed by automatically generated token sequences with no apparent meaning or syntactic structure, including sequences of vectors from a model's embedding space. We use machine-generated prompts to probe how models respond to input that is not composed of natural language expressions. We study the behavior of models of different sizes in multiple semantic tasks in response to both continuous and discrete machine-generated prompts, and compare it to the behavior in response to human-generated natural-language prompts. Even when producing a similar output, machine-generated and human prompts trigger different response patterns through the network processing pathways, including different perplexities, different attention and output entropy distributions, and different unit activation profiles. We provide preliminary insight into the nature of the units activated by different prompt types, suggesting that only natural language prompts recruit a genuinely linguistic circuit.",
        "paperId": "991d16222f1dbdf2f91f81fb81e022d161f3c640"
    },
    {
        "title": "What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers",
        "firstAuthor": "Boseop Kim",
        "url": "https://aclanthology.org/2021.emnlp-main.274.pdf",
        "dateSubmitted": "2021-09-10",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "GPT-3 shows remarkable in-context learning ability of large-scale language models (LMs) trained on hundreds of billion scale data. Here we address some remaining issues less reported by the GPT-3 paper, such as a non-English LM, the performances of different sized models, and the effect of recently introduced prompt optimization on in-context learning. To achieve this, we introduce HyperCLOVA, a Korean variant of 82B GPT-3 trained on a Korean-centric corpus of 560B tokens. Enhanced by our Korean-specific tokenization, HyperCLOVA with our training configuration shows state-of-the-art in-context zero-shot and few-shot learning performances on various downstream tasks in Korean. Also, we show the performance benefits of prompt-based learning and demonstrate how it can be integrated into the prompt engineering pipeline. Then we discuss the possibility of materializing the No Code AI paradigm by providing AI prototyping capabilities to non-experts of ML by introducing HyperCLOVA studio, an interactive prompt engineering interface. Lastly, we demonstrate the potential of our methods with three successful in-house applications.",
        "paperId": "a6d8d04962f84ae6225e72723869a002b9fc8036"
    },
    {
        "title": "Read-only Prompt Optimization for Vision-Language Few-shot Learning",
        "firstAuthor": "Dongjun Lee",
        "url": "https://arxiv.org/pdf/2308.14960",
        "dateSubmitted": "2023-08-29",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In recent years, prompt tuning has proven effective in adapting pre-trained vision-language models to downstream tasks. These methods aim to adapt the pre-trained models by introducing learnable prompts while keeping pre-trained weights frozen. However, learnable prompts can affect the internal representation within the self-attention module, which may negatively impact performance variance and generalization, especially in data-deficient settings. To address these issues, we propose a novel approach, Read-only Prompt Optimization (RPO). RPO leverages masked attention to prevent the internal representation shift in the pre-trained model. Further, to facilitate the optimization of RPO, the read-only prompts are initialized based on special tokens of the pre-trained model. Our extensive experiments demonstrate that RPO outperforms CLIP and CoCoOp in base-to-new generalization and domain generalization while displaying better robustness. Also, the proposed method achieves better generalization on extremely data-deficient settings, while improving parameter efficiency and computational overhead. Code is available at https://github.com/mlvlab/RPO.",
        "paperId": "b0b237dd905f12b23e3fc48ac7139e275158a007"
    },
    {
        "title": "Optimizing Mobile-Edge AI-Generated Everything (AIGX) Services by Prompt Engineering: Fundamental, Framework, and Case Study",
        "firstAuthor": "Yinqiu Liu",
        "url": "https://arxiv.org/pdf/2309.01065",
        "dateSubmitted": "2023-09-03",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "As the next-generation paradigm for content creation, AI-Generated Content (AIGC), i.e., generating content automatically by Generative AI (GAI) based on user prompts, has gained great attention and success recently. With the ever-increasing power of GAI, especially the emergence of Pretrained Foundation Models (PFMs) that contain billions of parameters and prompt engineering methods (i.e., finding the best prompts for the given task), the application range of AIGC is rapidly expanding, covering various forms of information for human, systems, and networks, such as network designs, channel coding, and optimization solutions. In this article, we present the concept of mobile-edge AI-Generated Everything (AIGX). Specifically, we first review the building blocks of AIGX, the evolution from AIGC to AIGX, as well as practical AIGX applications. Then, we present a unified mobile-edge AIGX framework, which employs edge devices to provide PFM-empowered AIGX services and optimizes such services via prompt engineering. More importantly, we demonstrate that suboptimal prompts lead to poor generation quality, which adversely affects user satisfaction, edge network performance, and resource utilization. Accordingly, we conduct a case study, showcasing how to train an effective prompt optimizer using ChatGPT and investigating how much improvement is possible with prompt engineering in terms of user experience, quality of generation, and network performance.",
        "paperId": "b349f3dd5b764168cba57bb4ad3fc240c2b3eddf"
    },
    {
        "title": "Ultrasound Imaging and Guidance in the Management of Adhesive Bursopathy of the Shoulder: A Video Demonstration",
        "firstAuthor": "V. Ricci",
        "url": null,
        "dateSubmitted": "2020-03-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Shoulder pain is a common musculoskeletal disorder in the general population, and the causes are variable, ranging from inflammatory to mechanical disorders. Currently, ultrasound (US) imaging is an established tool to promptly optimize the diagnosis and guide interventions in its management. Among others, the subacromial-subdeltoid (SASD) bursa is considered one of the primary pain-generating tissues in the shoulder, and bursopathy is the most commonly reported finding on diagnostic US imaging in patients with shoulder disorders. The SASD bursa is located superficial to the rotator cuff, below the deltoid muscle and the coracoacromial arch. It is a large synovial structure extending from the subcoracoid space medially to the subdeltoid space laterally. The mechanoreceptors and nociceptors located in the bursal subsynovial connective tissue can activate the reflex arc of the suprascapular and axillary nerves. In this sense, the anatomic distribution of SASD bursa-related (localized to widespread) pain can be highly variable. The physiologic function of this bursa is guaranteed by the regular gliding between the two synovial layers and the peribursal (extrasynovial) fat, a layer of adipose tissue contiguous with the intermuscular fat located between the rotator cuff and the surrounding muscles. Regarding the terminology commonly used in clinical practice, the word \u201cbursitis\u201d has completely replaced the word \u201cbursopathy,\u201d as if the pathologic mechanism of this bursa in the shoulder (and in general in musculoskeletal medicine) were Video online at jultrasoundmed.org",
        "paperId": "b51c770d60d5a366568090fbe0745a377c894ca7"
    },
    {
        "title": "Mitral annular systolic velocity as a marker of preclinical systolic dysfunction among patients with arterial hypertension",
        "firstAuthor": "I. Daskalov",
        "url": "https://cardiovascularultrasound.biomedcentral.com/track/pdf/10.1186/1476-7120-10-46",
        "dateSubmitted": "2012-11-28",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": null,
        "paperId": "b7cccfbffda1d0ac0e823cd11010d8dab6bba3c5"
    },
    {
        "title": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing",
        "firstAuthor": "Yueming Lyu",
        "url": "https://arxiv.org/pdf/2310.08785",
        "dateSubmitted": "2023-10-12",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Text-guided image editing faces significant challenges to training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models are put forward to avoid data collection, but they are also limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.",
        "paperId": "ba6de0dd76d6b0e79875472b76052d8c7b87f2d8"
    },
    {
        "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search",
        "firstAuthor": "Reid Pryzant",
        "url": "http://arxiv.org/pdf/2305.03495",
        "dateSubmitted": "2023-05-04",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language\"gradients\"that criticize the current prompt. The gradients are then\"propagated\"into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing techniques and improve an initial prompt's performance by up to 31%, by using data to rewrite vague task descriptions into more precise annotation instructions.",
        "paperId": "c76dd4a70361c3afd2e19d046343e2dedd16ecc3"
    },
    {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "firstAuthor": "Rui Pan",
        "url": null,
        "dateSubmitted": "2023-11-14",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly\"general\", i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in black-box prompt learning and Chain-of-Thought prompt tuning. Furthermore, we show that these methods can be used to discover more human-understandable prompts that were previously unknown, opening the door to a cornucopia of possibilities in prompt optimization. We release all the codes in \\url{https://github.com/research4pan/Plum}.",
        "paperId": "c874aa93efe663ed31f2ec72d45a5dd4b4cdffba"
    },
    {
        "title": "Implantable cardioverter defibrillators and devices for cardiac resynchronization therapy: what perspective for patients\u2019 apps combined with remote monitoring?",
        "firstAuthor": "D. Sgreccia",
        "url": null,
        "dateSubmitted": "2022-02-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "ABSTRACT Introduction Remote monitoring (RM) of cardiac implantable electronic devices (CIED) allows rapid detection of clinical and electrical events. Recently, several smartphone applications have been developed with the aim of improving patient compliance and better interpreting and integrating data deriving from remote control for the management of heart failure (HF). Areas covered Studies investigating the role of CIEDs\u2019 RM in HF patients to predict and early treat acute decompensation. The importance of new technologies and applications developed to provide crucial information to clinicians, to better manage HF patients. Expert opinion New medical technologies and smartphone applications for CIEDs\u2019 RM were developed to help clinicians in the management of CIED carriers. Indeed, the accessibility of technological devices (e.g. smartphones) and the improvements in medical technology provide the opportunity to optimize HF patients\u2019 monitoring by the transmission of device-related data, and with direct involvement of patients themselves. Thanks to these advancements, physicians have the possibility to recognize worsening signs of HF and promptly optimize treatments to potentially avoid hospitalization. The great value of this approach is its potential of reducing scheduled in-office visits or unnecessary medical contacts and optimizing healthcare resources management.",
        "paperId": "ca546bd3ee62f1b3dc992e0997f311b909bd3b37"
    },
    {
        "title": "Cisco 802.11 Wireless Networking Quick Reference",
        "firstAuthor": "T. Velte",
        "url": null,
        "dateSubmitted": "2005-10-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Your quick-and-easy reference to 802.11 WLAN components and protocolsi? Access wireless Cisco product information, including coverage on wireless client adapters and IP phones Learn the ideal configuration of access points, bridges, antennas, and routers for your specific situation Integrate a Cisco solution with various wireless networking gear Configure and troubleshoot access points and client devices promptly Optimize, secure, and tune your WLAN by following helpful tips and hints Refer to charts and tables that both network beginners and professionals can easily scan Make the right decision about your organization's wireless network with quick leverageWhether you are a network engineer, network administrator, business decision maker, or student, you know that wireless networking capabilities are an increasingly essential part of your purchasing and implementing decisions. You want the most out of your wireless gear, but memorizing every product and protocol is daunting when faced with a myriad of solutions and options. Now, you can turn to Cisco 802.11 Wireless Networking Quick Reference, a time-saving tool for the office, field, or classroom lab, when you need a memory-refresher or a quick-tip guide on maximizing your wireless network.If you work on a wireless network using Cisco\u00ae technologies, keep this book within reach. Compact and convenient, this concise reference can be browsed occasionally or consulted regularly for a glance at a technical specification or that elusive command argument. Divided into three easy-to-follow sections, Part I describes and provides ways for Cisco wireless LAN (WLAN) equipment offerings to be integrated into an existing network. Part II covers how to configure access points and clients and how to set up and manage a secure wireless network. Lastly, Part III shows you how to maintain a wireless network and troubleshoot common wireless issues. Meant to be used in a hands-on capacity, this transportable guide is a practical tool when performing a variety of tasks on your wireless network.This book is part of the Networking Technology Series from Cisco Press\u00ae, which offers networking professionals valuable information for constructing efficient networks, understanding new technologies, and building successful careers.",
        "paperId": "cc74b4f62e72900624a78de0809f77d0554c310f"
    },
    {
        "title": "Etiologies and Management of Aseptic Meningitis in Patients Admitted to an Internal Medicine Department",
        "firstAuthor": "I. Jarrin",
        "url": null,
        "dateSubmitted": "2016-01-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "AbstractSeveral studies have focused on the clinical and biological characteristics of meningitis in order to distinguish between bacterial and viral meningitis in the emergency setting. However, little is known about the etiologies and outcomes of aseptic meningitis in patients admitted to Internal Medicine.The aim of the study is to describe the etiologies, characteristics, and outcomes of aseptic meningitis with or without encephalitis in adults admitted to an Internal Medicine Department.A retrospective cohort study was conducted in the Internal Medicine Department of the Lariboisi\u00e8re Hospital in Paris, France, from January 2009 to December 2011. Clinical and biological characteristics of aseptic meningitis were recorded. These included cerebrospinal fluid analysis, results of polymerase chain reaction testing, final diagnoses, and therapeutic management.The cohort included 180 patients fulfilling the criteria for aseptic meningitis with (n\u200a=\u200a56) or without (n\u200a=\u200a124) encephalitis. A definitive etiological diagnosis was established in 83 of the 180 cases. Of the cases with a definitive diagnosis, 73 were due to infectious agents, mainly enteroviruses, Herpes Simplex Virus 2, and Varicella Zoster Virus (43.4%, 16.8%, and 14.5% respectively). Inflammatory diseases were diagnosed in 7 cases. Among the 97 cases without definitive diagnoses, 26 (26.8%) remained free of treatment throughout their management whereas antiviral or antibiotic therapy was initiated in the emergency department for the remaining 71 patients. The treatment was discontinued in only 10 patients deemed to have viral meningitis upon admission to Internal Medicine.The prevalence of inflammatory diseases among patients admitted to internal medicine for aseptic meningitis is not rare (4% of overall aseptic meningitis). The PCR upon admission to the emergency department is obviously of major importance for the prompt optimization of therapy and management. However, meningitis due to viral agents or inflammatory diseases could also be distinguished according to several clinical and biological characteristics highlighted in this retrospective study. As recommendations are now available concerning the prescriptions of antiviral agents in viral meningitis, better therapeutic management is expected in the future.",
        "paperId": "d5af3fd127a0cf17efbc127f32d6fa96e2e75166"
    },
    {
        "title": "Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker",
        "firstAuthor": "Sukmin Cho",
        "url": "http://arxiv.org/pdf/2305.13729",
        "dateSubmitted": "2023-05-23",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans against other prompt optimization methods.",
        "paperId": "d61f0820943a667917fb6d32225826aa5279f694"
    },
    {
        "title": "Evaluation of image quality with four positron emitters and three preclinical PET/CT systems",
        "firstAuthor": "J. Teuho",
        "url": null,
        "dateSubmitted": "2020-12-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": null,
        "paperId": "d64d7cf49a53ebbf91b1a8406bc8db36d715195d"
    },
    {
        "title": "Towards an Automatic Prompt Optimization Framework for AI Image Generation",
        "firstAuthor": "Ling Fan",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": null,
        "paperId": "d7265061f1ef23e985ba32e61d68296289e8ba9e"
    },
    {
        "title": "Information,Agency Conflict and State-ownedListed Bank Managers\u2032 Long-term Incentive\u2014\u2014An Analysis Based on Bank Manager Entrepreneur Competence",
        "firstAuthor": "Ma An-qin",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "A simple dynamic model is to be set up for an analysis on problerm of the region(department) managers\u2032 long-term incentive mechanism of state-owned listed banks.The model discloses the following meaningful implication.Entrepreneurs are the essential inducement for banking development.As far as performance assessment is concerned,EVA will be beneficial for the managers to make prompt,optimized investment decision;RAROC will be beneficial for bank's long development.Fixed return contracts will induce venture behavior of regional managers,making loan exceed optimized level;random payment contracts,or EVA state-reliance contracts will make the head office realize optimized loan size.When EVA is zero,removing institutions,recalling loan-granting power, etc.can reduce the present risks,but will make bank miss potential investment chances.Viewed statically,dismissal of managers will not necessarily have expected effect;while viewed dynamically,dismissal threat,with a threatening function,can force managers to work hard and add shareholder value.",
        "paperId": "df62a2287a25c11bfc4341db7ba9a70ef6f40b2b"
    },
    {
        "title": "Black-Box Prompt Optimization: Aligning Large Language Models without Model Training",
        "firstAuthor": "Jiale Cheng",
        "url": null,
        "dateSubmitted": "2023-11-07",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them. However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs. In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments. The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters. BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22% increase in the win rate against its original version, and 10% for GPT-4. Importantly, the BPO-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining BPO with PPO or DPO. Code and datasets are released at https://github.com/thu-coai/BPO.",
        "paperId": "e327ef8d46ea0413316c80ee1404453834d84f05"
    },
    {
        "title": "Becker Digital",
        "firstAuthor": "C. D. Burnham",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "We evaluated detection of ertapenem (ETP) resistance and Klebsiella pneumoniae carbapenemase (KPC) in 47 Klebsiella pneumoniae isolates using a novel automated microscopy system. Automated microscopy correctly classi\ufb01ed 22/23 isolates as ETP resistant and 24/24 as ETP susceptible and correctly classi\ufb01ed 21/21 isolates as KPC positive and 26/26 as KPC negative. C arbapenem-resistant Enterobacteriaceae (CRE) are emerging as a global threat; the plasmid-borne carbapenemase gene bla KPC is the predominant mechanism conferring carbapenem resistance in North America (1\u20135). This resistance gene has been reported in most species of Enterobacteriaceae , but it is most commonly found in Klebsiella pneumoniae . Timely detection of car-bapenem resistance is critical for prompt optimization of antimicrobial therapy, but the sensitivity of antimicrobial susceptibility testing methods for CRE detection is variable and turnaround time can be slow (6\u201310). It has been demonstrated that in vitro detection of K. pneumoniae carbapenemase (KPC) expression can be dif\ufb01cult, varying by bacterial species and level of enzyme expression. (Thisstudy was presented in part at the 113th American Society for Microbiology General Meeting, Denver, CO, May 2013.) The objective of our study was to evaluate automated microscopy for detection of ertapenem",
        "paperId": "ea5381c4a2cd99dd7563f1fe398b5eb68667c394"
    },
    {
        "title": "Intramural Atrial Hematoma: A Rare Complication of a Common Procedure",
        "firstAuthor": "L. Galiuto",
        "url": null,
        "dateSubmitted": "2013-09-01",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "In a 79-year-old woman admitted to another hospital for acute coronary syndrome and treated by urgent percutaneous coronary intervention (PCI) of right coronary artery (RCA), a left atrium (LA) formation, not previously seen at echocardiography, was surprisingly identified about 12 hours after revascularization. The patient was still asymptomatic, but, to better characterize such mass, she was early transferred to our department. Transthoracic echocardiography (TTE) (Philips iE33, Philips, Amsterdam, The Netherlands), performed at admission and within 24 hours from PCI, confirmed the presence of an anechoic formation (7.1 9 3.9 cm) with a thin hyperechoic wall, adhering to the free LA wall and protruding within the LA, with no valvular contact and transmitral medium gradient of 4 mmHg. No blood was found to flow inside the mass at color Doppler mode, neither any communication with atrial cavity could be identified. Presence of pericardial effusion was surely excluded and no other fluid was detected around the heart (Fig. 1A,B). Soon after admission, the patient developed high levels of systemic blood pressure associated with chest pain, dyspnea, and ST segment depression on lateral leads at electrocardiography. Then, an urgent coronary angiography (INNOVA, GE, Fairfield, CT, USA), that denied the onset of new coronary lesions, was performed. Interestingly, a leak and accumulation of contrast medium, which was not present at the time of PCI, was noted at RCA posterolateral side branch (Fig. 2A,B). Prompt optimization of antihypertensive therapy resolved chest pain and electrocardiographic changes and no elevation of cardiac necrosis biomarkers was further found. Shortness of breath, instead, was resolved resting on bed and was",
        "paperId": "ed6715c1f0f5a022fa0e66765c545e6f3d018292"
    },
    {
        "title": "DRPT: Disentangled and Recurrent Prompt Tuning for Compositional Zero-Shot Learning",
        "firstAuthor": "Xiaocheng Lu",
        "url": "http://arxiv.org/pdf/2305.01239",
        "dateSubmitted": "2023-05-02",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Compositional Zero-shot Learning (CZSL) aims to recognize novel concepts composed of known knowledge without training samples. Standard CZSL either identifies visual primitives or enhances unseen composed entities, and as a result, entanglement between state and object primitives cannot be fully utilized. Admittedly, vision- language models (VLMs) could naturally cope with CZSL through tuning prompts, while uneven entanglement leads prompts to be dragged into local optimum. In this paper, we take a further step to introduce a novel Disentangled and Recurrent Prompt Tuning framework termed DRPT to better tap the potential of VLMs in CZSL. Specifically, the state and object primitives are deemed as learnable tokens of vocabulary embedded in prompts and tuned on seen compositions. Instead of jointly tuning state and object, we devise a disentangled and recurrent tuning strategy to suppress the traction force caused by entanglement and gradually optimize the token parameters, leading to a better prompt space. Notably, we develop a progressive fine-tuning procedure that allows for incremental updates to the prompts, optimizing the object first, then the state, and vice versa. Meanwhile, the optimization of state and object is independent, thus clearer features can be learned to further alleviate the issue of entangling misleading optimization. Moreover, we quantify and analyze the entanglement in CZSL and supplement entanglement rebalancing optimization schemes. DRPT surpasses representative state-of-the-art methods on extensive benchmark datasets, demonstrating superiority in both accuracy and efficiency.",
        "paperId": "ee05be9be992c0b244ffd35d9ddd210ac9ee9a20"
    },
    {
        "title": "Emotion-Conditioned Text Generation through Automatic Prompt Optimization",
        "firstAuthor": "Yarik Menchaca Resendiz",
        "url": "https://arxiv.org/pdf/2308.04857",
        "dateSubmitted": "2023-08-09",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Conditional natural language generation methods often require either expensive fine-tuning or training a large language model from scratch. Both are unlikely to lead to good results without a substantial amount of data and computational resources. Prompt learning without changing the parameters of a large language model presents a promising alternative. It is a cost-effective approach, while still achieving competitive results. While this procedure is now established for zero- and few-shot text classification and structured prediction, it has received limited attention in conditional text generation. We present the first automatic prompt optimization approach for emotion-conditioned text generation with instruction-fine-tuned models. Our method uses an iterative optimization procedure that changes the prompt by adding, removing, or replacing tokens. As objective function, we only require a text classifier that measures the realization of the conditional variable in the generated text. We evaluate the method on emotion-conditioned text generation with a focus on event reports and compare it to manually designed prompts that also act as the seed for the optimization procedure. The optimized prompts achieve 0.75 macro-average F1 to fulfill the emotion condition in contrast to manually designed seed prompts with only 0.22 macro-average F1.",
        "paperId": "ef5cd0eb266e3df3eb64aec18e1854fe0244d228"
    },
    {
        "title": "The organizational managing methods in the medical-nursing first aid for group food poisoning events",
        "firstAuthor": "Pan Dai-ming",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Objective To explore the organizational managing methods for strengthening the medical-nursing first aid for group food poisoning events.Methods The measures included starting emergency plan promptly,optimizing the first aid routine,allocating human resources rationally,strengthening the management of emergency supplies and rationalizing macro-control.Results All the 252 cases of patients were clinically cured.The survival rate was 100.00% and patient satisfaction was 98.00%.No nursing errors and issues happened.Conclusion Efficient organizational management is the powerful guarantee to the successful rescue of group food poisoning patients.",
        "paperId": "f71f7f000e8ce63b4cb767c937cc854834b63c54"
    },
    {
        "title": "Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference",
        "firstAuthor": "Alessandro Sordoni",
        "url": "http://arxiv.org/pdf/2306.12509",
        "dateSubmitted": "2023-06-21",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "We view large language models (LLMs) as stochastic \\emph{language layers} in a network, where the learnable parameters are the natural language \\emph{prompts} at each layer. We stack two such layers, feeding the output of one layer to the next. We call the stacked architecture a \\emph{Deep Language Network} (DLN). We first show how to effectively perform prompt optimization for a 1-Layer language network (DLN-1). We then show how to train 2-layer DLNs (DLN-2), where two prompts must be learnt. We consider the output of the first layer as a latent variable to marginalize, and devise a variational inference algorithm for joint prompt training. A DLN-2 reaches higher performance than a single layer, sometimes comparable to few-shot GPT-4 even when each LLM in the network is smaller and less powerful. The DLN code is open source: https://github.com/microsoft/deep-language-networks .",
        "paperId": "f8783629a27af4e7d9a94890f5a2ef5d42d4d52a"
    },
    {
        "title": "Large Language Models as Optimizers",
        "firstAuthor": "Chengrun Yang",
        "url": "https://arxiv.org/pdf/2309.03409",
        "dateSubmitted": "2023-09-07",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.",
        "paperId": "f8a2dca1e8fe56e698984c077f7ff58d8ca867e9"
    },
    {
        "title": "Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Optimization for Few-shot Learning",
        "firstAuthor": "Chengzhengxu Li",
        "url": "https://arxiv.org/pdf/2308.07272",
        "dateSubmitted": "2023-08-14",
        "keyWords": [
            "prompt optimization"
        ],
        "abstract": "Prompt-based pre-trained language models (PLMs) paradigm have succeeded substantially in few-shot natural language processing (NLP) tasks. However, prior discrete prompt optimization methods require expert knowledge to design the base prompt set and identify high-quality prompts, which is costly, inefficient, and subjective. Meanwhile, existing continuous prompt optimization methods improve the performance by learning the ideal prompts through the gradient information of PLMs, whose high computational cost, and low readability and generalizability are often concerning. To address the research gap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt Optimization ($DP_2O$) method. We first design a multi-round dialogue alignment strategy for readability prompt set generation based on GPT-4. Furthermore, we propose an efficient prompt screening metric to identify high-quality prompts with linear complexity. Finally, we construct a reinforcement learning (RL) framework based on policy gradients to match the prompts to inputs optimally. By training a policy network with only 0.67% of the PLM parameter size on the tasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA) method by 1.52% in accuracy on average on four open-source datasets. Moreover, subsequent experiments also demonstrate that $DP_2O$ has good universality, robustness, and generalization ability.",
        "paperId": "ff96527c03fbea7c3bb7d44d1d656d875ddba75e"
    }
]