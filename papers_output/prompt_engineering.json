[
    {
        "title": "Artificial intelligence prompt engineering as a new digital competence: Analysis of generative AI technologies such as ChatGPT",
        "firstAuthor": "P. Korzy\u0144ski",
        "url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2142/863",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Objective: The article aims to offer a thorough examination and comprehension of the challenges and pro\u2010 spects connected with artificial intelligence (AI) prompt engineering. Our research aimed to create a theoret\u2010 ical framework that would highlight optimal approaches in the field of AI prompt engineering. Research Design & Methods: This research utilized a narrative and critical literature review and established a conceptual framework derived from existing literature taking into account both academic and practitioner sources. This article should be regarded as a conceptual work that emphasizes the best practices in the domain of AI prompt engineering. Findings: Based on the conducted deep and extensive query of academic and practitioner literature on the subject, as well as professional press and Internet portals, we identified various insights for effective AI prompt engineering. We provide specific prompting strategies. Implications & Recommendations: The study revealed the profound implications of AI prompt engineering across various domains such as entrepreneurship, art, science, and healthcare. We demonstrated how the effective crafting of prompts can significantly enhance the performance of large language models (LLMs), gen\u2010 erating more accurate and contextually relevant results. Our findings offer valuable insights for AI practition\u2010 ers, researchers, educators, and organizations integrating AI into their operations, emphasizing the need to invest time and resources in prompt engineering. Moreover, we contributed the AI PROMPT framework to the field, providing clear and actionable guidelines for text\u2010to\u2010text prompt engineering. Contribution & Value Added: The value of this study lies in its comprehensive exploration of AI prompt engineer\u2010 ing as a digital competence. By building upon existing research and prior literature, this study aimed to provide a deeper understanding of the intricacies involved in AI prompt engineering and its role as a digital competence. Article",
        "paperId": "0019e876188f781fdca0c0ed3bca39d0c70c2ad2"
    },
    {
        "title": "Digital Commons@Lindenwood University Digital Commons@Lindenwood University",
        "firstAuthor": "James Hutson",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "-AI will be increasingly integrated into artistic practices and creative workflows with prompt engineering assuming an increasingly important role in the process. With readily-available generative AI, such as Midjourney, DALL-E 2, and Craiyon (formerly DALLE-mini), anyone can seemingly create \"art,\u201d prompting questions about the future necessity of art and design education. However, whereas the ease with which content can be created has seen an outcry from the traditional artmaking community, fears over widespread adoption replacing the need for a firm foundation in art and design principles and fundamentals is unfounded. Instead, these tools should be seen and adopted as other photomechanical and computer-generated versions before them and leveraged to provide new models for artists to improve their workflow. Therefore, the case study here proposed the use of AI generative art for a traditional 3D design studio art course to determine the manner and degree of process change that may be expected and to determine potential benefits of the new technology. As such, students were prompted to use the Craiyon or DALLE-2 art generator to gather verbal cues to combine three different objects into a new version that would then be realized as a physical three-dimensional sculpture and/or model. GJHSS-A Classification: ExploringtheEducationalPotentialofAIGenerativeArtin3DDesignFundamentalsACaseStudyonPromptEngineeringandCreativeWorkflows",
        "paperId": "00d31eecd7894d1528ba6f45fad97b585d9d283f"
    },
    {
        "title": "TART: A plug-and-play Transformer module for task-agnostic reasoning",
        "firstAuthor": "K. Bhatia",
        "url": "http://arxiv.org/pdf/2306.07536",
        "dateSubmitted": "2023-06-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) exhibit in-context learning abilities which enable the same model to perform several tasks without any task-specific training. In contrast, traditional adaptation approaches, such as fine-tuning, modify the underlying models for each specific task. In-context learning, however, consistently underperforms task-specific tuning approaches even when presented with the same examples. While most existing approaches (e.g., prompt engineering) focus on the LLM's learned representations to patch this performance gap, our analysis actually reveal that LLM representations contain sufficient information to make good predictions. As such, we focus on the LLM's reasoning abilities and demonstrate that this performance gap exists due to their inability to perform simple probabilistic reasoning tasks. This raises an intriguing question: Are LLMs actually capable of learning how to reason in a task-agnostic manner? We answer this in the affirmative and propose TART which generically improves an LLM's reasoning abilities using a synthetically trained Transformer-based reasoning module. TART trains this reasoning module in a task-agnostic manner using only synthetic logistic regression tasks and composes it with an arbitrary real-world pre-trained model without any additional training. With a single inference module, TART improves performance across different model families (GPT-Neo, Pythia, BLOOM), model sizes (100M - 6B), tasks (14 NLP binary classification tasks), and even across different modalities (audio and vision). Additionally, on the RAFT Benchmark, TART improves GPT-Neo (125M)'s performance such that it outperforms BLOOM (176B), and is within 4% of GPT-3 (175B). Our code and models are available at https://github.com/HazyResearch/TART .",
        "paperId": "014c00319cb23c6322ea5218049661a4ce222946"
    },
    {
        "title": "Cataloging Prompt Patterns to Enhance the Discipline of Prompt Engineering",
        "firstAuthor": "D. Schmidt",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rapid advent of Large language models (LLMs), such as ChatGPT, are disrupting a number of domains, ranging from education to medicine and software engineering. LLMs rely on \"prompts\", which are natural language statements given to the LLM to query and program its capabilities. This paper provides several contributions to research on LLMs. First, discusses the importance of codifying \"prompt patterns\" to enable prompt engineering, which is a more disciplined and repeatable means of interacting with and evaluating LLMs. Second, it provides examples of prompt patterns that improve human interaction with LLMs in the context of software engineering, as well as other domains. We contend that prompt patterns play an essential role in providing the foundation for prompt engineering.",
        "paperId": "016c0da42e7fac7b3a05760b7cfbbf72062248a0"
    },
    {
        "title": "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification",
        "firstAuthor": "Shan Chen",
        "url": "http://arxiv.org/pdf/2304.02496",
        "dateSubmitted": "2023-04-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent advances in large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates the performance of LLMs such as the ChatGPT family of models (GPT-3.5s, GPT-4) in biomedical tasks beyond question-answering. Because no patient data can be passed to the OpenAI API public interface, we evaluated model performance with over 10000 samples as proxies for two fundamental tasks in the clinical domain - classification and reasoning. The first task is classifying whether statements of clinical and policy recommendations in scientific literature constitute health advice. The second task is causal relation detection from the biomedical literature. We compared LLMs with simpler models, such as bag-of-words (BoW) with logistic regression, and fine-tuned BioBERT models. Despite the excitement around viral ChatGPT, we found that fine-tuning for two fundamental NLP tasks remained the best strategy. The simple BoW model performed on par with the most complex LLM prompting. Prompt engineering required significant investment.",
        "paperId": "020e473d8c987dcfb03fcfffeb87b17812447031"
    },
    {
        "title": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
        "firstAuthor": "Robin Rombach",
        "url": "http://arxiv.org/pdf/2207.13038",
        "dateSubmitted": "2022-07-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Novel architectures have recently improved generative image synthesis leading to excellent visual quality in various tasks. Of particular note is the field of ``AI-Art'', which has seen unprecedented growth with the emergence of powerful multimodal models such as CLIP. By combining speech and image synthesis models, so-called ``prompt-engineering'' has become established, in which carefully selected and composed sentences are used to achieve a certain visual style in the synthesized image. In this note, we present an alternative approach based on retrieval-augmented diffusion models (RDMs). In RDMs, a set of nearest neighbors is retrieved from an external database during training for each training instance, and the diffusion model is conditioned on these informative samples. During inference (sampling), we replace the retrieval database with a more specialized database that contains, for example, only images of a particular visual style. This provides a novel way to prompt a general trained model after training and thereby specify a particular visual style. As shown by our experiments, this approach is superior to specifying the visual style within the text prompt. We open-source code and model weights at https://github.com/CompVis/latent-diffusion .",
        "paperId": "0270ec4bc946b59c5cf6204be2553682dee0346c"
    },
    {
        "title": "\u0412.\u0421. \u0410\u0411\u0420\u0423\u041a\u041e\u0412, \u0415.\u0412. \u041a\u0410\u0420\u041b\u041e\u0412\u0418\u0427, \u0410.\u0413. \u0418\u0412\u0410\u041d\u041e\u0412 \u041c\u041e\u0414\u0415\u041b\u0418\u0420\u041e\u0412\u0410\u041d\u0418\u0415 \u0413\u041e\u0420\u0415\u041d\u0418\u042f \u041a\u041e\u041d\u0414\u0415\u041d\u0421\u0418\u0420\u041e\u0412\u0410\u041d\u041d\u042b\u0425 \u0421\u0418\u0421\u0422\u0415\u041c \u0421 \u041f\u041e\u041c\u041e\u0429\u042c\u042e \u0421\u0420\u0415\u0414\u0421\u0422\u0412 DATA MINING",
        "firstAuthor": "V. S. Abrukov",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "burning of condensed systems, modeling, Data Mining, artificial neural networks, self-organizing Cohonen maps. The opportunities of Data Mining, in particular of artificial neural networks (ANN) and self-organizing Cohonen maps for modeling and prediction of burning behaviors of condensed systems (CS) represented. The computing models obtained permit to forecast burning behaviors of CS: regularities of extinction of the CS in pressure drop in the combustion chamber, a burning rate in dependence on a composition and availability of catalytic agents of CS at different pressures, The results obtained display that ANN can be considered as a good tool for approximation of multivariate experimental data that permit to extend and to forecast connection between variables of experiment, as the prompt engineering calculator specialized for problem solving of examination of process of CS burning, as a tool of obtaining of new \u00abexperimental\u00bb re-sults and detections of new unknowns before legitimacies of burning, as a good tool of representation and storage of experimental results obtained.",
        "paperId": "037b39a6a288b511b35bd149464a155fb4552b17"
    },
    {
        "title": "Original Research",
        "firstAuthor": "Shigang Gao",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rapid development and adoption of generative artificial intelligence (AI) tools in the art and design education landscape have introduced both opportunities and challenges. This timely study addresses the need to effectively inte-grate these tools into the classroom while considering ethical implications and the importance of prompt engineering. By examining the iterative process of refining original ideas through multiple iterations, verbal expansion, and the use of OpenAI\u2019s DALL-E2 for generating diverse visual outcomes, researchers gain insights into the potential benefits and pitfalls of these tools in an educational context. Students in the digital at case study were taught prompt engineering techniques and were tasked with crafting multiple prompts, focusing on refining their ideas over time. Participants demonstrated an increased understanding of the potential and limitations of generative AI tools and how to manipulate subject matter for more effective results. The iterative process encouraged students to explore and experiment with their creative ideas, leading to a deeper understanding of the possibilities offered by AI tools. Despite acknowledging the ethical concerns regarding copyright and the potential replacement of artists, students appreciated the value of generative AI tools for enhancing their sketchbooks and ideation process. Through prompt engineering and iterative processes, students developed a more detail-oriented approach to their work. The challenge of using AI-generated images as final products was conceptually intriguing, requiring further investigation and consideration of the prompts. This study highlights the potential benefits and challenges of integrating generative AI tools into art and design classrooms, emphasizing the importance of prompt engineering, iterative processes, and ethical considerations as these technologies continue to evolve.",
        "paperId": "039052a04d01dd07d7b46c292cd883e0e3dd9ffb"
    },
    {
        "title": "Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models",
        "firstAuthor": "Hendrik Strobelt",
        "url": "https://arxiv.org/pdf/2208.07852",
        "dateSubmitted": "2022-08-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "State-of-the-art neural language models can now be used to solve ad-hoc language tasks through zero-shot prompting without the need for supervised training. This approach has gained popularity in recent years, and researchers have demonstrated prompts that achieve strong accuracy on specific NLP tasks. However, finding a prompt for new tasks requires experimentation. Different prompt templates with different wording choices lead to significant accuracy differences. PromptIDE allows users to experiment with prompt variations, visualize prompt performance, and iteratively optimize prompts. We developed a workflow that allows users to first focus on model feedback using small data before moving on to a large data regime that allows empirical grounding of promising prompts using quantitative measures of the task. The tool then allows easy deployment of the newly created ad-hoc models. We demonstrate the utility of PromptIDE (demo: http://prompt.vizhub.ai) and our workflow using several real-world use cases.",
        "paperId": "0392d58335ce674a70f5e58ac8c438de296a0e6a"
    },
    {
        "title": "Artificial Intelligence for Health Message Generation: Theory, Method, and an Empirical Study Using Prompt Engineering",
        "firstAuthor": "Sue Lim",
        "url": "http://arxiv.org/pdf/2212.07507",
        "dateSubmitted": "2022-12-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study introduces and examines the potential of an AI system to generate health awareness messages. The topic of folic acid, a vitamin that is critical during pregnancy, served as a test case. Using prompt engineering, we generated messages that could be used to raise awareness and compared them to retweeted human-generated messages via computational and human evaluation methods. The system was easy to use and prolific, and computational analyses revealed that the AI-generated messages were on par with human-generated ones in terms of sentiment, reading ease",
        "paperId": "040ec58865ab50b5e6d91a355ffc146ec5034e9f"
    },
    {
        "title": "Artificial intelligence for health message generation: an empirical study using a large language model (LLM) and prompt engineering",
        "firstAuthor": "Sue Lim",
        "url": "https://www.frontiersin.org/articles/10.3389/fcomm.2023.1129082/pdf",
        "dateSubmitted": "2023-05-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Introduction This study introduces and examines the potential of an AI system to generate health awareness messages. The topic of folic acid, a vitamin that is critical during pregnancy, served as a test case. Method We used prompt engineering to generate awareness messages about folic acid and compared them to the most retweeted human-generated messages via human evaluation with an university sample and another sample comprising of young adult women. We also conducted computational text analysis to examine the similarities between the AI-generated messages and human generated tweets in terms of content and semantic structure. Results The results showed that AI-generated messages ranked higher in message quality and clarity across both samples. The computational analyses revealed that the AI generated messages were on par with human-generated ones in terms of sentiment, reading ease, and semantic content. Discussion Overall, these results demonstrate the potential of large language models for message generation. Theoretical, practical, and ethical implications are discussed.",
        "paperId": "04f1ff349424b4fb64a24fcaf44532d69826b0f4"
    },
    {
        "title": "Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation",
        "firstAuthor": "Zonghai Yao",
        "url": null,
        "dateSubmitted": "2023-11-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study examines the effect of prompt engineering on the performance of Large Language Models (LLMs) in clinical note generation. We introduce an Automatic Prompt Optimization (APO) framework to refine initial prompts and compare the outputs of medical experts, non-medical experts, and APO-enhanced GPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in standardizing prompt quality across clinical note sections. A human-in-the-loop approach shows that experts maintain content quality post-APO, with a preference for their own modifications, suggesting the value of expert customization. We recommend a two-phase optimization process, leveraging APO-GPT4 for consistency and expert input for personalization.",
        "paperId": "0544cad023bf49bbf51d69f44f8280dc63b20f57"
    },
    {
        "title": "Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language",
        "firstAuthor": "Paul Denny",
        "url": "https://eprints.iisc.ac.in/81157/1/SIGCSE_2023.pdf",
        "dateSubmitted": "2022-10-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.",
        "paperId": "0566c1c3eeeef5c968fced6d80b77fe22d02bbd9"
    },
    {
        "title": "ChatGPT vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations with Speech Functions",
        "firstAuthor": "Lidiia Ostyakova",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.",
        "paperId": "061d5b2ceb7e537c3c96d13f267c0cc22f8f96d3"
    },
    {
        "title": "Prompt-Engineering and Transformer-based Question Generation and Evaluation",
        "firstAuthor": "Rubaba Amyeen",
        "url": null,
        "dateSubmitted": "2023-10-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Question generation has numerous applications in the educational context. Question generation can prove helpful for students when reviewing content and testing themselves. Furthermore, a question generation model can aid teachers by lessening the burden of creating assessments and other practice material. This paper aims to find the best method to generate questions from textual data through a transformer model and prompt engineering. In this research, we finetuned a pretrained distilBERT model on the SQuAD question answering dataset to generate questions. In addition to training a transformer model, prompt engineering was applied to generate questions effectively using the LLaMA model. The generated questions were compared against the baseline questions in the SQuAD dataset to evaluate the effectiveness of four different prompts. All four prompts demonstrated over 60% similarity on average. Of the prompt-generated questions, 30% achieved a high similarity score greater than 70%.",
        "paperId": "06826c7023303af28b5f362f4286ea4d14c2531a"
    },
    {
        "title": "How does prompt engineering affect ChatGPT performance on unsupervised entity resolution?",
        "firstAuthor": "Khanin Sisaengsuwanchai",
        "url": "https://arxiv.org/pdf/2310.06174",
        "dateSubmitted": "2023-10-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Entity Resolution (ER) is the problem of semi-automatically determining when two entities refer to the same underlying entity, with applications ranging from healthcare to e-commerce. Traditional ER solutions required considerable manual expertise, including feature engineering, as well as identification and curation of training data. In many instances, such techniques are highly dependent on the domain. With recent advent in large language models (LLMs), there is an opportunity to make ER much more seamless and domain-independent. However, it is also well known that LLMs can pose risks, and that the quality of their outputs can depend on so-called prompt engineering. Unfortunately, a systematic experimental study on the effects of different prompting methods for addressing ER, using LLMs like ChatGPT, has been lacking thus far. This paper aims to address this gap by conducting such a study. Although preliminary in nature, our results show that prompting can significantly affect the quality of ER, although it affects some metrics more than others, and can also be dataset dependent.",
        "paperId": "06ab0710c8a7315e70c15c0d7eb1aa50210d945c"
    },
    {
        "title": "A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models",
        "firstAuthor": "Jindong Gu",
        "url": "https://arxiv.org/pdf/2307.12980",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\u2014Prompt engineering is a technique that involves augmenting a large pre-trained model with task-speci\ufb01c hints, known as prompts, to adapt the model to new tasks. Prompts can be created manually as natural language instructions or generated automatically as either natural language instructions or vector representations. Prompt engineering enables the ability to perform predictions based solely on prompts without updating model parameters, and the easier application of large pre-trained models in real-world tasks. In past years, Prompt engineering has been well-studied in natural language processing. Recently, it has also been intensively studied in vision-language modeling. However, there is currently a lack of a systematic overview of prompt engineering on pre-trained vision-language models. This paper aims to provide a comprehensive survey of cutting-edge research in prompt engineering on three types of vision-language models: multimodal-to-text generation models ( e.g., Flamingo), image-text matching models ( e.g., CLIP), and text-to-image generation models ( e.g., Stable Diffusion). For each type of model, a brief model summary, prompting methods, prompting-based applications, and the corresponding responsibility and integrity issues are summarized and discussed. Furthermore, the commonalities and differences between prompting on vision-language models, language models, and vision models are also discussed. The challenges, future directions, and research opportunities are summarized to foster future research on this topic.",
        "paperId": "06d8562831c32844285a691c5250d04726df3c61"
    },
    {
        "title": "Unveiling the potential of large language models in generating semantic and cross-language clones",
        "firstAuthor": "Palash R. Roy",
        "url": "https://arxiv.org/pdf/2309.06424",
        "dateSubmitted": "2023-09-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones",
        "paperId": "073972fa0de48db1304509041e877e568c94e7de"
    },
    {
        "title": "To be or not to be? an exploration of continuously controllable prompt engineering",
        "firstAuthor": "Yuhan Sun",
        "url": null,
        "dateSubmitted": "2023-11-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "As the use of large language models becomes more widespread, techniques like parameter-efficient fine-tuning and other methods for controlled generation are gaining traction for customizing models and managing their outputs. However, the challenge of precisely controlling how prompts influence these models is an area ripe for further investigation. In response, we introduce ControlPE (Continuously Controllable Prompt Engineering). ControlPE enables finer adjustments to prompt effects, complementing existing prompt engineering, and effectively controls continuous targets. This approach harnesses the power of LoRA (Low-Rank Adaptation) to create an effect akin to prompt weighting, enabling fine-tuned adjustments to the impact of prompts. Our methodology involves generating specialized datasets for prompt distillation, incorporating these prompts into the LoRA model, and carefully adjusting LoRA merging weight to regulate the influence of prompts. This provides a dynamic and adaptable tool for prompt control. Through our experiments, we have validated the practicality and efficacy of ControlPE. It proves to be a promising solution for control a variety of prompts, ranging from generating short responses prompts, refusal prompts to chain-of-thought prompts.",
        "paperId": "077e8f6d633c2ee7a7ba82579ac3d1fb98740785"
    },
    {
        "title": "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model",
        "firstAuthor": "Yao Lu",
        "url": "https://arxiv.org/pdf/2308.05345",
        "dateSubmitted": "2023-08-10",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Inspired by the recent success of large language models (LLMs) like ChatGPT, researchers start to explore the adoption of LLMs for agile hardware design, such as generating design RTL based on natural-language instructions. However, in existing works, their target designs are all relatively simple and in a small scale, and proposed by the authors themselves, making a fair comparison among different LLM solutions challenging. In addition, many prior works only focus on the design correctness, without evaluating the design qualities of generated design RTL. In this work, we propose an open-source benchmark named RTLLM, for generating design RTL with natural language instructions. To systematically evaluate the auto-generated design RTL, we summarized three progressive goals, named syntax goal, functionality goal, and design quality goal. This benchmark can automatically provide a quantitative evaluation of any given LLM-based solution. Furthermore, we propose an easy-to-use yet surprisingly effective prompt engineering technique named self-planning, which proves to significantly boost the performance of GPT-3.5 in our proposed benchmark.",
        "paperId": "079be8c8a93fc80274ff22251a3dac9804bec66a"
    },
    {
        "title": "Prompt Engineering for Text-Based Generative Art",
        "firstAuthor": "J. Oppenlaender",
        "url": "http://arxiv.org/pdf/2204.13988",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-based generative art has seen an explosion of interest in 2021. Online communities around text-based generative art as a novel digital medium have quickly emerged. This short paper identifies five types of prompt modifiers used by practitioners in the community of text-based generative art based on a 3-month ethnographic study on Twitter. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practices of text-based generative art, but also may help practitioners of text-based generative art improve their images. The paper concludes with a discussion of research opportunities in the space of text-based generative art and the broader implications of prompt engineering from the perspective of human-AI interaction in future applications beyond the use case of text-based generative art.",
        "paperId": "07cd498aacfb4d39fa2e0e8d8a9c8ad881257300"
    },
    {
        "title": "User-friendly Image Editing with Minimal Text Input: Leveraging Captioning and Injection Techniques",
        "firstAuthor": "Sunwoo Kim",
        "url": "http://arxiv.org/pdf/2306.02717",
        "dateSubmitted": "2023-06-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent text-driven image editing in diffusion models has shown remarkable success. However, the existing methods assume that the user's description sufficiently grounds the contexts in the source image, such as objects, background, style, and their relations. This assumption is unsuitable for real-world applications because users have to manually engineer text prompts to find optimal descriptions for different images. From the users' standpoint, prompt engineering is a labor-intensive process, and users prefer to provide a target word for editing instead of a full sentence. To address this problem, we first demonstrate the importance of a detailed text description of the source image, by dividing prompts into three categories based on the level of semantic details. Then, we propose simple yet effective methods by combining prompt generation frameworks, thereby making the prompt engineering process more user-friendly. Extensive qualitative and quantitative experiments demonstrate the importance of prompts in text-driven image editing and our method is comparable to ground-truth prompts.",
        "paperId": "0809c278fcdec2ce297da3a9d6e031fc192263f6"
    },
    {
        "title": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis",
        "firstAuthor": "Oscar J. Romero",
        "url": "https://arxiv.org/pdf/2308.09830",
        "dateSubmitted": "2023-08-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper explores the integration of two AI subdisciplines employed in the development of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). We present three integration approaches, each grounded in theoretical models and supported by preliminary empirical evidence. The modular approach, which introduces four models with varying degrees of integration, makes use of chain-of-thought prompting, and draws inspiration from augmented LLMs, the Common Model of Cognition, and the simulation theory of cognition. The agency approach, motivated by the Society of Mind theory and the LIDA cognitive architecture, proposes the formation of agent collections that interact at micro and macro cognitive levels, driven by either LLMs or symbolic components. The neuro-symbolic approach, which takes inspiration from the CLARION cognitive architecture, proposes a model where bottom-up learning extracts symbolic representations from an LLM layer and top-down guidance utilizes symbolic representations to direct prompt engineering in the LLM layer. These approaches aim to harness the strengths of both LLMs and CAs, while mitigating their weaknesses, thereby advancing the development of more robust AI systems. We discuss the tradeoffs and challenges associated with each approach.",
        "paperId": "0815c5a05f50fc3405299abdb97cf1343ad63ac9"
    },
    {
        "title": "Extracting Financial Data From Unstructured Sources: Leveraging Large Language Models",
        "firstAuthor": "Huaxia Li",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This research addresses the challenge of extracting financial data from unstructured sources, a persistent issue for accounting researchers, investors, and regulators. Leveraging large language models (LLMs), this study develops a framework for automated financial data extraction from PDF-formatted files. Following the design science methodology, this research develops the framework through a series of text mining and prompt engineering techniques and further applies it to governmental annual reports in PDF format. Pilot test results indicate that the framework achieves a 100% accuracy rate within a short period of time when extracting key financial indicators. This study contributes to the evolving literature on applying LLMs in accounting and finance, while also providing a practical tool for both academic and industry applications.",
        "paperId": "08a1c56ae37c6bf6f38b554e26a31a251abe7807"
    },
    {
        "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
        "firstAuthor": "Jules White",
        "url": "http://arxiv.org/pdf/2302.11382",
        "dateSubmitted": "2023-02-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt engineering is an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT. Prompts are instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM. This paper describes a catalog of prompt engineering techniques presented in pattern form that have been applied to solve common problems when conversing with LLMs. Prompt patterns are a knowledge transfer method analogous to software patterns since they provide reusable solutions to common problems faced in a particular context, i.e., output generation and interaction when working with LLMs. This paper provides the following contributions to research on prompt engineering that apply LLMs to automate software development tasks. First, it provides a framework for documenting patterns for structuring prompts to solve a range of problems so that they can be adapted to different domains. Second, it presents a catalog of patterns that have been applied successfully to improve the outputs of LLM conversations. Third, it explains how prompts can be built from multiple patterns and illustrates prompt patterns that benefit from combination with other prompt patterns.",
        "paperId": "08b85bce712168998004ee80ce4e475390413c74"
    },
    {
        "title": "Ebhaam at SemEval-2023 Task 1: A CLIP-Based Approach for Comparing Cross-modality and Unimodality in Visual Word Sense Disambiguation",
        "firstAuthor": "Zeinab Taghavi",
        "url": "https://aclanthology.org/2023.semeval-1.269.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents an approach to tackle the task of Visual Word Sense Disambiguation (Visual-WSD), which involves determining the most appropriate image to represent a given polysemous word in one of its particular senses. The proposed approach leverages the CLIP model, prompt engineering, and text-to-image models such as GLIDE and DALL-E 2 for both image retrieval and generation. To evaluate our approach, we participated in the SemEval 2023 shared task on \u201cVisual Word Sense Disambiguation (Visual-WSD)\u201d using a zero-shot learning setting, where we compared the accuracy of different combinations of tools, including \u201cSimple prompt-based\u201d methods and \u201cGenerated prompt-based\u201d methods for prompt engineering using completion models, and text-to-image models for changing input modality from text to image. Moreover, we explored the benefits of cross-modality evaluation between text and candidate images using CLIP. Our experimental results demonstrate that the proposed approach reaches better results than cross-modality approaches, highlighting the potential of prompt engineering and text-to-image models to improve accuracy in Visual-WSD tasks. We assessed our approach in a zero-shot learning scenario and attained an accuracy of 68.75\\% in our best attempt.",
        "paperId": "08e0e696732103e585fd629e23888fd4acbb22df"
    },
    {
        "title": "Exploring the Synergy of Prompt Engineering and Reinforcement Learning for Enhanced Control and Responsiveness in Chat GPT",
        "firstAuthor": "Neelesh Mungoli",
        "url": "https://doi.org/10.33140/jeee.02.03.02",
        "dateSubmitted": "2023-07-10",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Conversational AI systems, such as Chat GPT, have exhibited remarkable performance in generating human-like responses. However, achieving consistent control and responsiveness remains a challenge. This research paper explores the combined effects of prompt engineering and reinforcement learning techniques in enhancing control and responsiveness in Chat GPT. Our experiments demonstrate significant improvements in the model\u2019s performance across diverse domains and tasks. We discuss the implications of these findings for various real-world applications, such as customer support, virtual assistants, content generation, and education, and provide insights into future research directions and ethical considerations in the development of more reliable, controllable, and effective conversational AI systems.",
        "paperId": "093a45b90697a19586c11dbf6a01d8a1827f54dc"
    },
    {
        "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
        "firstAuthor": "Vivian Liu",
        "url": "https://arxiv.org/pdf/2109.06977",
        "dateSubmitted": "2021-09-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.",
        "paperId": "0968f1592f9401d72bf0d97e740496818c1a3135"
    },
    {
        "title": "Yes, You Can Make an App Too: A Systematic Study of Prompt Engineering in the Automatic Generation of Mobile Applications from User Queries",
        "firstAuthor": "Jasmine Shone",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Aptly aims to use large language models to allow for on-the-\ufb02y generation of full apps given only an user description of an app idea. In order to optimize this platform and to provide guidance for other platforms or companies aiming to personalize large language models (LLMs) for their needs, we embark on one of the \ufb01rst systematic studies of prompt engineering for the Codex model, a LLM that produces code from a natural-language input. Speci\ufb01cally, we examine the e\ufb00ect of varying the token length, mechanism of choosing examples (random selection, least to most token size, cosine similarity, or an adapted version of Minimum Redundancy Maximum Relevance), and how they are ordered within the prompt (highest to lowest ranked, lowest to highest ranked, randomly shu\ufb04ed) on the quality of generated code. We improve the pipeline\u2019s performance from baseline for complex apps by 55% (0.10 increase in BLEU score) using example selection mechanisms and 43% (0.13) for simple apps.",
        "paperId": "09e14c4c80e20e80c052e0adb0d49df51aff718d"
    },
    {
        "title": "On Codex Prompt Engineering for OCL Generation: An Empirical Study",
        "firstAuthor": "Seif Abukhalaf",
        "url": "https://arxiv.org/pdf/2303.16244",
        "dateSubmitted": "2023-03-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to Meta-Object Facility (MOF) models. OCL can provide precision and conciseness to UML models. Nevertheless, the unfamiliar syntax of OCL has hindered its adoption by software practitioners. LLMs, such as GPT-3, have made significant progress in many NLP tasks, such as text generation and semantic parsing. Similarly, researchers have improved on the downstream tasks by fine-tuning LLMs for the target task. Codex, a GPT-3 descendant by OpenAI, has been fine-tuned on publicly available code from GitHub and has proven the ability to generate code in many programming languages, powering the AI-pair programmer Copilot. One way to take advantage of Codex is to engineer prompts for the target downstream task. In this paper, we investigate the reliability of the OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications from various educational resources. We manually crafted a prompt template with slots to populate with the UML information and the target task in the prefix format to complete the template with the generated OCL constraint. We used both zero- and few-shot learning methods in the experiments. The evaluation is reported by measuring the syntactic validity and the execution accuracy metrics of the generated OCL constraints. Moreover, to get insight into how close or natural the generated OCL constraints are compared to human-written ones, we measured the cosine similarity between the sentence embedding of the correctly generated and human-written OCL constraints. Our findings suggest that by enriching the prompts with the UML information of the models and enabling few-shot learning, the reliability of the generated OCL constraints increases. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex.",
        "paperId": "0a0d6a98bd246a82aaaa9d33ec0eadf4ceae69dc"
    },
    {
        "title": "VisorGPT: Learning Visual Prior via Generative Pre-Training",
        "firstAuthor": "Jinheng Xie",
        "url": "http://arxiv.org/pdf/2305.13777",
        "dateSubmitted": "2023-05-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Various stuff and things in visual data possess specific traits, which can be learned by deep neural networks and are implicitly represented as the visual prior, e.g., object location and shape, in the model. Such prior potentially impacts many vision tasks. For example, in conditional image synthesis, spatial conditions failing to adhere to the prior can result in visually inaccurate synthetic results. This work aims to explicitly learn the visual prior and enable the customization of sampling. Inspired by advances in language modeling, we propose to learn Visual prior via Generative Pre-Training, dubbed VisorGPT. By discretizing visual locations of objects, e.g., bounding boxes, human pose, and instance masks, into sequences, VisorGPT can model visual prior through likelihood maximization. Besides, prompt engineering is investigated to unify various visual locations and enable customized sampling of sequential outputs from the learned prior. Experimental results demonstrate that VisorGPT can effectively model the visual prior, which can be employed for many vision tasks, such as customizing accurate human pose for conditional image synthesis models like ControlNet. Code will be released at https://github.com/Sierkinhane/VisorGPT.",
        "paperId": "0a61802b71aa044cf1fe0e81befec148e0d5001b"
    },
    {
        "title": "More Samples or More Prompt Inputs? Exploring Effective In-Context Sampling for LLM Few-Shot Prompt Engineering",
        "firstAuthor": "Bingsheng Yao",
        "url": null,
        "dateSubmitted": "2023-11-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "While most existing works on LLM prompt-engineering focus only on how to select a better set of data samples inside one single prompt input (In-Context Learning or ICL), why can't we design and leverage multiple prompt inputs together to further improve the LLM performance? In this work, we propose In-Context Sampling (ICS), a low-resource LLM prompt-engineering technique to produce the most confident prediction results by optimizing the construction of multiple ICL prompt inputs. Extensive experiments with two SOTA LLMs (FlanT5-XL and Mistral-7B) on three NLI datasets (e-SNLI, Multi-NLI, and ANLI) illustrate that ICS can consistently enhance LLM's prediction performance and confidence. An ablation study suggests that a diversity-based ICS strategy may further improve LLM's performance, which sheds light on a new yet promising future research direction.",
        "paperId": "0ab79543d98e375b9de1354766c024e165cc2369"
    },
    {
        "title": "Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students",
        "firstAuthor": "Dollaya Hirunyasiri",
        "url": "https://arxiv.org/pdf/2307.02018",
        "dateSubmitted": "2023-07-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Research suggests that providing specific and timely feedback to human tutors enhances their performance. However, it presents challenges due to the time-consuming nature of assessing tutor performance by human evaluators. Large language models, such as the AI-chatbot ChatGPT, hold potential for offering constructive feedback to tutors in practical settings. Nevertheless, the accuracy of AI-generated feedback remains uncertain, with scant research investigating the ability of models like ChatGPT to deliver effective feedback. In this work-in-progress, we evaluate 30 dialogues generated by GPT-4 in a tutor-student setting. We use two different prompting approaches, the zero-shot chain of thought and the few-shot chain of thought, to identify specific components of effective praise based on five criteria. These approaches are then compared to the results of human graders for accuracy. Our goal is to assess the extent to which GPT-4 can accurately identify each praise criterion. We found that both zero-shot and few-shot chain of thought approaches yield comparable results. GPT-4 performs moderately well in identifying instances when the tutor offers specific and immediate praise. However, GPT-4 underperforms in identifying the tutor's ability to deliver sincere praise, particularly in the zero-shot prompting scenario where examples of sincere tutor praise statements were not provided. Future work will focus on enhancing prompt engineering, developing a more general tutoring rubric, and evaluating our method using real-life tutoring dialogues.",
        "paperId": "0b94b999fdd9488e1a0914d37f8fb3ea7e9ea0fd"
    },
    {
        "title": "ChatGPT for Robotics: Design Principles and Model Abilities",
        "firstAuthor": "Sai Vemprala",
        "url": "https://arxiv.org/pdf/2306.17582",
        "dateSubmitted": "2023-02-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics.",
        "paperId": "0ba581718f294db1d7b3dbc159cc3d3380f74606"
    },
    {
        "title": "A Chat About Boring Problems: Studying GPT-based text normalization",
        "firstAuthor": "Yang Zhang",
        "url": "https://arxiv.org/pdf/2309.13426",
        "dateSubmitted": "2023-09-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.",
        "paperId": "0c8446eedfe083e0ee32f5c4f793e5435904014a"
    },
    {
        "title": "Controlled and Conditional Text to Image Generation with Diffusion Prior",
        "firstAuthor": "Pranav Aggarwal",
        "url": "https://arxiv.org/pdf/2302.11710",
        "dateSubmitted": "2023-02-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Denoising Diffusion models have shown remarkable performance in generating diverse, high quality images from text. Numerous techniques have been proposed on top of or in alignment with models like Stable Diffusion and Imagen that generate images directly from text. A lesser explored approach is DALLE-2's two step process comprising a Diffusion Prior that generates a CLIP image embedding from text and a Diffusion Decoder that generates an image from a CLIP image embedding. We explore the capabilities of the Diffusion Prior and the advantages of an intermediate CLIP representation. We observe that Diffusion Prior can be used in a memory and compute efficient way to constrain the generation to a specific domain without altering the larger Diffusion Decoder. Moreover, we show that the Diffusion Prior can be trained with additional conditional information such as color histogram to further control the generation. We show quantitatively and qualitatively that the proposed approaches perform better than prompt engineering for domain specific generation and existing baselines for color conditioned generation. We believe that our observations and results will instigate further research into the diffusion prior and uncover more of its capabilities.",
        "paperId": "0ca0247a2a4ef336da44546ff11b7f48e13ab58c"
    },
    {
        "title": "Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning",
        "firstAuthor": "Louis Castricato",
        "url": "http://arxiv.org/pdf/2210.07792",
        "dateSubmitted": "2022-10-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Controlled automated story generation seeks to generate natural language stories satisfying constraints from natural language critiques or preferences. Existing methods to control for story preference utilize prompt engineering which is labor intensive and often inconsistent. They may also use logit-manipulation methods which require annotated datasets to exist for the desired attributes. To address these issues, we first train a contrastive bi-encoder model to align stories with corresponding human critiques, named CARP, building a general purpose preference model. This is subsequently used as a reward function to fine-tune a generative language model via reinforcement learning. However, simply fine-tuning a generative language model with a contrastive reward model does not always reliably result in a story generation system capable of generating stories that meet user preferences. To increase story generation robustness we further fine-tune the contrastive reward model using a prompt-learning technique. A human participant study is then conducted comparing generations from our full system, ablations, and two baselines. We show that the full fine-tuning pipeline results in a story generator preferred over a LLM 20x as large as well as logit-based methods. This motivates the use of contrastive learning for general purpose human preference modeling.",
        "paperId": "0e1ae0bdcc8469db99a4f8008288e20f285f1c6d"
    },
    {
        "title": "Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset",
        "firstAuthor": "Zhixuan Liu",
        "url": "http://arxiv.org/pdf/2301.12073",
        "dateSubmitted": "2023-01-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "It has been shown that accurate representation in media improves the well-being of the people who consume it. By contrast, inaccurate representations can negatively affect viewers and lead to harmful perceptions of other cultures. To achieve inclusive representation in generated images, we propose a culturally-aware priming approach for text-to-image synthesis using a small but culturally curated dataset that we collected, known here as Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias prevalent in giant datasets. Our proposed approach is comprised of two fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs, and (2) Adding semantic context via automated prompt engineering using the fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware text data. CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture. Our experiments indicate that priming using both text and image is effective in improving the cultural relevance and decreasing the offensiveness of generated images while maintaining quality.",
        "paperId": "0e8e3d2a2f4413808c7aff7bee6e8e11ec2700d7"
    },
    {
        "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
        "firstAuthor": "Liang Chen",
        "url": "https://arxiv.org/pdf/2310.07289",
        "dateSubmitted": "2023-10-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) outperform information retrieval techniques for downstream knowledge-intensive tasks when being prompted to generate world knowledge. However, community concerns abound regarding the factuality and potential implications of using this uncensored knowledge. In light of this, we introduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed to systematically and automatically evaluate generated knowledge from six important perspectives -- Factuality, Relevance, Coherence, Informativeness, Helpfulness and Validity. We conduct an extensive empirical analysis of the generated knowledge from three different types of LLMs on two widely studied knowledge-intensive tasks, i.e., open-domain question answering and knowledge-grounded dialogue. Surprisingly, our study reveals that the factuality of generated knowledge, even if lower, does not significantly hinder downstream tasks. Instead, the relevance and coherence of the outputs are more important than small factual mistakes. Further, we show how to use CONNER to improve knowledge-intensive tasks by designing two strategies: Prompt Engineering and Knowledge Selection. Our evaluation code and LLM-generated knowledge with human annotations will be released to facilitate future research.",
        "paperId": "0f6fe87afd1a3571f77c790893b03717e5d0422a"
    },
    {
        "title": "ChatGPT4PCG Competition: Character-like Level Generation for Science Birds",
        "firstAuthor": "Pittawat Taveekitworachai",
        "url": "http://arxiv.org/pdf/2303.15662",
        "dateSubmitted": "2023-03-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the quality of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. We also allow only a single prompt to be used for generating all the characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of several modified versions of this sample prompt on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.",
        "paperId": "0fb8f3f86476e9ab8fa4679620acb7d525b222a8"
    },
    {
        "title": "ContrastNER: Contrastive-based Prompt Tuning for Few-shot NER",
        "firstAuthor": "Amirhossein Layegh",
        "url": "https://arxiv.org/pdf/2305.17951",
        "dateSubmitted": "2023-05-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt-based language models have produced encouraging results in numerous applications, including Named Entity Recognition (NER) tasks. NER aims to identify entities in a sentence and provide their types. However, the strong performance of most available NER approaches is heavily dependent on the design of discrete prompts and a verbalizer to map the model-predicted outputs to entity categories, which are complicated undertakings. To address these challenges, we present ContrastNER, a prompt-based NER framework that employs both discrete and continuous tokens in prompts and uses a contrastive learning approach to learn the continuous prompts and forecast entity types. The experimental results demonstrate that ContrastNER obtains competitive performance to the state-of-the-art NER methods in high-resource settings and outperforms the state-of-the-art models in low-resource circumstances without requiring extensive manual prompt engineering and verbalizer design.",
        "paperId": "1059b79598d6e08121503093f45d50fa963d2843"
    },
    {
        "title": "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization",
        "firstAuthor": "Puyuan Peng",
        "url": "https://arxiv.org/pdf/2305.11095",
        "dateSubmitted": "2023-05-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper",
        "paperId": "10e8dc07ea256c6a88d7043cf135417402ed38f4"
    },
    {
        "title": "METODOLOG\u00cdA DE EVALUACI\u00d3N CUALITATIVA DE ENSAYOS EN EDUCACI\u00d3N SUPERIOR UTILIZANDO INTELIGENCIA ARTIFICAL (IA): MODELOS LINGUISTICOS AVANZADOS (LLM)",
        "firstAuthor": "Nelly Mel\u00e9ndez G\u00f3mez",
        "url": null,
        "dateSubmitted": "2023-10-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Esta investigaci\u00f3n muestra el uso de varias metodolog\u00edas LLM (Large Language Models) o modelos ling\u00fc\u00edsticos avanzados (MLA), para determinar su potencial utilidad en la evaluaci\u00f3n de ensayos escritos por estudiantes. Los MLA son sistemas de redes neurales artificiales que son programadas con cientos de miles de par\u00e1metros para predecir la siguiente secuencia de caracteres, a partir de un texto usado como entrada en la l\u00ednea de comandos del modelo. La metodolog\u00eda fue experimental, usando \u201cPrompting Engineering\u201d, que pudiera traducirse como: \"Ingenier\u00eda de Est\u00edmulo\" o \"Ingenier\u00eda de Generaci\u00f3n de Instrucciones\" (IGI), en la cual se utiliza una receta para instruir a la Inteligencia artificial (IA) para realizar una serie de pasos a fin de efectuar una tarea o resolver un problema. En la metodolog\u00eda a cada uno de los MLA se le present\u00f3 una plantilla de IGI donde se suministraba un conjunto de instrucciones y el contenido de un ensayo (plantilla sin fuente), a continuaci\u00f3n, se repiti\u00f3 el experimento usando una plantilla m\u00e1s avanzada donde la IGI conten\u00eda en una primera parte el texto seleccionado como parte de la fuente a analizar, y en una segunda parte al contenido del ensayo (planilla con fuente). Los resultados: mostraron que ambas aproximaciones cumpl\u00edan su funci\u00f3n de evaluar los ensayos cualitativamente usando la r\u00fabrica suministrada, pero en la plantilla donde se suministraba la fuente o contenido a analizar, la respuesta suministrada por la MLA fue m\u00e1s precisa y exigente en materia de calidad del ensayo y mayor objetividad en los resultados obtenidos.",
        "paperId": "1194a20a062c952a593283c404bc42f7c4768d09"
    },
    {
        "title": "AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling",
        "firstAuthor": "Pivithuru Thejan Amarasinghe",
        "url": "https://arxiv.org/pdf/2309.13218",
        "dateSubmitted": "2023-09-22",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by fine-tuning a pre-trained LLM for problem formulation. To address token limitations, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. In addition, we design performance evaluation metrics that are more suitable for assessing the accuracy and quality of problem formulations compared to existing evaluation metrics. Experiment results demonstrate that our AI-Copilot can synthesize complex and large problem formulations for a typical business optimisation problem in production scheduling.",
        "paperId": "13fafa40eb7b15813cdf6c2ead1e1032e7b085f0"
    },
    {
        "title": "Co-audit: tools to help humans double-check AI-generated content",
        "firstAuthor": "Andrew D. Gordon",
        "url": "https://arxiv.org/pdf/2310.01297",
        "dateSubmitted": "2023-10-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Users are increasingly being warned to check AI-generated content for correctness. Still, as LLMs (and other generative models) generate more complex output, such as summaries, tables, or code, it becomes harder for the user to audit or evaluate the output for quality or correctness. Hence, we are seeing the emergence of tool-assisted experiences to help the user double-check a piece of AI-generated content. We refer to these as co-audit tools. Co-audit tools complement prompt engineering techniques: one helps the user construct the input prompt, while the other helps them check the output response. As a specific example, this paper describes recent research on co-audit tools for spreadsheet computations powered by generative models. We explain why co-audit experiences are essential for any application of generative AI where quality is important and errors are consequential (as is common in spreadsheet computations). We propose a preliminary list of principles for co-audit, and outline research challenges.",
        "paperId": "14dcafae548d578f6b8c683d0972531bc46423ca"
    },
    {
        "title": "Polyglot Prompt: Multilingual Multitask Prompt Training",
        "firstAuthor": "Jinlan Fu",
        "url": "https://aclanthology.org/2022.emnlp-main.674.pdf",
        "dateSubmitted": "2022-04-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper aims for a potential architectural improvement for multilingual learning and asks: Can different tasks from different languages be modeled in a monolithic framework, i.e. without any task/language-specific module? The benefit of achieving this could open new doors for future multilingual research, including allowing systems trained on low resources to be further assisted by other languages as well as other tasks. We approach this goal by developing a learning framework named Polyglot Prompting to exploit prompting methods for learning a unified semantic space for different languages and tasks with multilingual prompt engineering. We performed a comprehensive evaluation of 6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages. The experimental results demonstrated the efficacy of multilingual multitask prompt-based learning and led to inspiring observations. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and code.",
        "paperId": "15437760a28d528bb1b76794aa4b1d15e7ba2a16"
    },
    {
        "title": "Zero-shot Learning for Named Entity Recognition in Software Specification Documents",
        "firstAuthor": "Souvick Das",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Named entity recognition (NER) is a natural language processing task that has been used in Requirements Engineering for the identification of entities such as actors, actions, operators, resources, events, GUI elements, hardware, APIs, and others. NER might be particularly useful for extracting key information from Software Requirements Specification documents, which provide a blueprint for software development. However, a common challenge in this domain is the lack of annotated data. In this article, we propose and analyze two zero-shot approaches for NER in the requirements engineering domain. These are found to be particularly effective in situations where labeled data is scarce or non-existent. The first approach is a template-based zero-shot learning mechanism that uses the prompt engineering approach and achieves 93% accuracy according to our experimental results. The second solution takes an orthogonal approach by transforming the entity recognition problem into a question-answering task which results in 98% accuracy. Both zero-shot NER approaches introduced in this work perform better than the existing state-of-the-art solutions in the requirements engineering domain.",
        "paperId": "15c4e9d312bbde0f254da487f984a2e37fbbb515"
    },
    {
        "title": "A Taxonomy of Prompt Modifiers for Text-To-Image Generation",
        "firstAuthor": "J. Oppenlaender",
        "url": null,
        "dateSubmitted": "2022-04-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-to-image generation has seen an explosion of interest since 2021. Today, beautiful and intriguing digital images and artworks can be synthesized from textual inputs (\"prompts\") with deep generative models. Online communities around text-to-image generation and AI generated art have quickly emerged. This paper identifies six types of prompt modifiers used by practitioners in the online community based on a 3-month ethnographic study. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practice of text-to-image generation, but may also help practitioners of AI generated art improve their images. We further outline how prompt modifiers are applied in the practice of\"prompt engineering.\"We discuss research opportunities of this novel creative practice in the field of Human-Computer Interaction (HCI). The paper concludes with a discussion of broader implications of prompt engineering from the perspective of Human-AI Interaction (HAI) in future applications beyond the use case of text-to-image generation and AI generated art.",
        "paperId": "1676160139ca59c6728472f34092db69460567a8"
    },
    {
        "title": "ChatGPT as a mapping assistant: A novel method to enrich maps with generative AI and content derived from street-level photographs",
        "firstAuthor": "Levente Juh'asz",
        "url": "https://arxiv.org/pdf/2306.03204",
        "dateSubmitted": "2023-06-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper explores the concept of leveraging generative AI as a mapping assistant for enhancing the efficiency of collaborative mapping. We present results of an experiment that combines multiple sources of volunteered geographic information (VGI) and large language models (LLMs). Three analysts described the content of crowdsourced Mapillary street-level photographs taken along roads in a small test area in Miami, Florida. GPT-3.5-turbo was instructed to suggest the most appropriate tagging for each road in OpenStreetMap (OSM). The study also explores the utilization of BLIP-2, a state-of-the-art multimodal pre-training method as an artificial analyst of street-level photographs in addition to human analysts. Results demonstrate two ways to effectively increase the accuracy of mapping suggestions without modifying the underlying AI models: by (1) providing a more detailed description of source photographs, and (2) combining prompt engineering with additional context (e.g. location and objects detected along a road). The first approach increases the suggestion accuracy by up to 29%, and the second one by up to 20%.",
        "paperId": "16877baf3874038233279e07e330f891455fd880"
    },
    {
        "title": "Using Large Language Models to Generate Engaging Captions for Data Visualizations",
        "firstAuthor": "A. Liew",
        "url": "http://arxiv.org/pdf/2212.14047",
        "dateSubmitted": "2022-12-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Creating compelling captions for data visualizations has been a long- standing challenge. Visualization researchers are typically untrained in journalistic reporting and hence the captions that are placed be- low data visualizations tend to be not overly engaging and rather just stick to basic observations about the data. In this work we explore the opportunities offered by the newly emerging crop of large language models (LLM) which use sophisticated deep learning technology to produce human-like prose. We ask, can these power-ful software devices be purposed to produce engaging captions for generic data visualizations like a scatterplot. It turns out that the key challenge lies in designing the most effective prompt for the LLM, a task called prompt engineering . We report on first experiments using the popular LLM GPT-3 and deliver some promising results.",
        "paperId": "1696e03a35f1bcc724ed9bfe69bb028b789415e8"
    },
    {
        "title": "An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems",
        "firstAuthor": "Andreas Metzger",
        "url": "https://arxiv.org/pdf/2309.14391",
        "dateSubmitted": "2023-09-25",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more efficient explanations. Chat4XAI leverages modern AI chatbot technology and dedicated prompt engineering. Compared to earlier work on natural-language explanations using classical software-based dialogue systems, using an AI chatbot eliminates the need for eliciting and defining potential questions and answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API and evaluate the fidelity and stability of its explanations using an adaptive service exemplar.",
        "paperId": "16acd2d2faa236dfe5f6ab67a0b94a9ed1b1de57"
    },
    {
        "title": "Requirements Engineering using Generative AI: Prompts and Prompting Patterns",
        "firstAuthor": "Krishna Ronanki",
        "url": null,
        "dateSubmitted": "2023-11-07",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "[Context]: Companies are increasingly recognizing the importance of automating Requirements Engineering (RE) tasks due to their resource-intensive nature. The advent of GenAI has made these tasks more amenable to automation, thanks to its ability to understand and interpret context effectively. [Problem]: However, in the context of GenAI, prompt engineering is a critical factor for success. Despite this, we currently lack tools and methods to systematically assess and determine the most effective prompt patterns to employ for a particular RE task. [Method]: Two tasks related to requirements, specifically requirement classification and tracing, were automated using the GPT-3.5 turbo API. The performance evaluation involved assessing various prompts created using 5 prompt patterns and implemented programmatically to perform the selected RE tasks, focusing on metrics such as precision, recall, accuracy, and F-Score. [Results]: This paper evaluates the effectiveness of the 5 prompt patterns' ability to make GPT-3.5 turbo perform the selected RE tasks and offers recommendations on which prompt pattern to use for a specific RE task. Additionally, it also provides an evaluation framework as a reference for researchers and practitioners who want to evaluate different prompt patterns for different RE tasks.",
        "paperId": "1702e7a52a5367e5b5f267ff77e3e67b17d09c3f"
    },
    {
        "title": "Exploring the Path of Compiling TBCL Chinese Digital Teaching Materials with Generative AI\u2014Taking ChatGPT for Example",
        "firstAuthor": "Wu Chi",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study aims to integrate the Generative Artificial Intelligence (GenAI) platform\u2014ChatGPT with the Taiwan Benchmarks for the Chinese Language (TBCL)[14] for digital teaching materials (DTM) composition, proposing a digital teaching material composition model, showcasing the role of GenAI plays in DTM features. At the same, it shows the necessary measures to reduce the effect caused by the hallucination phenomenon[5] on the materials. The research production will be presented by web-based DTM which demonstrates the potential of GenAI in enhancing Chinese DTM composition. By adopting the IDEE framework[9] as foundational principles for designing web-based DTM with ChatGPT and using prompt engineering[11] as the research method, the study explores the strategies for avoiding the effect caused by the hallucination phenomenon in DTM composition with GenAI. It also delves into the potential features that GenAI can play in a web-based DTM. The procedure is as follows: (1) The instructional design is designed based on the Reference Guidelines for TBCL Application(RGTA) [15] and transcript as a unit outline. (2) input the unit outline into ChatGPT through prompt engineering, and generate DTM content based on the unit outline. (3) Using the Teaching Materials Editing Assistance System(TMEAS), the text is examined to ensure the content aligns with the TBCL proficiency level. Beyond assisting in material composition, GenAI can enhance features in web-based DTM as well : (1) utilize the \u201cchat\u201d from ChatGPT for \u201csituational dialogue\u201d and \u201cessay review\u201d by using prompt engineering, and (2) integrating \u201cchat\u201d by using webpage builder's Hyper Text Markup Language (HTML), allowing learners to use \u201ccontinue this chat\u201d feature to replicates the \u201cchat\u201d to their accounts for self-practice. The study presents a web-based DTM, combining the GenAI platform with the RGTA and TMEAS for material composition and interactive features for web-based DTM. We hope to draw attention to the effect caused by GenAI in Chinese language education. The study provides preliminary insights, looking forward to offering a reference direction for the future development of GenAI-assisted Chinese language teaching and web-based DTM composition",
        "paperId": "1796d4726eb1d1daf27951cfffe0f12f3a942c24"
    },
    {
        "title": "Semantic understanding and prompt engineering for large-scale traffic data imputation",
        "firstAuthor": "Kunpeng Zhang",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "17a6cc4441cdd9224dbb549fc51546caba209753"
    },
    {
        "title": "Using ChatGPT with Confidence for Biodiversity-Related Information Tasks",
        "firstAuthor": "Michael Elliott",
        "url": "https://biss.pensoft.net/article/112926/download/pdf/",
        "dateSubmitted": "2023-09-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent advancements in conversational Artificial Intelligence (AI), such as OpenAI's Chat Generative Pre-Trained Transformer (ChatGPT), present the possibility of using large language models (LLMs) as tools for retrieving, analyzing, and transforming scientific information. We have found that ChatGPT (GPT 3.5) can provide accurate biodiversity knowledge in response to questions about species descriptions, occurrences, and taxonomy, as well as structure information according to data sharing standards such as Darwin Core. A rigorous evaluation of ChatGPT's capabilities in biodiversity-related tasks may help to inform viable use cases for today's LLMs in research and information workflows. In this work, we test the extent of ChatGPT's biodiversity knowledge, characterize its mistakes, and suggest how LLM-based systems might be designed to complete knowledge-based tasks with confidence.\n To test ChatGPT's biodiversity knowledge, we compiled a question-and-answer test set derived from Darwin Core records available in Integrated Digitized Biocollections (iDigBio). Each question focuses on one or more Darwin Core terms to test the model\u2019s ability to recall species occurrence information and its understanding of the standard. The test set covers a range of locations, taxonomic groups, and both common and rare species (defined by the number of records in iDigBio). The results of the tests will be presented. We also tested ChatGPT on generative tasks, such as creating species occurrence maps. A visual comparison of the maps with iDigBio data shows that for some species, ChatGPT can generate fairly accurate representationsof their geographic ranges (Fig. 1).\n ChatGPT's incorrect responses in our tests show several patterns of mistakes. First, responses can be self-conflicting. For example, when asked \"Does Acer saccharum naturally occur in Benton, Oregon?\", ChatGPT responded \"YES, Acer saccharum DOES NOT naturally occur in Benton, Oregon\". ChatGPT can also be misled by semantics in species names. For Rafinesquia neomexicana, the word \"neomexicana\" leads ChatGPT to believe that the species primarily occurs in New Mexico, USA. ChatGPT may also confuse species, such as when attempting to describe a lesser-known species (e.g., a rare bee) within the same genus as a better-known species. Other causes of mistakes include hallucination (Ji et al. 2023), memorization (Chang and Bergen 2023), and user deception (Li et al. 2023).\n Some mistakes may be avoided by prompt engineering, e.g., few-shot prompting (Chang and Bergen 2023) and chain-of-thought prompting (Wei et al. 2022). These techniques assist Large Language Models (LLMs) by clarifying expectations or by guiding recollection. However, such methods cannot help when LLMs lack required knowledge. In these cases, alternative approaches are needed.\n A desired reliability can be theoretically guaranteed if responses that contain mistakes are discarded or corrected. This requires either detecting or predicting mistakes. Sometimes mistakes can be ruled out by verifying responses with a trusted source. For example, a trusted specimen record might be found that corroborates the response. The difficulty, however, is finding such records programmatically; e.g., using iDigBio and Global Biodiversity Information Facility's (GBIF) search Application Programming Interfaces (APIs) requires specifying indexed terms that might not appear in an LLM's response. This presents a secondary problem for which LLMs may be well suited. Note that with presence-only data, it can be difficult to disprove presence claims or prove absence claims.\n Besides verification, mistakes may be predicted using probabilistic methods. Formulating mistake probabilities often relies on heuristics. For example, variability in a model\u2019s responses to a repeated query can be a sign of hallucination (Manakul et al. 2023). In practice, both probabilistic and verification methods may be needed to reach a desired reliability. LLM outputs that can be verified may be directly accepted (or discarded), while others are judged by estimating mistake probabilities. We will consider a set of heuristics and verification methods, and report empirical assessments of their impact on ChatGPT\u2019s reliability.",
        "paperId": "17abf939baa953dd69dfaa4c2af5719217102c11"
    },
    {
        "title": "Label Supervised LLaMA Finetuning",
        "firstAuthor": "Zongxi Li",
        "url": "https://arxiv.org/pdf/2310.01208",
        "dateSubmitted": "2023-10-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The recent success of Large Language Models (LLMs) has gained significant attention in both academia and industry. Substantial efforts have been made to enhance the zero- and few-shot generalization capabilities of open-source LLMs through finetuning. Currently, the prevailing approach is instruction-tuning, which trains LLMs to complete real-world tasks by generating responses guided by natural language instructions. It is worth noticing that such an approach may underperform in sequence and token classification tasks. Unlike text generation tasks, classification tasks have a limited label space, where precise label prediction is more appreciated than generating diverse and human-like responses. Prior research has unveiled that instruction-tuned LLMs cannot outperform BERT, prompting us to explore the potential of leveraging latent representations from LLMs for supervised label prediction. In this paper, we introduce a label-supervised adaptation for LLMs, which aims to finetuning the model with discriminant labels. We evaluate this approach with Label Supervised LLaMA (LS-LLaMA), based on LLaMA-2-7B, a relatively small-scale LLM, and can be finetuned on a single GeForce RTX4090 GPU. We extract latent representations from the final LLaMA layer and project them into the label space to compute the cross-entropy loss. The model is finetuned by Low-Rank Adaptation (LoRA) to minimize this loss. Remarkably, without intricate prompt engineering or external knowledge, LS-LLaMA substantially outperforms LLMs ten times its size in scale and demonstrates consistent improvements compared to robust baselines like BERT-Large and RoBERTa-Large in text classification. Moreover, by removing the causal mask from decoders, LS-unLLaMA achieves the state-of-the-art performance in named entity recognition (NER). Our work will shed light on a novel approach to adapting LLMs for various downstream tasks.",
        "paperId": "17ca659a9d0fde83b0e7e21f66593d645b7dcc82"
    },
    {
        "title": "Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and Prompt Engineering",
        "firstAuthor": "Rahman S M Wahidur",
        "url": null,
        "dateSubmitted": "2023-10-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Blockchain technology has revolutionized the financial landscape, with cryptocurrencies gaining widespread adoption for their decentralized and transparent nature. As the sentiment expressed on social media platforms can significantly influence cryptocurrency discussions and market movements, sentiment analysis has emerged as a crucial tool for understanding public opinion and predicting market trends. Motivated by the aim to enhance sentiment analysis accuracy in the cryptocurrency domain, this paper investigates fine-tuning techniques on large language models. This paper also investigates the efficacy of supervised fine-tuning and instruction-based fine-tuning on large language models for unseen tasks. Experimental results demonstrate a significant average zero-shot performance gain of 40% after fine-tuning, highlighting the potential of this technique in optimizing pre-trained language model efficiency. Additionally, the impact of instruction tuning on models of varying scales is examined, revealing that larger models benefit from instruction tuning, achieving the highest average accuracy score of 75.16%. In contrast, smaller-scale models may experience reduced generalization due to the complete utilization of model capacity. To gain deeper insight about how instruction works with these language models, this paper presents an experimental investigation into the response of an instruction-based model under different instruction tuning setups. The investigation demonstrates that the model achieves an average accuracy score of 72.38% for short and simple instructions. This performance significantly outperforms its accuracy under long and complex instructions by over 12%, thereby effectively highlighting the profound significance of instruction characteristics in maximizing model performance.",
        "paperId": "17f2977382b88026be874094a548ecaf0a02acdf"
    },
    {
        "title": "ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations",
        "firstAuthor": "Chunkit Chan",
        "url": "http://arxiv.org/pdf/2304.14827",
        "dateSubmitted": "2023-04-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper aims to quantitatively evaluate the performance of ChatGPT, an interactive large language model, on inter-sentential relations such as temporal relations, causal relations, and discourse relations. Given ChatGPT's promising performance across various tasks, we conduct extensive evaluations on the whole test sets of 13 datasets, including temporal and causal relations, PDTB2.0-based and dialogue-based discourse relations, and downstream applications on discourse understanding. To achieve reliable results, we adopt three tailored prompt templates for each task, including the zero-shot prompt template, zero-shot prompt engineering (PE) template, and in-context learning (ICL) prompt template, to establish the initial baseline scores for all popular sentence-pair relation classification tasks for the first time. We find that ChatGPT exhibits strong performance in detecting and reasoning about causal relations, while it may not be proficient in identifying the temporal order between two events. It can recognize most discourse relations with existing explicit discourse connectives, but the implicit discourse relation still remains a challenging task. Meanwhile, ChatGPT performs poorly in the dialogue discourse parsing task that requires structural understanding in a dialogue before being aware of the discourse relation.",
        "paperId": "186e96fe036927182ec963b63f9dd7f8ff650158"
    },
    {
        "title": "Potential of ChatGPT and GPT-4 for Data Mining of Free-Text CT Reports on Lung Cancer.",
        "firstAuthor": "M. Fink",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Background The latest large language models (LLMs) solve unseen problems via user-defined text prompts without the need for retraining, offering potentially more efficient information extraction from free-text medical records than manual annotation. Purpose To compare the performance of the LLMs ChatGPT and GPT-4 in data mining and labeling oncologic phenotypes from free-text CT reports on lung cancer by using user-defined prompts. Materials and Methods This retrospective study included patients who underwent lung cancer follow-up CT between September 2021 and March 2023. A subset of 25 reports was reserved for prompt engineering to instruct the LLMs in extracting lesion diameters, labeling metastatic disease, and assessing oncologic progression. This output was fed into a rule-based natural language processing pipeline to match ground truth annotations from four radiologists and derive performance metrics. The oncologic reasoning of LLMs was rated on a five-point Likert scale for factual correctness and accuracy. The occurrence of confabulations was recorded. Statistical analyses included Wilcoxon signed rank and McNemar tests. Results On 424 CT reports from 424 patients (mean age, 65 years \u00b1 11 [SD]; 265 male), GPT-4 outperformed ChatGPT in extracting lesion parameters (98.6% vs 84.0%, P < .001), resulting in 96% correctly mined reports (vs 67% for ChatGPT, P < .001). GPT-4 achieved higher accuracy in identification of metastatic disease (98.1% [95% CI: 97.7, 98.5] vs 90.3% [95% CI: 89.4, 91.0]) and higher performance in generating correct labels for oncologic progression (F1 score, 0.96 [95% CI: 0.94, 0.98] vs 0.91 [95% CI: 0.89, 0.94]) (both P < .001). In oncologic reasoning, GPT-4 had higher Likert scale scores for factual correctness (4.3 vs 3.9) and accuracy (4.4 vs 3.3), with a lower rate of confabulation (1.7% vs 13.7%) than ChatGPT (all P < .001). Conclusion When using user-defined prompts, GPT-4 outperformed ChatGPT in extracting oncologic phenotypes from free-text CT reports on lung cancer and demonstrated better oncologic reasoning with fewer confabulations. \u00a9 RSNA, 2023 Supplemental material is available for this article. See also the editorial by Hafezi-Nejad and Trivedi in this issue.",
        "paperId": "19ec24c4f923b3eda61f9aa8ea657bb2105abff6"
    },
    {
        "title": "Augmenting Industrial Chatbots in Energy Systems using ChatGPT Generative AI",
        "firstAuthor": "Gihan Gamage",
        "url": null,
        "dateSubmitted": "2023-06-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Chatbots, the automation of communicative labor, have been widely deployed in industrial applications and systems. Built upon the Generative Pre-trained Transformer 3 (GPT-3), ChatGPT is a Generative Artificial Intelligence (AI) primed to transform all pre-existing chatbot capabilities with human-like conversation skills. It has already disrupted many disciplines including tertiary education and academic research methods, with increasing adoption in simple to complex tasks. However, the augmentation of pre-existing industrial chatbots with generative AI capabilities has not been fully investigated and demonstrated in recent literature. In this paper, we address this gap by presenting the augmentation of a pre-existing chatbot using ChatGPT generative AI capabilities. Our contribution encompasses the ten primary human-like conversation capabilities of ChatGPT, its augmentation of the pre-existing functionalities and the adopted prompt engineering strategies. Each capability is empirically demonstrated on Cooee, a functionally deployed chatbot in the microgrid energy systems of the La Trobe Energy Analytics Platform (LEAP).",
        "paperId": "1a26f9443e5b560ef9baaa3a544e61aaababab96"
    },
    {
        "title": "Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering",
        "firstAuthor": "J. Oppenlaender",
        "url": "http://arxiv.org/pdf/2303.13534",
        "dateSubmitted": "2023-03-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Humankind is entering a novel era of creativity - an era in which anybody can synthesize digital content. The paradigm under which this revolution takes place is prompt-based learning (or in-context learning). This paradigm has found fruitful application in text-to-image generation where it is being used to synthesize digital images from zero-shot text prompts in natural language for the purpose of creating AI art. This activity is referred to as prompt engineering - the practice of iteratively crafting prompts to generate and improve images. In this paper, we investigate prompt engineering as a novel creative skill for creating prompt-based art. In three studies with participants recruited from a crowdsourcing platform, we explore whether untrained participants could 1) recognize the quality of prompts, 2) write prompts, and 3) improve their prompts. Our results indicate that participants could assess the quality of prompts and respective images. This ability increased with the participants' experience and interest in art. Participants further were able to write prompts in rich descriptive language. However, even though participants were specifically instructed to generate artworks, participants' prompts were missing the specific vocabulary needed to apply a certain style to the generated images. Our results suggest that prompt engineering is a learned skill that requires expertise and practice. Based on our findings and experience with running our studies with participants recruited from a crowdsourcing platform, we provide ten recommendations for conducting experimental research on text-to-image generation and prompt engineering with a paid crowd. Our studies offer a deeper understanding of prompt engineering thereby opening up avenues for research on the future of prompt engineering. We conclude by speculating on four possible futures of prompt engineering.",
        "paperId": "1bc9974780230573bfe9f89789115cb4fbf8bfc6"
    },
    {
        "title": "Team Bias Busters at WASSA 2023 Empathy, Emotion and Personality Shared Task: Emotion Detection with Generative Pretrained Transformers",
        "firstAuthor": "Andrew Nedilko",
        "url": "https://aclanthology.org/2023.wassa-1.53.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper describes the approach that we used to take part in the multi-label multi-class emotion classification as Track 3 of the WASSA 2023 Empathy, Emotion and Personality Shared Task at ACL 2023. The overall goal of this track is to build models that can predict 8 classes (7 emotions + neutral) based on short English essays written in response to news article that talked about events perceived as harmful to people. We used OpenAI generative pretrained transformers with full-scale APIs for the emotion prediction task by fine-tuning a GPT-3 model and doing prompt engineering for zero-shot / few-shot learning with ChatGPT and GPT-4 models based on multiple experiments on the dev set. The most efficient method was fine-tuning a GPT-3 model which allowed us to beat our baseline character-based XGBoost Classifier and rank 2nd among all other participants by achieving a macro F1 score of 0.65 and a micro F1 score of 0.7 on the final blind test set.",
        "paperId": "1dab5c672a85f1e7eebd93013a4b49963fedc30c"
    },
    {
        "title": "Argument Mining with Modular BERT and Transfer Learning",
        "firstAuthor": "Umer Mushtaq",
        "url": null,
        "dateSubmitted": "2023-06-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We introduce BERT\u2013MINUS, a modular, feature-enriched and transfer learning enabled model for Argument Mining. BERT\u2013MINUS consists of: 1) a joint module which embeds the paragraph text, and 2) a dedicated module, consisting of three customized BERT models, which contextualize the argument markers, argument components and additional features given as text, respectively. BERT\u2013MINUS implements two kinds of transfer learning \u2013 auto-transfer (transfer from a task to itself) and cross-transfer (classical transfer from one task to another) \u2013 via a novel Selective Fine-tuning mechanism. BERT\u2013MINUS achieves state-of-the-art results on the Link Identification task and competitive results on the Argument Type Classification task. The synergy between the Features as Text and Selective Fine-tuning mechanisms significantly improves the performance of the model. Our work reveals the importance and potential of transfer learning via selective fine-tuning for modular Language Models. Moreover, this study dovetails naturally into the Prompt Engineering paradigm in NLP.",
        "paperId": "1e05a4cac35f146a29248cd017f180e36324dcce"
    },
    {
        "title": "Generative AI tools in art education: Exploring prompt engineering and iterative processes for enhanced creativity",
        "firstAuthor": "Peter Cotroneo",
        "url": null,
        "dateSubmitted": "2023-06-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rapid development and adoption of generative artificial intelligence (AI) tools in the art and design education landscape have introduced both opportunities and challenges. This timely study addresses the need to effectively integrate these tools into the classroom while considering ethical implications and the importance of prompt engineering. By examining the iterative process of refining original ideas through multiple iterations, verbal expansion, and the use of OpenAI\u2019s DALL-E2 for generating diverse visual outcomes, researchers gain insights into the potential benefits and pitfalls of these tools in an educational context. Students in the digital at case study were taught prompt engineering techniques and were tasked with crafting multiple prompts, focusing on refining their ideas over time. Participants demonstrated an increased understanding of the potential and limitations of generative AI tools and how to manipulate subject matter for more effective results. The iterative process encouraged students to explore and experiment with their creative ideas, leading to a deeper understanding of the possibilities offered by AI tools. Despite acknowledging the ethical concerns regarding copyright and the potential replacement of artists, students appreciated the value of generative AI tools for enhancing their sketchbooks and ideation process. Through prompt engineering and iterative processes, students developed a more detail-oriented approach to their work. The challenge of using AI-generated images as final products was conceptually intriguing, requiring further investigation and consideration of the prompts. This study highlights the potential benefits and challenges of integrating generative AI tools into art and design classrooms, emphasizing the importance of prompt engineering, iterative processes, and ethical considerations as these technologies continue to evolve.",
        "paperId": "1e39f3ca4aff09dccc3b951cdd355c7d8e7cbc2f"
    },
    {
        "title": "Solving and Generating NPR Sunday Puzzles with Large Language Models",
        "firstAuthor": "Jin Zhao",
        "url": "http://arxiv.org/pdf/2306.12255",
        "dateSubmitted": "2023-06-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We explore the ability of large language models to solve and generate puzzles from the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15 years of on-air puzzles. We evaluate four large language models using PUZZLEQA, in both multiple choice and free response formats, and explore two prompt engineering techniques to improve free response performance: chain-of-thought reasoning and prompt summarization. We find that state-of-the-art large language models can solve many PUZZLEQA puzzles: the best model, GPT-3.5, achieves 50.2% loose accuracy. However, in our few-shot puzzle generation experiment, we find no evidence that models can generate puzzles: GPT-3.5 generates puzzles with answers that do not conform to the generated rules. Puzzle generation remains a challenging task for future work.",
        "paperId": "1e5743366625128e225879dbcfb568f6b8f1bcdc"
    },
    {
        "title": "Vibration syndrome in chipping and grinding workers.",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "A clear conclusion from these studies is that vibration syndrome occurs in chipping and grinding workers in this country and that earlier reports that it may not exist were probably inaccurate. The careful selection of exposed and control groups for analysis strengthens the observed association between vibration syndrome and the occupational use of pneumatic chipping hammers and grinding tools. In the foundry populations studied the vibration syndrome was severe, with short latencies and high prevalences of the advanced stages. The shipyard population did not display this pattern. This difference can be attributed to variations in work practices but the more important factor seems to be the effect of incentive work schedules. Comparisons of groups of hourly and incentive workers from the shipyard and within foundry populations consistently demonstrated that incentive work was associated with increased severity of vibration syndrome. Excessive vibration levels were measured on chipping and grinding tools. Of the factors studied, reduction of throttle level decreased the vibration levels measured on chipping hammers. For grinders, the working condition of the tool affected the measured vibration acceleration levels. Grinders receiving average to poor maintenance showed higher vibration levels. The results of objective clinical testing did not yield tests with diagnostic properties. To date, the clinical judgment of the physician remains the primary focus of the diagnosis of vibration syndrome. A number of actions can be taken to prevent vibration syndrome. Preplacement medical examinations can identify workers predisposed to or experiencing Raynaud's phenomenon or disease. Informing employees and employers about the signs, symptoms, and consequences of vibration syndrome can encourage workers to report the condition to their physicians promptly. Engineering approaches to preventing vibration syndrome include increased quality control on castings to reduce finishing time and automation of the finishing process. Tool manufacturers can contribute by modifying or redesigning tools to reduce vibration. The technology to reduce vibration from hand tools exists but the engineering application is difficult. Vibration from chain saws has been reduced through changes in design and some companies have begun to redesign jackhammers, scalers, grinders, and chipping hammers. As these become available, purchasers can encourage manufacturers by selecting tools with antivibration characteristics. Vibration from tools currently in use can be controlled by periodically scheduled inspection and maintenance programs for vibrating tools.(ABSTRACT TRUNCATED AT 400 WORDS)",
        "paperId": "1e9177ef6144e24c391adac09789b73a8eda096f"
    },
    {
        "title": "ZWI\u0118KSZANIE POTENCJA\u0141U SZTUCZNEJ INTELIGENCJI GENERATYWNEJ DZI\u0118KI PROMPT ENGINEERING",
        "firstAuthor": "M. Bistro\u0144",
        "url": null,
        "dateSubmitted": "2023-08-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "1ed716c467901ee1fa51fd3ead63ec48f0e36c70"
    },
    {
        "title": "TEAM BIAS BUSTERS@LT-EDI-2023: Detecting Signs of Depression with Generative Pretrained Transformers",
        "firstAuthor": "Andrew Nedilko",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper describes our methodology adopted to participate in the multi-class classification task under the auspices of the Third Workshop on Language Technology for Equality, Diversity, Inclusion (LT-EDI) in the Recent Advances in Natural Language Processing (RANLP) 2023 conference. The overall objective was to employ ML algorithms to detect signs of depression in English social media content, classifying each post into one of three categories: no depression, moderate depression, and severe depression. To accomplish this we utilized generative pretrained transformers (GPTs), leveraging the full-scale OpenAI API. Our strategy incorporated prompt engineering for zero-shot and few-shot learning scenarios with ChatGPT and fine-tuning a GPT-3 model. The latter approach yielded the best results which allowed us to outperform our benchmark XGBoost classifier based on character-level features on the dev set and score a macro F1 score of 0.419 on the final blind test set.",
        "paperId": "1f965c3440ef1d2a2ed60925b2554efdc08662bc"
    },
    {
        "title": "Improve Performance of Fine-tuning Language Models with Prompting",
        "firstAuthor": "No\u00e9mi Ligeti-Nagy",
        "url": "https://www.infocommunications.hu/documents/169298/4882687/InfocomJournal_2023_SpecISS_ICAI_10.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper explores the effectiveness of prompt programming in the fine-tuning process of a Hungarian language model. The study builds on the prior success of prompt engineering in natural language processing tasks and employs the prompting method to enhance the fine-tuning performance of a huBERT model on several benchmark datasets of HuLU. The experimentation involves testing 45 prompt combinations for the HuCoPA dataset and 15 prompt variations for the HuRTE and HuWNLI datasets. The findings reveal that the addition of an instructional text consistently produces the best results across all winning cases, and that the [CLS] token produces the best results in the separator token experiments. The most significant enhancement was observed in the HuWNLI dataset, with an increase in accuracy from 65% to 85%. These results demon- strate that the addition of instruct text is crucial and sufficient in enabling the language model to effectively interpret and solve the Winograd Schemata problem. These results showcase the potential of prompt programming in enhancing the performance of language models in fine-tuning tasks, and highlight the importance of incorporating task-specific instructions to improve model interpretability and accuracy.",
        "paperId": "1fa49437707e703349f9335208cbede42166082e"
    },
    {
        "title": "Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation",
        "firstAuthor": "Dawei Gao",
        "url": "https://arxiv.org/pdf/2308.15363",
        "dateSubmitted": "2023-08-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. To explore the potential of open-source LLM, we investigate them in various scenarios, and further enhance their performance with supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the supervised fine-tuning. Additionally, towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspires further investigations and broad applications.",
        "paperId": "1fc89ce338b94f6a46e41b9a13aa99366a762eea"
    },
    {
        "title": "BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis",
        "firstAuthor": "Tingfeng Cao",
        "url": null,
        "dateSubmitted": "2023-11-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recently, diffusion-based deep generative models (e.g., Stable Diffusion) have shown impressive results in text-to-image synthesis. However, current text-to-image models often require multiple passes of prompt engineering by humans in order to produce satisfactory results for real-world applications. We propose BeautifulPrompt, a deep generative model to produce high-quality prompts from very simple raw descriptions, which enables diffusion-based models to generate more beautiful images. In our work, we first fine-tuned the BeautifulPrompt model over low-quality and high-quality collecting prompt pairs. Then, to ensure that our generated prompts can generate more beautiful images, we further propose a Reinforcement Learning with Visual AI Feedback technique to fine-tune our model to maximize the reward values of the generated prompts, where the reward values are calculated based on the PickScore and the Aesthetic Scores. Our results demonstrate that learning from visual AI feedback promises the potential to improve the quality of generated prompts and images significantly. We further showcase the integration of BeautifulPrompt to a cloud-native AI platform to provide better text-to-image generation service in the cloud.",
        "paperId": "20487deedce041069721992efc574d84837c8106"
    },
    {
        "title": "Large Language Model-Empowered Agents for Simulating Macroeconomic Activities",
        "firstAuthor": "Nian Li",
        "url": null,
        "dateSubmitted": "2023-10-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The advent of the Web has brought about a paradigm shift in traditional economics, particularly in the digital economy era, enabling the precise recording and analysis of individual economic behavior. This has led to a growing emphasis on data-driven modeling in macroeconomics. In macroeconomic research, Agent-based modeling (ABM) emerged as an alternative, evolving through rule-based agents, machine learning-enhanced decision-making, and, more recently, advanced AI agents. However, the existing works are suffering from three main challenges when endowing agents with human-like decision-making, including agent heterogeneity, the influence of macroeconomic trends, and multifaceted economic factors. Large language models (LLMs) have recently gained prominence in offering autonomous human-like characteristics. Therefore, leveraging LLMs in macroeconomic simulation presents an opportunity to overcome traditional limitations. In this work, we take an early step in introducing a novel approach that leverages LLMs in macroeconomic simulation. We design prompt-engineering-driven LLM agents to exhibit human-like decision-making and adaptability in the economic environment, with the abilities of perception, reflection, and decision-making to address the abovementioned challenges. Simulation experiments on macroeconomic activities show that LLM-empowered agents can make realistic work and consumption decisions and emerge more reasonable macroeconomic phenomena than existing rule-based or AI agents. Our work demonstrates the promising potential to simulate macroeconomics based on LLM and its human-like characteristics.",
        "paperId": "208b93a39802466785169494caa7f2a8995ea39f"
    },
    {
        "title": "The impact of prompt engineering in large language model performance: a psychiatric example",
        "firstAuthor": "D. Grabb",
        "url": null,
        "dateSubmitted": "2023-10-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "20aa1ceae2832216a5ff0bd6307d864a184ee23b"
    },
    {
        "title": "Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa",
        "firstAuthor": "Shriyash Upadhyay",
        "url": "https://arxiv.org/pdf/2307.10633",
        "dateSubmitted": "2023-07-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models have many methods for solving the same problem. This introduces novel strengths (different methods may work well for different problems) and weaknesses (it may be difficult for users to know which method to use). In this paper, we introduce Multi-Method Self-Training (MMST), where one method is trained on the filtered outputs of another, allowing us to augment the strengths and ameliorate the weaknesses of each method. Using a 176B parameter model trained on both language and code, we show that MMST can 1) improve the less performant method (up to 30%) making the model easier to use, 2) improve the more performant method (up to 32.2%) making the model more performant, and 3) improve the performance of related but distinct tasks (up to 10.3%) by improving the ability of the model to generate rationales. We then conduct ablation analyses to explore why MMST works. We show that MMST generates more data than traditional self-training, but the improvement in performance is driven by the use of multiple methods. We also analyze prompt-engineering and anti-correlated performance between methods as means of making MMST more effective. We hope the evidence from our paper motivates machine learning researchers to explore ways in which advances in language models allow for new forms of training.",
        "paperId": "20d448a8712238ea34d9a18287e3bf05bc61dd2c"
    },
    {
        "title": "Unsupervised Human Activity Recognition through Two-stage Prompting with ChatGPT",
        "firstAuthor": "Qingxin Xia",
        "url": "http://arxiv.org/pdf/2306.02140",
        "dateSubmitted": "2023-06-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Wearable sensor devices, which offer the advantage of recording daily objects used by a person while performing an activity, enable the feasibility of unsupervised Human Activity Recognition (HAR). Unfortunately, previous unsupervised approaches using the usage sequence of objects usually require a proper description of activities manually prepared by humans. Instead, we leverage the knowledge embedded in a Large Language Model (LLM) of ChatGPT. Because the sequence of objects robustly characterizes the activity identity, it is possible that ChatGPT already learned the association between activities and objects from existing contexts. However, previous prompt engineering for ChatGPT exhibits limited generalization ability when dealing with a list of words (i.e., sequence of objects) due to the similar weighting assigned to each word in the list. In this study, we propose a two-stage prompt engineering, which first guides ChatGPT to generate activity descriptions associated with objects while emphasizing important objects for distinguishing similar activities; then outputs activity classes and explanations for enhancing the contexts that are helpful for HAR. To the best of our knowledge, this is the first study that utilizes ChatGPT to recognize activities using objects in an unsupervised manner. We conducted our approach on three datasets and demonstrated the state-of-the-art performance.",
        "paperId": "20db2ac68c0a0daa8417696cced923e518c07681"
    },
    {
        "title": "S3: Social-network Simulation System with Large Language Model-Empowered Agents",
        "firstAuthor": "Chen Gao",
        "url": "https://arxiv.org/pdf/2307.14984",
        "dateSubmitted": "2023-07-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Social network simulation plays a crucial role in addressing various challenges within social science. It offers extensive applications such as state prediction, phenomena explanation, and policy-making support, among others. In this work, we harness the formidable human-like capabilities exhibited by large language models (LLMs) in sensing, reasoning, and behaving, and utilize these qualities to construct the S$^3$ system (short for $\\textbf{S}$ocial network $\\textbf{S}$imulation $\\textbf{S}$ystem). Adhering to the widely employed agent-based simulation paradigm, we employ prompt engineering and prompt tuning techniques to ensure that the agent's behavior closely emulates that of a genuine human within the social network. Specifically, we simulate three pivotal aspects: emotion, attitude, and interaction behaviors. By endowing the agent in the system with the ability to perceive the informational environment and emulate human actions, we observe the emergence of population-level phenomena, including the propagation of information, attitudes, and emotions. We conduct an evaluation encompassing two levels of simulation, employing real-world social network data. Encouragingly, the results demonstrate promising accuracy. This work represents an initial step in the realm of social network simulation empowered by LLM-based agents. We anticipate that our endeavors will serve as a source of inspiration for the development of simulation systems within, but not limited to, social science.",
        "paperId": "221a72a3631ebf8b555c27bc864338390611feb1"
    },
    {
        "title": "The c4h, tat, hppr and hppd Genes Prompted Engineering of Rosmarinic Acid Biosynthetic Pathway in Salvia miltiorrhiza Hairy Root Cultures",
        "firstAuthor": "Ying Xiao",
        "url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0029713&type=printable",
        "dateSubmitted": "2011-12-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Rational engineering to produce biologically active plant compounds has been greatly impeded by our poor understanding of the regulatory and metabolic pathways underlying the biosynthesis of these compounds. Here we capitalized on our previously described gene-to-metabolite network in order to engineer rosmarinic acid (RA) biosynthesis pathway for the production of beneficial RA and lithospermic acid B (LAB) in Salvia miltiorrhiza hairy root cultures. Results showed their production was greatly elevated by (1) overexpression of single gene, including cinnamic acid 4-hydroxylase (c4h), tyrosine aminotransferase (tat), and 4-hydroxyphenylpyruvate reductase (hppr), (2) overexpression of both tat and hppr, and (3) suppression of 4-hydroxyphenylpyruvate dioxygenase (hppd). Co-expression of tat/hppr produced the most abundant RA (906 mg/liter) and LAB (992 mg/liter), which were 4.3 and 3.2-fold more than in their wild-type (wt) counterparts respectively. And the value of RA concentration was also higher than that reported before, that produced by means of nutrient medium optimization or elicitor treatment. It is the first report of boosting RA and LAB biosynthesis through genetic manipulation, providing an effective approach for their large-scale commercial production by using hairy root culture systems as bioreactors.",
        "paperId": "221e801f9a39ff055773b2a20d91e3efadbea921"
    },
    {
        "title": "Plain Template Insertion: Korean-Prompt-Based Engineering for Few-Shot Learners",
        "firstAuthor": "Jaehyung Seo",
        "url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09913979.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt-based learning is a method used for language models to interpret natural language by remembering the prior knowledge acquired and the training objective. Recent prompt-based few-shot learners have achieved superior performance by alleviating the catastrophic forgetting that occurs in pretrained language models. Few-shot learning contributes towards solving the data scarcity problem, an enormous challenge in AI systems and a significant consideration in natural language processing research. In spite of the significance of few-shot learning, research on Korean language-based few-shot learning is insufficient, and whether the prompt-based approach is appropriate for the Korean language has not been thoroughly verified. As a step toward realizing a Korean-prompt-based few-shot learner, we attempt to apply prompt engineering to the Korean language understanding benchmark dataset and introduce plain template insertion to overcome data scarcity in a more practical few-shot setting. The contributions of this study are as follows: (1) presumably, this is the first study to apply prompt-based few-shot learning to Korean benchmark datasets. With 32 few-shot settings, it improves performance by +14.88, +29.04, and +1.81 in the natural language inference, semantic textual similarity, and topic classification tasks. (2) We present prompt engineering, which merely inserts a plain template and increases data efficiency without training example selection, augmentation, reformulation, and retrieval. (3) Our approach is robust to the Korean prompt\u2019s contextual information and sentence structure and is applicable to both hard- and soft-prompt.",
        "paperId": "228feaf502368e8a522a0d7897bec537101b2b98"
    },
    {
        "title": "Prompting meaning: a hermeneutic approach to optimising prompt engineering with ChatGPT",
        "firstAuthor": "Leah Henrickson",
        "url": "https://link.springer.com/content/pdf/10.1007/s00146-023-01752-8.pdf",
        "dateSubmitted": "2023-09-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "22e5d6ad9c1c5376015be844521542a2eacc15b1"
    },
    {
        "title": "Towards Multimodal Computational Humanities. Using CLIP to Analyze Late-Nineteenth Century Magic Lantern Slides",
        "firstAuthor": "T. Smits",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The introduction of the CLIP model signaled a breakthrough in multimodal deep learning. This paper examines whether CLIP can be fruitfully applied to a (binary) classification task in the Humanities. We focus on a historical collection of late-nineteenth century magic lantern slides from the Lucerna database. Based on the available metadata, we evaluate CLIP\u2019s performance on classifying slide images into \u2018exterior\u2019 and \u2018interior\u2019 categories. We compare the performance of several textual prompts for CLIP to two conventional mono-modal models (textual and visual) which we train and evaluate on the same stratified set of 5,244 magic lantern slides and their captions. We find that the textual and multimodal models achieve a respectable performance (\u223c0.80 accuracy) but are still outperformed by a vision model that was fine-tuned to the task (\u223c0.89). We flag three methodological issues that might arise from the application of CLIP in the (computational) humanities. First, the lack of (need for) labelled data makes it hard to inspect and/or interpret the performance of the model. Second, CLIP\u2019s zero-shot capability only allows for classification tasks to be simulated, which makes it doubtful if standard metrics can be used to compare its performance to text and/or image models. Third, the lack of effective prompt engineering techniques makes the performance of CLIP (highly) unstable.",
        "paperId": "2416687fad3ff0344201b76b7015579d24ddf712"
    },
    {
        "title": "Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4",
        "firstAuthor": "Jiaxian Guo",
        "url": "https://arxiv.org/pdf/2309.17277",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce \\textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a planning strategy that enables GPT-4 to competently play against different opponents, adapting its gameplay style as needed, while requiring only the game rules and descriptions of observations as input. In the experiments, we qualitatively showcase the capabilities of Suspicion-Agent across three different imperfect information games and then quantitatively evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can potentially outperform traditional algorithms designed for imperfect information games, without any specialized training or examples. In order to encourage and foster deeper insights within the community, we make our game-related data publicly available.",
        "paperId": "25ec4e51e515548cb55e0270f449ac55f3b0840c"
    },
    {
        "title": "Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering",
        "firstAuthor": "Krishna Kumar",
        "url": "http://arxiv.org/pdf/2304.02138",
        "dateSubmitted": "2023-04-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The widespread adoption of large language models (LLMs), such as OpenAI's ChatGPT, could revolutionize various industries, including geotechnical engineering. However, GPT models can sometimes generate plausible-sounding but false outputs, leading to hallucinations. In this article, we discuss the importance of prompt engineering in mitigating these risks and harnessing the full potential of GPT for geotechnical applications. We explore the challenges and pitfalls associated with LLMs and highlight the role of context in ensuring accurate and valuable responses. Furthermore, we examine the development of context-specific search engines and the potential of LLMs to become a natural interface for complex tasks, such as data analysis and design. We also develop a unified interface using natural language to handle complex geotechnical engineering tasks and data analysis. By integrating GPT into geotechnical engineering workflows, professionals can streamline their work and develop sustainable and resilient infrastructure systems for the future.",
        "paperId": "26f560e592419891c9de1b25d0e4d4d16014d54e"
    },
    {
        "title": "Toward Reproducing Network Research Results Using Large Language Models",
        "firstAuthor": "Qiao Xiang",
        "url": "https://arxiv.org/pdf/2309.04716",
        "dateSubmitted": "2023-09-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.",
        "paperId": "279c798fd53c8dc84044273d08b6a060dbe9f702"
    },
    {
        "title": "Inducing anxiety in large language models increases exploration and bias",
        "firstAuthor": "Julian Coda-Forno",
        "url": "http://arxiv.org/pdf/2304.11111",
        "dateSubmitted": "2023-04-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a strong increase in biases when prompted with anxiety-inducing text. Thus, it is likely that how prompts are communicated to large language models has a strong influence on their behavior in applied settings. These results progress our understanding of prompt engineering and demonstrate the usefulness of methods taken from computational psychiatry for studying the capable algorithms to which we increasingly delegate authority and autonomy.",
        "paperId": "27c16cca907aa43397cc226a182b73b396c5cf66"
    },
    {
        "title": "Can ChatGPT Understand Causal Language in Science Claims?",
        "firstAuthor": "Yuheun Kim",
        "url": "https://aclanthology.org/2023.wassa-1.33.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study evaluated ChatGPT\u2019s ability to understand causal language in science papers and news by testing its accuracy in a task of labeling the strength of a claim as causal, conditional causal, correlational, or no relationship. The results show that ChatGPT is still behind the existing fine-tuned BERT models by a large margin. ChatGPT also had difficulty understanding conditional causal claims mitigated by hedges. However, its weakness may be utilized to improve the clarity of human annotation guideline. Chain-of-Thoughts were faithful and helpful for improving prompt performance, but finding the optimal prompt is difficult with inconsistent results and the lack of effective method to establish cause-effect between prompts and outcomes, suggesting caution when generalizing prompt engineering results across tasks or models.",
        "paperId": "27d80545d142ced9b921290b5b2798cabd55468b"
    },
    {
        "title": "Embracing AI for better quality engineering",
        "firstAuthor": "",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Infosys has already progressed towards this with an AI-first quality engineering framework leveraging traditional and generative AI techniques, large language models (LLMs) trained for specific QE tasks using Infosys test case repository, prompt engineering for testing use cases etc. With its unmatched ability to automate even unsolved testing tasks, analyse patterns and anomalies, detect performance issues early, and produce smart insights, AI will set the benchmarks in quality engineering.",
        "paperId": "27e225be3e00d56e22f6c468ba1a5e863f341d55"
    },
    {
        "title": "IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models",
        "firstAuthor": "Hu Ye",
        "url": "https://arxiv.org/pdf/2308.06721",
        "dateSubmitted": "2023-08-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent years have witnessed the strong power of large text-to-image diffusion models for the impressive generative capability to create high-fidelity images. However, it is very tricky to generate desired images using only text prompt as it often involves complex prompt engineering. An alternative to text prompt is image prompt, as the saying goes:\"an image is worth a thousand words\". Although existing methods of direct fine-tuning from pretrained models are effective, they require large computing resources and are not compatible with other base models, text prompt, and structural controls. In this paper, we present IP-Adapter, an effective and lightweight adapter to achieve image prompt capability for the pretrained text-to-image diffusion models. The key design of our IP-Adapter is decoupled cross-attention mechanism that separates cross-attention layers for text features and image features. Despite the simplicity of our method, an IP-Adapter with only 22M parameters can achieve comparable or even better performance to a fully fine-tuned image prompt model. As we freeze the pretrained diffusion model, the proposed IP-Adapter can be generalized not only to other custom models fine-tuned from the same base model, but also to controllable generation using existing controllable tools. With the benefit of the decoupled cross-attention strategy, the image prompt can also work well with the text prompt to achieve multimodal image generation. The project page is available at \\url{https://ip-adapter.github.io}.",
        "paperId": "2854e5bab8e6f36e54c64456628a9559bf67019e"
    },
    {
        "title": "Picture This: AI-Assisted Image Generation as a Resource for Problem Construction in Creative Problem-Solving",
        "firstAuthor": "J. Rafner",
        "url": null,
        "dateSubmitted": "2023-06-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this paper, we explore the potential of AI-assisted visualization during the problem identification and construction phase of the creative problem-solving process. We examine this within the context of the ongoing crea.visions research project, which employs AI technologies to visualize citizens' visions of the future. Our findings underscore various factors contributing to the effectiveness of assisted visualization in this setting, such as: 1) the tool's dual role as both a visual and ideational aid, 2) the introduction of innovative collaborative elements like prompt engineering, 3) the enhancement of visual expression without requiring artistic skills, and 4) the facilitation of idea communication. We also recognize limitations related to the tool and the problem context such as abstract concepts. This study serves as a foundation for future research on AI-assisted image generation as a resource in creative problem-solving, laying the groundwork for the creation of increasingly effective and user-friendly tools.",
        "paperId": "28dfdaa9647f1acd286d9d93f41a0397d807c13e"
    },
    {
        "title": "Conceptual Design Generation Using Large Language Models",
        "firstAuthor": "Kevin Ma",
        "url": "http://arxiv.org/pdf/2306.01779",
        "dateSubmitted": "2023-05-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Concept generation is a creative step in the conceptual design phase, where designers often turn to brainstorming, mindmapping, or crowdsourcing design ideas to complement their own knowledge of the domain. Recent advances in natural language processing (NLP) and machine learning (ML) have led to the rise of Large Language Models (LLMs) capable of generating seemingly creative outputs from textual prompts. The success of these models has led to their integration and application across a variety of domains, including art, entertainment, and other creative work. In this paper, we leverage LLMs to generate solutions for a set of 12 design problems and compare them to a baseline of crowdsourced solutions. We evaluate the differences between generated and crowdsourced design solutions through multiple perspectives, including human expert evaluations and computational metrics. Expert evaluations indicate that the LLM-generated solutions have higher average feasibility and usefulness while the crowdsourced solutions have more novelty. We experiment with prompt engineering and find that leveraging few-shot learning can lead to the generation of solutions that are more similar to the crowdsourced solutions. These findings provide insight into the quality of design solutions generated with LLMs and begins to evaluate prompt engineering techniques that could be leveraged by practitioners to generate higher-quality design solutions synergistically with LLMs.",
        "paperId": "29203f0b8b9be7fd70d99bf7390c6a78b68a9289"
    },
    {
        "title": "Digital Commons@Lindenwood University Digital Commons@Lindenwood University",
        "firstAuthor": "James Hutson",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The integration of generative artificial intelligence (AI) tools in art and design has disrupted the traditional creative landscape, leading to debates on the legitimacy of AI-generated art and the emergence of new markets such as non-fungible tokens (NFTs). The US Copyright Office\u2019s February 21, 2023, ruling withdrawing copyright protection for AI-generated comic artwork, while protecting the accompanying text and arrangement, highlights the contested nature of AI art and suggests that significant human intervention in the creative process will be required for monetization. Whether considered content interpolation or content creation, AI generative content for the creation of art and design is here with human-AI collaboration. To explore the potential of AI tools in creative practice, this study introduced students in a digital art course to Craiyon and Midjourney generative AI tools, with DALL-E 2 selected as the primary tool due to its varied output. The students were tasked with selecting a preferred prompt from one tool and then reproducing the output from both tools. The results revealed significant variations in replicating the outputs of different AI tools and limited exploration of prompt engineering, leading to restrictions in the iterative process of artmaking. The students agreed that generative AI tools are not a substitute for human creativity and should be used for final projects. The study demonstrates the potential and limitations of integrating AI tools in art and design and suggests the need for further research in developing effective prompt engineering strategies.",
        "paperId": "2aae79fc8b9121b7e347b185b0929f107e81e223"
    },
    {
        "title": "Fixing Hardware Security Bugs with Large Language Models",
        "firstAuthor": "Baleegh Ahmad",
        "url": "http://arxiv.org/pdf/2302.01215",
        "dateSubmitted": "2023-02-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work we consider how LLMs maybe leveraged to automatically repair security relevant bugs present in hardware designs. We focus on bug repair in code written in the Hardware Description Language Verilog. For this study we build a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all ten of our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware bug repair tool on its own suite of bugs. These results show that LLMs can repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair framework.",
        "paperId": "2af6a21a1b682ceb585165359d3605e89f4cf6b0"
    },
    {
        "title": "Toxicity Detection with Generative Prompt-based Inference",
        "firstAuthor": "Yau-Shian Wang",
        "url": "https://arxiv.org/pdf/2205.12390",
        "dateSubmitted": "2022-05-24",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Due to the subtleness, implicity, and different possible interpretations perceived by different people, detecting undesirable content from text is a nuanced difficulty. It is a long-known risk that language models (LMs), once trained on corpus containing undesirable content, have the power to manifest biases and toxicity. However, recent studies imply that, as a remedy, LMs are also capable of identifying toxic content without additional fine-tuning. Prompt-methods have been shown to effectively harvest this surprising self-diagnosing capability. However, existing prompt-based methods usually specify an instruction to a language model in a discriminative way. In this work, we explore the generative variant of zero-shot prompt-based toxicity detection with comprehensive trials on prompt engineering. We evaluate on three datasets with toxicity labels annotated on social media posts. Our analysis highlights the strengths of our generative classification approach both quantitatively and qualitatively. Interesting aspects of self-diagnosis and its ethical implications are discussed.",
        "paperId": "2afb07359e9c67499e1f373ac6f1520d3ea9c46a"
    },
    {
        "title": "What does CLIP know about a red circle? Visual prompt engineering for VLMs",
        "firstAuthor": "Aleksandar Shtedritski",
        "url": "https://arxiv.org/pdf/2304.06712",
        "dateSubmitted": "2023-04-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large-scale Vision-Language Models, such as CLIP, learn powerful image-text representations that have found numerous applications, from zero-shot classification to text-to-image generation. Despite that, their capabilities for solving novel discriminative tasks via prompting fall behind those of large language models, such as GPT-3. Here we explore the idea of visual prompt engineering for solving computer vision tasks beyond classification by editing in image space instead of text. In particular, we discover an emergent ability of CLIP, where, by simply drawing a red circle around an object, we can direct the model's attention to that region, while also maintaining global information. We show the power of this simple approach by achieving state-of-the-art in zero-shot referring expressions comprehension and strong performance in keypoint localization tasks. Finally, we draw attention to some potential ethical concerns of large language-vision models.",
        "paperId": "2ba2a875161b6f09815817542f02f1ac9171952a"
    },
    {
        "title": "Exploring EFL students' prompt engineering in human-AI story writing: an Activity Theory perspective",
        "firstAuthor": "D. Woo",
        "url": "http://arxiv.org/pdf/2306.01798",
        "dateSubmitted": "2023-06-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study applies Activity Theory to investigate how English as a foreign language (EFL) students prompt generative artificial intelligence (AI) tools during short story writing. Sixty-seven Hong Kong secondary school students created generative-AI tools using open-source language models and wrote short stories with them. The study collected and analyzed the students' generative-AI tools, short stories, and written reflections on their conditions or purposes for prompting. The research identified three main themes regarding the purposes for which students prompt generative-AI tools during short story writing: a lack of awareness of purposes, overcoming writer's block, and developing, expanding, and improving the story. The study also identified common characteristics of students' activity systems, including the sophistication of their generative-AI tools, the quality of their stories, and their school's overall academic achievement level, for their prompting of generative-AI tools for the three purposes during short story writing. The study's findings suggest that teachers should be aware of students' purposes for prompting generative-AI tools to provide tailored instructions and scaffolded guidance. The findings may also help designers provide differentiated instructions for users at various levels of story development when using a generative-AI tool.",
        "paperId": "2bb34cfe22d0d46394dd91ba8934e525563e1274"
    },
    {
        "title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder",
        "firstAuthor": "Anh Pham Thi Minh",
        "url": "https://arxiv.org/pdf/2309.07760",
        "dateSubmitted": "2023-09-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large pre-trained vision-language models such as CLIP have demonstrated great potential in zero-shot transferability to downstream tasks. However, to attain optimal performance, the manual selection of prompts is necessary to improve alignment between the downstream image distribution and the textual class descriptions. This manual prompt engineering is the major challenge for deploying such models in practice since it requires domain expertise and is extremely time-consuming. To avoid non-trivial prompt engineering, recent work Context Optimization (CoOp) introduced the concept of prompt learning to the vision domain using learnable textual tokens. While CoOp can achieve substantial improvements over manual prompts, its learned context is worse generalizable to wider unseen classes within the same dataset. In this work, we present Prompt Learning with Reparameterization Encoder (PRE) - a simple and efficient method that enhances the generalization ability of the learnable prompt to unseen classes while maintaining the capacity to learn Base classes. Instead of directly optimizing the prompts, PRE employs a prompt encoder to reparameterize the input prompt embeddings, enhancing the exploration of task-specific knowledge from few-shot samples. Experiments and extensive ablation studies on 8 benchmarks demonstrate that our approach is an efficient method for prompt learning. Specifically, PRE achieves a notable enhancement of 5.60% in average accuracy on New classes and 3% in Harmonic mean compared to CoOp in the 16-shot setting, all achieved within a good training time.",
        "paperId": "2c66f49e328ca5815c13dda106abc2c326d4f28b"
    },
    {
        "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models",
        "firstAuthor": "Fobo Shi",
        "url": "http://arxiv.org/pdf/2306.03799",
        "dateSubmitted": "2023-06-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt engineering is an essential technique for enhancing the abilities of large language models (LLMs) by providing explicit and specific instructions. It enables LLMs to excel in various tasks, such as arithmetic reasoning, question answering, summarization, relation extraction, machine translation, and sentiment analysis. Researchers have been actively exploring different prompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and In-context learning. However, an unresolved problem arises from the fact that current approaches lack a solid theoretical foundation for determining optimal prompts. To address this issue in prompt engineering, we propose a new and effective approach called Prompt Space. Our methodology utilizes text embeddings to obtain basis vectors by matrix decomposition, and then constructs a space for representing all prompts. Prompt Space significantly outperforms state-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably, without the help of the CoT method and the prompt\"Let's think step by step\", Prompt Space shows superior performance over the few-shot method. Overall, our approach provides a robust and fundamental theoretical framework for selecting simple and effective prompts. This advancement marks a significant step towards improving prompt engineering for a wide variety of applications in LLMs.",
        "paperId": "2d338cdd12091814dec11155d3f6f848d7bab4d8"
    },
    {
        "title": "Contextual stance classification using prompt engineering",
        "firstAuthor": "Felipe Penhorate Carvalho de Fonseca",
        "url": "https://sol.sbc.org.br/index.php/stil/article/download/25435/25256",
        "dateSubmitted": "2023-09-25",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper introduces a prompt-based method for few-shot learning addressing, as an application example, contextual stance classification, that is, the task of determining the attitude expressed by a given statement within a conversation thread with multiple points of view towards another statement. More specifically, we envisaged a method that uses the existing conversation thread (i.e., messages that are part of the test data) to create natural language prompts for few-shot learning with minimal reliance on training samples, whose preliminary results suggest that prompt engineering may be a competitive alternative to supervised methods both in terms of accuracy and development costs for the task at hand.",
        "paperId": "2d90460431c093757fcf651e333bc0da5f5404c2"
    },
    {
        "title": "ii Editorial : Engineering Education and Society REGULAR ARTICLES",
        "firstAuthor": "K. Martin\u00e1s",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The continually changing, contemporary global society has been placing new demands on the engineering profession. The complexity of today\u2019s environmental, social and economic context has prompted engineering educators to call for a general reform in engineering education. While the common theme among this professional group is the necessity of reforming the engineering curriculum, how this should be done, and which changes are needed, is still a matter of contention. Non-technical content in engineering curricula has been implemented in order to address the perceived lack in competences when it comes to social or \u201csoft-skills\u201d. However, certain proponents of reform, e.g. S. Beder, E. Conlon and H. Zandvoort [1-3], have voiced concerns regarding the focus on \u201csoft-skills\u201d and management competencies on the one hand, and a certain disregard for a broader understanding of non-technical knowledge for engineers on the other. This broader understanding implies teaching engineering students to take into consideration the relevant social context and contributing to the community in their daily practice of engineering. The first part of this paper deals with the mentioned contentions within the engineering professional community. As an answer to the described dilemmas, the paper explores the necessities and possibilities of incorporating critical thinking into the engineering curriculum. The paper proposes a tentative implementation of P. Freire\u2019s humanist education in engineering education [4]. The possibilities of the pedagogy of critical consciousness have the capacity to move beyond the mentioned divisions by merging practical social skills (i. e. \u201csoft skills\u201d) with involvement in the community.",
        "paperId": "2dbbdbd3a8ad9ec3aa43068cb52d59b0784329e5"
    },
    {
        "title": "Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions.",
        "firstAuthor": "Tugba Akinci D\u2019Antonoli",
        "url": null,
        "dateSubmitted": "2023-10-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "With the advent of large language models (LLMs), the artificial intelligence revolution in medicine and radiology is now more tangible than ever. Every day, an increasingly large number of articles are published that utilize LLMs in radiology. To adopt and safely implement this new technology in the field, radiologists should be familiar with its key concepts, understand at least the technical basics, and be aware of the potential risks and ethical considerations that come with it. In this review article, the authors provide an overview of the LLMs that might be relevant to the radiology community and include a brief discussion of their short history, technical basics, ChatGPT, prompt engineering, potential applications in medicine and radiology, advantages, disadvantages and risks, ethical and regulatory considerations, and future directions.",
        "paperId": "2dceb28ed6eda0fe1fc24e00502ab004920a8628"
    },
    {
        "title": "Abstractive Summarization Evaluation for Prompt Engineering",
        "firstAuthor": "Shayak Chakraborty",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "2dd6cf3698dc06f0677137e8e5c446a2b2ec89bb"
    },
    {
        "title": "InsightsSumm - Summarization of ITOps Incidents Through In-Context Prompt Engineering",
        "firstAuthor": "Suranjana Samanta",
        "url": null,
        "dateSubmitted": "2023-07-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "AI has been extensively used to help Site Reliability Engineers (SREs) to resolve faults in cloud services and applications. It helps to accelerate resolution time by navigating through the vast amount of heterogeneous data (logs, metrics, alerts, etc) related to a fault. A good ITOps system should help SREs by giving precise and meaningful insights for a quick understanding of the data at hand. In this paper, we design a framework to summarize the context or insight present in the heterogeneous data related to a fault. The proposed framework constructs queries/prompts, specific to the ITOps domain, which helps us to generate more insightful abstractive summaries using state-of-the-art text generator models. Initial study on simulated faults shows promising results, which can be expanded to accommodate other datatype, providing summaries for real-world cases.",
        "paperId": "2e40c17db3d391705cba66ac51e7f150cc59f891"
    },
    {
        "title": "ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing",
        "firstAuthor": "Ian Arawjo",
        "url": "https://arxiv.org/pdf/2309.09128",
        "dateSubmitted": "2023-09-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Evaluating outputs of large language models (LLMs) is challenging, requiring making -- and making sense of -- many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.",
        "paperId": "2ed64d90670177bf58cdce6bda04a48a8731a18f"
    },
    {
        "title": "A Prompt Engineering Approach to Scientific Text Simplification: CYUT at SimpleText2023 Task3",
        "firstAuthor": "Shih-Hung Wu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "2fa691669c4e2766a4dea914ef30050ff6cb2578"
    },
    {
        "title": "VisPercep: A Vision-Language Approach to Enhance Visual Perception for People with Blindness and Low Vision",
        "firstAuthor": "Yu Hao",
        "url": null,
        "dateSubmitted": "2023-10-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "People with blindness and low vision (pBLV) encounter substantial challenges when it comes to comprehensive scene recognition and precise object identification in unfamiliar environments. Additionally, due to the vision loss, pBLV have difficulty in accessing and identifying potential tripping hazards on their own. In this paper, we present a pioneering approach that leverages a large vision-language model to enhance visual perception for pBLV, offering detailed and comprehensive descriptions of the surrounding environments and providing warnings about the potential risks. Our method begins by leveraging a large image tagging model (i.e., Recognize Anything (RAM)) to identify all common objects present in the captured images. The recognition results and user query are then integrated into a prompt, tailored specifically for pBLV using prompt engineering. By combining the prompt and input image, a large vision-language model (i.e., InstructBLIP) generates detailed and comprehensive descriptions of the environment and identifies potential risks in the environment by analyzing the environmental objects and scenes, relevant to the prompt. We evaluate our approach through experiments conducted on both indoor and outdoor datasets. Our results demonstrate that our method is able to recognize objects accurately and provide insightful descriptions and analysis of the environment for pBLV.",
        "paperId": "3031eedb7cf3ef20f1911c2902f3a8e5aeeb2c3f"
    },
    {
        "title": "Accelerated materials language processing enabled by GPT",
        "firstAuthor": "Jaewoong Choi",
        "url": "https://arxiv.org/pdf/2308.09354",
        "dateSubmitted": "2023-08-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Materials language processing (MLP) is one of the key facilitators of materials science research, as it enables the extraction of structured information from massive materials science literature. Prior works suggested high-performance MLP models for text classification, named entity recognition (NER), and extractive question answering (QA), which require complex model architecture, exhaustive fine-tuning and a large number of human-labelled datasets. In this study, we develop generative pretrained transformer (GPT)-enabled pipelines where the complex architectures of prior MLP models are replaced with strategic designs of prompt engineering. First, we develop a GPT-enabled document classification method for screening relevant documents, achieving comparable accuracy and reliability compared to prior models, with only small dataset. Secondly, for NER task, we design an entity-centric prompts, and learning few-shot of them improved the performance on most of entities in three open datasets. Finally, we develop an GPT-enabled extractive QA model, which provides improved performance and shows the possibility of automatically correcting annotations. While our findings confirm the potential of GPT-enabled MLP models as well as their value in terms of reliability and practicability, our scientific methods and systematic approach are applicable to any materials science domain to accelerate the information extraction of scientific literature.",
        "paperId": "3034d8571e16e25c6a839bf492f20daf855d04a0"
    },
    {
        "title": "A Transformer-based Approach for Abstractive Summarization of Requirements from Obligations in Software Engineering Contracts",
        "firstAuthor": "Chirag Jain",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Software Engineering (SE) contracts are a valuable source of software requirements. Seed requirements derived from SE contracts can provide a starting point to the Requirements Engineering (RE) phase. To extract such a seed however, a correct interpretation of contracts text is crucial. A major challenge with contracts text interpretation is that the text is lengthy, convoluted, and it incorporates a complex Legalese. If a summary of the high-level requirements from obligations present in SE contracts is available to the requirement analysts in a language that is comprehensible to them, they can use this seed requirements knowledge to ask the right questions to the stakeholders. In this paper, we propose an approach for summarizing the requirements present in obligations in a language comprehensible to requirement analysts. We use the principles of Prompt Engineering to prompt GPT-3 to generate summaries for training Natural Language Generation (NLG) models for generating SE-specific summaries. Experiments using NLG models such as BART, GPT-2, T5, and Pegasus indicate that Pegasus generates the most accurate summaries with the highest ROUGE score as compared to other models.",
        "paperId": "309c4a68ae22d91b3d127fae6b80d4e1f5609537"
    },
    {
        "title": "In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search",
        "firstAuthor": "Huihan Li",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Since large language models have approached human-level performance on many tasks, it has become increasingly harder for researchers to find tasks that are still challenging to the models. Failure cases usually come from the long-tail distribution - data that an oracle language model could assign a probability on the lower end of its distribution. Current methodology such as prompt engineering or crowdsourcing are insufficient for creating long-tail examples because humans are constrained by cognitive bias. We propose a Logic-Induced-Knowledge-Search (LINK) framework for systematically generating long-tail knowledge statements. Grounded by a symbolic rule, we search for long-tail values for each variable of the rule by first prompting a LLM, then verifying the correctness of the values with a critic, and lastly pushing for the long-tail distribution with a reranker. With this framework we construct a dataset, Logic-Induced-Long-Tail (LINT), consisting of 200 symbolic rules and 50K knowledge statements spanning across four domains. Human annotations find that 84% of the statements in LINT are factually correct. In contrast, ChatGPT and GPT4 struggle with directly generating long-tail statements under the guidance of logic rules, each only getting 56% and 78% of their statements correct. Moreover, their\"long-tail\"generations in fact fall into the higher likelihood range, and thus are not really long-tail. Our findings suggest that LINK is effective for generating data in the long-tail distribution while enforcing quality. LINT can be useful for systematically evaluating LLMs' capabilities in the long-tail distribution. We challenge the models with a simple entailment classification task using samples from LINT. We find that ChatGPT and GPT4's capability in identifying incorrect knowledge drop by ~3% in the long-tail distribution compared to head distribution.",
        "paperId": "31282fc5a46f4410450bb4324d47aad0a37d4a36"
    },
    {
        "title": "Prompt Engineering in Medical Education",
        "firstAuthor": "Thomas F. Heston",
        "url": "https://www.mdpi.com/2813-141X/2/3/19/pdf?version=1693479951",
        "dateSubmitted": "2023-08-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Artificial intelligence-powered generative language models (GLMs), such as ChatGPT, Perplexity AI, and Google Bard, have the potential to provide personalized learning, unlimited practice opportunities, and interactive engagement 24/7, with immediate feedback. However, to fully utilize GLMs, properly formulated instructions are essential. Prompt engineering is a systematic approach to effectively communicating with GLMs to achieve the desired results. Well-crafted prompts yield good responses from the GLM, while poorly constructed prompts will lead to unsatisfactory responses. Besides the challenges of prompt engineering, significant concerns are associated with using GLMs in medical education, including ensuring accuracy, mitigating bias, maintaining privacy, and avoiding excessive reliance on technology. Future directions involve developing more sophisticated prompt engineering techniques, integrating GLMs with other technologies, creating personalized learning pathways, and researching the effectiveness of GLMs in medical education.",
        "paperId": "3159478fbc81e562c812b9d5dc1891271b21f0c4"
    },
    {
        "title": "A Communication Theory Perspective on Prompting Engineering Methods for Large Language Models",
        "firstAuthor": "Yuanfeng Song",
        "url": null,
        "dateSubmitted": "2023-10-24",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The springing up of Large Language Models (LLMs) has shifted the community from single-task-orientated natural language processing (NLP) research to a holistic end-to-end multi-task learning paradigm. Along this line of research endeavors in the area, LLM-based prompting methods have attracted much attention, partially due to the technological advantages brought by prompt engineering (PE) as well as the underlying NLP principles disclosed by various prompting methods. Traditional supervised learning usually requires training a model based on labeled data and then making predictions. In contrast, PE methods directly use the powerful capabilities of existing LLMs (i.e., GPT-3 and GPT-4) via composing appropriate prompts, especially under few-shot or zero-shot scenarios. Facing the abundance of studies related to the prompting and the ever-evolving nature of this field, this article aims to (i) illustrate a novel perspective to review existing PE methods, within the well-established communication theory framework; (ii) facilitate a better/deeper understanding of developing trends of existing PE methods used in four typical tasks; (iii) shed light on promising research directions for future PE methods.",
        "paperId": "31b092d23154d3467d4a92065d77e8b441dfa440"
    },
    {
        "title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",
        "firstAuthor": "Jongyoon Lim",
        "url": "https://arxiv.org/pdf/2309.16898",
        "dateSubmitted": "2023-09-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This research explores using lightweight deep neural network architectures to enable the humanoid robot Pepper to understand American Sign Language (ASL) and facilitate non-verbal human-robot interaction. First, we introduce a lightweight and efficient model for ASL understanding optimized for embedded systems, ensuring rapid sign recognition while conserving computational resources. Building upon this, we employ large language models (LLMs) for intelligent robot interactions. Through intricate prompt engineering, we tailor interactions to allow the Pepper Robot to generate natural Co-Speech Gesture responses, laying the foundation for more organic and intuitive humanoid-robot dialogues. Finally, we present an integrated software pipeline, embodying advancements in a socially aware AI interaction model. Leveraging the Pepper Robot's capabilities, we demonstrate the practicality and effectiveness of our approach in real-world scenarios. The results highlight a profound potential for enhancing human-robot interaction through non-verbal interactions, bridging communication gaps, and making technology more accessible and understandable.",
        "paperId": "31e04aec55f749dc560afe1d8673112f9b32f46b"
    },
    {
        "title": "The prompt engineering librarian",
        "firstAuthor": "Brady Lund",
        "url": null,
        "dateSubmitted": "2023-10-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\nPurpose\nIn terms of training the public in prompt engineering skills, no single discipline or profession currently takes the lead, presenting an opportunity for professions like librarianship to step into this role. Librarians are already well-equipped to educate the public in a wide range of literacy skills and tasks, so prompt engineering may be a natural progression. The purpose of this paper is to examine the potential role of prompt engineering for library professionals.\n\n\nDesign/methodology/approach\nPrompt engineering is the process of optimizing the text that is provided to an artificial intelligence (A)I model to ensure proper interpretation and the generation of relevant, detailed results. The field of prompt engineering is relatively young, evolving alongside the growth of large language models like ChatGPT and BARD. This conceptual paper will explore prompt engineering as a possible domain of expertise for librarians.\n\n\nFindings\nThis paper delves into the world of prompt engineering, its alignment with the existing roles and expertise of librarians, and the potential emergence of a new role known as the \u201cprompt engineering librarian,\u201d akin to the well-established \u201cinformation literacy librarian\u201d role that has gained prominence in recent decades.\n\n\nOriginality/value\nThe significance of this work lies in exploring the synergy between prompt engineering and the traditional roles of librarians, highlighting the potential for a new and valuable profession in the form of prompt engineering librarians. This innovative concept could bridge the gap in AI literacy and facilitate more effective interactions with AI systems, contributing to the broader goal of AI accessibility and understanding.\n",
        "paperId": "330ceb123b4090b0bb2cec0b88c83776266f339d"
    },
    {
        "title": "Benchmarking Causal Study to Interpret Large Language Models for Source Code",
        "firstAuthor": "Daniel Rodr\u00edguez-C\u00e1rdenas",
        "url": "https://arxiv.org/pdf/2308.12415",
        "dateSubmitted": "2023-08-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs' performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model's performance. In an effort to bring statistical rigor to the evaluation of LLMs, this paper introduces a benchmarking strategy named Galeras comprised of curated testbeds for three SE tasks (i.e., code completion, code summarization, and commit generation) to help aid the interpretation of LLMs' performance. We illustrate the insights of our benchmarking strategy by conducting a case study on the performance of ChatGPT under distinct prompt engineering methods. The results of the case study demonstrate the positive causal influence of prompt semantics on ChatGPT's generative performance by an average treatment effect of $\\approx 3\\%$. Moreover, it was found that confounders such as prompt size are highly correlated with accuracy metrics ($\\approx 0.412\\%$). The end result of our case study is to showcase causal inference evaluations, in practice, to reduce confounding bias. By reducing the bias, we offer an interpretable solution for the accuracy metric under analysis.",
        "paperId": "3352d4bb5756a8a6bfcc1cde169b6aa9fd94497d"
    },
    {
        "title": "Cases of EFL Secondary Students' Prompt Engineering Pathways to Complete a Writing Task with ChatGPT",
        "firstAuthor": "D. Woo",
        "url": "https://arxiv.org/pdf/2307.05493",
        "dateSubmitted": "2023-06-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ChatGPT is a state-of-the-art (SOTA) chatbot. Although it has potential to support English as a foreign language (EFL) students' writing, to effectively collaborate with it, a student must learn to engineer prompts, that is, the skill of crafting appropriate instructions so that ChatGPT produces desired outputs. However, writing an appropriate prompt for ChatGPT is not straightforward for non-technical users who suffer a trial-and-error process. This paper examines the content of EFL students' ChatGPT prompts when completing a writing task and explores patterns in the quality and quantity of the prompts. The data come from iPad screen recordings of secondary school EFL students who used ChatGPT and other SOTA chatbots for the first time to complete the same writing task. The paper presents a case study of four distinct pathways that illustrate the trial-and-error process and show different combinations of prompt content and quantity. The cases contribute evidence for the need to provide prompt engineering education in the context of the EFL writing classroom, if students are to move beyond an individual trial-and-error process, learning a greater variety of prompt content and more sophisticated prompts to support their writing.",
        "paperId": "344f801663a76aa15e0dd13344261d8648c382a2"
    },
    {
        "title": "LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked",
        "firstAuthor": "Alec Helbling",
        "url": "https://arxiv.org/pdf/2308.07308",
        "dateSubmitted": "2023-08-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) are popular for high-quality text generation but can produce harmful content, even when aligned with human values through reinforcement learning. Adversarial prompts can bypass their safety measures. We propose LLM Self Defense, a simple approach to defend against these attacks by having an LLM screen the induced responses. Our method does not require any fine-tuning, input preprocessing, or iterative output generation. Instead, we incorporate the generated content into a pre-defined prompt and employ another instance of an LLM to analyze the text and predict whether it is harmful. We test LLM Self Defense on GPT 3.5 and Llama 2, two of the current most prominent LLMs against various types of attacks, such as forcefully inducing affirmative responses to prompts and prompt engineering attacks. Notably, LLM Self Defense succeeds in reducing the attack success rate to virtually 0 using both GPT 3.5 and Llama 2.",
        "paperId": "34f9c825ba24889fa5e164ba9f99bfe4fc2f3e61"
    },
    {
        "title": "CHiLS: Zero-Shot Image Classification with Hierarchical Label Sets",
        "firstAuthor": "Zachary Novack",
        "url": "http://arxiv.org/pdf/2302.02551",
        "dateSubmitted": "2023-02-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing zero-shot pipelines and requires no additional training cost. Code is available at: https://github.com/acmi-lab/CHILS.",
        "paperId": "34fd95dd4dd32e704d4284fc31165e85b303bb1e"
    },
    {
        "title": "CICESE at DA-VINCIS 2023: Violent Events Detection in Twitter using Data Augmentation Techniques",
        "firstAuthor": "Esteban Ponce-Le\u00f3n",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper describes our participation in the shared evaluation campaign of DA-VINCIS at IberLEF 2023. In this work, we address the subtasks proposed, Violent Event Identification (subtask 1) and Violent Event Category Recognition (subtask 2) using multimodal information from tweets (text and images), by using a Bidirectional Encoder Representations from Transformers (BERT) with and without data augmentation techniques. For text augmentation, the GPT-3 model and prompt engineering were used meanwhile for image augmentation an image recovery approach from the web was used, and image captioning to handle the images from the visual information. Our approach obtained second place for subtask 1 (F1 = 0.9203) and first place for subtask 2 (F1 = 0.8797) among 16 different teams.",
        "paperId": "3574d10d56e96db9180caefe074a9021d1af89c7"
    },
    {
        "title": "ChatGPT opens a new door for bioinformatics",
        "firstAuthor": "Dong Xu",
        "url": "https://journal.hep.com.cn/qb/EN/PDF/10.15302/J-QB-023-0328",
        "dateSubmitted": "2023-04-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ChatGPT is an artificial intelligence (AI) system that can perform sophisticated writing and dialogs after learning from vast amounts of linguistic data. The success of ChatGPT is phenomenal. AI-based human-machine language interaction has been at the center of AI competition in recent years. The major players in this game have been Google, Meta, and OpenAI. Google was in the best position from the outset, given its invention of Transformer (the cornerstone of all cutting-edge language models) and its significant edge in reinforcement learning. Yet, Google\u2019s efforts in this area were rather diffusing. It kept generating language model variants with incremental innovations but failed to reach the next level. Meta has a strong AI team, including many top AI researchers in the world. Nevertheless, their faith in self-supervised learning to solve human-machine interaction did not deliver high-impact success. Conversely, OpenAI, with a small team, stayed focused on a single product line (GPT, including its latest release of GPT-4). It moved in the right direction of using human input to \u201calign\u201d the language model based on the Reinforcement Learning from Human Feedback (RLHF) approach. The fact that OpenAI ultimately prevailed in this game shows that the model alignment to human labeling through supervised and reinforcement learning is critical for human-machine interaction. However, a chatbot\u2019s actions rely heavily on cues (prompts) provided by human operators. To properly utilize ChatGPT\u2019s capabilities, prompts to instruct or mentor the chatbot must be carefully designed to get valuable, valid, and robust responses. This process becomes another \u201calignment\u201d problem of using prompt engineering to best probe ChatGPT\u2019s knowledge graph for best serving users\u2019 needs.",
        "paperId": "358d1d9eed69a6eadcda9996b3f13b0e0a356b88"
    },
    {
        "title": "Statistical Analysis of Bias in ChatGPT Using Prompt Engineering",
        "firstAuthor": "R. Sinha",
        "url": null,
        "dateSubmitted": "2023-06-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Abstract: ChatGPT is a leading Large Language Model trained on an extensive and diverse assortment of text data. However, the utilization of potentially biased training data from the internet corpora could lead to fundamental bias introduced in the model, which will subsequently reflect on its generated output. This paper quantifies bias present in GPT-3.0 model responses on various controversial topics using carefully engineered prompts. We measured raw bias in each generated response by leveraging the Bipartisan Press API. Using statistical methods such as the T-test and ANOVA on raw bias measurements, we tested our hypothesis. Our results demonstrate that there is statistically significant left leaning bias present in 9 out of the 11 controversial topics we tested. Further, ANOVA analysis shows that the bias present varies based on topics. We posit that our findings could be instrumental in guiding future efforts to mitigate training bias and address the larger alignment problem present in generative AI.",
        "paperId": "3605653916ccf8ceb995edbfcc79acba8dbffa64"
    },
    {
        "title": "Generating Novel Leads for Drug Discovery using LLMs with Logical Feedback",
        "firstAuthor": "Shreyas Bhat Brahmavar",
        "url": "https://www.biorxiv.org/content/biorxiv/early/2023/09/17/2023.09.14.557698.full.pdf",
        "dateSubmitted": "2023-09-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models (LLMs) can be used as repositories of biological and chemical information to generate pharmacological lead compounds. However, for LLMs to focus on specific drug targets typically require experimentation with progressively more refined prompts. Results thus become dependent not just on what is known about the target, but also on what is known about the prompt-engineering. In this paper, we separate the prompt into domain-constraints that can be written in a standard logical form, and a simple text-based query. We investigate whether LLMs can be guided, not by refining prompts manually, but by refining the the logical component automatically, keeping the query unchanged. We describe an iterative procedure LMLF (\u201cLanguage Models with Logical Feedback\u201d) in which the constraints are progressively refined using a logical notion of generalisation. On any iteration, newly generated instances are verified against the constraint, providing \u201clogical-feedback\u201d for the next iteration\u2019s refinement of the constraints. We evaluate LMLF using two well-known targets (inhibition of the Janus Kinase 2; and Dopamine Receptor D2); and two different LLMs (GPT-3 and PaLM). We show that LMLF, starting with the same logical constraints and query text, can guide both LLMs to generate potential leads. We find: (a) Binding affinities of LMLF-generated molecules are skewed towards higher binding affinities than those from existing baselines; LMLF results in generating molecules that are skewed towards higher binding affinities than without logical feedback; (c) Assessment by a computational chemist suggests that LMLF generated compounds may be novel inhibitors. These findings suggest that LLMs with logical feedback may provide a mechanism for generating new leads without requiring the domain-specialist to acquire sophisticated skills in prompt-engineering.",
        "paperId": "3613299c54bbea66dd6db1b00573f7ade021a5a9"
    },
    {
        "title": "Geotechnical Parrot Tales (GPT): Overcoming GPT hallucinations with prompt engineering for geotechnical applications",
        "firstAuthor": "Krishna Kumar",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rise of large language models (LLMs) has generated widespread interest due to their ability to answer questions, generate text/code",
        "paperId": "372f5e69e7a9392fe909dc6a3866deb31fe2de00"
    },
    {
        "title": "Flows: Building Blocks of Reasoning and Collaborating AI",
        "firstAuthor": "Martin Josifoski",
        "url": "https://arxiv.org/pdf/2308.01285",
        "dateSubmitted": "2023-08-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles. Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate. To support rapid and rigorous research, we introduce the aiFlows library. The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows. The aiFlows library is available at https://github.com/epfl-dlab/aiflows. Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.",
        "paperId": "377d4d6c1be01b9df32edfd94b2c5946971b0108"
    },
    {
        "title": "Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models",
        "firstAuthor": "Junchi Yu",
        "url": "https://arxiv.org/pdf/2310.03965",
        "dateSubmitted": "2023-10-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models (LLMs) have achieved remarkable success in reasoning tasks with the development of prompting methods. However, existing prompting approaches cannot reuse insights of solving similar problems and suffer from accumulated errors in multi-step reasoning, since they prompt LLMs to reason \\textit{from scratch}. To address these issues, we propose \\textbf{\\textit{Thought Propagation} (TP)}, which explores the analogous problems and leverages their solutions to enhance the complex reasoning ability of LLMs. These analogous problems are related to the input one, with reusable solutions and problem-solving strategies. Thus, it is promising to propagate insights of solving previous analogous problems to inspire new problem-solving. To achieve this, TP first prompts LLMs to propose and solve a set of analogous problems that are related to the input one. Then, TP reuses the results of analogous problems to directly yield a new solution or derive a knowledge-intensive plan for execution to amend the initial solution obtained from scratch. TP is compatible with existing prompting approaches, allowing plug-and-play generalization and enhancement in a wide range of tasks without much labor in task-specific prompt engineering. Experiments across three challenging tasks demonstrate TP enjoys a substantial improvement over the baselines by an average of 12\\% absolute increase in finding the optimal solutions in Shortest-path Reasoning, 13\\% improvement of human preference in Creative Writing, and 15\\% enhancement in the task completion rate of LLM-Agent Planning.",
        "paperId": "3784fd84b61d482b52f7ef72aac66bcb886b892b"
    },
    {
        "title": "Prompt Engineering for Healthcare: Methodologies and Applications",
        "firstAuthor": "Jiaqi Wang",
        "url": "http://arxiv.org/pdf/2304.14670",
        "dateSubmitted": "2023-04-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This review will introduce the latest advances in prompt engineering in the field of natural language processing (NLP) for the medical domain. First, we will provide a brief overview of the development of prompt engineering and emphasize its significant contributions to healthcare NLP applications such as question-answering systems, text summarization, and machine translation. With the continuous improvement of general large language models, the importance of prompt engineering in the healthcare domain is becoming increasingly prominent. The aim of this article is to provide useful resources and bridges for healthcare NLP researchers to better explore the application of prompt engineering in this field. We hope that this review can provide new ideas and inspire ample possibilities for research and application in medical NLP.",
        "paperId": "385376b8aa48c25403f17d6206db7c09b67e1314"
    },
    {
        "title": "ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP",
        "firstAuthor": "Lu Yan",
        "url": "https://arxiv.org/pdf/2308.02122",
        "dateSubmitted": "2023-08-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Backdoor attacks have emerged as a prominent threat to natural language processing (NLP) models, where the presence of specific triggers in the input can lead poisoned models to misclassify these inputs to predetermined target classes. Current detection mechanisms are limited by their inability to address more covert backdoor strategies, such as style-based attacks. In this work, we propose an innovative test-time poisoned sample detection framework that hinges on the interpretability of model predictions, grounded in the semantic meaning of inputs. We contend that triggers (e.g., infrequent words) are not supposed to fundamentally alter the underlying semantic meanings of poisoned samples as they want to stay stealthy. Based on this observation, we hypothesize that while the model's predictions for paraphrased clean samples should remain stable, predictions for poisoned samples should revert to their true labels upon the mutations applied to triggers during the paraphrasing process. We employ ChatGPT, a state-of-the-art large language model, as our paraphraser and formulate the trigger-removal task as a prompt engineering problem. We adopt fuzzing, a technique commonly used for unearthing software vulnerabilities, to discover optimal paraphrase prompts that can effectively eliminate triggers while concurrently maintaining input semantics. Experiments on 4 types of backdoor attacks, including the subtle style backdoors, and 4 distinct datasets demonstrate that our approach surpasses baseline methods, including STRIP, RAP, and ONION, in precision and recall.",
        "paperId": "3a733c27bff68259b17dc4f835b0d192ac8fab70"
    },
    {
        "title": "Enhancing Arabic Content Generation with Prompt Augmentation Using Integrated GPT and Text-to-Image Models",
        "firstAuthor": "Wala Elsharif",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3573381.3596466",
        "dateSubmitted": "2023-06-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "With the current and continuous advancements in the field of text-to-image modeling, it has become critical to design prompts that make the best of these model capabilities and guides them to generate the most desirable images, and thus the field of prompt engineering has emerged. Here, we study a method to use prompt engineering to enhance text-to-image model representation of the Arabic culture. This work proposes a simple, novel approach for prompt engineering that uses the domain knowledge of a state-of-the-art language model, GPT, to perform the task of prompt augmentation, where a simple, initial prompt is used to generate multiple, more detailed prompts related to the Arabic culture from multiple categories through a GPT model through a process known as in-context learning. The augmented prompts are then used to generate images enhanced for the Arabic culture. We perform multiple experiments with a number of participants to evaluate the performance of the proposed method, which shows promising results, specially for generating prompts that are more inclusive of the different Arabic countries and with a wider variety in terms of image subjects, where we find that our proposed method generates image with more variety 85 % of the time and are more inclusive of the Arabic countries more than 72.66 % of the time, compared to the direct approach.",
        "paperId": "3bb1a0193cb0b5dd9405a729b16320c6ec31b1dd"
    },
    {
        "title": "Transforming Sentiment Analysis in the Financial Domain with ChatGPT",
        "firstAuthor": "G. Fatouros",
        "url": "https://arxiv.org/pdf/2308.07935",
        "dateSubmitted": "2023-08-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero-shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1-score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an additional evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35\\% enhanced performance in sentiment classification and a 36\\% higher correlation with market returns. By underlining the significance of prompt engineering, particularly in zero-shot contexts, this study spotlights ChatGPT's potential to substantially boost sentiment analysis in financial applications. By sharing the utilized dataset, our intention is to stimulate further research and advancements in the field of financial services.",
        "paperId": "3c4f1244301577cffff9affc73690669725e7e08"
    },
    {
        "title": "QA-CLIMS: Question-Answer Cross Language Image Matching for Weakly Supervised Semantic Segmentation",
        "firstAuthor": "Songhe Deng",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3581783.3612148",
        "dateSubmitted": "2023-10-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Class Activation Map (CAM) has emerged as a popular tool for weakly supervised semantic segmentation (WSSS), allowing the localization of object regions in an image using only image-level labels. However, existing CAM methods suffer from under-activation of target object regions and false-activation of background regions due to the fact that a lack of detailed supervision can hinder the model's ability to understand the image as a whole. In this paper, we propose a novel Question-Answer Cross-Language-Image Matching framework for WSSS (QA-CLIMS), leveraging the vision-language foundation model to maximize the text-based understanding of images and guide the generation of activation maps. First, a series of carefully designed questions are posed to the VQA (Visual Question Answering) model with Question-Answer Prompt Engineering (QAPE) to generate a corpus of both foreground target objects and backgrounds that are adaptive to query images. We then employ contrastive learning in a Region Image Text Contrastive (RITC) network to compare the obtained foreground and background regions with the generated corpus. Our approach exploits the rich textual information from the open vocabulary as additional supervision, enabling the model to generate high-quality CAMs with a more complete object region and reduce false-activation of background regions. We conduct extensive analysis to validate the proposed method and show that our approach performs state-of-the-art on both PASCAL VOC 2012 and MS COCO datasets.",
        "paperId": "3da79f3fe4e0ff1bb59efb34c8baa2bcf632c2b9"
    },
    {
        "title": "Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts",
        "firstAuthor": "Mayug Maniparambil",
        "url": "https://arxiv.org/pdf/2307.11661",
        "dateSubmitted": "2023-07-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have revolutionized visual representation learning by providing good performance on downstream datasets. VLMs are 0-shot adapted to a downstream dataset by designing prompts that are relevant to the dataset. Such prompt engineering makes use of domain expertise and a validation dataset. Meanwhile, recent developments in generative pretrained models like GPT-4 mean they can be used as advanced internet search tools. They can also be manipulated to provide visual information in any structure. In this work, we show that GPT-4 can be used to generate text that is visually descriptive and how this can be used to adapt CLIP to downstream tasks. We show considerable improvements in 0-shot transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD (~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt. We also design a simple few-shot adapter that learns to choose the best possible sentences to construct generalizable classifiers that outperform the recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized fine-grained datasets. The code, prompts, and auxiliary text dataset is available at https://github.com/mayug/VDT-Adapter.",
        "paperId": "3e0a691277183a6704310af3e4e9e271400612bc"
    },
    {
        "title": "Large Language Models as Data Preprocessors",
        "firstAuthor": "Haochen Zhang",
        "url": "https://arxiv.org/pdf/2308.16361",
        "dateSubmitted": "2023-08-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the performance and efficiency of these models. The effectiveness of LLMs in data preprocessing is evaluated through an experimental study spanning 12 datasets. GPT-4 emerged as a standout, achieving 100\\% accuracy or F1 score on 4 datasets, suggesting LLMs' immense potential in these tasks. Despite certain limitations, our study underscores the promise of LLMs in this domain and anticipates future developments to overcome current hurdles.",
        "paperId": "3e1ca026052d30e3b9677e363616fae23f6616df"
    },
    {
        "title": "Revisiting Prompt Engineering via Declarative Crowdsourcing",
        "firstAuthor": "Aditya G. Parameswaran",
        "url": "https://arxiv.org/pdf/2308.03854",
        "dateSubmitted": "2023-08-07",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach",
        "paperId": "3e4991bd206214f596a10e9932cd441fe5bd1f8c"
    },
    {
        "title": "The CLEAR path: A framework for enhancing information literacy through prompt engineering",
        "firstAuthor": "Leo S. Lo",
        "url": null,
        "dateSubmitted": "2023-07-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "3ea7ac6d9113a66584ac36143de7613204c4958b"
    },
    {
        "title": "Do prompt positions really matter?",
        "firstAuthor": "Junyu Mao",
        "url": null,
        "dateSubmitted": "2023-05-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt-based models have gathered a lot of attention from researchers due to their remarkable advancements in the fields of zero-shot and few-shot learning. Developing an effective prompt template plays a critical role. However, prior studies have mainly focused on prompt vocabulary selection or embedding initialization within a predefined template with the prompt position fixed. In this empirical study, we conduct the most comprehensive analysis to date of prompt position for diverse natural language process tasks. Our findings quantify the substantial impact prompt position has on model performance. We observe that the prompt position used in prior studies is often sub-optimal. These findings suggest prompt position optimisation as a valuable research direction to fill the gap in existing prompt engineering methodologies.",
        "paperId": "405b3b7f04380c87677735e471b8434616d2e229"
    },
    {
        "title": "Demonstrations of the Potential of AI-based Political Issue Polling",
        "firstAuthor": "Nathan Sanders",
        "url": "https://arxiv.org/pdf/2307.04781",
        "dateSubmitted": "2023-07-10",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Political polling is a multi-billion dollar industry with outsized influence on the societal trajectory of the United States and nations around the world. However, it has been challenged by factors that stress its cost, availability, and accuracy. At the same time, artificial intelligence (AI) chatbots have become compelling stand-ins for human behavior, powered by increasingly sophisticated large language models (LLMs). Could AI chatbots be an effective tool for anticipating public opinion on controversial issues to the extent that they could be used by campaigns, interest groups, and polling firms? We have developed a prompt engineering methodology for eliciting human-like survey responses from ChatGPT, which simulate the response to a policy question of a person described by a set of demographic factors, and produce both an ordinal numeric response score and a textual justification. We execute large scale experiments, querying for thousands of simulated responses at a cost far lower than human surveys. We compare simulated data to human issue polling data from the Cooperative Election Study (CES). We find that ChatGPT is effective at anticipating both the mean level and distribution of public opinion on a variety of policy issues such as abortion bans and approval of the US Supreme Court, particularly in their ideological breakdown (correlation typically>85%). However, it is less successful at anticipating demographic-level differences. Moreover, ChatGPT tends to overgeneralize to new policy issues that arose after its training data was collected, such as US support for involvement in the war in Ukraine. Our work has implications for our understanding of the strengths and limitations of the current generation of AI chatbots as virtual publics or online listening platforms, future directions for LLM development, and applications of AI tools to the political domain. (Abridged)",
        "paperId": "407a8d6227ece351d9870f96576d4c287a746166"
    },
    {
        "title": "Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality",
        "firstAuthor": "Fabrizio Dell'Acqua",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The public release of Large Language Models (LLMs) has sparked tremendous interest in how humans will use Artificial Intelligence (AI) to accomplish a variety of tasks. In our study conducted with Boston Consulting Group, a global management consulting firm, we examine the performance implications of AI on realistic, complex, and knowledge-intensive tasks. The pre-registered experiment involved 758 consultants comprising about 7% of the individual contributor-level consultants at the company. After establishing a performance baseline on a similar task, subjects were randomly assigned to one of three conditions: no AI access, GPT-4 AI access, or GPT-4 AI access with a prompt engineering overview. We suggest that the capabilities of AI create a \u201cjagged technological frontier\u201d where some tasks are easily done by AI, while others, though seemingly similar in difficulty level, are outside the current capability of AI. For each one of a set of 18 realistic consulting tasks within the frontier of AI capabilities, consultants using AI were significantly more productive (they completed 12.2% more tasks on average, and completed tasks 25.1% more quickly), and produced significantly higher quality results (more than 40% higher quality compared to a control group). Consultants across the skills distribution benefited significantly from having AI augmentation, with those below the average performance threshold increasing by 43% and those above increasing by 17% compared to their own scores. For a task selected to be outside the frontier, however, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI. Further, our analysis shows the emergence of two distinctive patterns of successful AI use by humans along a spectrum of humanAI integration. One set of consultants acted as \u201cCentaurs,\u201d like the mythical halfhorse/half-human creature, dividing and delegating their solution-creation activities to the AI or to themselves. Another set of consultants acted more like \u201cCyborgs,\u201d completely integrating their task flow with the AI and continually interacting with the technology.",
        "paperId": "409dc9f1801947f85c53231cba346f0e314cb208"
    },
    {
        "title": "EvoPrompting: Language Models for Code-Level Neural Architecture Search",
        "firstAuthor": "Angelica Chen",
        "url": "https://arxiv.org/pdf/2302.14838",
        "dateSubmitted": "2023-02-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Given the recent impressive accomplishments of language models (LMs) for code generation, we explore the use of LMs as adaptive mutation and crossover operators for an evolutionary neural architecture search (NAS) algorithm. While NAS still proves too difficult a task for LMs to succeed at solely through prompting, we find that the combination of evolutionary prompt engineering with soft prompt-tuning, a method we term EvoPrompting, consistently finds diverse and high performing models. We first demonstrate that EvoPrompting is effective on the computationally efficient MNIST-1D dataset, where EvoPrompting produces convolutional architecture variants that outperform both those designed by human experts and naive few-shot prompting in terms of accuracy and model size. We then apply our method to searching for graph neural networks on the CLRS Algorithmic Reasoning Benchmark, where EvoPrompting is able to design novel architectures that outperform current state-of-the-art models on 21 out of 30 algorithmic reasoning tasks while maintaining similar model size. EvoPrompting is successful at designing accurate and efficient neural network architectures across a variety of machine learning tasks, while also being general enough for easy adaptation to other tasks beyond neural network design.",
        "paperId": "411b16add23976ffcdf6422f932453f6ebcca119"
    },
    {
        "title": "A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering",
        "firstAuthor": "Chaoning Zhang",
        "url": "http://arxiv.org/pdf/2306.06211",
        "dateSubmitted": "2023-05-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Segment anything model (SAM) developed by Meta AI Research has recently attracted significant attention. Trained on a large segmentation dataset of over 1 billion masks, SAM is capable of segmenting any object on a certain image. In the original SAM work, the authors turned to zero-short transfer tasks (like edge detection) for evaluating the performance of SAM. Recently, numerous works have attempted to investigate the performance of SAM in various scenarios to recognize and segment objects. Moreover, numerous projects have emerged to show the versatility of SAM as a foundation model by combining it with other models, like Grounding DINO, Stable Diffusion, ChatGPT, etc. With the relevant papers and projects increasing exponentially, it is challenging for the readers to catch up with the development of SAM. To this end, this work conducts the first yet comprehensive survey on SAM. This is an ongoing project and we intend to update the manuscript on a regular basis. Therefore, readers are welcome to contact us if they complete new works related to SAM so that we can include them in our next version.",
        "paperId": "42219b26a503d03bf70e9953edc3af94c255cb2a"
    },
    {
        "title": "Scalable 3D Captioning with Pretrained Models",
        "firstAuthor": "Tiange Luo",
        "url": "http://arxiv.org/pdf/2306.07279",
        "dateSubmitted": "2023-06-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We introduce Cap3D, an automatic approach for generating descriptive text for 3D objects. This approach utilizes pretrained models from image captioning, image-text alignment, and LLM to consolidate captions from multiple views of a 3D asset, completely side-stepping the time-consuming and costly process of manual annotation. We apply Cap3D to the recently introduced large-scale 3D dataset, Objaverse, resulting in 660k 3D-text pairs. Our evaluation, conducted using 41k human annotations from the same dataset, demonstrates that Cap3D surpasses human-authored descriptions in terms of quality, cost, and speed. Through effective prompt engineering, Cap3D rivals human performance in generating geometric descriptions on 17k collected annotations from the ABO dataset. Finally, we finetune Text-to-3D models on Cap3D and human captions, and show Cap3D outperforms; and benchmark the SOTA including Point-E, Shape-E, and DreamFusion.",
        "paperId": "4279a38a098d1d359881b73c6a88a112fe93443a"
    },
    {
        "title": "Making Large Language Models Better Data Creators",
        "firstAuthor": "Dong-Ho Lee",
        "url": null,
        "dateSubmitted": "2023-10-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Although large language models (LLMs) have advanced the state-of-the-art in NLP significantly, deploying them for downstream applications is still challenging due to cost, responsiveness, control, or concerns around privacy and security. As such, trainable models are still the preferred option in some cases. However, these models still require human-labeled data for optimal performance, which is expensive and time-consuming to obtain. In order to address this issue, several techniques to reduce human effort involve labeling or generating data using LLMs. Although these methods are effective for certain applications, in practice they encounter difficulties in real-world scenarios. Labeling data requires careful data selection, while generating data necessitates task-specific prompt engineering. In this paper, we propose a unified data creation pipeline that requires only a single formatting example, and which is applicable to a broad range of tasks, including traditionally problematic ones with semantically devoid label spaces. In our experiments we demonstrate that instruction-following LLMs are highly cost-effective data creators, and that models trained with these data exhibit performance better than those trained with human-labeled data (by up to 17.5%) on out-of-distribution evaluation, while maintaining comparable performance on in-distribution tasks. These results have important implications for the robustness of NLP systems deployed in the real-world.",
        "paperId": "439f1aacbcb32cba6da8f75bd9b15f7ea35e9d4d"
    },
    {
        "title": "Interactive Data Synthesis for Systematic Vision Adaptation via LLMs-AIGCs Collaboration",
        "firstAuthor": "Qifan Yu",
        "url": "http://arxiv.org/pdf/2305.12799",
        "dateSubmitted": "2023-05-22",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. In parallel, the problem of data scarcity has brought a growing interest in employing AIGC technology for high-quality data expansion. However, this paradigm requires well-designed prompt engineering that cost-less data expansion and labeling remain under-explored. Inspired by LLM's powerful capability in task guidance, we propose a new paradigm of annotated data expansion named as ChatGenImage. The core idea behind it is to leverage the complementary strengths of diverse models to establish a highly effective and user-friendly pipeline for interactive data augmentation. In this work, we extensively study how LLMs communicate with AIGC model to achieve more controllable image generation and make the first attempt to collaborate them for automatic data augmentation for a variety of downstream tasks. Finally, we present fascinating results obtained from our ChatGenImage framework and demonstrate the powerful potential of our synthetic data for systematic vision adaptation. Our codes are available at https://github.com/Yuqifan1117/Labal-Anything-Pipeline.",
        "paperId": "43a55dbd95c9d5cd82de8db276f41adeec4a937d"
    },
    {
        "title": "Performance Evaluation on Human-Machine Teaming Augmented Machine Translation Enabled by GPT-4",
        "firstAuthor": "Ming Qian",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Translation has been modeled as a multiple-phase process where pre-editing analyses guide meaning transfer and interlingual restructure. Present-day machine translation (MT) tools provide no means for source text analyses. Generative AI with Large language modeling (LLM), equipped with prompt engineering and fine-tuning capabilities, can enable augmented MT solutions by explicitly including AI or human generated analyses/instruction, and/or human-generated reference translation as pre-editing or interactive inputs. Using an English-to-Chinese translation piece that had been carefully studied during a translator slam event, Four types of translation outputs on 20 text segments were evaluated: human-generated translation, Google Translate MT, instruction-augmented MT using GPT4-LLM, and Human-Machine-Teaming (HMT)-augmented translation based on both human reference translation and instruction using GPT4-LLM. While human translation had the best performance, both augmented MT approaches performed better than un-augmented MT. The HMT-augmented MT performed better than instruction-augmented MT because it combined the guidance and knowledge provided by both human reference translation and style instruction. However, since it is unrealistic to generate sentence-by-sentence human translation as MT input, better approaches to HMT-augmented MT need to be invented. The evaluation showed that generative AI with LLM can enable new MT workflow facilitating pre-editing analyses and interactive restructuring and achieving better performance.",
        "paperId": "4468681a486ff795275888bd3b89c1a92d657a32"
    },
    {
        "title": "Using ChatGPT Standard Prompt Engineering Techniques in Lesson Preparation: Role, Instructions and Seed-Word Prompts",
        "firstAuthor": "A. Spasic",
        "url": null,
        "dateSubmitted": "2023-06-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The application of available natural language processing systems can have a significant impact on the education process. The primary aim of this research was to test the impact of three standard prompting techniques on the results obtained from ChatGPT. Generation of a lesson plan for programming for preschoolers was chosen as the task set for AI. The obtained results show that use of a standard prompting with additional defined roles and seed words can be useful in preparation of teaching units and lessons and it can be considered as a technique of teachers' choice.",
        "paperId": "44cbf7206f1dc9e0518c14c2f82b7e6cc0edd74c"
    },
    {
        "title": "Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology",
        "firstAuthor": "Tiago Lubiana",
        "url": null,
        "dateSubmitted": "2023-03-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rise of advanced chatbots, such as ChatGPT, has sparked curiosity in the scientific community. ChatGPT is a general-purpose chatbot powered by large language models (LLMs) GPT-3.5 and GPT-4, with the potential to impact numerous fields, including computational biology. In this article, we offer ten tips based on our experience with ChatGPT to assist computational biologists in optimizing their workflows. We have collected relevant prompts and reviewed the nascent literature in the field, compiling tips we project to remain pertinent for future ChatGPT and LLM iterations, ranging from code refactoring to scientific writing to prompt engineering. We hope our work will help bioinformaticians to complement their workflows while staying aware of the various implications of using this technology. Additionally, to track new and creative applications for bioinformatics tools such as ChatGPT, we have established a GitHub repository at https://github.com/csbl-br/awesome-compbio-chatgpt. Our belief is that ethical adherence to ChatGPT and other LLMs will increase the efficiency of computational biologists, ultimately advancing the pace of scientific discovery in the life sciences.",
        "paperId": "44e8b1aba0b1d1366b74993593d39bafe8c1b4ac"
    },
    {
        "title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
        "firstAuthor": "L. Giray",
        "url": null,
        "dateSubmitted": "2023-06-07",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "44f0876dec21a04533587def2add230b878a5006"
    },
    {
        "title": "GPT Takes the Bar Exam",
        "firstAuthor": "M. Bommarito",
        "url": "http://arxiv.org/pdf/2212.14402",
        "dateSubmitted": "2022-12-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Nearly all jurisdictions in the United States require a professional license exam, commonly referred to as\"the Bar Exam,\"as a precondition for law practice. To even sit for the exam, most jurisdictions require that an applicant completes at least seven years of post-secondary education, including three years at an accredited law school. In addition, most test-takers also undergo weeks to months of further, exam-specific preparation. Despite this significant investment of time and capital, approximately one in five test-takers still score under the rate required to pass the exam on their first try. In the face of a complex task that requires such depth of knowledge, what, then, should we expect of the state of the art in\"AI?\"In this research, we document our experimental evaluation of the performance of OpenAI's `text-davinci-003` model, often-referred to as GPT-3.5, on the multistate multiple choice (MBE) section of the exam. While we find no benefit in fine-tuning over GPT-3.5's zero-shot performance at the scale of our training data, we do find that hyperparameter optimization and prompt engineering positively impacted GPT-3.5's zero-shot performance. For best prompt and parameters, GPT-3.5 achieves a headline correct rate of 50.3% on a complete NCBE MBE practice exam, significantly in excess of the 25% baseline guessing rate, and performs at a passing rate for both Evidence and Torts. GPT-3.5's ranking of responses is also highly-correlated with correctness; its top two and top three choices are correct 71% and 88% of the time, respectively, indicating very strong non-entailment performance. While our ability to interpret these results is limited by nascent scientific understanding of LLMs and the proprietary nature of GPT, we believe that these results strongly suggest that an LLM will pass the MBE component of the Bar Exam in the near future.",
        "paperId": "458147b5f7242c998ec4f33798a59b7c48867329"
    },
    {
        "title": "Prompts Matter: Insights and Strategies for Prompt Engineering in Automated Software Traceability",
        "firstAuthor": "Alberto D. Rodriguez",
        "url": "https://arxiv.org/pdf/2308.00229",
        "dateSubmitted": "2023-08-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models (LLMs) have the potential to revolutionize automated traceability by overcoming the challenges faced by previous methods and introducing new possibilities. However, the optimal utilization of LLMs for automated traceability remains unclear. This paper explores the process of prompt engineering to extract link predictions from an LLM. We provide detailed insights into our approach for constructing effective prompts, offering our lessons learned. Additionally, we propose multiple strategies for leveraging LLMs to generate traceability links, improving upon previous zero-shot methods on the ranking of candidate links after prompt refinement. The primary objective of this paper is to inspire and assist future researchers and engineers by highlighting the process of constructing traceability prompts to effectively harness LLMs for advancing automatic traceability.",
        "paperId": "4591f6cea22b66eccda0103b83002be45e8216b6"
    },
    {
        "title": "Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure",
        "firstAuthor": "Philipp E. Koralus",
        "url": "http://arxiv.org/pdf/2303.17276",
        "dateSubmitted": "2023-03-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4. This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data. According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the\"bad\"cases could paradoxically be learned from the\"good\"cases. We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes.",
        "paperId": "45c46687bc8d2dbdea6f92fc14d4dc7a548ddd12"
    },
    {
        "title": "Large Language Models Are Human-Level Prompt Engineers",
        "firstAuthor": "Yongchao Zhou",
        "url": "http://arxiv.org/pdf/2211.01910",
        "dateSubmitted": "2022-11-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the\"program,\"optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.",
        "paperId": "4610ffb1b016acaa82a2065ffd1a3adbae1ce722"
    },
    {
        "title": "Fake it Till You Make it: Learning Transferable Representations from Synthetic ImageNet Clones",
        "firstAuthor": "Mert Bulent Sariyildiz",
        "url": "https://arxiv.org/pdf/2212.08420",
        "dateSubmitted": "2022-12-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we answer part of this provocative question by investigating the need for real images when training models for ImageNet classification. Provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful these are for training classification models from scratch. We show that with minimal and class-agnostic prompt engineering, ImageNet clones are able to close a large part of the gap between models produced by synthetic images and models trained with real images, for the several standard classification benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhibit strong generalization properties and perform on par with models trained on real data for transfer. Project page: https://europe.naverlabs.com/imagenet-sd",
        "paperId": "466aed7471eefcb54bfc762ad009e7cd5e81a2b2"
    },
    {
        "title": "Digital Commons@Lindenwood University Digital Commons@Lindenwood University",
        "firstAuthor": "James Hutson",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The rapid development and adoption of generative artificial intelligence (AI) tools in the art and design education landscape have introduced both opportunities and challenges. This timely study addresses the need to effectively integrate these tools into the classroom while considering ethical implications and the importance of prompt engineering. By examining the iterative process of refining original ideas through multiple iterations, verbal expansion, and the use of OpenAI\u2019s DALL-E2 for generating diverse visual outcomes, researchers gain insights into the potential benefits and pitfalls of these tools in an educational context. Students in the digital at case study were taught prompt engineering techniques and were tasked with crafting multiple prompts, focusing on refining their ideas over time. Participants demonstrated an increased understanding of the potential and limitations of generative AI tools and how to manipulate subject matter for more effective results. The iterative process encouraged students to explore and experiment with their creative ideas, leading to a deeper understanding of the possibilities offered by AI tools. Despite acknowledging the ethical concerns regarding copyright and the potential replacement of artists, students appreciated the value of generative AI tools for enhancing their sketchbooks and ideation process. Through prompt engineering and iterative processes, students developed a more detail-oriented approach to their work. The challenge of using AI-generated images as final products was conceptually intriguing, requiring further investigation and consideration of the prompts. This study highlights the potential benefits and challenges of integrating generative AI tools into art and design classrooms, emphasizing the importance of prompt engineering, iterative processes, and ethical considerations as these technologies continue to evolve.",
        "paperId": "4748329434e481d5fb963e4a9c0759d33fd1bbf1"
    },
    {
        "title": "Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification",
        "firstAuthor": "Hengyu Luo",
        "url": "https://arxiv.org/pdf/2309.14779",
        "dateSubmitted": "2023-09-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this, We further validate the effectiveness of active few-shot sampling and the ensemble strategy in the prompt-learning pipeline that contribute to a remarkable performance gain. Besides, in zero-shot settings with a fixed model, we underscore a pivotal observation that, although the GPT-3.5-turbo equipped with around 154B parameters garners an accuracy of 55.16%, the power of well designed prompts becomes evident when the FLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achieves an accuracy exceeding 31% with the optimized prompt, a leap from its sub-18% performance with an unoptimized one. Our findings underscore the promise of prompt-learning in classification tasks with SLMs, emphasizing the benefits of active few-shot sampling, and ensemble strategies in few-shot settings, and the importance of prompt engineering in zero-shot settings.",
        "paperId": "47d04bcfe0f1bed72d03c68cce76b4cf4be03f11"
    },
    {
        "title": "Prompting Is All You Need: Automated Android Bug Replay with Large Language Models",
        "firstAuthor": "Sidong Feng",
        "url": null,
        "dateSubmitted": "2023-06-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using the software. As such, researchers have committed considerable resources toward automating bug replay to expedite the process of software maintenance. Nonetheless, the success of current automated approaches is largely dictated by the characteristics and quality of bug reports, as they are constrained by the limitations of manually-crafted patterns and pre-defined vocabulary lists. Inspired by the success of Large Language Models (LLMs) in natural language understanding, we propose AdbGPT, a new lightweight approach to automatically reproduce the bugs from bug reports through prompt engineering, without any training and hard-coding effort. AdbGPT leverages few-shot learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning from LLMs to accomplish the bug replay in a manner similar to a developer. Our evaluations demonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3% of bug reports in 253.6 seconds, outperforming the state-of-the-art baselines and ablation studies. We also conduct a small-scale user study to confirm the usefulness of AdbGPT in enhancing developers' bug replay capabilities.",
        "paperId": "48385ded07af641da331c05f6ea3f93694a08425"
    },
    {
        "title": "TagGPT: Large Language Models are Zero-shot Multimodal Taggers",
        "firstAuthor": "Chen Li",
        "url": "http://arxiv.org/pdf/2304.03022",
        "dateSubmitted": "2023-04-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT.",
        "paperId": "4895d443c36bd136a818be2db34442354ba408d1"
    },
    {
        "title": "Human-in-the-loop Machine Translation with Large Language Model",
        "firstAuthor": "Xinyi Yang",
        "url": "https://arxiv.org/pdf/2310.08908",
        "dateSubmitted": "2023-10-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The large language model (LLM) has garnered significant attention due to its in-context learning mechanisms and emergent capabilities. The research community has conducted several pilot studies to apply LLMs to machine translation tasks and evaluate their performance from diverse perspectives. However, previous research has primarily focused on the LLM itself and has not explored human intervention in the inference process of LLM. The characteristics of LLM, such as in-context learning and prompt engineering, closely mirror human cognitive abilities in language tasks, offering an intuitive solution for human-in-the-loop generation. In this study, we propose a human-in-the-loop pipeline that guides LLMs to produce customized outputs with revision instructions. The pipeline initiates by prompting the LLM to produce a draft translation, followed by the utilization of automatic retrieval or human feedback as supervision signals to enhance the LLM\u2019s translation through in-context learning. The human-machine interactions generated in this pipeline are also stored in an external database to expand the in-context retrieval database, enabling us to leverage human supervision in an offline setting. We evaluate the proposed pipeline using the GPT-3.5-turbo API on five domain-specific benchmarks for German-English translation. The results demonstrate the effectiveness of the pipeline in tailoring in-domain translations and improving translation performance compared to direct translation instructions. Additionally, we discuss the experimental results from the following perspectives: 1) the effectiveness of different in-context retrieval methods; 2) the construction of a retrieval database under low-resource scenarios; 3) the observed differences across selected domains; 4) the quantitative analysis of sentence-level and word-level statistics; and 5) the qualitative analysis of representative translation cases.",
        "paperId": "4950bf6f873ba1409a7bbad25cf5c93c8f833453"
    },
    {
        "title": "Game of Tones: Faculty detection of GPT-4 generated content in university assessments",
        "firstAuthor": "Mike Perkins",
        "url": "https://arxiv.org/pdf/2305.18081",
        "dateSubmitted": "2023-05-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "496dab67b98785b46867173f0d777eaa9a32ca9c"
    },
    {
        "title": "Large Language Model for Multi-objective Evolutionary Optimization",
        "firstAuthor": "Fei Liu",
        "url": null,
        "dateSubmitted": "2023-10-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the search operators need a carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well on new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose a new version of decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on different test benchmarks show that our proposed method can achieve competitive performance with widely used MOEAs. It is also promising to see the operator only learned from a few instances can have robust generalization performance on unseen problems with quite different patterns and settings. The results reveal the potential benefits of using pre-trained LLMs in the design of MOEAs.",
        "paperId": "49f302e9a76eb39c88fcd861bdd0d954bd3d76b0"
    },
    {
        "title": "CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought",
        "firstAuthor": "Bowen Zhang",
        "url": "https://arxiv.org/pdf/2309.11143",
        "dateSubmitted": "2023-09-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Unsupervised sentence representation learning aims to transform input sentences into fixed-length vectors enriched with intricate semantic information while obviating the reliance on labeled data. Recent progress within this field, propelled by contrastive learning and prompt engineering, has significantly bridged the gap between unsupervised and supervised strategies. Nonetheless, the potential utilization of Chain-of-Thought, remains largely untapped within this trajectory. To unlock latent capabilities within pre-trained models, such as BERT, we propose a two-stage approach for sentence representation: comprehension and summarization. Subsequently, the output of the latter phase is harnessed as the vectorized representation of the input sentence. For further performance enhancement, we meticulously refine both the contrastive learning loss function and the template denoising technique for prompt engineering. Rigorous experimentation substantiates our method, CoT-BERT, transcending a suite of robust baselines without necessitating other text representation models or external databases.",
        "paperId": "4a99a85f071e67bf15ae4bc53ec37af28b650ec4"
    },
    {
        "title": "Contextualizing Problems to Student Interests at Scale in Intelligent Tutoring System Using Large Language Models",
        "firstAuthor": "Gautam Yadav",
        "url": "http://arxiv.org/pdf/2306.00190",
        "dateSubmitted": "2023-05-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Contextualizing problems to align with student interests can significantly improve learning outcomes. However, this task often presents scalability challenges due to resource and time constraints. Recent advancements in Large Language Models (LLMs) like GPT-4 offer potential solutions to these issues. This study explores the ability of GPT-4 in the contextualization of problems within CTAT, an intelligent tutoring system, aiming to increase student engagement and enhance learning outcomes. Through iterative prompt engineering, we achieved meaningful contextualization that preserved the difficulty and original intent of the problem, thereby not altering values or overcomplicating the questions. While our research highlights the potential of LLMs in educational settings, we acknowledge current limitations, particularly with geometry problems, and emphasize the need for ongoing evaluation and research. Future work includes systematic studies to measure the impact of this tool on students' learning outcomes and enhancements to handle a broader range of problems.",
        "paperId": "4b6df5f9885c9dc0ce3125791fd01824e3cf37b7"
    },
    {
        "title": "Backdoor Attacks for In-Context Learning with Language Models",
        "firstAuthor": "Nikhil Kandpal",
        "url": "https://arxiv.org/pdf/2307.14692",
        "dateSubmitted": "2023-07-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Because state-of-the-art language models are expensive to train, most practitioners must make use of one of the few publicly available language models or language model APIs. This consolidation of trust increases the potency of backdoor attacks, where an adversary tampers with a machine learning model in order to make it perform some malicious behavior on inputs that contain a predefined backdoor trigger. We show that the in-context learning ability of large language models significantly complicates the question of developing backdoor attacks, as a successful backdoor must work against various prompting strategies and should not affect the model's general purpose capabilities. We design a new attack for eliciting targeted misclassification when language models are prompted to perform a particular target task and demonstrate the feasibility of this attack by backdooring multiple large language models ranging in size from 1.3 billion to 6 billion parameters. Finally we study defenses to mitigate the potential harms of our attack: for example, while in the white-box setting we show that fine-tuning models for as few as 500 steps suffices to remove the backdoor behavior, in the black-box setting we are unable to develop a successful defense that relies on prompt engineering alone.",
        "paperId": "4d21debb0f5fec315181e0912b5105c6ce4fc67f"
    },
    {
        "title": "Optimizing Prompts for Text-to-Image Generation",
        "firstAuthor": "Y. Hao",
        "url": "http://arxiv.org/pdf/2212.09611",
        "dateSubmitted": "2022-12-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Well-designed prompts can guide text-to-image models to generate amazing images. However, the performant prompts are often model-specific and misaligned with user input. Instead of laborious human engineering, we propose prompt adaptation, a general framework that automatically adapts original user input to model-preferred prompts. Specifically, we first perform supervised fine-tuning with a pretrained language model on a small collection of manually engineered prompts. Then we use reinforcement learning to explore better prompts. We define a reward function that encourages the policy to generate more aesthetically pleasing images while preserving the original user intentions. Experimental results on Stable Diffusion show that our method outperforms manual prompt engineering in terms of both automatic metrics and human preference ratings. Moreover, reinforcement learning further boosts performance, especially on out-of-domain prompts. The pretrained checkpoints are available at https://aka.ms/promptist. The demo can be found at https://aka.ms/promptist-demo.",
        "paperId": "4d81c33b295c092016ac236cfd32020a5bb70b97"
    },
    {
        "title": "Is GPT a Computational Model of Emotion? Detailed Analysis",
        "firstAuthor": "Ala Nekouvaght Tak",
        "url": "https://arxiv.org/pdf/2307.13779",
        "dateSubmitted": "2023-07-25",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective.",
        "paperId": "4dd461b2392a6983d36618744d2384349c4170f9"
    },
    {
        "title": "A Lightweight Framework for High-Quality Code Generation",
        "firstAuthor": "Mohammed Latif Siddiq",
        "url": "https://arxiv.org/pdf/2307.08220",
        "dateSubmitted": "2023-07-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In recent years, the use of automated source code generation utilizing transformer-based generative models has expanded, and these models can generate functional code according to the requirements of the developers. However, recent research revealed that these automatically generated source codes can contain vulnerabilities and other quality issues. Despite researchers' and practitioners' attempts to enhance code generation models, retraining and fine-tuning large language models is time-consuming and resource-intensive. Thus, we describe FRANC, a lightweight framework for recommending more secure and high-quality source code derived from transformer-based code generation models. FRANC includes a static filter to make the generated code compilable with heuristics and a quality-aware ranker to sort the code snippets based on a quality score. Moreover, the framework uses prompt engineering to fix persistent quality issues. We evaluated the framework with five Python and Java code generation models and six prompt datasets, including a newly created one in this work (SOEval). The static filter improves 9% to 46% Java suggestions and 10% to 43% Python suggestions regarding compilability. The average improvement over the NDCG@10 score for the ranking system is 0.0763, and the repairing techniques repair the highest 80% of prompts. FRANC takes, on average, 1.98 seconds for Java; for Python, it takes 0.08 seconds.",
        "paperId": "4e96d7fa9f27857523d786230294fbcc6060212c"
    },
    {
        "title": "The Art and Science of Prompt Engineering: A New Literacy in the Information Age",
        "firstAuthor": "Leo S. Lo",
        "url": null,
        "dateSubmitted": "2023-06-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "4f89e51a8bb10ad7c90d31b01bef61ae2c0dbd7b"
    },
    {
        "title": "Text2Cohort: Democratizing the NCI Imaging Data Commons with Natural Language Cohort Discovery",
        "firstAuthor": "Pranav Kulkarni",
        "url": "http://arxiv.org/pdf/2305.07637",
        "dateSubmitted": "2023-05-12",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The Imaging Data Commons (IDC) is a cloud-based database that provides researchers with open access to cancer imaging data, with the goal of facilitating collaboration in medical imaging research. However, querying the IDC database for cohort discovery and access to imaging data has a significant learning curve for researchers due to its complex nature. We developed Text2Cohort, a large language model (LLM) based toolkit to facilitate user-friendly and intuitive natural language cohort discovery in the IDC. Text2Cohorts translates user input into IDC database queries using prompt engineering and autocorrection and returns the query's response to the user. Autocorrection resolves errors in queries by passing the errors back to the model for interpretation and correction. We evaluate Text2Cohort on 50 natural language user inputs ranging from information extraction to cohort discovery. The resulting queries and outputs were verified by two computer scientists to measure Text2Cohort's accuracy and F1 score. Text2Cohort successfully generated queries and their responses with an 88% accuracy and F1 score of 0.94. However, it failed to generate queries for 6/50 (12%) user inputs due to syntax and semantic errors. Our results indicate that Text2Cohort succeeded at generating queries with correct responses, but occasionally failed due to a lack of understanding of the data schema. Despite these shortcomings, Text2Cohort demonstrates the utility of LLMs to enable researchers to discover and curate cohorts using data hosted on IDC with high levels of accuracy using natural language in a more intuitive and user-friendly way.",
        "paperId": "4ff0fccc922f9da7c818c86c8a13aef23ea08345"
    },
    {
        "title": "LLMs Killed the Script Kiddie: How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing",
        "firstAuthor": "Stephen Moskal",
        "url": "https://arxiv.org/pdf/2310.06936",
        "dateSubmitted": "2023-10-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this paper, we explore the potential of Large Language Models (LLMs) to reason about threats, generate information about tools, and automate cyber campaigns. We begin with a manual exploration of LLMs in supporting specific threat-related actions and decisions. We proceed by automating the decision process in a cyber campaign. We present prompt engineering approaches for a plan-act-report loop for one action of a threat campaign and and a prompt chaining design that directs the sequential decision process of a multi-action campaign. We assess the extent of LLM's cyber-specific knowledge w.r.t the short campaign we demonstrate and provide insights into prompt design for eliciting actionable responses. We discuss the potential impact of LLMs on the threat landscape and the ethical considerations of using LLMs for accelerating threat actor capabilities. We report a promising, yet concerning, application of generative AI to cyber threats. However, the LLM's capabilities to deal with more complex networks, sophisticated vulnerabilities, and the sensitivity of prompts are open questions. This research should spur deliberations over the inevitable advancements in LLM-supported cyber adversarial landscape.",
        "paperId": "50aaac5fdc2b5a33bfd3ba93cdf4e5e302f34297"
    },
    {
        "title": "Interactive Task Planning with Language Models",
        "firstAuthor": "Boyi Li",
        "url": null,
        "dateSubmitted": "2023-10-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution. However, most traditional methods require predefined module design, which makes it hard to generalize to different goals. Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain-specific pretrained models. To tackle this, we propose a simple framework that achieves interactive task planning with language models. Our system incorporates both high-level planning and low-level function execution via language. We verify the robustness of our system in generating novel high-level instructions for unseen objectives and its ease of adaptation to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering. Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps. Please check more details on our https://wuphilipp.github.io/itp_site and https://youtu.be/TrKLuyv26_g.",
        "paperId": "50b59143bf3469f082b2308fa394bb6d55091a41"
    },
    {
        "title": "Zero-shot Nuclei Detection via Visual-Language Pre-trained Models",
        "firstAuthor": "Yongjian Wu",
        "url": "http://arxiv.org/pdf/2306.17659",
        "dateSubmitted": "2023-06-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large-scale visual-language pre-trained models (VLPM) have proven their excellent performance in downstream object detection for natural scenes. However, zero-shot nuclei detection on H\\&E images via VLPMs remains underexplored. The large gap between medical images and the web-originated text-image pairs used for pre-training makes it a challenging task. In this paper, we attempt to explore the potential of the object-level VLPM, Grounded Language-Image Pre-training (GLIP) model, for zero-shot nuclei detection. Concretely, an automatic prompts design pipeline is devised based on the association binding trait of VLPM and the image-to-text VLPM BLIP, avoiding empirical manual prompts engineering. We further establish a self-training framework, using the automatically designed prompts to generate the preliminary results as pseudo labels from GLIP and refine the predicted boxes in an iterative manner. Our method achieves a remarkable performance for label-free nuclei detection, surpassing other comparison methods. Foremost, our work demonstrates that the VLPM pre-trained on natural image-text pairs exhibits astonishing potential for downstream tasks in the medical field as well. Code will be released at https://github.com/wuyongjianCODE/VLPMNuD.",
        "paperId": "50bbca86de82d6b72d92bba0ec988b58e644dac3"
    },
    {
        "title": "GPTCloneBench: A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench",
        "firstAuthor": "A. Alam",
        "url": "https://arxiv.org/pdf/2308.13963",
        "dateSubmitted": "2023-08-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "With the emergence of Machine Learning, there has been a surge in leveraging its capabilities for problem-solving across various domains. In the code clone realm, the identification of type-4 or semantic clones has emerged as a crucial yet challenging task. Researchers aim to utilize Machine Learning to tackle this challenge, often relying on the BigCloneBench dataset. However, it's worth noting that BigCloneBench, originally not designed for semantic clone detection, presents several limitations that hinder its suitability as a comprehensive training dataset for this specific purpose. Furthermore, CLCDSA dataset suffers from a lack of reusable examples aligning with real-world software systems, rendering it inadequate for cross-language clone detection approaches. In this work, we present a comprehensive semantic clone and cross-language clone benchmark, GPTCloneBench by exploiting SemanticCloneBench and OpenAI's GPT-3 model. In particular, using code fragments from SemanticCloneBench as sample inputs along with appropriate prompt engineering for GPT-3 model, we generate semantic and cross-language clones for these specific fragments and then conduct a combination of extensive manual analysis, tool-assisted filtering, functionality testing and automated validation in building the benchmark. From 79,928 clone pairs of GPT-3 output, we created a benchmark with 37,149 true semantic clone pairs, 19,288 false semantic pairs(Type-1/Type-2), and 20,770 cross-language clones across four languages (Java, C, C#, and Python). Our benchmark is 15-fold larger than SemanticCloneBench, has more functional code examples for software systems and programming language support than CLCDSA, and overcomes BigCloneBench's qualities, quantification, and language variety limitations.",
        "paperId": "50d40d05598e456188a3be42983b8daabd3f04f7"
    },
    {
        "title": "From Web Catalogs to Google: A Retrospective Study of Web Search Engines Sustainable Development",
        "firstAuthor": "M. Duka",
        "url": "https://www.mdpi.com/2071-1050/15/8/6768/pdf?version=1681779086",
        "dateSubmitted": "2023-04-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study presents a review of search engines and search engine optimization and shows how the search engine landscape relates to sustainable development. We have used a narrative review research method and described three main topics: the past and present of web catalogs and search engines; current knowledge about the dominant types of search results presented in Google search; and methods of search engine optimization. Technical elements of important website areas related to technical website auditing are discussed. We summarize our research with several key findings on how web search engines are involved in sustainable development and offer a glimpse into the future use of web searching with the help of artificial intelligence chats and prompt engineering.",
        "paperId": "513b96c7d5d1f9a74afd9d946d5a7c83fe592869"
    },
    {
        "title": "ChatGPT-Based Debate Game Application Utilizing Prompt Engineering",
        "firstAuthor": "Eunyul Lee",
        "url": null,
        "dateSubmitted": "2023-08-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper1 focuses on the implementation of a debate game using ChatGPT, aiming to investigate the feasibility of incorporating large language models into the educational domain through prompt engineering. The study explores strategies to elicit desired outputs from the GPT model by employing the prompt engineering methodology, as provided by Microsoft. Specifically, the game implementation involves the customization of ChatGPT's responses to facilitate a natural progression of debates, varying levels of difficulty, and an evaluation system for assessing the quality of discourse. By leveraging the prompt engineering methodology, we demonstrate that providing specific instructions or case-based prompts improves the accuracy and relevance of ChatGPT's answers. The developed application targets teenagers, enabling them to engage in real-time debates with ChatGPT and enhance their literacy skills. Furthermore, the game fosters the development of logical reasoning, persuasive abilities, effective expression, active participation, and attentive listening while expressing personal opinions, ultimately fostering a sense of accomplishment. Moreover, through debate evaluation and personalized advice, ChatGPT is expected to recognize and address its shortcomings, thereby continuously improving its conversational capabilities. Overall, this research contributes to the understanding of how large language models can be harnessed in educational settings and underscores the potential benefits of prompt engineering techniques in optimizing the outputs of such models.",
        "paperId": "51630e94d13c6af1ce86aa0a654ded7d78e7e49f"
    },
    {
        "title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models",
        "firstAuthor": "Peter West",
        "url": "https://aclanthology.org/2022.naacl-main.341.pdf",
        "dateSubmitted": "2021-10-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The common practice for training commonsense models has gone from\u2013human\u2013to\u2013corpus\u2013to\u2013machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from\u2013machine\u2013to\u2013corpus\u2013to\u2013machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al. 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically\u2013as text\u2013in addition to the neural model. We distill only one aspect\u2013the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model\u2019s commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and will share our new symbolic knowledge graph and commonsense models.",
        "paperId": "521ccc898395a2818fced22b4cf371b0e5121f94"
    },
    {
        "title": "Can Prompt Learning Benefit Radiology Report Generation?",
        "firstAuthor": "Jun Wang",
        "url": "https://arxiv.org/pdf/2308.16269",
        "dateSubmitted": "2023-08-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Radiology report generation aims to automatically provide clinically meaningful descriptions of radiology images such as MRI and X-ray. Although great success has been achieved in natural scene image captioning tasks, radiology report generation remains challenging and requires prior medical knowledge. In this paper, we propose PromptRRG, a method that utilizes prompt learning to activate a pretrained model and incorporate prior knowledge. Since prompt learning for radiology report generation has not been explored before, we begin with investigating prompt designs and categorise them based on varying levels of knowledge: common, domain-specific and disease-enriched prompts. Additionally, we propose an automatic prompt learning mechanism to alleviate the burden of manual prompt engineering. This is the first work to systematically examine the effectiveness of prompt learning for radiology report generation. Experimental results on the largest radiology report generation benchmark, MIMIC-CXR, demonstrate that our proposed method achieves state-of-the-art performance. Code will be available upon the acceptance.",
        "paperId": "531678c18fd2c5a9620b68f3550131fc3fd3636c"
    },
    {
        "title": "Just Tell Me: Prompt Engineering in Business Process Management",
        "firstAuthor": "Kiran Busch",
        "url": "http://arxiv.org/pdf/2304.07183",
        "dateSubmitted": "2023-04-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization. Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text. This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data. A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them. Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research. We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges.",
        "paperId": "53e7475a3ed0caee37122a9dbdb53d1da0691a33"
    },
    {
        "title": "Be-or-Not Prompt Enhanced Hard Negatives Generating For Memes Category Detection",
        "firstAuthor": "Jian Cui",
        "url": null,
        "dateSubmitted": "2023-07-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Memes are one of the most popular social media in online disinformation campaigns. Their creators often use a variety of rhetoric and psychological skills to achieve the purpose of misinformed audiences. These characteristics lead to the unsatisfactory performance of memes category detection tasks, such as predicting propaganda techniques, being harmful or not, and so on. To this end, we propose a novel memes category detection model via Be-or-Not Prompt Enhanced hard Negatives generating (BNPEN). Firstly, our BNPEN is reformulated into a contrastive learning-based image-text matching (ITM) task through category-padded prompt engineering. Secondly, we design the be-or-not prompt templates to keep the writing style of memes and create hard negative image-text pairs. Finally, our negatives generating can alleviate the negative-positive-coupling (NPC) effects in contrastive learning, thus improving the image-text matching quality. Conducted on two public datasets, experimental results show that our BNPEN is better than the off-the-shelf multi-modal learning models in terms of F1 and Accuracy measures.",
        "paperId": "54c57d23ce1b3e4d4bed15d2f9f4f665d4753ebd"
    },
    {
        "title": "A Novel Framework leveraging Prompt Engineering and the Grey-Based Approach\u2013 A case study in Libya",
        "firstAuthor": "Ali M. Abdulshahed",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "553bcf2ade3d2122c91980fca910152e1d30a0ff"
    },
    {
        "title": "Prompt position really matters in few-shot and zero-shot NLU tasks",
        "firstAuthor": "Junyu Mao",
        "url": "https://arxiv.org/pdf/2305.14493",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt-based models have made remarkable advancements in the fields of zero-shot and few-shot learning, attracting a lot of attention from researchers. Developing an effective prompt template plays a critical role. However, prior studies have mainly focused on prompt vocabulary selection or embedding initialization with the reserved prompt position fixed. In this empirical study, we conduct the most comprehensive analysis to date of prompt position option for natural language understanding tasks. Our findings quantify the substantial impact prompt position has on model performance. We observe that the prompt position used in prior studies is often sub-optimal for both zero-shot and few-shot settings. These findings suggest prompt position optimisation as an interesting research direction alongside the existing focus on prompt engineering.",
        "paperId": "56a9c96a29f4047be8465244576d731f0df2d9df"
    },
    {
        "title": "I Was Blind but Now I See: Implementing Vision-Enabled Dialogue in Social Robots",
        "firstAuthor": "Giulio Antonio Abbo",
        "url": null,
        "dateSubmitted": "2023-11-15",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In the rapidly evolving landscape of human-computer interaction, the integration of vision capabilities into conversational agents stands as a crucial advancement. This paper presents an initial implementation of a dialogue manager that leverages the latest progress in Large Language Models (e.g., GPT-4, IDEFICS) to enhance the traditional text-based prompts with real-time visual input. LLMs are used to interpret both textual prompts and visual stimuli, creating a more contextually aware conversational agent. The system's prompt engineering, incorporating dialogue with summarisation of the images, ensures a balance between context preservation and computational efficiency. Six interactions with a Furhat robot powered by this system are reported, illustrating and discussing the results obtained. By implementing this vision-enabled dialogue system, the paper envisions a future where conversational agents seamlessly blend textual and visual modalities, enabling richer, more context-aware dialogues.",
        "paperId": "56f77cc79143aecd677e52429fcfe50c8f47f01a"
    },
    {
        "title": "Situated Natural Language Explanations",
        "firstAuthor": "Zining Zhu",
        "url": "https://arxiv.org/pdf/2308.14115",
        "dateSubmitted": "2023-08-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Natural language is among the most accessible tools for explaining decisions to humans, and large pretrained language models (PLMs) have demonstrated impressive abilities to generate coherent natural language explanations (NLE). The existing NLE research perspectives do not take the audience into account. An NLE can have high textual quality, but it might not accommodate audiences' needs and preference. To address this limitation, we propose an alternative perspective, situated NLE, including a situated generation framework and a situated evaluation framework. On the generation side, we propose simple prompt engineering methods that adapt the NLEs to situations. In human studies, the annotators preferred the situated NLEs. On the evaluation side, we set up automated evaluation scores in lexical, semantic, and pragmatic categories. The scores can be used to select the most suitable prompts to generate NLEs. Situated NLE provides a perspective to conduct further research on automatic NLE generations.",
        "paperId": "57404bd8c71e2b17fce63b49229b278b6a66bf13"
    },
    {
        "title": "Better Integrating Vision and Semantics for Improving Few-shot Classification",
        "firstAuthor": "Zhuoling Li",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3581783.3613819",
        "dateSubmitted": "2023-10-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Some recent methods address few-shot classification by integrating visual and semantic prototypes. However, they usually ignore the difference in feature structure between the visual and semantic modalities, which leads to limited performance improvements. In this paper, we propose a novel method, called bimodal integrator (BMI), to better integrate visual and semantic prototypes. In BMI, we first construct a latent space for each modality via a variational autoencoder, and then align the semantic latent space to the visual latent space. Through this semantics-to-vision alignment, the semantic modality is mapped to the visual latent space and has the same feature structure as the visual modality. As a result, the visual and semantic prototypes can be better integrated. In addition, based on the multivariate Gaussian distribution and the prompt engineering, a data augmentation scheme is designed to ensure the accuracy of modality alignment during the training process. Experimental results demonstrate that BMI significantly improves few-shot classification, making simple baselines outperform the most advanced methods on miniImageNet and tieredImageNet datasets.",
        "paperId": "579ee305d538a679d72b808ffe8322680561a177"
    },
    {
        "title": "What's the Magic Word? A Control Theory of LLM Prompting",
        "firstAuthor": "Aman Bhargava",
        "url": "https://arxiv.org/pdf/2310.04444",
        "dateSubmitted": "2023-10-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt engineering is effective and important in the deployment of LLMs but is poorly understood mathematically. Here, we formalize prompt engineering as an optimal control problem on LLMs -- where the prompt is considered a control variable for modulating the output distribution of the LLM. Within this framework, we ask a simple question: given a sequence of tokens, does there always exist a prompt we can prepend that will steer the LLM toward accurately predicting the final token? We call such an optimal prompt the magic word since prepending the prompt causes the LLM to output the correct answer. If magic words exist, can we find them? If so, what are their properties? We offer analytic analysis on the controllability of the self-attention head where we prove a bound on controllability as a function of the singular values of its weight matrices. We take inspiration from control theory to propose a metric called $k-\\epsilon$ controllability to characterize LLM steerability. We compute the $k-\\epsilon$ controllability of a panel of large language models, including Falcon-7b, Llama-7b, and Falcon-40b on 5000 WikiText causal language modeling tasks. Remarkably, we find that magic words of 10 tokens or less exist for over 97% of WikiText instances surveyed for each model.",
        "paperId": "57a4f8f69908d3474565d3cd6f58b1ca651ff673"
    },
    {
        "title": "Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering",
        "firstAuthor": "Han Zhou",
        "url": "https://arxiv.org/pdf/2309.17249",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompting and in-context learning (ICL) have become efficient learning paradigms for large language models (LLMs). However, LLMs suffer from prompt brittleness and various bias factors in the prompt, including but not limited to the formatting, the choice verbalizers, and the ICL examples. To address this problem that results in unexpected performance degradation, calibration methods have been developed to mitigate the effects of these biases while recovering LLM performance. In this work, we first conduct a systematic analysis of the existing calibration methods, where we both provide a unified view and reveal the failure cases. Inspired by these analyses, we propose Batch Calibration (BC), a simple yet intuitive method that controls the contextual bias from the batched input, unifies various prior approaches, and effectively addresses the aforementioned issues. BC is zero-shot, inference-only, and incurs negligible additional costs. In the few-shot setup, we further extend BC to allow it to learn the contextual bias from labeled data. We validate the effectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate state-of-the-art performance over previous calibration baselines across more than 10 natural language understanding and image classification tasks.",
        "paperId": "57bb978b8075fd5701a61770c5ee7244c414e8fd"
    },
    {
        "title": "OmniscientDB: A Large Language Model-Augmented DBMS That Knows What Other DBMSs Do Not Know",
        "firstAuthor": "Matthias Urban",
        "url": "http://publikationen.ub.uni-frankfurt.de/files/74426/06_08.pdf",
        "dateSubmitted": "2023-06-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this paper, we present our vision of OmniscientDB, a novel database that leverages the implicitly-stored knowledge in large language models to augment datasets for analytical queries or even machine learning tasks. OmiscientDB empowers its users to augment their datasets by means of simple SQL queries and thus has the potential to dramatically reduce the manual overhead associated with data integration. It uses automatic prompt engineering to construct appropriate prompts for given SQL queries and passes them to a large language model like GPT-3 to contribute additional data (i.e., new rows, columns, or entire tables), augmenting the explicitly stored data. Our initial evaluation demonstrates the general feasibility of our vision, explores different prompting techniques in greater detail, and points towards several directions for future research.",
        "paperId": "59266e06cdb867c2541603f9d94e13f67d55938f"
    },
    {
        "title": "Prompt Engineering or Fine Tuning: An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks",
        "firstAuthor": "Jiho Shin",
        "url": null,
        "dateSubmitted": "2023-10-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this paper, we investigate the effectiveness of state-of-the-art LLM, i.e., GPT-4, with three different prompting engineering techniques (i.e., basic prompting, in-context learning, and task-specific prompting) against 18 fine-tuned LLMs on three typical ASE tasks, i.e., code generation, code summarization, and code translation. Our quantitative analysis of these prompting strategies suggests that prompt engineering GPT-4 cannot necessarily and significantly outperform fine-tuning smaller/older LLMs in all three tasks. For comment generation, GPT-4 with the best prompting strategy (i.e., task-specific prompt) had outperformed the first-ranked fine-tuned model by 8.33% points on average in BLEU. However, for code generation, the first-ranked fine-tuned model outperforms GPT-4 with best prompting by 16.61% and 28.3% points, on average in BLEU. For code translation, GPT-4 and fine-tuned baselines tie as they outperform each other on different translation tasks. To explore the impact of different prompting strategies, we conducted a user study with 27 graduate students and 10 industry practitioners. From our qualitative analysis, we find that the GPT-4 with conversational prompts (i.e., when a human provides feedback and instructions back and forth with a model to achieve best results) showed drastic improvement compared to GPT-4 with automatic prompting strategies. Moreover, we observe that participants tend to request improvements, add more context, or give specific instructions as conversational prompts, which goes beyond typical and generic prompting strategies. Our study suggests that, at its current state, GPT-4 with conversational prompting has great potential for ASE tasks, but fully automated prompt engineering with no human in the loop requires more study and improvement.",
        "paperId": "59e0e0c1aa06d51430792eb5d8308911a1b0110f"
    },
    {
        "title": "Large Language Models (LLMs) for Natural Language Processing (NLP) of Oil and Gas Drilling Data",
        "firstAuthor": "Prateek Kumar",
        "url": null,
        "dateSubmitted": "2023-10-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\n In the oil and gas industry, drilling activities spawn substantial volumes of unstructured textual data. The examination and interpretation of these data pose significant challenges. This research exploits the emerging capabilities of large language models (LLMs) with over 100 billion parameters to extract actionable insights from raw drilling data. Through fine-tuning methodologies and the use of various prompt engineering strategies, we addressed several text downstream tasks, including summarization, classification, entity recognition, and information extraction. This study delves into our methods, findings, and the novel application of LLMs for efficient and precise analysis of drilling data.",
        "paperId": "5a4b8c44870df919956c1710237f11b5bc1f56b8"
    },
    {
        "title": "Towards Interpretable Mental Health Analysis with ChatGPT",
        "firstAuthor": "Kailai Yang",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Automated mental health analysis shows great potential for enhancing the ef\ufb01ciency and accessibility of mental health care, with recent methods using pre-trained language models (PLMs) and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on Chat-GPT for mental health analysis bear limitations in inadequate evaluations, ignorance of emotional information, and lack of explain-ability. To bridge these gaps, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, and analyze the effects of various emotion-based prompting strategies. Based on these prompts, we further explore LLMs for interpretable mental health analysis by instructing them to also generate explanations for each of their decisions. With an annotation protocol designed by domain experts, we convey human evaluations to assess the quality of explanations generated by Chat-GPT and GPT-3. The annotated corpus will be released for future research. Experimental results show that ChatGPT outperforms traditional neural network-based methods but still has a signi\ufb01cant gap with advanced task-speci\ufb01c methods. Prompt engineering with emotional cues can be effective in improving performance on mental health analysis but suffers from a lack of robustness and inaccurate reasoning. In addition, ChatGPT signi\ufb01cantly outperforms GPT-3 on all criteria in human evaluations of the explanations and approaches to human performance, showing its great potential in explainable mental health analysis.",
        "paperId": "5aaa39b360c39e8a43957e688d7adf549b1e95e5"
    },
    {
        "title": "Frog After Frog: Prompt Engineering With Alternate Translations",
        "firstAuthor": "Seong-Young Her",
        "url": null,
        "dateSubmitted": "2023-09-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "5b4fa92989ceebb4bea2838619ee1c4dccb358c3"
    },
    {
        "title": "Evaluation of prompt engineering strategies for pharmacokinetic data analysis with the ChatGPT large language model.",
        "firstAuthor": "Euibeom Shin",
        "url": null,
        "dateSubmitted": "2023-11-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "5bfd50eb6d5cd6365d98c640c2fc79fdee8281c0"
    },
    {
        "title": "GPTutor: an open-source AI pair programming tool alternative to Copilot",
        "firstAuthor": "Eason Chen",
        "url": null,
        "dateSubmitted": "2023-10-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents the latest progress of GPTutor: a ChatGPT-powered programming tool extension in Visual Studio Code. The emergence of Large Language Models (LLMs) has improved software development efficiency, but their performance can be hindered by training data limitations and prompt design issues. Existing LLM development tools often operate as black boxes, with users unable to view the prompts used and unable to improve performance by correcting prompts when errors occur. To address the aforementioned issues, GPTutor was introduced as an open-source AI pair programming tool, offering an alternative to Copilot. GPTutor empowers users to customize prompts for various programming languages and scenarios, with support for 120+ human languages and 50+ programming languages. Users can fine-tune prompts to correct the errors from LLM for precision and efficient code generation. At the end of the paper, we underscore GPTutor's potential through examples, including demonstrating its proficiency in interpreting and generating Sui-Move, a newly introduced smart contract language, using prompt engineering.",
        "paperId": "5cadd5902f0335767e4cd95abb91fbf73d2d431c"
    },
    {
        "title": "JVNV: A Corpus of Japanese Emotional Speech with Verbal Content and Nonverbal Expressions",
        "firstAuthor": "Detai Xin",
        "url": "https://arxiv.org/pdf/2310.06072",
        "dateSubmitted": "2023-10-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We present the JVNV, a Japanese emotional speech corpus with verbal content and nonverbal vocalizations whose scripts are generated by a large-scale language model. Existing emotional speech corpora lack not only proper emotional scripts but also nonverbal vocalizations (NVs) that are essential expressions in spoken language to express emotions. We propose an automatic script generation method to produce emotional scripts by providing seed words with sentiment polarity and phrases of nonverbal vocalizations to ChatGPT using prompt engineering. We select 514 scripts with balanced phoneme coverage from the generated candidate scripts with the assistance of emotion confidence scores and language fluency scores. We demonstrate the effectiveness of JVNV by showing that JVNV has better phoneme coverage and emotion recognizability than previous Japanese emotional speech corpora. We then benchmark JVNV on emotional text-to-speech synthesis using discrete codes to represent NVs. We show that there still exists a gap between the performance of synthesizing read-aloud speech and emotional speech, and adding NVs in the speech makes the task even harder, which brings new challenges for this task and makes JVNV a valuable resource for relevant works in the future. To our best knowledge, JVNV is the first speech corpus that generates scripts automatically using large language models.",
        "paperId": "5ce2a1dc9dfa8b4f1368220ac7f7d30a395ffca9"
    },
    {
        "title": "Red Teaming Language Models with Language Models",
        "firstAuthor": "Ethan Perez",
        "url": "https://aclanthology.org/2022.emnlp-main.225.pdf",
        "dateSubmitted": "2022-02-07",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Language Models (LMs) often cannot be deployed because of their potential to harm users in hard-to-predict ways. Prior work identifies harmful behaviors before deployment by using human annotators to hand-write test cases. However, human annotation is expensive, limiting the number and diversity of test cases. In this work, we automatically find cases where a target LM behaves in a harmful way, by generating test cases (\u201cred teaming\u201d) using another LM. We evaluate the target LM\u2019s replies to generated test questions using a classifier trained to detect offensive content, uncovering tens of thousands of offensive replies in a 280B parameter LM chatbot. We explore several methods, from zero-shot generation to reinforcement learning, for generating test cases with varying levels of diversity and difficulty. Furthermore, we use prompt engineering to control LM-generated test cases to uncover a variety of other harms, automatically finding groups of people that the chatbot discusses in offensive ways, personal and hospital phone numbers generated as the chatbot\u2019s own contact info, leakage of private training data in generated text, and harms that occur over the course of a conversation. Overall, LM-based red teaming is one promising tool (among many needed) for finding and fixing diverse, undesirable LM behaviors before impacting users.",
        "paperId": "5d49c7401c5f2337c4cc88d243ae39ed659afe64"
    },
    {
        "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
        "firstAuthor": "Kailai Yang",
        "url": null,
        "dateSubmitted": "2023-04-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The latest large language models (LLMs) such as ChatGPT, exhibit strong capabilities in automated mental health analysis. However, existing relevant studies bear several limitations, including inadequate evaluations, lack of prompting strategies, and ignorance of exploring LLMs for explainability. To bridge these gaps, we comprehensively evaluate the mental health analysis and emotional reasoning ability of LLMs on 11 datasets across 5 tasks. We explore the effects of different prompting strategies with unsupervised and distantly supervised emotional information. Based on these prompts, we explore LLMs for interpretable mental health analysis by instructing them to generate explanations for each of their decisions. We convey strict human evaluations to assess the quality of the generated explanations, leading to a novel dataset with 163 human-assessed explanations. We benchmark existing automatic evaluation metrics on this dataset to guide future related works. According to the results, ChatGPT shows strong in-context learning ability but still has a significant gap with advanced task-specific methods. Careful prompt engineering with emotional cues and expert-written few-shot examples can also effectively improve performance on mental health analysis. In addition, ChatGPT generates explanations that approach human performance, showing its great potential in explainable mental health analysis.",
        "paperId": "5d879530c443dd06d3686f31d32cfe34c7ade9bc"
    },
    {
        "title": "EXPLORING THE DESIGN SPACE OF AI BASED CODE COMPLETION ENGINES",
        "firstAuthor": "Parth Thakkar",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Artificial Intelligence (AI) based code completion tools such as Github Copilot have recently gained tremendous popularity due to their ability to suggest arbitrary length snippets, improving developer productivity dramatically. However, there is little public understanding of what it takes to build such a tool. In this thesis, we explore the design space of building such a tool. We study the importance of the two key components of such a tool: the Large Language Model (LLM) that predicts the suggestions, and the system around it that feeds it the right context and filters out the bad suggestions. We start by exploring the design of Github Copilot to understand the state of the art, and describe the three key components of Copilot: Prompt Engineering, Model Invocation and Feedback loop. We then study the various factors that affect the quality of the suggestions generated by the LLM. We study both (a) the impact of the context fed to the LLM, and (b) the impact of the LLM itself. For the former, we study the impact including context from other files and code after the cursor along with different methods of context collection and amount of collected context. For the latter, we study the impact of the size of the LLM and the training procedure. Apart from factors affecting the quality of suggestions, we also study the factors affecting the latency of such code completion engines, as low latency is critical for building good code completion engines. We find that the context fed to the model makes a significant difference in the quality of generated suggestions, and good context collection can improve the quality of suggestions by 11-26% points (20-113% relative improvement) on the exact match metric for one line suggestions. Models that can exploit the context after the cursor can further improve the quality of suggestions by 6-14% points (12-16% relative improvement). Our experiments show that increasing the prompt length beyond a point does not improve suggestion quality significantly, and that 2048-4096 tokens are sufficient. We also find that the size of the LLM has a much smaller impact on the quality of suggestions than other factors such as the context fed to the model and the training procedure used. For example, we found that the SantaCoder model (1.1B parameters) provided better suggestions than the 16B CodeGen-Multi",
        "paperId": "5d9eede603ebe7c86882c38cc3f29acf1f4bb0cb"
    },
    {
        "title": "Trash to Treasure: Using text-to-image models to inform the design of physical artefacts",
        "firstAuthor": "Amy Smith",
        "url": "http://arxiv.org/pdf/2302.00561",
        "dateSubmitted": "2023-02-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-to-image generative models have recently exploded in popularity and accessibility. Yet so far, use of these models in creative tasks that bridge the 2D digital world and the creation of physical artefacts has been understudied. We conduct a pilot study to investigate if and how text-to-image models can be used to assist in upstream tasks within the creative process, such as ideation and visualization, prior to a sculpture-making activity. Thirty participants selected sculpture-making materials and generated three images using the Stable Diffusion text-to-image generator, each with text prompts of their choice, with the aim of informing and then creating a physical sculpture. The majority of participants (23/30) reported that the generated images informed their sculptures, and 28/30 reported interest in using text-to-image models to help them in a creative task in the future. We identify several prompt engineering strategies and find that a participant's prompting strategy relates to their stage in the creative process. We discuss how our findings can inform support for users at different stages of the design process and for using text-to-image models for physical artefact design.",
        "paperId": "5de60d53bce194b34dae1e531876af9acffba1a3"
    },
    {
        "title": "The Aleph & Other Metaphors for Image Generation",
        "firstAuthor": "Gonzalo A. Ramos",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this position paper, we reflect on fictional stories dealing with the infinite and how they connect with the current, fast-evolving field of image generation models. We draw attention to how some of these literary constructs can serve as powerful metaphors for guiding human-centered design and technical thinking in the space of these emerging technologies and the experiences we build around them. We hope our provocations seed conversations about current and yet-to-be developed interactions with these emerging models in ways that may amplify human agency. 1 Borges, infinites and latent spaces. The works of the writer Jorge Luis Borges often deal with fantastical and mathematical themes, and of these, notions about the infinite stand out with subtle connections to the fast-paced emergence of image generation models (IGMs) such as Dall-E 2, Stable Diffusion, and Imagen [10, 11, 12]. In El Aleph (1945) [2], we read about the existence of a space anomaly: \u201cthe Aleph\u201d, a point in space containing all other points. When looking at it, the protagonist of the story can see each thing in it as \u201cinfinite things, since I distinctly saw it from every angle of the universe\u201d. There are undeniable parallels between this concept and IGMs\u2019 latent spaces that have richly embedded semantic meaning for the visual spaces they encode. These spaces allow for computational variations of an image and also computational interpolations between the images themselves. In La Biblioteca de Babel (1941) [3], Borges makes us reflect about infinite spaces and the limits of human knowledge. \u201cBabel\u2019s Library\u201d is a universe, an infinite-size structure made of interconnected hexagonal galleries, each containing exactly 640 books, each written using a script consisting of 25 different characters. Borges provokes the reader by arguing that, because of the finite nature of human language, such a library must contain a finite number of sensical books 1. Somewhere within this vast collection of possible permutations, any story imaginable would be found, but the searching librarian is hopelessly lost among the magnitude of possibilities. There is now the provocation that IGMs may provide a computational mapping of the near-infinite possibilities of meaningful embeddings. El Libro de Arena (1941) [1] can be seen as a cautionary tale about the addictive perils of having access to an infinite generator of stories. The reader of this hypothetical book is ultimately horrified by it and decides to get rid of it, not by destroying it (burning an infinite book will suffocate the world), but by hiding it in a library\u2019s basement expressing \u201cthe best place to hide a leaf is in a forest\u201d. This argument can be followed by thinking about constraining the size of each book to a certain number of characters and pages. 36th Conference on Neural Information Processing Systems (NeurIPS 2022). Others are rightfully better suited to speak about the legacy of Borges\u2019 writings. Instead, we draw attention to how some of his literary constructs can serve as powerful metaphors for guiding humancentered design and technical thinking in the space of IGMs. 2 Metaphors of the infinite as provocations. Metaphors are powerful instruments that we use to try to make sense of what we do not know: we understand and measure the world using metaphors. Metaphors are at the center of the creative process in the fields of interaction and experience design. The desktop, the typewriter are famous examples of metaphors that still guide the ways we think about interacting with computers. Metaphors are useful until they break, and then they open the door to a new space of innovation from which new metaphors emerge.We present two provocations that we hope inspire conversations that lead to more human-centered outcomes in the context of these emerging IGMs. 2.1 Infinite library metaphors help us understand IGMs from a human-centered ML lens. Libraries, generalize bookshelfs and remain a relatable, knowable place where one goes to obtain a particular book, or search for one that will satisfy a goal. This includes exploration, since surprise is a valid goal. Making the library infinite does not negate its utility, but allows for a familiar lens to the potentially infinite number of image representations (books) contained within the latent spaces of IGMs 2. The usefulness of the metaphor stems from the familiar (human-centered) interfaces libraries have for people to interact with them: there is a librarian that can help us find what we are looking for, there is an indexing system, there are thematic hallways, etc. In contrast, some metaphors provide less defined agencies. Thinking about image generators as entities that \u201cdream\u201d or \u201challucinate\u201d capture their stochastic nature, but what is the interface or agency we have over dreams? The next provocation elaborates on the importance of a metaphor\u2019s interfaces. 2.2 These metaphors\u2019 interfaces inspire the design and development of meaningful experiences with IGMs. Current text/image to image experiences already allude to a librarian or curator. One merely must ask (through a multimodal prompt) for a particular book, and an encoder [9] (i.e. librarian) maps that ask into a sensible location in the library. This capability is an intellectually significant departure from Borges\u2019 pessimistic hopes to index the library. Still, this does not mean that there is a systematic index of the latent space understandable to humans; it is not yet clear how to navigate the library\u2019s hallways in semantically sensible ways. Prompt engineering is an indirect (chaotic even) way to navigate the latent space. The arcane nature of prompt articulation has already launched marketplaces [8] where prompt experts map, trade, and gatekeep access to safe destinations in the library. A library metaphor inspires us to think about experiences where people (not prompt whisperers) can explore the library\u2019s hallways with a semblance of agency that can include, but go beyond prompt trial and error, or predefined dimensions of style such as artist, camera [16], or generation parameters such as notions of temperature, guidance, seeds, and diffusion steps. There are promising ideas ahead. Text inversion [5] hints at potential solutions to define concepts that allow one to explore the latent space in personal, meaningful ways. Current advances in simulation environments used to safely train autonomous agents [13] or face detectors [15] hint at the possibility of defining training sets that include variations along semantically useful concepts. Creative communities are already combining components in pipelines that allow them to craft sequences of semantically and temporally coherent images [7, 4, 6]. An Aleph has less defined interfaces, but surprise is sometimes a goal in itself. An example of this is Quantum Mirror [14], an Aleph that allows the viewer to take a glance at the many variations of a point in space. It is essential to support efforts in UX design, tooling, and learning algorithms that enable people navigating with intention and agency from one image to the next. 3 Closing thoughts: other metaphors and perspectives. Other metaphors emerge as we witness the emergence of IGMs and how they are being used. IGMs can be seen as a Material, a Tool, and in particular, as a communication and artistic Medium. Each of There can be many infinite libraries, depending on how one trains the generation model.",
        "paperId": "5de7f28f738366e76a9e3709484ccaa726dd790e"
    },
    {
        "title": "Prompt engineering when using generative AI in nursing education.",
        "firstAuthor": "Siobhan O\u2019CONNOR",
        "url": null,
        "dateSubmitted": "2023-11-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "5dfa9be98705b77247624e31d2e0f130149c6849"
    },
    {
        "title": "MindWatch: A Smart Cloud-based AI solution for Suicide Ideation Detection leveraging Large Language Models",
        "firstAuthor": "Runa Bhaumik",
        "url": "https://www.medrxiv.org/content/medrxiv/early/2023/09/26/2023.09.25.23296062.full.pdf",
        "dateSubmitted": "2023-09-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Suicide, a serious public health concern affecting millions of individuals worldwide, refers to the intentional act of ending one's own life. Mental health issues such as depression, frustration, and hopelessness can directly or indirectly influence the emergence of suicidal thoughts. Early identification of these thoughts is crucial for timely diagnosis. In recent years, advances in artificial intelligence (AI) and natural language processing (NLP) have paved the way for revolutionizing mental health support and education. In this proof-of-concept study, we have created MindWatch, a cutting-edge tool that harnesses the power of AI-driven language models to serve as a valuable computer-aided system for the mental health professions to achieve two important goals such as early symptom detection, and personalized psychoeducation. We utilized ALBERT and Bio-Clinical BERT language models and fine-tuned them with the Reddit dataset to build the classifiers. We evaluated the performance of bi-LSTM, ALBERT, Bio-Clinical BERT, OpenAI GPT3.5 (via prompt engineering), and an ensembled voting classifier to detect suicide ideation. For personalized psychoeducation, we used the state-of-the-art Llama 2 foundation model leveraging prompt engineering. The tool is developed in the Amazon Web Service environment. All models performed exceptionally well, with accuracy and precision/recall greater than 92%. ALBERT performed better (AUC=.98) compared to the zero-shot classification accuracies obtained from OpenAI GPT3.5 Turbo (ChatGPT) on hidden datasets (AUC=.91). Furthermore, we observed that the inconclusiveness rate of the Llama 2 model is low while tested for few examples. This study emphasizes how transformer models can help provide customized psychoeducation to individuals dealing with mental health issues. By tailoring content to address their unique mental health conditions, treatment choices, and self-help resources, this approach empowers individuals to actively engage in their recovery journey. Additionally, these models have the potential to advance the automated detection of depressive disorders.",
        "paperId": "5e01b8383e9260b2e251274a6bad89677cb1bbd3"
    },
    {
        "title": "Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs",
        "firstAuthor": "Jiaoayan Chen",
        "url": "http://arxiv.org/pdf/2305.09858",
        "dateSubmitted": "2023-05-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Knowledge Graphs (KGs) play a crucial role in enhancing e-commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between products or product types, which can be utilized in recommender systems. However, relation labeling in KGs remains a challenging task due to the dynamic nature of e-commerce domains and the associated cost of human labor. Recently, breakthroughs in Large Language Models (LLMs) have shown surprising results in numerous natural language processing tasks. In this paper, we conduct an empirical study of LLMs for relation labeling in e-commerce KGs, investigating their powerful learning capabilities in natural language and effectiveness in predicting relations between product types with limited labeled data. We evaluate various LLMs, including PaLM and GPT-3.5, on benchmark datasets, demonstrating their ability to achieve competitive performance compared to humans on relation labeling tasks using just 1 to 5 labeled examples per relation. Additionally, we experiment with different prompt engineering techniques to examine their impact on model performance. Our results show that LLMs significantly outperform existing KG completion models in relation labeling for e-commerce KGs and exhibit performance strong enough to replace human labeling.",
        "paperId": "5e8dd82419f78025093acbec3ba2e345fff85d11"
    },
    {
        "title": "Executive Function: A Contrastive Value Policy for Resampling and Relabeling Perceptions via Hindsight Summarization?",
        "firstAuthor": "Christopher T. Lengerich",
        "url": "http://arxiv.org/pdf/2204.12639",
        "dateSubmitted": "2022-04-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We develop the few-shot continual learning task from first principles and hypothesize an evolutionary motivation and mechanism of action for executive function as a contrastive value policy which resamples and relabels perception data via hindsight summarization to minimize attended prediction error, similar to an online prompt engineering problem. This is made feasible by the use of a memory policy and a pretrained network with inductive biases for a grammar of learning and is trained to maximize evolutionary survival. We show how this model of executive function can be used to implement hypothesis testing as a stream of consciousness and may explain observations of human few-shot learning and neuroanatomy.",
        "paperId": "5e9de56c7f4d1fe89c84630cf7eefc126f0dca54"
    },
    {
        "title": "Automatic Bug Fixing via Deliberate Problem Solving with Large Language Models",
        "firstAuthor": "Guoyang Weng",
        "url": null,
        "dateSubmitted": "2023-10-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Developers dedicate a significant share of their activities to finding and fixing defects in their code. Automated program repair (APR) attempts to reduce this effort by a set of techniques for automatically fixing errors or vulnerabilities in software systems. Recent Large Language Models (LLMs) such as GPT-4 offer an effective alternative to existing APR methods, featuring out-of-the-box bug fixing performance comparable to even sophisticated deep learning approaches such as CoCoNut. In this work we propose a further extension to LLM-based program repair techniques by leveraging a recently introduced interactive prompting technique called Tree of Thoughts (ToT). Specifically, we ask a LLM to propose multiple hypotheses about the location of a bug, and based on the aggregated response we prompt for bug fixing suggestions. A preliminary evaluation shows that our approach is able to fix multiple complex bugs previously unsolved by GPT-4 even with prompt engineering. This result motivates further exploration of hybrid approaches which combine LLMs with suitable meta-strategies.",
        "paperId": "60179cebde7da4ccfabf349ea65a6573bbbbc23e"
    },
    {
        "title": "Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators",
        "firstAuthor": "Zhizheng Zhang",
        "url": "http://arxiv.org/pdf/2306.01242",
        "dateSubmitted": "2023-06-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The recent success of Large Language Models (LLMs) signifies an impressive stride towards artificial general intelligence. They have shown a promising prospect in automatically completing tasks upon user instructions, functioning as brain-like coordinators. The associated risks will be revealed as we delegate an increasing number of tasks to machines for automated completion. A big question emerges: how can we make machines behave responsibly when helping humans automate tasks as personal copilots? In this paper, we explore this question in depth from the perspectives of feasibility, completeness and security. In specific, we present Responsible Task Automation (ResponsibleTA) as a fundamental framework to facilitate responsible collaboration between LLM-based coordinators and executors for task automation with three empowered capabilities: 1) predicting the feasibility of the commands for executors; 2) verifying the completeness of executors; 3) enhancing the security (e.g., the protection of users' privacy). We further propose and compare two paradigms for implementing the first two capabilities. One is to leverage the generic knowledge of LLMs themselves via prompt engineering while the other is to adopt domain-specific learnable models. Moreover, we introduce a local memory mechanism for achieving the third capability. We evaluate our proposed ResponsibleTA on UI task automation and hope it could bring more attentions to ensuring LLMs more responsible in diverse scenarios. The research project homepage is at https://task-automation-research.github.io/responsible_task_automation.",
        "paperId": "615962d8969c8e0ffe43319689dce6c50cbf1f29"
    },
    {
        "title": "PEACE: Prompt Engineering Automation for CLIPSeg Enhancement in Aerial Robotics",
        "firstAuthor": "Haechan Mark Bong",
        "url": "https://arxiv.org/pdf/2310.00085",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "From industrial to space robotics, safe landing is an essential component for flight operations. With the growing interest in artificial intelligence, we direct our attention to learning based safe landing approaches. This paper extends our previous work, DOVESEI, which focused on a reactive UAV system by harnessing the capabilities of open vocabulary image segmentation. Prompt-based safe landing zone segmentation using an open vocabulary based model is no more just an idea, but proven to be feasible by the work of DOVESEI. However, a heuristic selection of words for prompt is not a reliable solution since it cannot take the changing environment into consideration and detrimental consequences can occur if the observed environment is not well represented by the given prompt. Therefore, we introduce PEACE (Prompt Engineering Automation for CLIPSeg Enhancement), powering DOVESEI to automate the prompt generation and engineering to adapt to data distribution shifts. Our system is capable of performing safe landing operations with collision avoidance at altitudes as low as 20 meters using only monocular cameras and image segmentation. We take advantage of DOVESEI's dynamic focus to circumvent abrupt fluctuations in the terrain segmentation between frames in a video stream. PEACE shows promising improvements in prompt generation and engineering for aerial images compared to the standard prompt used for CLIP and CLIPSeg. Combining DOVESEI and PEACE, our system was able improve successful safe landing zone selections by 58.62% compared to using only DOVESEI. All the source code is open source and available online.",
        "paperId": "615ef4518f9a41a10881b66ce10f0eb490e2d75c"
    },
    {
        "title": "Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation",
        "firstAuthor": "Seugnjun Lee",
        "url": "http://arxiv.org/pdf/2306.14514",
        "dateSubmitted": "2023-06-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this paper, we introduce a data-driven approach for Formality-Sensitive Machine Translation (FSMT) that caters to the unique linguistic properties of four target languages. Our methodology centers on two core strategies: 1) language-specific data handling, and 2) synthetic data generation using large-scale language models and empirical prompt engineering. This approach demonstrates a considerable improvement over the baseline, highlighting the effectiveness of data-centric techniques. Our prompt engineering strategy further improves performance by producing superior synthetic translation examples.",
        "paperId": "632dc69c2e504d693533fc434b8122a2a8a42844"
    },
    {
        "title": "Efficient Black-Box Adversarial Attacks on Neural Text Detectors",
        "firstAuthor": "Vitalii Fishchuk",
        "url": null,
        "dateSubmitted": "2023-11-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Neural text detectors are models trained to detect whether a given text was generated by a language model or written by a human. In this paper, we investigate three simple and resource-efficient strategies (parameter tweaking, prompt engineering, and character-level mutations) to alter texts generated by GPT-3.5 that are unsuspicious or unnoticeable for humans but cause misclassification by neural text detectors. The results show that especially parameter tweaking and character-level mutations are effective strategies.",
        "paperId": "6345f3ac2dd5ebe6592be9f9f8e249a74c2e9efe"
    },
    {
        "title": "Development of meta-prompts for Large Language Models to screen titles and abstracts for diagnostic test accuracy reviews",
        "firstAuthor": "Y. Kataoka",
        "url": "https://www.medrxiv.org/content/medrxiv/early/2023/10/31/2023.10.31.23297818.full.pdf",
        "dateSubmitted": "2023-11-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Systematic reviews (SRs) are a critical component of evidence-based medicine, but the process of screening titles and abstracts is time-consuming. This study aimed to develop and externally validate a method using large language models to classify abstracts for diagnostic test accuracy (DTA) systematic reviews, thereby reducing the human workload. We used a previously collected dataset for developing DTA abstract classifiers and applied prompt engineering. We developed an optimized meta-prompt for Generative Pre-trained Transformer (GPT)-3.5-turbo and GPT-4 to classify abstracts. In the external validation dataset 1, the prompt with GPT-3.5 turbo showed a sensitivity of 0.988, and a specificity of 0.298. GPT-4 showed a sensitivity of 0.982, and a specificity of 0.677. In the external validation dataset 2, GPT-3.5 turbo showed a sensitivity of 0.919, and a specificity of 0.434. GPT-4 showed a sensitivity of 0.806, and a specificity of 0.740. If we included eligible studies from among the references of the identified studies, GPT-3.5 turbo had no critical misses, while GPT-4 had some misses. Our study indicates that GPT-3.5 turbo can be effectively used to classify abstracts for DTA systematic reviews. Further studies using other dataset are warranted to confirm our results. Additionally, we encourage the use of our framework and publicly available dataset for further exploration of more effective classifiers using other LLMs and prompts (https://github.com/youkiti/ARE/).",
        "paperId": "6384921f1bd1059c6b4c37ac3c4e4f19e45d40c1"
    },
    {
        "title": "The artificially intelligent entrepreneur: ChatGPT, prompt engineering, and entrepreneurial rhetoric creation",
        "firstAuthor": "Cole E. Short",
        "url": null,
        "dateSubmitted": "2023-06-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "63d2dd59155d08df49d7dfe468657080f00166e3"
    },
    {
        "title": "Forgetful Large Language Models: Lessons Learned from Using LLMs in Robot Programming",
        "firstAuthor": "Juo-Tung Chen",
        "url": "https://arxiv.org/pdf/2310.06646",
        "dateSubmitted": "2023-10-10",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models offer new ways of empowering people to program robot applications-namely, code generation via prompting. However, the code generated by LLMs is susceptible to errors. This work reports a preliminary exploration that empirically characterizes common errors produced by LLMs in robot programming. We categorize these errors into two phases: interpretation and execution. In this work, we focus on errors in execution and observe that they are caused by LLMs being\"forgetful\"of key information provided in user prompts. Based on this observation, we propose prompt engineering tactics designed to reduce errors in execution. We then demonstrate the effectiveness of these tactics with three language models: ChatGPT, Bard, and LLaMA-2. Finally, we discuss lessons learned from using LLMs in robot programming and call for the benchmarking of LLM-powered end-user development of robot applications.",
        "paperId": "6474370fe46e38896288305c35d3058a403b1db2"
    },
    {
        "title": "Understanding prompt engineering may not require rethinking generalization",
        "firstAuthor": "Victor Akinwande",
        "url": null,
        "dateSubmitted": "2023-10-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Zero-shot learning in prompted vision-language models, the practice of crafting prompts to build classifiers without an explicit training process, has achieved impressive performance in many settings. This success presents a seemingly surprising observation: these methods suffer relatively little from overfitting, i.e., when a prompt is manually engineered to achieve low error on a given training set (thus rendering the method no longer actually zero-shot), the approach still performs well on held-out test data. In this paper, we show that we can explain such performance well via recourse to classical PAC-Bayes bounds. Specifically, we show that the discrete nature of prompts, combined with a PAC-Bayes prior given by a language model, results in generalization bounds that are remarkably tight by the standards of the literature: for instance, the generalization bound of an ImageNet classifier is often within a few percentage points of the true test error. We demonstrate empirically that this holds for existing handcrafted prompts and prompts generated through simple greedy search. Furthermore, the resulting bound is well-suited for model selection: the models with the best bound typically also have the best test performance. This work thus provides a possible justification for the widespread practice of prompt engineering, even if it seems that such methods could potentially overfit the training data.",
        "paperId": "64bed4a665d3f51de76ea55388ff0a04e6f2db11"
    },
    {
        "title": "Large language models for aspect-based sentiment analysis",
        "firstAuthor": "Paul F. Simmering",
        "url": null,
        "dateSubmitted": "2023-10-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of prompt engineering versus fine-tuning when using LLMs for ABSA.",
        "paperId": "65896b638de95d436f1e75fa4967b9d2763edd67"
    },
    {
        "title": "The Creativity of Text-based Generative Art",
        "firstAuthor": "J. Oppenlaender",
        "url": "http://arxiv.org/pdf/2206.02904",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-based generation of digital images has made a giant leap to-wards becoming a mainstream phenomenon. With text-based generative systems, anybody can create digital images and artworks. This provokes the question of whether text-based generative art is creative. This paper expounds on the nature of human creativity involved in text-based generative art with a specific focus on the practice of prompt engineering, drawing on Rhodes\u2019s conceptual model of creativity. The paper critiques the current product-centered view of creativity which may fall short in the context of text-based generative art. An case exemplifying this shortcoming is provided and future opportunities for research on text-based generative art are outlined.",
        "paperId": "65d6c17a5f947a2aa92ab1fa0b876e4e3c75720c"
    },
    {
        "title": "Multimodal Propaganda Detection Via Anti-Persuasion Prompt enhanced contrastive learning",
        "firstAuthor": "Jian Cui",
        "url": null,
        "dateSubmitted": "2023-06-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Propaganda, commonly used in memes disinformation, can influence the thinking of the audience and increase the reach of communication. Usually logical fallacy, as a kind of popular expression of memes, aims to create a logical reasonable illusion where the conclusion cannot be drawn with the use of correct logic rules. However, this characteristic inherent in memes leads to difficulties for classic multi-label classifiers to understand propagation techniques. To this end, we propose a novel propaganda detection model called Antipersuasion Prompt Enhanced Contrastive Learning (abbreviated as APCL). First, our APCL reformulates the multi-label classification task by leveraging the category words of propaganda technique based prompt engineering, which is converted into an image-text matching (ITM). Second, prompt engineering is designed with a persuasion prompt template and an anti-persuasion prompt template. The former is to build matched text-image pairs, and the latter is to form mismatched text-image pairs which fit the logical fallacy style of memes. Finally, the propagation technique is predicted based on the distances between the above two prompt templates enhanced texts and an input image. Experimental results on the memes dataset of SemEval2021 task 6 show that our APCL outperforms the state-of-the-art multimodal classification models in terms of F1 measures.",
        "paperId": "65e45895b9d9047b13d4f3ba58f4a386278d8cb0"
    },
    {
        "title": "Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns",
        "firstAuthor": "Julian Hazell",
        "url": "http://arxiv.org/pdf/2305.06972",
        "dateSubmitted": "2023-05-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent progress in artificial intelligence (AI), particularly in the domain of large language models (LLMs), has resulted in powerful and versatile dual-use systems. Indeed, cognition can be put towards a wide variety of tasks, some of which can result in harm. This study investigates how LLMs can be used for spear phishing, a form of cybercrime that involves manipulating targets into divulging sensitive information. I first explore LLMs' ability to assist with the reconnaissance and message generation stages of a successful spear phishing attack, where I find that advanced LLMs are capable of improving cybercriminals' efficiency during these stages. To explore how LLMs can be used to scale spear phishing campaigns, I then create unique spear phishing messages for over 600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models. My findings reveal that these messages are not only realistic but also cost-effective, with each email costing only a fraction of a cent to generate. Next, I demonstrate how basic prompt engineering can circumvent safeguards installed in LLMs by the reinforcement learning from human feedback fine-tuning process, highlighting the need for more robust governance interventions aimed at preventing misuse. To address these evolving risks, I propose two potential solutions: structured access schemes, such as application programming interfaces, and LLM-based defensive systems.",
        "paperId": "661e8ac4908a9d2a85835245ea99b6a314cc4a60"
    },
    {
        "title": "Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis",
        "firstAuthor": "Hongyi Zheng",
        "url": null,
        "dateSubmitted": "2023-11-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent advances in prompt engineering enable large language models (LLMs) to solve multi-hop logical reasoning problems with impressive accuracy. However, there is little existing work investigating the robustness of LLMs with few-shot prompting techniques. Therefore, we introduce a systematic approach to test the robustness of LLMs in multi-hop reasoning tasks via domain-agnostic perturbations. We include perturbations at multiple levels of abstractions (e.g. lexical perturbations such as typos, and semantic perturbations such as the inclusion of intermediate reasoning steps in the questions) to conduct behavioral analysis on the LLMs. Throughout our experiments, we find that models are more sensitive to certain perturbations such as replacing words with their synonyms. We also demonstrate that increasing the proportion of perturbed exemplars in the prompts improves the robustness of few-shot prompting methods.",
        "paperId": "675e079cc3c11f9234f8f70bab9f763911b97955"
    },
    {
        "title": "Prompt Engineering For Students of Medicine and Their Teachers",
        "firstAuthor": "Thomas F. Heston",
        "url": "https://arxiv.org/pdf/2308.11628",
        "dateSubmitted": "2023-08-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\"Prompt Engineering for Students of Medicine and Their Teachers\"brings the principles of prompt engineering for large language models such as ChatGPT and Google Bard to medical education. This book contains a comprehensive guide to prompt engineering to help both teachers and students improve education in the medical field. Just as prompt engineering is critical in getting good information out of an AI, it is also critical to get students to think and understand more deeply. The principles of prompt engineering that we have learned from AI systems have the potential to simultaneously revolutionize learning in the healthcare field. The book analyzes from multiple angles the anatomy of a good prompt for both AI models and students. The different types of prompts are examined, showing how each style has unique characteristics and applications. The principles of prompt engineering, applied properly, are demonstrated to be effective in teaching across the diverse fields of anatomy, physiology, pathology, pharmacology, and clinical skills. Just like ChatGPT and similar large language AI models, students need clear and detailed prompting in order for them to fully understand a topic. Using identical principles, a prompt that gets good information from an AI will also cause a student to think more deeply and accurately. The process of prompt engineering facilitates this process. Because each chapter contains multiple examples and key takeaways, it is a practical guide for implementing prompt engineering in the learning process. It provides a hands-on approach to ensure readers can immediately apply the concepts they learn",
        "paperId": "6862113724aa1a578c5d4e0ec7f1d9bed4288241"
    },
    {
        "title": "Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models",
        "firstAuthor": "Jake Chanenson",
        "url": null,
        "dateSubmitted": "2023-11-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Identifying contextual integrity (CI) and governing knowledge commons (GKC) parameters in privacy policy texts can facilitate normative privacy analysis. However, GKC-CI annotation has heretofore required manual or crowdsourced effort. This paper demonstrates that high-accuracy GKC-CI parameter annotation of privacy policies can be performed automatically using large language models. We fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotations from 16 ground truth privacy policies. Our best-performing model (fine-tuned GPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding the performance of prior crowdsourcing approaches despite the complexity of privacy policy texts and the nuance of the GKC-CI annotation task. We apply our best-performing model to privacy policies from 164 popular online services, demonstrating the effectiveness of scaling GKC-CI annotation for data exploration. We make all annotated policies as well as the training data and scripts needed to fine-tune our best-performing model publicly available for future research.",
        "paperId": "68c6b65b127158df2e74f36757117613b9ae9146"
    },
    {
        "title": "System Report for CCL23-Eval Task 9: HUST1037 Explore Proper Prompt Strategy for LLM in MRC Task",
        "firstAuthor": "Xiao Liu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\u201cOur research paper delves into the Adversarial Robustness Evaluation for Chinese Gaokao Read-ing Comprehension (GCRC advRobust). While Chinese reading comprehension tasks havegained significant attention in recent years, previous methods have not proven effective for thischallenging dataset. We focus on exploring how prompt engineering can impact a model\u2019s read-ing comprehension ability. Through our experiments using ChatGLM, GPT3.5, and GPT4, wediscovered a correlation between prompt and LLM reading comprehension ability, and found thatprompt engineering improves the performance of each model. Our team submitted the results ofour system evaluation, which ranked first in three indexes and total scores.Keywords\u2014 LLM, Prompt, Chinese Reading Comprehension\u201d",
        "paperId": "693c3c1c54c1c65561a0a7628177b55a0ebad603"
    },
    {
        "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models",
        "firstAuthor": "Chaoyou Fu",
        "url": "http://arxiv.org/pdf/2306.13394",
        "dateSubmitted": "2023-06-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform multimodal tasks, showing amazing emergent abilities in recent studies, such as writing poems based on an image. However, it is difficult for these case studies to fully reflect the performance of MLLM, lacking a comprehensive evaluation. In this paper, we fill in this blank, presenting the first MLLM Evaluation benchmark MME. It measures both perception and cognition abilities on a total of 14 subtasks. In order to avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instruction-answer pairs are all manually designed. The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering. Besides, with such an instruction, we can also easily carry out quantitative statistics. A total of 12 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the subsequent model optimization.",
        "paperId": "697e0add95e880bd42e00bef838181e105f91981"
    },
    {
        "title": "Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis",
        "firstAuthor": "James R. Kirk",
        "url": "https://arxiv.org/pdf/2306.06770",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": ": Large language models (LLMs) offer significant promise as a knowledge source for robotic task learning. Prompt engineering has been shown to be effective for eliciting knowledge from an LLM but alone is insufficient for acquiring relevant, situationally grounded knowledge for an embodied robotic agent learning novel tasks. We describe a cognitive-agent approach that extends and complements prompt engineering, mitigating its limitations, and thus enabling a robot to acquire new task knowledge matched to its native language capabilities, embodiment, environment, and user preferences. The approach is to increase the response space of LLMs and deploy general strategies, embedded within the autonomous robot, to evaluate, repair, and select among candidate responses produced by the LLM. We describe the approach and experiments that show how a robot, by retrieving and evaluating a breadth of responses from the LLM, can achieve > 75% task completion in one-shot learning without user oversight. The approach achieves 100% task completion when human oversight (such as indication of preference) is provided, while greatly reducing how much human oversight is needed.",
        "paperId": "6b80c6e220ca2e2434f5a80b2eb5e8b645e97ae1"
    },
    {
        "title": "Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3",
        "firstAuthor": "Pragya Srivastava",
        "url": "https://arxiv.org/pdf/2210.17284",
        "dateSubmitted": "2022-10-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We present very early results on using GPT-3 to perform question answering on tabular data. We find that stock pre-trained GPT-3 is able to zero-shot learn the table structure from a serialized JSON array-of-arrays representation, and able to answer lookup queries and simple comparison questions in natural language without any fine-tuning. We further find that simple prompt engineering to include few-shot static Q&A examples significantly improves accuracy. Lastly, we find that intermixing passage text improves accuracy even further on heterogeneous data. We apply our approach on a novel dataset of simple tables in newspaper infographics with promising results. Overall, we find much cause for optimism in this basic approach.",
        "paperId": "6b8f26678785ebd7b7b27984af3cb9a273b722b0"
    },
    {
        "title": "Unleashing ChatGPT's Power: A Case Study on Optimizing Information Retrieval in Flipped Classrooms via Prompt Engineering",
        "firstAuthor": "Mo Wang",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "6cde86a7e0352b9cc08e65e5674d0f307900f6f3"
    },
    {
        "title": "Understanding Users' Dissatisfaction with ChatGPT Responses: Types, Resolving Tactics, and the Effect of Knowledge Level",
        "firstAuthor": "Yoonsu Kim",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) with chat-based capabilities, such as ChatGPT, are widely used in various workflows. However, due to a limited understanding of these large-scale models, users struggle to use this technology and experience different kinds of dissatisfaction. Researchers have introduced several methods such as prompt engineering to improve model responses. However, they focus on crafting one prompt, and little has been investigated on how to deal with the dissatisfaction the user encountered during the conversation. Therefore, with ChatGPT as the case study, we examine end users' dissatisfaction along with their strategies to address the dissatisfaction. After organizing users' dissatisfaction with LLM into seven categories based on a literature review, we collected 511 instances of dissatisfactory ChatGPT responses from 107 users and their detailed recollections of dissatisfied experiences, which we release as a publicly accessible dataset. Our analysis reveals that users most frequently experience dissatisfaction when ChatGPT fails to grasp their intentions, while they rate the severity of dissatisfaction the highest with dissatisfaction related to accuracy. We also identified four tactics users employ to address their dissatisfaction and their effectiveness. We found that users often do not use any tactics to address their dissatisfaction, and even when using tactics, 72% of dissatisfaction remained unresolved. Moreover, we found that users with low knowledge regarding LLMs tend to face more dissatisfaction on accuracy while they often put minimal effort in addressing dissatisfaction. Based on these findings, we propose design implications for minimizing user dissatisfaction and enhancing the usability of chat-based LLM services.",
        "paperId": "6d3da24a9bcef989900d646aaea23b446ffd39e1"
    },
    {
        "title": "Prompt engineering for zero\u2010shot and few\u2010shot defect detection and classification using a visual\u2010language pretrained model",
        "firstAuthor": "Gunwoo Yong",
        "url": null,
        "dateSubmitted": "2022-11-28",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Zero\u2010shot learning, applied with vision\u2010language pretrained (VLP) models, is expected to be an alternative to existing deep learning models for defect detection, under insufficient dataset. However, VLP models, including contrastive language\u2010image pretraining (CLIP), showed fluctuated performance on prompts (inputs), resulting in research on prompt engineering\u2014optimization of prompts for improving performance. Therefore, this study aims to identify the features of a prompt that can yield the best performance in classifying and detecting building defects using the zero\u2010shot and few\u2010shot capabilities of CLIP. The results reveal the following: (1) domain\u2010specific definitions are better than general definitions and images; (2) a complete sentence is better than a set of core terms; and (3) multimodal information is better than single\u2010modal information. The resulting detection performance using the proposed prompting method outperformed that of existing supervised models.",
        "paperId": "6f6e378ada22ac0f1c2b8124debb7a25cd51d471"
    },
    {
        "title": "Specialized Syntactic Quran Search Engines: Evaluation and Limitations",
        "firstAuthor": "A. Bakr",
        "url": null,
        "dateSubmitted": "2023-07-15",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The Quran is the sacred text that provides guidance and teachings to the followers of Islam. This paper aims to analyze and evaluate the limitations of current specialized search engines used for retrieving information from the Quran. Also, this work includes an initial evaluation of Quran search with a large language model (LLM) employing prompt engineering. The study focuses on the syntactic aspect of information retrieval, while acknowledging the necessity of considering the semantic meaning of Quranic words and verses for a more comprehensive analysis. Furthermore, recommendations and guidelines for future research are proposed, stressing the significance of developing syntactic search capabilities to improve the accuracy and relevance of search results.",
        "paperId": "6fb9fa5f7c31402214964099a0f30a6170f2279c"
    },
    {
        "title": "An Empirical Study on Few-shot Knowledge Probing for Pretrained Language Models",
        "firstAuthor": "Tianxing He",
        "url": null,
        "dateSubmitted": "2021-09-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt-based knowledge probing for 1-hop relations has been used to measure how much world knowledge is stored in pretrained language models. Existing work uses considerable amounts of data to tune the prompts for better performance. In this work, we compare a variety of approaches under a few-shot knowledge probing setting, where only a small number (e.g., 10 or 20) of example triples are available. In addition, we create a new dataset named TREx-2p, which contains 2-hop relations. We report that few-shot examples can strongly boost the probing performance for both 1-hop and 2-hop relations. In particular, we find that a simple-yet-effective approach of finetuning the bias vectors in the model outperforms existing prompt-engineering methods. Our dataset and code are available at \\url{https://github.com/cloudygoose/fewshot_lama}.",
        "paperId": "6fc4a39bb4697a21286bb1cf503ecf17407aeae2"
    },
    {
        "title": "Fake it till you make it: Learning(s) from a synthetic ImageNet clone",
        "firstAuthor": "Mert Bulent Sariyildiz",
        "url": "http://arxiv.org/pdf/2212.08420",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent large-scale image generation models such as Stable Diffusion have exhibited an impressive ability to generate fairly realistic images starting from a very simple text prompt. Could such models render real images obsolete for training image prediction models? In this paper, we an-swer part of this provocative question by questioning the need for real images when training models for ImageNet classi\ufb01cation. More precisely, provided only with the class names that have been used to build the dataset, we explore the ability of Stable Diffusion to generate synthetic clones of ImageNet and measure how useful they are for training classi\ufb01cation models from scratch. We show that with minimal and class-agnostic prompt engineering those ImageNet clones we denote as ImageNet-SD are able to close a large part of the gap between models produced by synthetic images and models trained with real images for the several standard classi\ufb01cation benchmarks that we consider in this study. More importantly, we show that models trained on synthetic images exhibit strong generalization properties and perform on par with models trained on real data.",
        "paperId": "70e8f98fbb0a0acdbd08af343a8504e7fd664267"
    },
    {
        "title": "Exploring the Effectiveness of Dataset Synthesis: An application of Apple Detection in Orchards",
        "firstAuthor": "A. V. Meekeren",
        "url": "http://arxiv.org/pdf/2306.11763",
        "dateSubmitted": "2023-06-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Deep object detection models have achieved notable successes in recent years, but one major obstacle remains: the requirement for a large amount of training data. Obtaining such data is a tedious process and is mainly time consuming, leading to the exploration of new research avenues like synthetic data generation techniques. In this study, we explore the usability of Stable Diffusion 2.1-base for generating synthetic datasets of apple trees for object detection and compare it to a baseline model trained on real-world data. After creating a dataset of realistic apple trees with prompt engineering and utilizing a previously trained Stable Diffusion model, the custom dataset was annotated and evaluated by training a YOLOv5m object detection model to predict apples in a real-world apple detection dataset. YOLOv5m was chosen for its rapid inference time and minimal hardware demands. Results demonstrate that the model trained on generated data is slightly underperforming compared to a baseline model trained on real-world images when evaluated on a set of real-world images. However, these findings remain highly promising, as the average precision difference is only 0.09 and 0.06, respectively. Qualitative results indicate that the model can accurately predict the location of apples, except in cases of heavy shading. These findings illustrate the potential of synthetic data generation techniques as a viable alternative to the collection of extensive training data for object detection models.",
        "paperId": "71020779c6eeb9c76fe0a0eb2155d1d4f7d29ff9"
    },
    {
        "title": "\u201cGene-to-Metabolite\u201d network prompted engineering of rosmarinic acid biosynthetic pathway in Salvia miltiorrhiza hairy root cultures",
        "firstAuthor": "Ying Xiao",
        "url": null,
        "dateSubmitted": "2014-12-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "7272ce78b030c9114acbfa111a5e5d0a92e21e69"
    },
    {
        "title": "Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models",
        "firstAuthor": "Gabriel H. Sarch",
        "url": null,
        "dateSubmitted": "2023-10-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot's visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user's language and action plans, to assist future inferences and personalize them to the user's language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project's website: https://helper-agent-llm.github.io.",
        "paperId": "729fc01274cc26798654a318d1a95e73c61f99a3"
    },
    {
        "title": "Leveraging Large Language Models for Exploiting ASR Uncertainty",
        "firstAuthor": "Pranay Dighe",
        "url": "https://arxiv.org/pdf/2309.04842",
        "dateSubmitted": "2023-09-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "While large language models excel in a variety of natural language processing (NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they must either rely on off-the-shelf automatic speech recognition (ASR) systems for transcription, or be equipped with an in-built speech modality. This work focuses on the former scenario, where LLM's accuracy on SLU tasks is constrained by the accuracy of a fixed ASR system on the spoken input. Specifically, we tackle speech-intent classification task, where a high word-error-rate can limit the LLM's ability to understand the spoken intent. Instead of chasing a high accuracy by designing complex or specialized architectures regardless of deployment costs, we seek to answer how far we can go without substantially changing the underlying ASR and LLM, which can potentially be shared by multiple unrelated tasks. To this end, we propose prompting the LLM with an n-best list of ASR hypotheses instead of only the error-prone 1-best hypothesis. We explore prompt-engineering to explain the concept of n-best lists to the LLM; followed by the finetuning of Low-Rank Adapters on the downstream tasks. Our approach using n-best lists proves to be effective on a device-directed speech detection task as well as on a keyword spotting task, where systems using n-best list prompts outperform those using 1-best ASR hypothesis; thus paving the way for an efficient method to exploit ASR uncertainty via LLMs for speech-based applications.",
        "paperId": "72fb75f7c38a83424308c8205bb36cd88995494b"
    },
    {
        "title": "Unsupervised Prompt Learning for Vision-Language Models",
        "firstAuthor": "Hao Huang",
        "url": "http://arxiv.org/pdf/2204.03649",
        "dateSubmitted": "2022-04-07",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Contrastive vision-language models like CLIP have shown great progress in transfer learning. In the inference stage, the proper text description, also known as prompt, needs to be carefully designed to correctly classify the given images. In order to avoid laborious prompt engineering, recent works such as CoOp, CLIP-Adapter and Tip-Adapter propose to adapt vision-language models for downstream image recognition tasks on a small set of labeled data. Though promising improvements are achieved, requiring labeled data from the target datasets may restrict the scalability. In this paper, we explore a different scenario, in which the labels of the target datasets are unprovided, and we present an unsupervised prompt learning (UPL) approach to avoid prompt engineering while simultaneously improving transfer performance of CLIP-like vision-language models. As far as we know, UPL is the first work to introduce unsupervised learning into prompt learning. Experimentally, our UPL outperforms original CLIP with prompt engineering on ImageNet as well as other 10 datasets. An enhanced version of UPL is even competitive with the 8-shot CoOp and the 8-shot TIP-Adapter on most datasets. Code and models are available at https://github.com/tonyhuang2022/UPL.",
        "paperId": "732627c703a9dbc78d9384f1be4c791c3a554391"
    },
    {
        "title": "Controlling Diffusion Input-Output Mapping of the Components of a Diffusion Model as a Potential Approach for Enhanced Model Control Master\u2019s thesis in Complex adaptive systems",
        "firstAuthor": "Philip F Gard",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In this thesis, the primary focus is the exploration and evaluation of input-output mappings within the components of diffusion models, extending conventional methods of control like prompt engineering. The objective is not to propose a definitive solution for control within diffusion models, but rather to probe the underlying mappings that drive these processes. The project examines two main components: The attention maps within the CLIP model, and the input-output relationships in the diffusion process itself. By doing so, the intention is to increase understanding of the inherent complexity of the models and identify potential control opportunities. In the intricate domain of diffusion models, the evaluation of input-output maps might not always offer a clear-cut measure of success. This project contributes by examining the interplay between various components of the model, as viewed through the lens of input-output mappings. Instead of presenting conclusive control methods, it examines these components, setting a possible path for further exploration.",
        "paperId": "732761bad14162fcff61eccebb4f97f89fd1415b"
    },
    {
        "title": "Rewriting Math Word Problems with Large Language Models",
        "firstAuthor": "Kole Norberg",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models have recently achieved high performance on many writing tasks. In a recent study, math word problems in Carnegie Learning\u2019s MATHia adaptive learning software were rewritten by human authors to improve their clarity and specificity. The randomized experiment found that emerging readers who received the rewritten word problems spent less time completing the problems and also achieved higher mastery compared to emerging readers who received the original content. We used GPT-4 to rewrite the same set of math word problems, prompting it to follow the same guidelines that the human authors followed. We lay out our prompt engineering process, comparing several prompting strategies: zero-shot, few-shot, and chain-of-thought prompting. Additionally, we overview how we leveraged GPT\u2019s ability to write python code in order to encode mathematical components of word problems. We report text analysis of the original, human-rewritten, and GPT-rewritten problems. GPT rewrites had the most optimal readability, lexical diversity, and cohesion scores but used more low frequency words. We present our plan to test the GPT outputs in upcoming randomized field trials in MATHia.",
        "paperId": "7397f9861a3c8110540a0ca55072d3d6ea54cba5"
    },
    {
        "title": "Unsupervised Dual Modality Prompt Learning for Facial Expression Recognition",
        "firstAuthor": "Muhammad Shahid",
        "url": null,
        "dateSubmitted": "2023-04-21",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "A method of facial expression recognition using a vision language model is proposed. Recently vision-language models for example CLIP (Contrastive Language-Image Pre-training) models developed by OpenAI have achieved exceptional results on a variety of image recognition and retrieval tasks, exhibiting strong zero-shot performance. Transferable representations can be adapted through prompt tuning to a variety of downstream tasks. From the general knowledge stored in a pre-trained model, prompt tuning attempts to extract useful information for downstream tasks. In order to avoid time-consuming prompt engineering, recent works use a small amount of labeled data for adapting vision language models to downstream image recognition problems. However, requiring target datasets to be labeled may restrict their scalability. Moreover, we also note that adapting prompt learning techniques in only one branch of CLIP (vision or language) is suboptimal because it won't allow for the dynamic adjustment of both representation spaces on a downstream task. In this paper, we evaluated the performance of the CLIP model as a zero-shot face recognizer and proposed an Unsupervised Dual Modality Prompt Learning framework for Facial Expression Recognition. Our model tunes the prompts through learning text and visual prompts simultaneously to improve alignment between the linguistic and visual representations when labels are not provided for the target dataset. The experimental results on CK+, JAFFE, RAF-DB, and FER2013 datasets showed that our proposed method performs better compared with CLIP Zero-Shot and other unsupervised prompt-based learning methods for facial expression recognition tasks.",
        "paperId": "74f57c4a207aaab8addc9f43cce9ace297c66547"
    },
    {
        "title": "Instruction Distillation Makes Large Language Models Efficient Zero-shot Rankers",
        "firstAuthor": "Weiwei Sun",
        "url": null,
        "dateSubmitted": "2023-11-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent studies have demonstrated the great potential of Large Language Models (LLMs) serving as zero-shot relevance rankers. The typical approach involves making comparisons between pairs or lists of documents. Although effective, these listwise and pairwise methods are not efficient and also heavily rely on intricate prompt engineering. To tackle this problem, we introduce a novel instruction distillation method. The key idea is to distill the pairwise ranking ability of open-sourced LLMs to a simpler but more efficient pointwise ranking. Specifically, given the same LLM, we first rank documents using the effective pairwise approach with complex instructions, and then distill the teacher predictions to the pointwise approach with simpler instructions. Evaluation results on the BEIR, TREC, and ReDial datasets demonstrate that instruction distillation can improve efficiency by 10 to 100x and also enhance the ranking performance of LLMs. Furthermore, our approach surpasses the performance of existing supervised methods like monoT5 and is on par with the state-of-the-art zero-shot methods. The code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.",
        "paperId": "751855a18fceb0c613d7c0366824560d2077eb14"
    },
    {
        "title": "Review of Large Vision Models and Visual Prompt Engineering",
        "firstAuthor": "Jiaqi Wang",
        "url": "http://arxiv.org/pdf/2307.00855",
        "dateSubmitted": "2023-07-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Visual prompt engineering is a fundamental technology in the field of visual and image Artificial General Intelligence, serving as a key component for achieving zero-shot capabilities. As the development of large vision models progresses, the importance of prompt engineering becomes increasingly evident. Designing suitable prompts for specific visual tasks has emerged as a meaningful research direction. This review aims to summarize the methods employed in the computer vision domain for large vision models and visual prompt engineering, exploring the latest advancements in visual prompt engineering. We present influential large models in the visual domain and a range of prompt engineering methods employed on these models. It is our hope that this review provides a comprehensive and systematic description of prompt engineering methods based on large visual models, offering valuable insights for future researchers in their exploration of this field.",
        "paperId": "7619a98ef077c8f75e0bfb98953457649209e07e"
    },
    {
        "title": "Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales",
        "firstAuthor": "M. Ruskov",
        "url": "https://arxiv.org/pdf/2302.08961",
        "dateSubmitted": "2023-02-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The quality of text-to-image generation is continuously improving, yet the boundaries of its applicability are still unclear. In particular, refinement of the text input with the objective of achieving better results - commonly called prompt engineering - so far seems to have not been geared towards work with pre-existing texts. We investigate whether text-to-image generation and prompt engineering could be used to generate basic illustrations of popular fairytales. Using Midjourney v4, we engage in action research with a dual aim: to attempt to generate 5 believable illustrations for each of 5 popular fairytales, and to define a prompt engineering process that starts from a pre-existing text and arrives at an illustration of it. We arrive at a tentative 4-stage process: i) initial prompt, ii) composition adjustment, iii) style refinement, and iv) variation selection. We also discuss three reasons why the generation model struggles with certain illustrations: difficulties with counts, bias from stereotypical configurations and inability to depict overly fantastic situations. Our findings are not limited to the specific generation model and are intended to be generalisable to future ones.",
        "paperId": "76bb8f753c40d66f435015f2776c672b3999d8b5"
    },
    {
        "title": "Test-Time Training on Nearest Neighbors for Large Language Models",
        "firstAuthor": "Moritz Hardt",
        "url": "http://arxiv.org/pdf/2305.18466",
        "dateSubmitted": "2023-05-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Many recent efforts aim to augment language models with relevant information retrieved from a database at test time. We avoid the need for prompt engineering by directly fine-tuning the model on data retrieved at test time using its standard training setup. For this purpose, we build a large-scale distributed nearest neighbor index based on text embeddings of the Pile dataset. Given a query to a language model, our system retrieves the neighbors of the query and fine-tunes the model on the text data corresponding to those neighbors. Surprisingly, retrieving and training on as few as 20 neighbors, each for only one gradient iteration, drastically improves performance across more than twenty language modeling tasks in the Pile benchmark. For example, test-time training significantly narrows the performance gap between a small GPT2 model and a GPTNeo model, more than ten times larger, that was specifically trained to convergence on the Pile. Sufficient index quality and size, however, are important. Our work establishes a valuable first baseline for implementing test-time training in the context of large language models, opening the door to numerous promising research avenues.",
        "paperId": "776a9274623d3150cd4811b179bc001a99521bf0"
    },
    {
        "title": "Generating Requirements Elicitation Interview Scripts with Large Language Models",
        "firstAuthor": "Binnur G\u00f6rer",
        "url": null,
        "dateSubmitted": "2023-09-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Requirements elicitation interviews are the most popular requirements elicitation technique and an integral part of requirements engineering education. Good and bad interview scripts provide students with examples of applying the theory. Constructing an interview script requires technical knowledge, practical experience, and creativity. As a result, only a few educational interview scripts are available to the community. This paper explores automatically generating interview scripts with large language models through prompt engineering. Our contribution is two-fold: First, we present a graph representation of interactive interview scripts. Second, we apply prompt engineering techniques to generate business domain descriptions, linear scripts, and conversation pieces focused on certain types of mistakes. Our findings indicate that large language models face challenges in handling interview conversation graphs. However, we can enhance the quality of the generated interview scripts by decomposing the task into smaller components and refining the prompts to provide more precise instructions.",
        "paperId": "78b779bdd002a9a927adeca89d2f7650a1646029"
    },
    {
        "title": "Cheap-Fake Detection with LLM Using Prompt Engineering",
        "firstAuthor": "Guangyang Wu",
        "url": "https://arxiv.org/pdf/2306.02776",
        "dateSubmitted": "2023-06-05",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The misuse of real photographs with conflicting image captions in news items is an example of the out-of-context (OOC) misuse of media. In order to detect OOC media, individuals must determine the accuracy of the statement and evaluate whether the triplet (i.e., the image and two captions) relates to the same event. This paper presents a novel learnable approach for detecting OOC media in ICME'23 Grand Challenge on Detecting Cheapfakes. The proposed method is based on the COSMOS structure, which assesses the coherence between an image and captions, as well as between two captions. We enhance the baseline algorithm by incorporating a Large Language Model (LLM), GPT3.5, as a feature extractor. Specifically, we propose an innovative approach to feature extraction utilizing prompt engineering to develop a robust and reliable feature extractor with GPT3.5 model. The proposed method captures the correlation between two captions and effectively integrates this module into the COSMOS baseline model, which allows for a deeper understanding of the relationship between captions. By incorporating this module, we demonstrate the potential for significant improvements in cheap-fakes detection performance. The proposed methodology holds promising implications for various applications such as natural language processing, image captioning, and text-to-image synthesis. Docker for submission is available at https://hub.docker.com/repository/docker/mulns/acmmmcheapfakes.",
        "paperId": "790c247dabe004f022ef9330fb59c36a77bdbbb2"
    },
    {
        "title": "Making Language Models Better Tool Learners with Execution Feedback",
        "firstAuthor": "Shuofei Qiao",
        "url": "http://arxiv.org/pdf/2305.13068",
        "dateSubmitted": "2023-05-22",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Tools serve as pivotal interfaces that enable humans to understand and reshape the world. With the advent of foundational models, AI systems can utilize tools to expand their capabilities and interact with the world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce language models to utilize tools indiscriminately, as complex problems often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance. This leads to the research question: can we teach language models when and how to use tools? To meet this need, we propose Tool leaRning wIth exeCution fEedback (TRICE), a two-stage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively. Experimental results, backed by further analysis, show that TRICE can make the language model to selectively use tools by decreasing the model's dependency on tools while enhancing the performance. Code and datasets will be available in https://github.com/zjunlp/trice.",
        "paperId": "7919cb1a1dcf70ed7803c43a71d43dba696ef149"
    },
    {
        "title": "ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT",
        "firstAuthor": "Fatemeh Nazary",
        "url": "https://arxiv.org/pdf/2308.09731",
        "dateSubmitted": "2023-08-17",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This study presents an innovative approach to the application of large language models (LLMs) in clinical decision-making, focusing on OpenAI's ChatGPT. Our approach introduces the use of contextual prompts-strategically designed to include task description, feature description, and crucially, integration of domain knowledge-for high-quality binary classification tasks even in data-scarce scenarios. The novelty of our work lies in the utilization of domain knowledge, obtained from high-performing interpretable ML models, and its seamless incorporation into prompt design. By viewing these ML models as medical experts, we extract key insights on feature importance to aid in decision-making processes. This interplay of domain knowledge and AI holds significant promise in creating a more insightful diagnostic tool. Additionally, our research explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supervised ML models in different data conditions, we aim to provide insights into the effectiveness of prompt engineering strategies under varied data availability. In essence, this paper bridges the gap between AI and healthcare, proposing a novel methodology for LLMs application in clinical decision support systems. It highlights the transformative potential of effective prompt design, domain knowledge integration, and flexible learning approaches in enhancing automated decision-making.",
        "paperId": "793eb805800c4af0b06260079e178efa0377b9d7"
    },
    {
        "title": "Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations",
        "firstAuthor": "Deren Lei",
        "url": "https://arxiv.org/pdf/2310.03951",
        "dateSubmitted": "2023-10-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) can generate fluent natural language texts when given relevant documents as background context. This ability has attracted considerable interest in developing industry applications of LLMs. However, LLMs are prone to generate hallucinations that are not supported by the provided sources. In this paper, we propose a hierarchical framework to detect and mitigate such ungrounded hallucination. Our framework uses Chain of Natural Language Inference (CoNLI) for hallucination detection and hallucination reduction via post-editing. Our approach achieves state-of-the-art performance on hallucination detection and enhances text quality through rewrite, using LLMs without any fine-tuning or domain-specific prompt engineering. We show that this simple plug-and-play framework can serve as an effective choice for hallucination detection and reduction, achieving competitive performance across various contexts.",
        "paperId": "79429814fd4d967b9277af2805c53f370e52ebb5"
    },
    {
        "title": "Federated Large Language Model: A Position Paper",
        "firstAuthor": "Chaochao Chen",
        "url": "https://arxiv.org/pdf/2307.08925",
        "dateSubmitted": "2023-07-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large scale language models (LLM) have received significant attention and found diverse applications across various domains, but their development encounters challenges in real-world scenarios. These challenges arise due to the scarcity of public domain data availability and the need to maintain privacy with respect to private domain data. To address these issues, federated learning (FL) has emerged as a promising technology that enables collaborative training of shared models while preserving decentralized data. We propose the concept of federated LLM, which comprises three key components, i.e., federated LLM pre-training, federated LLM fine-tuning, and federated LLM prompt engineering. For each component, we discuss its advantage over traditional LLM training methods and propose specific engineering strategies for implementation. Furthermore, we explore the novel challenges introduced by the integration of FL and LLM. We analyze existing solutions and identify potential obstacles faced by these solutions within the context of federated LLM.",
        "paperId": "7aad760762c4a10dfbc2d3391eb8bdb28c80b236"
    },
    {
        "title": "PromptIE - Information Extraction with Prompt-Engineering and Large Language Models",
        "firstAuthor": "Sigurd Schacht",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "7ae523db11d8aecd1fc3574e10d546d73bac0efa"
    },
    {
        "title": "Exploring Early Adopters' Perceptions of ChatGPT as a Code Generation Tool",
        "firstAuthor": "Gian Luca Scoccia",
        "url": null,
        "dateSubmitted": "2023-09-11",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ChatGPT is an artificial intelligence chatbot developed by OpenAI, able of interacting in a conversational way by taking into account successive input prompts. Among many possible uses, ChatGPT has been found to possess code generation capabilities, being able to generate code snippets and assist developers in their programming tasks. This paper performs a qualitative exploration of perceptions of early adopters regarding the use of ChatGPT for code generation, acknowledging the substantial impact this tool can have in the software development landscape. We collected a diverse set of discussions from early adopters of ChatGPT code generation capabilities and, leveraging an open card sorting methodology categorized it into relevant topics with the goal of extracting insights into the experiences, opinions, and challenges they faced. We found that early adopters (i) report their own mixed usage experiences, (ii) share suggestions for prompt engineering, (iii) debate the extent to which they can trust generated code, and (iv) discuss the impact that ChatGPT can have on the software development process. We discuss the implications of the insights we extracted from early adopters' perspectives and provide recommendations for future research.",
        "paperId": "7afa53db93d2c7717e578f7bb774a7fb388101cf"
    },
    {
        "title": "SimpleText Best of Labs in CLEF-2022: Simplify Text Generation with Prompt Engineering",
        "firstAuthor": "Shih-Hung Wu",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "7c27962596c64937e2e4c326ed5a5bfd4dfda4bb"
    },
    {
        "title": "Evaluation of Prompts to Simplify Cardiovascular Disease Information Using a Large Language Model",
        "firstAuthor": "Mbbs Vishala Mishra",
        "url": "https://www.medrxiv.org/content/medrxiv/early/2023/11/09/2023.11.08.23298225.full.pdf",
        "dateSubmitted": "2023-11-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "AI chatbots powered by large language models (LLMs) are emerging as an important source of public-facing medical information. Generative models hold promise for producing tailored guidance at scale, which could advance health literacy and mitigate well-known disparities in the accessibility of health-protective information. In this study, we highlight an important limitation of basic approaches to AI-powered text simplification: when given a zero-shot or one-shot simplification prompt, GPT-4 often responds by omitting critical details. To address this limitation, we developed a new prompting strategy, which we term rubric prompting. Rubric prompts involve a combination of a zero-shot simplification prompt with brief reminders about important topics to address. Using rubric prompts, we generate recommendations about cardiovascular disease prevention that are more complete, more readable, and have lower syntactic complexity than baseline responses produced without prompt engineering. This analysis provides a blueprint for rigorous evaluation of AI model outputs in medicine.",
        "paperId": "7cf954437d9bcb6cba6176459f4c8101545d1193"
    },
    {
        "title": "Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review",
        "firstAuthor": "Banghao Chen",
        "url": null,
        "dateSubmitted": "2023-10-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper delves into the pivotal role of prompt engineering in unleashing the capabilities of Large Language Models (LLMs). Prompt engineering is the process of structuring input text for LLMs and is a technique integral to optimizing the efficacy of LLMs. This survey elucidates foundational principles of prompt engineering, such as role-prompting, one-shot, and few-shot prompting, as well as more advanced methodologies such as the chain-of-thought and tree-of-thoughts prompting. The paper sheds light on how external assistance in the form of plugins can assist in this task, and reduce machine hallucination by retrieving external knowledge. We subsequently delineate prospective directions in prompt engineering research, emphasizing the need for a deeper understanding of structures and the role of agents in Artificial Intelligence-Generated Content (AIGC) tools. We discuss how to assess the efficacy of prompt methods from different perspectives and using different methods. Finally, we gather information about the application of prompt engineering in such fields as education and programming, showing its transformative potential. This comprehensive survey aims to serve as a friendly guide for anyone venturing through the big world of LLMs and prompt engineering.",
        "paperId": "7d083d654f66f763302d8a5f0678beb753f6507b"
    },
    {
        "title": "Large Language Models in Fault Localisation",
        "firstAuthor": "Yonghao Wu",
        "url": "https://arxiv.org/pdf/2308.15276",
        "dateSubmitted": "2023-08-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large Language Models (LLMs) have shown promise in multiple software engineering tasks including code generation, program repair, code summarisation, and test generation. Fault localisation is instrumental in enabling automated debugging and repair of programs and was prominently featured as a highlight during the launch event of ChatGPT-4. Nevertheless, the performance of LLMs compared to state-of-the-art methods, as well as the impact of prompt design and context length on their efficacy, remains unclear. To fill this gap, this paper presents an in-depth investigation into the capability of ChatGPT-3.5 and ChatGPT-4, the two state-of-the-art LLMs, on fault localisation. Using the widely-adopted large-scale Defects4J dataset, we compare the two LLMs with the existing fault localisation techniques. We also investigate the consistency of LLMs in fault localisation, as well as how prompt engineering and the length of code context affect the fault localisation effectiveness. Our findings demonstrate that within function-level context, ChatGPT-4 outperforms all the existing fault localisation methods. Additional error logs can further improve ChatGPT models' localisation accuracy and consistency, with an average 46.9% higher accuracy over the state-of-the-art baseline SmartFL on the Defects4J dataset in terms of TOP-1 metric. However, when the code context of the Defects4J dataset expands to the class-level, ChatGPT-4's performance suffers a significant drop, with 49.9% lower accuracy than SmartFL under TOP-1 metric. These observations indicate that although ChatGPT can effectively localise faults under specific conditions, limitations are evident. Further research is needed to fully harness the potential of LLMs like ChatGPT for practical fault localisation applications.",
        "paperId": "7d3d98707182e0733d8cf5ee763314c60d638f4a"
    },
    {
        "title": "Prompt Engineering: Guiding the Way to Effective Large Language Models",
        "firstAuthor": "Mohammad Aljanabi",
        "url": "https://journal.esj.edu.iq/index.php/IJCM/article/download/1356/321",
        "dateSubmitted": "2023-11-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) have become prominent tools in various domains, such as natural language processing, machine translation, and the development of creative text. Nevertheless, in order to fully exploit the capabilities of Language Models, it is imperative to establish efficient communication channels between humans and machines. The discipline of engineering involves the creation of well-constructed and informative prompts, which act as a crucial link between human intention and the execution of tasks by machines. The present study examines the concept of rapid engineering, elucidating its underlying concepts, methodologies, and diverse range of practical applications.",
        "paperId": "7de25ad5ac7433e4d4071f450461b03fd2a39b8d"
    },
    {
        "title": "Supervised machine learning techniques for predicting multiple damage classes in bridges",
        "firstAuthor": "V. Giglioni",
        "url": null,
        "dateSubmitted": "2023-04-18",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The increasing number of bridge collapses has progressively fueled the interest towards the development of monitoring strategies able to ensure real-time damage assessment and preserve structural integrity with correct maintenance. In the context of vibration-based Structural Health Monitoring, recent improvements in sensor technologies and computer science have encouraged the use of Machine Learning algorithms in many engineering fields. In this light, the described methodology proposes to combine Domain Adaptation with supervised learning methods, such as the K-Nearest Neighbors algorithm, in order to correctly assign damage labels to statistically-aligned features. To this aim, natural frequencies gathered during healthy and abnormal conditions are selected as damage-sensitive quantities, bringing a physical meaning and providing information on global structural dynamics. Damage detection results are evaluated and compared before and after Domain Adaptation by employing specific performance metrics. The developed procedure is validated on the Z24 benchmark bridge and the Finite Element Model of the same structure, properly calibrated based on available experimental data. Within the numerical environment, several modal analysis are carried out both assuming pristine conditions and simulating realistic damage scenarios, that involve concrete elastic modulus\u2019 reduction for specific bridge elements. The goal of the proposed technique would be to effectively identify and classify different types of damage cases, enabling knowledge transfer among a population of structures and thus representing a prompt engineering decision-support tool to capture damage-induced variations.",
        "paperId": "7e4909d20357dd4b2ca04acdc8226a9c3d39d6c9"
    },
    {
        "title": "Prompt-Free Diffusion: Taking \"Text\" out of Text-to-Image Diffusion Models",
        "firstAuthor": "Xingqian Xu",
        "url": "http://arxiv.org/pdf/2305.16223",
        "dateSubmitted": "2023-05-25",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Text-to-image (T2I) research has grown explosively in the past year, owing to the large-scale pre-trained diffusion models and many emerging personalization and editing approaches. Yet, one pain point persists: the text prompt engineering, and searching high-quality text prompts for customized results is more art than science. Moreover, as commonly argued:\"an image is worth a thousand words\"- the attempt to describe a desired image with texts often ends up being ambiguous and cannot comprehensively cover delicate visual details, hence necessitating more additional controls from the visual domain. In this paper, we take a bold step forward: taking\"Text\"out of a pre-trained T2I diffusion model, to reduce the burdensome prompt engineering efforts for users. Our proposed framework, Prompt-Free Diffusion, relies on only visual inputs to generate new images: it takes a reference image as\"context\", an optional image structural conditioning, and an initial noise, with absolutely no text prompt. The core architecture behind the scene is Semantic Context Encoder (SeeCoder), substituting the commonly used CLIP-based or LLM-based text encoder. The reusability of SeeCoder also makes it a convenient drop-in component: one can also pre-train a SeeCoder in one T2I model and reuse it for another. Through extensive experiments, Prompt-Free Diffusion is experimentally found to (i) outperform prior exemplar-based image synthesis approaches; (ii) perform on par with state-of-the-art T2I models using prompts following the best practice; and (iii) be naturally extensible to other downstream applications such as anime figure generation and virtual try-on, with promising quality. Our code and models are open-sourced at https://github.com/SHI-Labs/Prompt-Free-Diffusion.",
        "paperId": "7ee8487178a0bb8927e97aff94d338d3b31097fe"
    },
    {
        "title": "\u041c\u043e\u0434\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0433\u043e\u0440\u0435\u043d\u0438\u044f \u043a\u043e\u043d\u0434\u0435\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0441\u0438\u0441\u0442\u0435\u043c \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0440\u0435\u0434\u0441\u0442\u0432 Data Mining",
        "firstAuthor": "\u0410\u0431\u0440\u0443\u043a\u043e\u0432 \u0412\u0438\u043a\u0442\u043e\u0440 \u0421\u0435\u0440\u0433\u0435\u0435\u0432\u0438\u0447",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The opportunities of Data Mining, in particular of artificial neural networks (ANN) and self-organizing Cohonen maps for modeling and prediction of burning behaviors of condensed systems (CS) represented. The computing models obtained permit to forecast burning behaviors of CS: regularities of extinction of the CS in pressure drop in the combustion chamber, a burning rate in dependence on a composition and availability of catalytic agents of CS at different pressures, The results obtained display that ANN can be considered as a good tool for approximation of multivariate experimental data that permit to extend and to forecast connection between variables of experiment, as the prompt engineering calculator specialized for problem solving of examination of process of CS burning, as a tool of obtaining of new \u00abexperimental\u00bb results and detections of new unknowns before legitimacies of burning, as a good tool of representation and storage of experimental results obtained.",
        "paperId": "7fab45df5d67a8947eafdfe0dc2fa5e6140d16e1"
    },
    {
        "title": "Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery",
        "firstAuthor": "Debadutta Dash",
        "url": "http://arxiv.org/pdf/2304.13714",
        "dateSubmitted": "2023-04-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Despite growing interest in using large language models (LLMs) in healthcare, current explorations do not assess the real-world utility and safety of LLMs in clinical settings. Our objective was to determine whether two LLMs can serve information needs submitted by physicians as questions to an informatics consultation service in a safe and concordant manner. Sixty six questions from an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple prompts. 12 physicians assessed the LLM responses' possibility of patient harm and concordance with existing reports from an informatics consultation service. Physician assessments were summarized based on majority vote. For no questions did a majority of physicians deem either LLM response as harmful. For GPT-3.5, responses to 8 questions were concordant with the informatics consult report, 20 discordant, and 9 were unable to be assessed. There were 29 responses with no majority on\"Agree\",\"Disagree\", and\"Unable to assess\". For GPT-4, responses to 13 questions were concordant, 15 discordant, and 3 were unable to be assessed. There were 35 responses with no majority. Responses from both LLMs were largely devoid of overt harm, but less than 20% of the responses agreed with an answer from an informatics consultation service, responses contained hallucinated references, and physicians were divided on what constitutes harm. These results suggest that while general purpose LLMs are able to provide safe and credible responses, they often do not meet the specific information need of a given question. A definitive evaluation of the usefulness of LLMs in healthcare settings will likely require additional research on prompt engineering, calibration, and custom-tailoring of general purpose models.",
        "paperId": "80785017029cab501fcdb90b98985cd2b36e1fb8"
    },
    {
        "title": "Engineering in the Community: Critical Consciousness and Engineering Education",
        "firstAuthor": "Helena Trbu\u0161i\u0107",
        "url": null,
        "dateSubmitted": "2014-04-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The continually changing, contemporary global society has been placing new demands on the engineering profession. The complexity of today's environmental, social and economic context has prompted engineering educators to call for a general reform in engineering education. While the common theme among this professional group is the necessity of reforming the engineering curriculum, how this should be done, and which changes are needed, is still a matter of contention. Non-technical content in engineering curricula has been implemented in order to address the perceived lack in competences when it comes to social or \"soft-skills\". However, certain proponents of reform, e.g. S. Beder, E. Conlon and H. Zandvoort, have voiced concerns regarding the focus on \"soft-skills\" and management competencies on the one hand, and a certain disregard for a broader understanding of non-technical knowledge for engineers on the other. This broader understanding implies teaching engineering students to take into consideration the relevant social context and contributing to the community in their daily practice of engineering. The first part of this paper deals with the mentioned contentions within the engineering professional community. As an answer to the described dilemmas, the paper explores the necessities and possibilities of incorporating critical thinking into the engineering curriculum. The paper proposes a tentative implementation of P. Freire's humanist education in engineering education [4]. The possibilities of the pedagogy of critical consciousness have the capacity to move beyond the mentioned divisions by merging practical social skills (i. e. \"soft skills\") with involvement in the community.",
        "paperId": "80e8dbbfff1906bfe33a86e80ec3dbc4b1d5a8ba"
    },
    {
        "title": "Indicative Summarization of Long Discussions",
        "firstAuthor": "S. Syed",
        "url": null,
        "dateSubmitted": "2023-11-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Online forums encourage the exchange and discussion of different stances on many topics. Not only do they provide an opportunity to present one's own arguments, but may also gather a broad cross-section of others' arguments. However, the resulting long discussions are difficult to overview. This paper presents a novel unsupervised approach using large language models (LLMs) to generating indicative summaries for long discussions that basically serve as tables of contents. Our approach first clusters argument sentences, generates cluster labels as abstractive summaries, and classifies the generated cluster labels into argumentation frames resulting in a two-level summary. Based on an extensively optimized prompt engineering approach, we evaluate 19~LLMs for generative cluster labeling and frame classification. To evaluate the usefulness of our indicative summaries, we conduct a purpose-driven user study via a new visual interface called Discussion Explorer: It shows that our proposed indicative summaries serve as a convenient navigation tool to explore long discussions.",
        "paperId": "813370072963a32c6a3a371fd5000bdbf777eca3"
    },
    {
        "title": "Peer-Prompted Engineering Design: How Do Adolescents Interact and Strategize?",
        "firstAuthor": "K. Strong",
        "url": null,
        "dateSubmitted": "2020-05-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "829dc0c538fd48590ccd2efaa90b350e47cc7173"
    },
    {
        "title": "Large Language Models and Prompt Engineering for Biomedical Query Focused Multi-Document Summarisation",
        "firstAuthor": "Diego Moll\u00e1 Aliod",
        "url": null,
        "dateSubmitted": "2023-11-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper reports on the use of prompt engineering and GPT-3.5 for biomedical query-focused multi-document summarisation. Using GPT-3.5 and appropriate prompts, our system achieves top ROUGE-F1 results in the task of obtaining short-paragraph-sized answers to biomedical questions in the 2023 BioASQ Challenge (BioASQ 11b). This paper confirms what has been observed in other domains: 1) Prompts that incorporated few-shot samples generally improved on their counterpart zero-shot variants; 2) The largest improvement was achieved by retrieval augmented generation. The fact that these prompts allow our top runs to rank within the top two runs of BioASQ 11b demonstrate the power of using adequate prompts for Large Language Models in general, and GPT-3.5 in particular, for query-focused summarisation.",
        "paperId": "82c39d297d4ca723e6faa4bfe0dd7cc9918d623f"
    },
    {
        "title": "Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering",
        "firstAuthor": "Edward Junprung",
        "url": "https://arxiv.org/pdf/2308.07411",
        "dateSubmitted": "2023-08-14",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The final frontier for simulation is the accurate representation of complex, real-world social systems. While agent-based modeling (ABM) seeks to study the behavior and interactions of agents within a larger system, it is unable to faithfully capture the full complexity of human-driven behavior. Large language models (LLMs), like ChatGPT, have emerged as a potential solution to this bottleneck by enabling researchers to explore human-driven interactions in previously unimaginable ways. Our research investigates simulations of human interactions using LLMs. Through prompt engineering, inspired by Park et al. (2023), we present two simulations of believable proxies of human behavior: a two-agent negotiation and a six-agent murder mystery game.",
        "paperId": "831fd0c18d10e42330cca36e0c5769762fb419e7"
    },
    {
        "title": "AutoHint: Automatic Prompt Optimization with Hint Generation",
        "firstAuthor": "Hong Sun",
        "url": "https://arxiv.org/pdf/2307.07415",
        "dateSubmitted": "2023-07-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induction dataset for both zero-shot and few-short prompts, where experiments demonstrate our method is able to significantly boost accuracy for multiple tasks.",
        "paperId": "838e1317454724a9bb758d05d97e6058e11a8251"
    },
    {
        "title": "Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate (WebNLG 2023)",
        "firstAuthor": "Michela Lorandi",
        "url": "https://arxiv.org/pdf/2308.09957",
        "dateSubmitted": "2023-08-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "LLMs are great at tasks involving English which dominates in their training data. We explore their ability to address tasks involving languages that are severely under-represented in their training data. More specifically, we do this in the context of data-to-text generation for Irish, Maltese, Welsh and Breton. During the prompt-engineering phase we tested GPT-3.5 and~4 with a range of prompt types and formats on a small sample of example input/output pairs. We then fully evaluated the two most promising prompts in two scenarios: (i) direct generation into the under-resourced languages, and (ii) generation into English followed by translation into the under-resourced languages. We find that few-shot prompting works better for direct generation into under-resourced languages, but that the difference disappears when pivoting via English. The few-shot + translation system variants were submitted to the WebNLG 2023 shared task where they outperformed all other systems by substantial margins in all languages on all automatic metrics. We conclude that good performance can be achieved with state-of-the-art LLMs out-of-the box for under-resourced languages. However, best results (for Welsh) of BLEU 25.12, ChrF++ 0.55, and TER 0.64 are well below the lowest ranked English system at WebNLG\u201920 with BLEU 0.391, ChrF++ 0.579, and TER 0.564.",
        "paperId": "842f79c5acab440f8d7a592201738a3e854a5186"
    },
    {
        "title": "Supporting self-directed learning and self-assessment using TeacherGAIA, a generative AI chatbot application: Learning approaches and prompt engineering",
        "firstAuthor": "Farhan Ali",
        "url": null,
        "dateSubmitted": "2023-07-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ABSTRACT Self-directed learning and self-assessment require student responsibility over learning needs, goals, processes, and outcomes. However, this student-led learning can be challenging to achieve in a classroom limited by a one-to-many teacher-led instruction. We, thus, have designed and prototyped a generative artificial intelligence chatbot application (GAIA), named TeacherGAIA, that can be used to asynchronously support students in their self-directed learning and self-assessment outside the classroom. We first identified diverse constructivist learning approaches that align with, and promote, student-led learning. These included knowledge construction, inquiry-based learning, self-assessment, and peer teaching. The in-context learning abilities of large language model (LLM) from OpenAI were then leveraged via prompt engineering to steer interactions supporting these different learning approaches. These interactions contrasted with ChatGPT, OpenAI\u2019s chatbot which by default engaged in the traditional transmissionist mode of learning reminiscent of teacher-led instruction. Preliminary design, prompt engineering and prototyping suggested fidelity to the learning approaches, cognitive guidance, and social-emotional support, all of which were implemented in a generative AI manner without pre-specified rules or \u201chard-coding\u201d. Other affordances of TeacherGAIA are discussed and future development outlined. We anticipate TeacherGAIA to be a useful application for teachers in facilitating self-directed learning and self-assessment among K-12 students.",
        "paperId": "84b8624b41eb594abbd8d256cc5bc8a43c942a75"
    },
    {
        "title": "The application of ChatGPT in healthcare progress notes: A commentary from a clinical and research perspective",
        "firstAuthor": "Josh Nguyen",
        "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ctm2.1324",
        "dateSubmitted": "2023-07-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ChatGPT, powered by one of the most advanced language processing systems, gained over 100 million users in just 2 months following its release in November 2022.1 This unprecedented popularity is likely due to its wide range of potential applications in fields, such as engineering, education and healthcare.2\u20134 The integration of artificial intelligence (AI)\u2014driven language models like ChatGPT has the potential to revolutionize documentation practices, streamline workflows, and ultimately lead to more efficient and patient-centred care,2 though the use of such tools is not without its challenges. Here, we outline the potential benefits and pitfalls of implementing AI-driven language models, such as ChatGPT, in the creation and management of healthcare progress notes using prompt engineering techniques. We provide recommendations for responsible and effective integration into clinical practice and priorities for future research. Healthcare clinicians spend 35% of their time documenting patient data, and evidence suggests the length of healthcare case notes has been increasing over time.5 Existing innovations, such as speech recognition technology, yield no clear benefit in timesaving or documentation quality.6 With the ability to coherently write logical and accurate text within a few seconds, ChatGPT has the potential to reduce time spent on tasks such as preparing healthcare progress notes, and might also enhance",
        "paperId": "86d84341fb7f6d3990acccf4a433147501b20934"
    },
    {
        "title": "Prompt Engineering in Medical Image Segmentation: An Overview of the Paradigm Shift",
        "firstAuthor": "Hazrat Ali",
        "url": null,
        "dateSubmitted": "2023-09-16",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Foundation AI models have emerged as powerful pre-trained models on a large scale, capable of seamlessly handling diverse tasks across multiple domains with minimal or no fine-tuning. These models, exemplified by the impressive achievements of GPT-3 and BERT in natural language processing (NLP), as well as CLIP and DALL-E in computer vision, have garnered considerable attention for their exceptional performance. A noteworthy addition to the realm of image segmentation is the Segment Anything Model (SAM), a foundation AI model that revolutionizes image segmentation. With a single click or a natural language prompt, SAM exhibits the remarkable ability to segment any object within an image, marking a significant paradigm shift in medical image segmentation. Unlike conventional approaches that rely on labeled data and domain-specific knowledge, SAM breaks free from these constraints. Deep convolutional neural network (DCNN)-based, SAM comprises an image encoder, a prompt encoder, and a mask decoder, showcasing its efficient and flexible architecture. Medical image segmentation, in particular, benefits from SAM\u2019s exceptional speed and high-quality segmentation. In this paper, we delve into the effectiveness of SAM for medical image segmentation shedding light on its capabilities. Moreover, our investigation explores the strengths and limitations of prompt engineering in medical computer vision applications, not only encompassing SAM but also other foundation AI models. Through this exploration, we unravel their immense potential in catalyzing a paradigm shift in the field of medical imaging.",
        "paperId": "87526862142942608826022650b23e30014a7619"
    },
    {
        "title": "A Simple Zero-shot Prompt Weighting Technique to Improve Prompt Ensembling in Text-Image Models",
        "firstAuthor": "J. Allingham",
        "url": "https://arxiv.org/pdf/2302.06235",
        "dateSubmitted": "2023-02-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Contrastively trained text-image models have the remarkable ability to perform zero-shot classification, that is, classifying previously unseen images into categories that the model has never been explicitly trained to identify. However, these zero-shot classifiers need prompt engineering to achieve high accuracy. Prompt engineering typically requires hand-crafting a set of prompts for individual downstream tasks. In this work, we aim to automate this prompt engineering and improve zero-shot accuracy through prompt ensembling. In particular, we ask\"Given a large pool of prompts, can we automatically score the prompts and ensemble those that are most suitable for a particular downstream dataset, without needing access to labeled validation data?\". We demonstrate that this is possible. In doing so, we identify several pathologies in a naive prompt scoring method where the score can be easily overconfident due to biases in pre-training and test data, and we propose a novel prompt scoring method that corrects for the biases. Using our proposed scoring method to create a weighted average prompt ensemble, our method outperforms equal average ensemble, as well as hand-crafted prompts, on ImageNet, 4 of its variants, and 11 fine-grained classification benchmarks, all while being fully automatic, optimization-free, and not requiring access to labeled validation data.",
        "paperId": "877e27a1d89095fcf686ab675f62a8432d3285ee"
    },
    {
        "title": "Leveraging GIS and ChatGPT for Social Goods and Higher Education",
        "firstAuthor": "Yijun Gao",
        "url": "https://iopn.library.illinois.edu/journals/aliseacp/article/download/1392/1045",
        "dateSubmitted": "2023-09-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 GIS (Geographic Information System) is a powerful tool for managing, analyzing, and presenting spatial data. It has a wide range of applications for social goods, from mapping public services (data) to analyzing the spatial distribution of information resources and use. On the other hand, ChatGPT is an AI-based chatbot that engages in natural language conversations with users. It can be trained to answer questions, provide assistance, and facilitate learning in social services and higher education. Our research combines the two technologies to find innovative and efficient ways of delivering social services and improved LIS education. For example, GIS can map out the locations of library resources, patron demographics, local history, and support other services (i.e., crisis responses). ChatGPT can provide personalized assistance and information to users based on their location and preferences. We intend to use GIS + ChatGPT to create more accessible services/APPs for the underrepresented population in community or higher education. Utilizing GIS and ChatGPT (and other generative AI services) will create more accessible and convenient ways for users to access public data, especially for the seniors and new immigrants in the Great Chicago Area. We will also explore new initiatives to improve the librarian\u2019s professional training in \u201cContent Engineering\u201d and \u201cPrompt Engineering\u201d in the era of AI. We will also focus on the ethical implications of these technologies and ensure that they are used to respect user privacy and promote equitable access to quality information services and social justice.",
        "paperId": "88d2181b824ce5d7cb53213c9f545436df344bbf"
    },
    {
        "title": "Prompt Engineering Through the Lens of Optimal Control",
        "firstAuthor": "Yifan Luo",
        "url": null,
        "dateSubmitted": "2023-10-22",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Prompt Engineering (PE) has emerged as a critical technique for guiding Large Language Models (LLMs) in solving intricate tasks. Its importance is highlighted by its potential to significantly enhance the efficiency and effectiveness of human-machine interaction. As tasks grow increasingly complex, recent advanced PE methods have extended beyond the limitations of single-round interactions to embrace multi-round interactions, which allows for a deeper and more nuanced engagement with LLMs. In this paper, we propose an optimal control framework tailored for multi-round interactions with LLMs. This framework provides a unified mathematical structure that not only systematizes the existing PE methods but also sets the stage for rigorous analytical improvements. Furthermore, we extend this framework to include PE via ensemble methods and multi-agent collaboration, thereby enlarging the scope of applicability. By adopting an optimal control perspective, we offer fresh insights into existing PE methods and highlight theoretical challenges that warrant future research. Besides, our work lays a foundation for the development of more effective and interpretable PE methods.",
        "paperId": "8a1792a03c4b0ced9650940ca6e9ea495922ace2"
    },
    {
        "title": "Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering",
        "firstAuthor": "Angus Addlesee",
        "url": "https://arxiv.org/pdf/2308.15231",
        "dateSubmitted": "2023-08-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other\u2019s goals, and provide other people\u2019s goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The \u2018reasoning\u2019 style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A \u2018story\u2019 style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.",
        "paperId": "8a1a8290f7d42b0ce60445a4c0130ef737b3ff69"
    },
    {
        "title": "Large Language Models for Propaganda Detection",
        "firstAuthor": "Kilian Sprenkamp",
        "url": "https://arxiv.org/pdf/2310.06422",
        "dateSubmitted": "2023-10-10",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The prevalence of propaganda in our digital society poses a challenge to societal harmony and the dissemination of truth. Detecting propaganda through NLP in text is challenging due to subtle manipulation techniques and contextual dependencies. To address this issue, we investigate the effectiveness of modern Large Language Models (LLMs) such as GPT-3 and GPT-4 for propaganda detection. We conduct experiments using the SemEval-2020 task 11 dataset, which features news articles labeled with 14 propaganda techniques as a multi-label classification problem. Five variations of GPT-3 and GPT-4 are employed, incorporating various prompt engineering and fine-tuning strategies across the different models. We evaluate the models' performance by assessing metrics such as $F1$ score, $Precision$, and $Recall$, comparing the results with the current state-of-the-art approach using RoBERTa. Our findings demonstrate that GPT-4 achieves comparable results to the current state-of-the-art. Further, this study analyzes the potential and challenges of LLMs in complex tasks like propaganda detection.",
        "paperId": "8a419947c46b8fa491ec613664372e376eb9f0c6"
    },
    {
        "title": "AI Foundation Models for Weather and Climate: Applications, Design, and Implementation",
        "firstAuthor": "S. K. Mukkavilli",
        "url": "https://arxiv.org/pdf/2309.10808",
        "dateSubmitted": "2023-09-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting. There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth. Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks. With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI. In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks. Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models. Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology. We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions. We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers. In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model.",
        "paperId": "8a8ac2467aee4d70866a1b2410e59565ef6ae292"
    },
    {
        "title": "iTutor: A Generative Tutorial System for Teaching the Elders to Use Smartphone Applications",
        "firstAuthor": "Ruishi Zou",
        "url": null,
        "dateSubmitted": "2023-10-29",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We present iTutor, a generative tutorial system for promoting smartphone use proficiency among elders. iTutor is unique because it can dynamically generate tutorials based on current operation goals and UI context, which we achieved through leveraging prompt engineering to large language models (LLMs). Our evaluations showed potential for this approach, as we yielded 78.6% accuracy in the instruction generation process. We conclude by providing the roadmap for further development.",
        "paperId": "8c5298558ce8e7905e4cb61bdd5f65eccaa2de0c"
    },
    {
        "title": "LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation",
        "firstAuthor": "Christian Munley",
        "url": "https://arxiv.org/pdf/2310.04963",
        "dateSubmitted": "2023-10-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Large language models (LLMs) are a new and powerful tool for a wide span of applications involving natural language and demonstrate impressive code generation abilities. In this paper, we explore the capabilitity of state-of-the-art LLMs, including closed-source options like OpenAI GPT-4 and open-source alternatives like Meta AI Codellama, to automatically generate tests and use these tests to validate and verify compiler implementations of a directive-based programming paradigm, OpenACC. Our approach entails exploring various prompt engineering techniques including a code template, retrieval-augmented generation (RAG) with code template, expressive prompt using RAG with code template, one-shot example, and RAG with one-shot example. This paper focusses on (a) exploring the capabilities of the latest LLMs for code generation, (b) investigating prompt and fine tuning methods, and (c) analyzing the outcome of LLMs generated tests",
        "paperId": "8c52b3bbe5897ba3f42b38c5bfc33bbd48f9a1f2"
    },
    {
        "title": "Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements",
        "firstAuthor": "Conrad Borchers",
        "url": "https://arxiv.org/pdf/2205.11374",
        "dateSubmitted": "2022-05-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias.",
        "paperId": "8c90bfe05c06fd47eaec0f5b1662e06862572afe"
    },
    {
        "title": "VOICE: Visual Oracle for Interaction, Conversation, and Explanation",
        "firstAuthor": "Donggang Jia",
        "url": "http://arxiv.org/pdf/2304.04083",
        "dateSubmitted": "2023-04-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We present VOICE, a novel approach for connecting large language models' (LLM) conversational capabilities with interactive exploratory visualization. VOICE introduces several innovative technical contributions that drive our conversational visualization framework. Our foundation is a pack-of-bots that can perform specific tasks, such as assigning tasks, extracting instructions, and generating coherent content. We employ fine-tuning and prompt engineering techniques to tailor bots' performance to their specific roles and accurately respond to user queries, and a new prompt-based iterative scene-tree generation establishes a coupling with a structural model. Our text-to-visualization method generates a flythrough sequence matching the content explanation. Finally, 3D natural language interaction provides capabilities to navigate and manipulate the 3D models in real-time. The VOICE framework can receive arbitrary voice commands from the user and responds verbally, tightly coupled with corresponding visual representation with low latency and high accuracy. We demonstrate the effectiveness and high generalizability potential of our approach by applying it to two distinct domains: analyzing three 3D molecular models with multi-scale and multi-instance attributes, and showcasing its effectiveness on a cartographic map visualization. A free copy of this paper and all supplemental materials are available at https://osf.io/g7fbr/.",
        "paperId": "8ca384547bb4b21b7f38d478119bf3168eb9c9cd"
    },
    {
        "title": "Distilled Language Models are economically efficient for the enterprise. ...mostly.",
        "firstAuthor": "Kristen Howell",
        "url": "http://arxiv.org/pdf/2306.07402",
        "dateSubmitted": "2023-06-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Contacting customer service via chat is a common practice. Because employing customer service agents is expensive, many companies are turning to NLP that assists human agents by auto-generating responses that can be used directly or with modifications. With their ability to handle large context windows, Large Language Models (LLMs) are a natural fit for this use case. However, their efficacy must be balanced with the cost of training and serving them. This paper assesses the practical cost and impact of LLMs for the enterprise as a function of the usefulness of the responses that they generate. We present a cost framework for evaluating an NLP model\u2019s utility for this use case and apply it to a single brand as a case study in the context of an existing agent assistance product. We compare three strategies for specializing an LLM \u2014 prompt engineering, fine-tuning, and knowledge distillation \u2014 using feedback from the brand\u2019s customer service agents. We find that the usability of a model\u2019s responses can make up for a large difference in inference cost for our case study brand, and we extrapolate our findings to the broader enterprise space.",
        "paperId": "8e5af286e461ad07625e43e17d4c69e8b16d9fbb"
    },
    {
        "title": "Is GPT4 a Good Trader?",
        "firstAuthor": "Bingzhe Wu",
        "url": "https://arxiv.org/pdf/2309.10982",
        "dateSubmitted": "2023-09-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recently, large language models (LLMs), particularly GPT-4, have demonstrated significant capabilities in various planning and reasoning tasks \\cite{cheng2023gpt4,bubeck2023sparks}. Motivated by these advancements, there has been a surge of interest among researchers to harness the capabilities of GPT-4 for the automated design of quantitative factors that do not overlap with existing factor libraries, with an aspiration to achieve alpha returns \\cite{webpagequant}. In contrast to these work, this study aims to examine the fidelity of GPT-4's comprehension of classic trading theories and its proficiency in applying its code interpreter abilities to real-world trading data analysis. Such an exploration is instrumental in discerning whether the underlying logic GPT-4 employs for trading is intrinsically reliable. Furthermore, given the acknowledged interpretative latitude inherent in most trading theories, we seek to distill more precise methodologies of deploying these theories from GPT-4's analytical process, potentially offering invaluable insights to human traders. To achieve this objective, we selected daily candlestick (K-line) data from specific periods for certain assets, such as the Shanghai Stock Index. Through meticulous prompt engineering, we guided GPT-4 to analyze the technical structures embedded within this data, based on specific theories like the Elliott Wave Theory. We then subjected its analytical output to manual evaluation, assessing its interpretative depth and accuracy vis-\\`a-vis these trading theories from multiple dimensions. The results and findings from this study could pave the way for a synergistic amalgamation of human expertise and AI-driven insights in the realm of trading.",
        "paperId": "8efcdc15c5f028f968d6a004a64593245c49927b"
    },
    {
        "title": "Cut the CARP: Fishing for zero-shot story evaluation",
        "firstAuthor": "Shahbuland Matiana",
        "url": null,
        "dateSubmitted": "2021-10-06",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recent advances in large-scale language models (Raffel et al., 2019; Brown et al., 2020) have brought significant qualitative and quantitative improvements in machine-driven text generation. Despite this, generation and evaluation of machine-generated narrative text remains a challenging problem. Objective evaluation of computationally-generated stories may be prohibitively expensive, require meticulously annotated datasets, or may not adequately measure the logical coherence of a generated story's narratological structure. Informed by recent advances in contrastive learning (Radford et al., 2021), we present Contrastive Authoring and Reviewing Pairing (CARP): a scalable, efficient method for performing qualitatively superior, zero-shot evaluation of stories. We show a strong correlation between human evaluation of stories and those of CARP. Model outputs more significantly correlate with corresponding human input than those language-model based methods which utilize finetuning or prompt engineering approaches. We also present and analyze the Story-Critique Dataset, a new corpora composed of 1.3 million aligned story-critique pairs derived from over 80,000 stories. We expect this corpus to be of interest to NLP researchers.",
        "paperId": "8f5177778ba5915a763e08d20977173bc18f5c87"
    },
    {
        "title": "Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions",
        "firstAuthor": "Dawen Zhang",
        "url": "https://arxiv.org/pdf/2307.03941",
        "dateSubmitted": "2023-07-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. It was a significant emergent right as the result of the evolution of technology. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of differential privacy, machine unlearning, model editing, and prompt engineering. With the rapid advancement of AI and the increasing need of regulating this powerful technology, learning from the case of RTBF can provide valuable lessons for technical practitioners, legal experts, organizations, and authorities.",
        "paperId": "8f93f95e093aab16e594b4a246a205007e107c7a"
    },
    {
        "title": "Why Johnny Can\u2019t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts",
        "firstAuthor": "J. Zamfirescu-Pereira",
        "url": "https://dl.acm.org/doi/pdf/10.1145/3544548.3581388",
        "dateSubmitted": "2023-04-19",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Pre-trained large language models (\u201cLLMs\u201d) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (\u201cprompting\u201d) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in \u201cend-user prompt engineering\u201d using a design probe\u2014a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.",
        "paperId": "8f9e864fab09bbae4a46a2a62bb954db1a88eb3e"
    },
    {
        "title": "CONA: A novel CONtext-Aware instruction paradigm for communication using large language model",
        "firstAuthor": "Nan Zhou",
        "url": "http://arxiv.org/pdf/2305.18620",
        "dateSubmitted": "2023-05-26",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "We introduce CONA, a novel context-aware instruction paradigm for effective knowledge dissemination using generative pre-trained transformer (GPT) models. CONA is a flexible framework designed to leverage the capabilities of Large Language Models (LLMs) and incorporate DIKW (Data, Information, Knowledge, Wisdom) hierarchy to automatically instruct and optimise presentation content, anticipate potential audience inquiries, and provide context-aware answers that adaptive to the knowledge level of the audience group. The unique aspect of the CONA paradigm lies in its combination of an independent advisory mechanism and a recursive feedback loop rooted on the DIKW hierarchy. This synergy significantly enhances context-aware contents, ensuring they are accessible and easily comprehended by the audience. This paradigm is an early pioneer to explore new methods for knowledge dissemination and communication in the LLM era, offering effective support for everyday knowledge sharing scenarios. We conduct experiments on a range of audience roles, along with materials from various disciplines using GPT4. Both quantitative and qualitative results demonstrated that the proposed CONA paradigm achieved remarkable performance compared to the outputs guided by conventional prompt engineering.",
        "paperId": "90b1baf2cf299ef0e0ef7611a12311bd6cab3ed7"
    },
    {
        "title": "Assessing Test-time Variability for Interactive 3D Medical Image Segmentation with Diverse Point Prompts",
        "firstAuthor": "Hao Li",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Interactive segmentation model leverages prompts from users to produce robust segmentation. This advancement is facilitated by prompt engineering, where interactive prompts serve as strong priors during test-time. However, this is an inherently subjective and hard-to-reproduce process. The variability in user expertise and inherently ambiguous boundaries in medical images can lead to inconsistent prompt selections, potentially affecting segmentation accuracy. This issue has not yet been extensively explored for medical imaging. In this paper, we assess the test-time variability for interactive medical image segmentation with diverse point prompts. For a given target region, the point is classified into three sub-regions: boundary, margin, and center. Our goal is to identify a straightforward and efficient approach for optimal prompt selection during test-time based on three considerations: (1) benefits of additional prompts, (2) effects of prompt placement, and (3) strategies for optimal prompt selection. We conduct extensive experiments on the public Medical Segmentation Decathlon dataset for challenging colon tumor segmentation task. We suggest an optimal strategy for prompt selection during test-time, supported by comprehensive results. The code is publicly available at https://github.com/MedICL-VU/variability",
        "paperId": "90c0759c2004e5c2d6f9a7fb913ccb1bea548809"
    },
    {
        "title": "The Limits of Prompt Engineering in Medical Problem-Solving: A Comparative Analysis with ChatGPT on calculation based USMLE Medical Questions",
        "firstAuthor": "Dhavalkumar Patel",
        "url": "https://www.medrxiv.org/content/medrxiv/early/2023/08/09/2023.08.06.23293710.full.pdf",
        "dateSubmitted": "2023-08-09",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Background: Prompt engineering significantly improves the performance of Large Language Models (LLMs), including GPT3.5 and GPT4. However, its utilization remains largely uncharted in the medical field. Objective: This research aimed to assess the influence of different prompt engineering strategies on ChatGPT (GPT3.5) in solving medical problems, specifically focusing on medical calculations and clinical scenarios. Design: We utilized three different prompting strategies direct prompting, the chain of thoughts (CoT), and a modified CoT method across two sets of USMLE-style questions. Setting: The experiment was conducted using a 1000-question dataset, generated by GPT-4 with a specialized prompt, and a secondary analysis with 95 actual USMLE Step 1 questions. Measurements: Model performance was assessed based on accuracy in answering medical calculation and clinical scenario questions across varying difficulty levels and medical subjects. Results: Direct prompting demonstrated non-inferior accuracy compared to the CoT and modified CoT methods in both question categories. This trend remained consistent regardless of difficulty level or subject matter in the GPT4 generated dataset and USMLE Step 1 sample questions. Limitations: The study evaluated GPT3.5 for answering and GPT 4 for question generation, limiting generalizability. Conclusion: Our findings indicate that while prompt engineering can facilitate question generation, as exemplified by GPT4, it does not necessarily improve model performance in answering medical calculation or clinical scenario questions. This suggests that the ChatGPT model is already effectively optimized for such tasks. Additionally, this finding simplifies the use of such models in healthcare settings, allowing practitioners to interact effectively with tools like ChatGPT without the need for complex prompt engineering, potentially encouraging wider adoption in clinical practice for problem-solving, patient care, and continuous learning.",
        "paperId": "90f9c8364f7ffc54fe19854ffa456c7744ba8316"
    },
    {
        "title": "Prompt Engineering: a methodology for optimizing interactions with AI-Language Models in the field of engineering",
        "firstAuthor": "Juan David Vel\u00e1squez-Henao",
        "url": "https://revistas.unal.edu.co/index.php/dyna/article/download/111700/90275",
        "dateSubmitted": "2023-11-03",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "ChatGPT is a versatile conversational Artificial Intelligence model that responds to user input prompts, with applications in academia and various sectors. However, crafting effective prompts can be challenging, leading to potentially inaccurate or contextually inappropriate responses, emphasizing the importance of prompt engineering in achieving accurate outcomes across different domains. This study aims to address this void by introducing a methodology for optimizing interactions with Artificial Intelligence language models, like ChatGPT, through prompts in the field of engineering. The approach is called GPEI and relies on the latest advancements in this area; and consists of four steps: define the objective, design the prompt, evaluate the response, and iterate. Our proposal involves two key aspects: data inclusion in prompt design for engineering applications and the integration of Explainable Artificial Intelligence principles to assess responses, enhancing transparency. It combines insights from various methodologies to address issues like hallucinations, emphasizing iterative prompt refinement techniques like posing opposing questions and using specific patterns for improvement. This methodology could improve prompt precision and utility in engineering.",
        "paperId": "9182b7d9848442db8ca60731ce66d3bf169975e7"
    },
    {
        "title": "Unsupervised Hashing with Semantic Concept Mining",
        "firstAuthor": "Rong-Cheng Tu",
        "url": "https://arxiv.org/pdf/2209.11475",
        "dateSubmitted": "2022-09-23",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Recently, to improve the unsupervised image retrieval performance, plenty of unsupervised hashing methods have been proposed by designing a semantic similarity matrix, which is based on the similarities between image features extracted by a pre-trained CNN model. However, most of these methods tend to ignore high-level abstract semantic concepts contained in images. Intuitively, concepts play an important role in calculating the similarity among images. In real-world scenarios, each image is associated with some concepts, and the similarity between two images will be larger if they share more identical concepts. Inspired by the above intuition, in this work, we propose a novel Unsupervised Hashing with Semantic Concept Mining, called UHSCM, which leverages a VLP model to construct a high-quality similarity matrix. Specifically, a set of randomly chosen concepts is first collected. Then, by employing a vision-language pretraining (VLP) model with the prompt engineering which has shown strong power in visual representation learning, the set of concepts is denoised according to the training images. Next, the proposed method UHSCM applies the VLP model with prompting again to mine the concept distribution of each image and construct a high-quality semantic similarity matrix based on the mined concept distributions. Finally, with the semantic similarity matrix as guiding information, a novel hashing loss with a modified contrastive loss based regularization item is proposed to optimize the hashing network. Extensive experiments on three benchmark datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.",
        "paperId": "91a291780103b328f65e700896ae6fa2230ec2e7"
    },
    {
        "title": "Human-in-the-Loop Interaction for continuously Improving Generative Model in Conversational Agent for Behavioral Intervention",
        "firstAuthor": "Xin Sun",
        "url": null,
        "dateSubmitted": "2023-03-27",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Conversational agent (CA) for psychotherapy and behavioral intervention has great potential to provide solutions that can benefit human health. However, most CA for behavior intervention and healthcare are based on pre-scripted conversations and rules instead of generative models, because the generative model is not stable enough to be used in the highly sensitive domain like behavioral intervention. Based on the fact that generative models and reinforcement learning techniques have been widely used in various domains, a CA integrating generative models for behavioral interventions is proposed in this work and the approach is expected to continuously improve the generative model and the agent itself based on collected human feedback from both client and therapist during the interaction. The approach involves techniques, such as few-shot generation by language models, prompt engineering, and reinforcement learning from human feedback (RLHF) as the Human-in-the-Loop interaction. We expect that this approach can enable the generative models to be used in highly sensitive fields such as mental healthcare and behavioral intervention.",
        "paperId": "92273c2d3ce3ae8316d776fcd24bb56455d100ad"
    },
    {
        "title": "Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue",
        "firstAuthor": "Junkai Zhou",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses. However, LLMs still lack an important ability: communication skills, which makes them more like information seeking tools than anthropomorphic chatbots. To make LLMs more anthropomorphic and proactive during the conversation, we add five communication skills to the response generation process: topic transition, proactively asking questions, concept guidance, empathy, and summarising often. The addition of communication skills increases the interest of users in the conversation and attracts them to chat for longer. To enable LLMs better understand and use communication skills, we design and add the inner monologue to LLMs. The complete process is achieved through prompt engineering and in-context learning. To evaluate communication skills, we construct a benchmark named Cskills for evaluating various communication skills, which can also more comprehensively evaluate the dialogue generation ability of the model. Experimental results show that the proposed CSIM strategy improves the backbone models and outperforms the baselines in both automatic and human evaluations.",
        "paperId": "93a10102cdd501fdc1ccc79868416313fe719e01"
    },
    {
        "title": "Me and the Machines: Possibilities and Pitfalls of Using Artificial Intelligence for Qualitative Data Analysis",
        "firstAuthor": "L. Chubb",
        "url": "https://journals.sagepub.com/doi/pdf/10.1177/16094069231193593",
        "dateSubmitted": "2023-01-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper describes how one researcher learned to overcome artificial intelligence (AI) paralysis and embrace ChatPDF. This freely available AI application uses natural language processing (NLP) to respond to user queries about an uploaded PDF. Researcher insights from experimenting with the AI tool ChatPDF for qualitative data analysis are presented, highlighting the advantages, pitfalls, and application-related considerations. As a two-phase curiosity experiment, the researcher engaged in a theory-building exercise to explore key concepts for understanding when using ChatPDF to assist researchers in qualitative data analysis. The experiment generated insights about the purposeful use of AI tools that incorporate NLP for analysis and the risks of inaccuracy when researchers are not familiar with the data or skilled in prompt engineering. Insights raise questions about whether ChatPDF is a viable research assistant for qualitative researchers, ethical issues with specific forms of qualitative data, and the potential of AI tools for community and student researchers.",
        "paperId": "93e907603cfe1a8af175e8670df485aaa9d0a522"
    },
    {
        "title": "P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting",
        "firstAuthor": "Ziyi Wang",
        "url": "http://arxiv.org/pdf/2208.02812",
        "dateSubmitted": "2022-08-04",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Nowadays, pre-training big models on large-scale datasets has become a crucial topic in deep learning. The pre-trained models with high representation ability and transferability achieve a great success and dominate many downstream tasks in natural language processing and 2D vision. However, it is non-trivial to promote such a pretraining-tuning paradigm to the 3D vision, given the limited training data that are relatively inconvenient to collect. In this paper, we provide a new perspective of leveraging pre-trained 2D knowledge in 3D domain to tackle this problem, tuning pre-trained image models with the novel Point-to-Pixel prompting for point cloud analysis at a minor parameter cost. Following the principle of prompting engineering, we transform point clouds into colorful images with geometry-preserved projection and geometry-aware coloring to adapt to pre-trained image models, whose weights are kept frozen during the end-to-end optimization of point cloud analysis tasks. We conduct extensive experiments to demonstrate that cooperating with our proposed Point-to-Pixel Prompting, better pre-trained image model will lead to consistently better performance in 3D vision. Enjoying prosperous development from image pre-training field, our method attains 89.3% accuracy on the hardest setting of ScanObjectNN, surpassing conventional point cloud models with much fewer trainable parameters. Our framework also exhibits very competitive performance on ModelNet classification and ShapeNet Part Segmentation. Code is available at https://github.com/wangzy22/P2P.",
        "paperId": "94a96f64bd93ad91642fa04da09bb709a26ac277"
    },
    {
        "title": "How to Create Business Value Through Technological Innovations Using ICCT Underlying Technologies",
        "firstAuthor": "P. Aithal",
        "url": "https://supublication.com/index.php/ijaeml/article/download/110/81/289",
        "dateSubmitted": "2023-06-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Purpose: Organizations are struggling to sustain and grow in the 21st century due to many challenges and uncertainties while doing their business. Long-term sustaining in the business needs retaining the existing customers and attracting new customers through various strategies for satisfying, delighting, and enlightening existing customers, and creating overwhelming demand through business value creation for attracting new customers. It is a challenge for all the decision-makers to find out how to create business value to retain existing customers and attract new customers. Here, a conceptual and exploratory analysis is made of how the innovations using technology create business value for organizations in general. \nMethodology: This conceptual analysis uses an exploratory research method. The information is collected using Google, Google Scholar, and Artificial Intelligence GPT search engines using appropriate keywords and prompt engineering respectively and the collected, analysed, compared, evaluated, and interpreted towards creating business value using technology with special emphasis on the use of ICCT underlying technologies. The advantages, benefits, constraints, and disadvantages of business value creation using ICCT underlying technologies for business value creation are listed from stakeholders\u2019 points of view. \nOutcome: The role of twelve ICCT Underlying Technologies including AI, Blockchain, Business intelligence, Cloud computing, Cyber security, 3D printing, IoT, Quantum computing, Mobile marketing, Information storage technology, Ubiquitous education technology, and VR & AR for Business Value Creation like Innovation and Differentiation, Customer focus, Operational efficiency, Strategic Partnerships and Alliances, Talent Management, Effective Marketing and Branding, Financial Performance and Growth, Sustainability and Corporate Social Responsibility, and Adaptability and Agility.\nOriginality/Value: New knowledge and interpretation are presented on how to create business value for long time sustainability by organizations in every industry. \nType o Paper: Exploratory Research Analysis",
        "paperId": "957929506442b88943950a7a2bcfd4b5ba664824"
    },
    {
        "title": "Prompt Engineering for Large Language Models",
        "firstAuthor": "Andrew Gao",
        "url": null,
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "95840ec08ba2e30490ee02fd0518bbfc0e8a0f4c"
    },
    {
        "title": "StyleMC: Multi-Channel Based Fast Text-Guided Image Generation and Manipulation",
        "firstAuthor": "Umut Kocasari",
        "url": "https://arxiv.org/pdf/2112.08493",
        "dateSubmitted": "2021-12-15",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Discovering meaningful directions in the latent space of GANs to manipulate semantic attributes typically requires large amounts of labeled data. Recent work aims to overcome this limitation by leveraging the power of Contrastive Language-Image Pre-training (CLIP), a joint text-image model. While promising, these methods require several hours of preprocessing or training to achieve the desired manipulations. In this paper, we present StyleMC, a fast and efficient method for text-driven image generation and manipulation. StyleMC uses a CLIP-based loss and an identity loss to manipulate images via a single text prompt without significantly affecting other attributes. Unlike prior work, StyleMC requires only a few seconds of training per text prompt to find stable global directions, does not require prompt engineering and can be used with any pre-trained StyleGAN2 model. We demonstrate the effectiveness of our method and compare it to state-of-the-art methods. Our code can be found at http://catlab-team.github.io/stylemc.",
        "paperId": "958cd33eb354d7f3d117767c2ff981614c940c8f"
    },
    {
        "title": "On the Discussion of Large Language Models: Symmetry of Agents and Interplay with Prompts",
        "firstAuthor": "Qineng Wang",
        "url": null,
        "dateSubmitted": "2023-11-13",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Two ways has been discussed to unlock the reasoning capability of a large language model. The first one is prompt engineering and the second one is to combine the multiple inferences of large language models, or the multi-agent discussion. Theoretically, this paper justifies the multi-agent discussion mechanisms from the symmetry of agents. Empirically, this paper reports the empirical results of the interplay of prompts and discussion mechanisms, revealing the empirical state-of-the-art performance of complex multi-agent mechanisms can be approached by carefully developed prompt engineering. This paper also proposes a scalable discussion mechanism based on conquer and merge, providing a simple multi-agent discussion solution with simple prompts but state-of-the-art performance.",
        "paperId": "95dae66002ebe9e560c01f6aa1ad412d7362c15c"
    },
    {
        "title": "Development of a privacy preserving large language model for automated data extraction from thyroid cancer pathology reports",
        "firstAuthor": "Denise T Lee",
        "url": "https://www.medrxiv.org/content/medrxiv/early/2023/11/08/2023.11.08.23298252.full.pdf",
        "dateSubmitted": "2023-11-08",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Introduction: Popularized by ChatGPT, large language models (LLM) are poised to transform the scalability of clinical natural language processing (NLP) downstream tasks such as medical question answering (MQA) and may enhance the ability to rapidly and accurately extract key information from clinical narrative reports. However, the use of LLMs in the healthcare setting is limited by cost, computing power and concern for patient privacy. In this study we evaluate the extraction performance of a privacy preserving LLM for automated MQA from surgical pathology reports. Study Design: 84 thyroid cancer surgical pathology reports were assessed by two independent reviewers and the open-source FastChat-T5 3B-parameter LLM using institutional computing resources. Longer text reports were converted to embeddings. 12 medical questions for staging and recurrence risk data extraction were formulated and answered for each report. Time to respond and concordance of answers were evaluated. Results: Out of a total of 1008 questions answered, reviewers 1 and 2 had an average concordance rate of responses of 99.1% (SD: 1.0%). The LLM was concordant with reviewers 1 and 2 at an overall average rate of 88.86% (SD: 7.02%) and 89.56% (SD: 7.20%). The overall time to review and answer questions for all reports was 206.9, 124.04 and 19.56 minutes for Reviewers 1, 2 and LLM, respectively. Conclusion: A privacy preserving LLM may be used for MQA with considerable time-saving and an acceptable accuracy in responses. Prompt engineering and fine tuning may further augment automated data extraction from clinical narratives for the provision of real-time, essential clinical insights.",
        "paperId": "96205d66c4e29780ece647a119afe36e1561a5ee"
    },
    {
        "title": "Activation Addition: Steering Language Models Without Optimization",
        "firstAuthor": "A. Turner",
        "url": "https://arxiv.org/pdf/2308.10248",
        "dateSubmitted": "2023-08-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Reliably controlling the behavior of large language models is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback, prompt engineering, and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language. Unlike past work which learned these steering vectors, our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort than finetuning, allows users to provide natural language specifications, and its overhead scales naturally with model size.",
        "paperId": "965d15261b682fd3fd766311b99a11257322ac4c"
    },
    {
        "title": "Exploring the Effectiveness of Prompt Engineering for Legal Reasoning Tasks",
        "firstAuthor": "Fang Yu",
        "url": "https://aclanthology.org/2023.findings-acl.858.pdf",
        "dateSubmitted": null,
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": ",",
        "paperId": "9661dda8024192342097647c37423eb7fccee298"
    },
    {
        "title": "Language Models for Multimessenger Astronomy",
        "firstAuthor": "Vladimir Sotnikov",
        "url": "https://www.mdpi.com/2075-4434/11/3/63/pdf?version=1682947662",
        "dateSubmitted": "2023-05-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "With the increasing reliance of astronomy on multi-instrument and multi-messenger observations for detecting transient phenomena, communication among astronomers has become more critical. Apart from automatic prompt follow-up observations, short reports, e.g., GCN circulars and ATels, provide essential human-written interpretations and discussions of observations. These reports lack a defined format, unlike machine-readable messages, making it challenging to associate phenomena with specific objects or coordinates in the sky. This paper examines the use of large language models (LLMs)\u2014machine learning models with billions of trainable parameters or more that are trained on text\u2014such as InstructGPT-3 and open-source Flan-T5-XXL for extracting information from astronomical reports. The study investigates the zero-shot and few-shot learning capabilities of LLMs and demonstrates various techniques to improve the accuracy of predictions. The study shows the importance of careful prompt engineering while working with LLMs, as demonstrated through edge case examples. The study\u2019s findings have significant implications for the development of data-driven applications for astrophysical text analysis.",
        "paperId": "96c9524916bc38c14e1569c8a21e6497dac709cf"
    },
    {
        "title": "Learning to Prompt for Vision-Language Models",
        "firstAuthor": "Kaiyang Zhou",
        "url": "https://arxiv.org/pdf/2109.01134",
        "dateSubmitted": "2021-09-02",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": null,
        "paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96"
    },
    {
        "title": "Pair Programming with Large Language Models for Sampling and Estimation of Copulas",
        "firstAuthor": "Jan G'orecki",
        "url": "http://arxiv.org/pdf/2303.18116",
        "dateSubmitted": "2023-03-31",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.",
        "paperId": "975da5bb7fdd800ba577535d8c6ee5a5bc835d52"
    },
    {
        "title": "Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models",
        "firstAuthor": "Keyu Pan",
        "url": "https://arxiv.org/pdf/2307.16180",
        "dateSubmitted": "2023-07-30",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "The field of large language models (LLMs) has made significant progress, and their knowledge storage capacity is approaching that of human beings. Furthermore, advanced techniques, such as prompt learning and reinforcement learning, are being employed to address ethical concerns and hallucination problems associated with LLMs, bringing them closer to aligning with human values. This situation naturally raises the question of whether LLMs with human-like abilities possess a human-like personality? In this paper, we aim to investigate the feasibility of using the Myers-Briggs Type Indicator (MBTI), a widespread human personality assessment tool, as an evaluation metric for LLMs. Specifically, extensive experiments will be conducted to explore: 1) the personality types of different LLMs, 2) the possibility of changing the personality types by prompt engineering, and 3) How does the training dataset affect the model's personality. Although the MBTI is not a rigorous assessment, it can still reflect the similarity between LLMs and human personality. In practice, the MBTI has the potential to serve as a rough indicator. Our codes are available at https://github.com/HarderThenHarder/transformers_tasks/tree/main/LLM/llms_mbti.",
        "paperId": "97717368b5f7e6a544f0a1c73a441bdcb4b6a046"
    },
    {
        "title": "Black-box Prompt Tuning for Vision-Language Model as a Service",
        "firstAuthor": "Lang-Chi Yu",
        "url": "https://www.ijcai.org/proceedings/2023/0187.pdf",
        "dateSubmitted": "2023-08-01",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "In the scenario of Model-as-a-Service (MaaS), pre-trained models are usually released as inference APIs. Users are allowed to query those models with manually crafted prompts. Without accessing the network structure and gradient information, it's tricky to perform continuous prompt tuning on MaaS, especially for vision-language models (VLMs) considering cross-modal interaction. In this paper, we propose a black-box prompt tuning framework for VLMs to learn task-relevant prompts without back-propagation. In particular, the vision and language prompts are jointly optimized in the intrinsic parameter subspace with various evolution strategies. Different prompt variants are also explored to enhance the cross-model interaction. Experimental results show that our proposed black-box prompt tuning framework outperforms both hand-crafted prompt engineering and gradient-based prompt learning methods, which serves as evidence of its capability to train task-relevant prompts in a derivative-free manner.",
        "paperId": "97dd91310930c3f3384ca15586ccf6b67a89d0be"
    },
    {
        "title": "Safurai 001: New Qualitative Approach for Code LLM Evaluation",
        "firstAuthor": "Davide Cifarelli",
        "url": "https://arxiv.org/pdf/2309.11385",
        "dateSubmitted": "2023-09-20",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more.",
        "paperId": "98b445c5cc76764c7032254a4371d29cdb79eb99"
    },
    {
        "title": "Identifying and Extracting Rare Disease Phenotypes with Large Language Models",
        "firstAuthor": "Cathy Shyr",
        "url": "http://arxiv.org/pdf/2306.12656",
        "dateSubmitted": "2023-06-22",
        "keyWords": [
            "prompt engineering"
        ],
        "abstract": "Rare diseases (RDs) are collectively common and affect 300 million people worldwide. Accurate phenotyping is critical for informing diagnosis and treatment, but RD phenotypes are often embedded in unstructured text and time-consuming to extract manually. While natural language processing (NLP) models can perform named entity recognition (NER) to automate extraction, a major bottleneck is the development of a large, annotated corpus for model training. Recently, prompt learning emerged as an NLP paradigm that can lead to more generalizable results without any (zero-shot) or few labeled samples (few-shot). Despite growing interest in ChatGPT, a revolutionary large language model capable of following complex human prompts and generating high-quality responses, none have studied its NER performance for RDs in the zero- and few-shot settings. To this end, we engineered novel prompts aimed at extracting RD phenotypes and, to the best of our knowledge, are the first the establish a benchmark for evaluating ChatGPT's performance in these settings. We compared its performance to the traditional fine-tuning approach and conducted an in-depth error analysis. Overall, fine-tuning BioClinicalBERT resulted in higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.591 in the zero- and few-shot settings, respectively). Despite this, ChatGPT achieved similar or higher accuracy for certain entities (i.e., rare diseases and signs) in the one-shot setting (F1 of 0.776 and 0.725). This suggests that with appropriate prompt engineering, ChatGPT has the potential to match or outperform fine-tuned language models for certain entity types with just one labeled sample. While the proliferation of large language models may provide opportunities for supporting RD diagnosis and treatment, researchers and clinicians should critically evaluate model outputs and be well-informed of their limitations.",
        "paperId": "994a6040fab375669a92cab0e67fb2fd203cd67f"
    }
]