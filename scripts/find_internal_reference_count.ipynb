{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install networkx matplotlib pandas pytest-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('SEMANTIC_SCHOLAR_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle rate limiting\n",
    "def rate_limited_request(url, headers, limit=10, endpoint_type='other'):\n",
    "    # if endpoint_type in ['paper/batch', 'paper/search', 'recommendations']:\n",
    "    #     time.sleep(1) \n",
    "    # else:\n",
    "    time.sleep(1.0 / limit)  \n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  \n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get paperId, get list of paper references (list of paperIds)\n",
    "def get_references(title, api_key):\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={title}&limit=1&fields=references\"\n",
    "    headers = {\"x-api-key\": api_key}\n",
    "    response = rate_limited_request(url, headers, endpoint_type='paper/search')\n",
    "\n",
    "    if response:\n",
    "        data = response.json()\n",
    "        if 'data' in data and data['data']:\n",
    "            paper_id = data['data'][0]['paperId']\n",
    "\n",
    "            references = data['data'][0].get('references', [])\n",
    "            reference_ids = [ref['paperId'] for ref in references if 'paperId' in ref]\n",
    "            return paper_id, reference_ids\n",
    "        else:\n",
    "            # print(f\"No matching paper found for title: '{title}'\")\n",
    "            return None, []\n",
    "    else:\n",
    "        print(f\"No response from API for title: '{title}'\")\n",
    "        return None, []\n",
    "    \n",
    "# Function to get the title for a given paper ID\n",
    "def get_paper_title(paper_id, api_key):\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}\"\n",
    "    headers = {\"x-api-key\": api_key}\n",
    "    response = rate_limited_request(url, headers)\n",
    "\n",
    "    if response and response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get('title')\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for paper ID: {paper_id}\")\n",
    "        return None\n",
    "    \n",
    "def get_references_by_paper_id(paper_id, api_key):\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/references?fields=title,authors&limit=1000\"\n",
    "    headers = {\"x-api-key\": api_key}\n",
    "    response = rate_limited_request(url, headers)\n",
    "\n",
    "    if response and response.status_code == 200:\n",
    "        data = response.json()\n",
    "        reference_ids = []\n",
    "\n",
    "        if 'data' in data:\n",
    "            for ref in data['data']:\n",
    "                if 'citedPaper' in ref and 'paperId' in ref['citedPaper']:\n",
    "                    reference_ids.append(ref['citedPaper']['paperId'])\n",
    "\n",
    "        return reference_ids\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First main function to run this for the entire datatset\n",
    "\n",
    "# Path to the directory containing the PDF files\n",
    "paper_directory = './PapersDirectory/papers'  # Change this to your directory path\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(paper_directory):\n",
    "    print(f\"Directory does not exist: {paper_directory}\")\n",
    "else:\n",
    "    # List all PDF files in the directory\n",
    "    pdf_files = [f for f in os.listdir(paper_directory) if f.endswith('.pdf')]\n",
    "\n",
    "    # Print the number of PDF files found\n",
    "    print(f\"Number of PDF files found: {len(pdf_files)}\")\n",
    "\n",
    "    # Limiting the number of papers processed\n",
    "    # max_papers = 10\n",
    "    # pdf_files = pdf_files[:max_papers]\n",
    "\n",
    "    # Extracting titles from the file names (assuming filename is title.pdf)\n",
    "    paper_titles = [os.path.splitext(f)[0] for f in pdf_files]\n",
    "\n",
    "\n",
    "paper_references = {}\n",
    "unmatched_titles = {}\n",
    "\n",
    "# Processing the papers with a progress bar\n",
    "for title in tqdm(paper_titles, desc=\"Processing Papers\"):\n",
    "    paper_id, references = get_references(title, api_key)\n",
    "    if paper_id:\n",
    "        paper_references[paper_id] = references\n",
    "    else:\n",
    "        unmatched_titles[title] = \"No matching paper ID found\"\n",
    "\n",
    "# Save the results to JSON files\n",
    "with open('paper_references.json', 'w') as json_file:\n",
    "    json.dump(paper_references, json_file, indent=4)\n",
    "print(\"Data saved to paper_references.json\")\n",
    "\n",
    "with open('unmatched_titles.json', 'w') as json_file:\n",
    "    json.dump(unmatched_titles, json_file, indent=4)\n",
    "print(\"Data saved to unmatched_titles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second main to add important papers not in our original dataset\n",
    "\n",
    "\n",
    "paper_references = {}\n",
    "unmatched_titles = {}\n",
    "\n",
    "titles = [\"Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints\",\n",
    "\"Language Models are Few-Shot Learners\",\n",
    "\"A Survey on In-context Learning\",\n",
    "\"What Makes Good In-Context Examples for GPT-3?\",\n",
    "\"Finding Support Examples for In-Context Learning\",\n",
    "\"Unified Demonstration Retriever for In-Context Learning\",\n",
    "\"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity\",\n",
    "\"Reordering Examples Helps during Priming-based Few-Shot Learning\",\n",
    "\"Learning To Retrieve Prompts for In-Context Learning\",\n",
    "\"Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator\",\n",
    "\"Large Language Models are Zero-Shot Reasoners\",\n",
    "\"Large Language Models Are Human-Level Prompt Engineers\",\n",
    "\"Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models\",\n",
    "\"Thread of Thought Unraveling Chaotic Contexts\",\n",
    "\"When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment\",\n",
    "\"Automatic Chain of Thought Prompting in Large Language Models\",\n",
    "\"True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4\",\n",
    "\"Contrastive Chain-of-Thought Prompting\",\n",
    "\"Gemini: A Family of Highly Capable Multimodal Models\",\n",
    "\"Complexity-Based Prompting for Multi-Step Reasoning\",\n",
    "\"Active Prompting with Chain-of-Thought for Large Language Models\",\n",
    "\"MoT: Memory-of-Thought Enables ChatGPT to Self-Improve\",\n",
    "\"Measuring and Narrowing the Compositionality Gap in Language Models\",\n",
    "\"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data\",\n",
    "\"Tab-CoT: Zero-shot Tabular Chain of Thought\",\n",
    "\"Is a Question Decomposition Unit All We Need?\",\n",
    "\"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models\",\n",
    "\"Decomposed Prompting: A Modular Approach for Solving Complex Tasks\",\n",
    "\"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models\",\n",
    "\"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\",\n",
    "\"Large Language Model Guided Tree-of-Thought\",\n",
    "\"Cumulative Reasoning with Large Language Models\",\n",
    "\"Graph of thoughts: Solving elaborate problems with large language models\",\n",
    "\"Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models\",\n",
    "\"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks\",\n",
    "\"Faithful Chain-of-Thought Reasoning\",\n",
    "\"Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding\",\n",
    "\"Exploring Demonstration Ensembling for In-context Learning\",\n",
    "\"$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference\",\n",
    "\"An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels\",\n",
    "\"Self-Consistency Improves Chain of Thought Reasoning in Language Models\",\n",
    "\"Universal Self-Consistency for Large Language Model Generation\",\n",
    "\"Making Language Models Better Reasoners with Step-Aware Verifier\",\n",
    "\"Language Models (Mostly) Know What They Know\",\n",
    "\"Self-Refine: Iterative Refinement with Self-Feedback\",\n",
    "\"RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought\",\n",
    "\"Large Language Models are Better Reasoners with Self-Verification\",\n",
    "\"Deductive Verification of Chain-of-Thought Reasoning\",\n",
    "\"Chain-of-Verification Reduces Hallucination in Large Language Models\",\n",
    "\"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations\",\n",
    "\"Large Language Models Understand and Can be Enhanced by Emotional Stimuli\",\n",
    "\"Re-Reading Improves Reasoning in Language Models\",\n",
    "\"Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities\",\n",
    "\"Better Zero-Shot Reasoning with Self-Adaptive Prompting\",\n",
    "\"Universal Self-Adaptive Prompting\",\n",
    "\"System 2 Attention (is something you might need too)\",\n",
    "\"Large Language Models as Optimizers\",\n",
    "\"Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves\"]\n",
    "\n",
    "# Processing the papers with a progress bar\n",
    "for title in tqdm(titles):\n",
    "    paper_id, references = get_references(title, api_key)\n",
    "    if paper_id:\n",
    "        paper_references[paper_id] = references\n",
    "    else:\n",
    "        unmatched_titles[title] = \"No matching paper ID found\"\n",
    "\n",
    "# Save the results to JSON files\n",
    "with open('paper_references_additional.json', 'w') as json_file:\n",
    "    json.dump(paper_references, json_file, indent=4)\n",
    "print(\"Data saved to paper_references_additional.json\")\n",
    "\n",
    "with open('unmatched_titles_additional.json', 'w') as json_file:\n",
    "    json.dump(unmatched_titles, json_file, indent=4)\n",
    "print(\"Data saved to unmatched_titles_additional.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the unmatched titles\n",
    "with open('unmatched_titles.json', 'r') as file:\n",
    "    unmatched_titles = json.load(file)\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('master_papers.csv')\n",
    "\n",
    "\n",
    "# Process papers\n",
    "paper_references = {}\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Papers\"):\n",
    "    title = row['title']\n",
    "    source = row['source']\n",
    "    paper_id = row['paperId']\n",
    "\n",
    "    if title in unmatched_titles and source == 'Semantic Scholar':\n",
    "        references = get_references_by_paper_id(paper_id, api_key)\n",
    "        paper_references[paper_id] = references\n",
    "\n",
    "\n",
    "\n",
    "# Save the results to JSON file\n",
    "with open('paper_references_from_csv.json', 'w') as file:\n",
    "    json.dump(paper_references, file, indent=4)\n",
    "\n",
    "print(\"Data saved to paper_references_from_csv.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two files\n",
    "\n",
    "# Load the existing data from both JSON files\n",
    "with open('paper_references.json', 'r') as file:\n",
    "    paper_references = json.load(file)\n",
    "\n",
    "with open('paper_references_additional.json', 'r') as file:\n",
    "    paper_references_additional = json.load(file)\n",
    "\n",
    "with open('paper_references_from_csv.json', 'r') as file:\n",
    "    paper_references_from_csv = json.load(file)\n",
    "\n",
    "# Merge the two dictionaries\n",
    "# If there are duplicate keys, the values from paper_references_additional will be used\n",
    "paper_references.update(paper_references_additional)\n",
    "paper_references.update(paper_references_from_csv)\n",
    "\n",
    "\n",
    "# Save the merged data back to a JSON file\n",
    "with open('new_merged_paper_references.json', 'w') as file:\n",
    "    json.dump(paper_references, file, indent=4)\n",
    "\n",
    "print(\"Merged data saved to merged_paper_references.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only keep refernces which refer to papers in our combined dataset\n",
    "\n",
    "# Load the merged paper references\n",
    "with open('new_merged_paper_references.json', 'r') as file:\n",
    "    merged_paper_references = json.load(file)\n",
    "\n",
    "# Filter the references so that only those that are keys in the dictionary are kept\n",
    "for paper_id, references in merged_paper_references.items():\n",
    "    merged_paper_references[paper_id] = [ref for ref in references if ref in merged_paper_references]\n",
    "\n",
    "# Save the cleaned data back to a JSON file\n",
    "with open('new_cleaned_merged_paper_references.json', 'w') as file:\n",
    "    json.dump(merged_paper_references, file, indent=4)\n",
    "\n",
    "print(\"Cleaned data saved to cleaned_merged_paper_references.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the cleaned references\n",
    "with open('new_cleaned_merged_paper_references.json', 'r') as json_file:\n",
    "    paper_references = json.load(json_file)\n",
    "\n",
    "# Create the graph\n",
    "G = nx.DiGraph()\n",
    "for paper_id, references in paper_references.items():\n",
    "    for ref_id in references:\n",
    "        G.add_edge(paper_id, ref_id)\n",
    "\n",
    "# Remove isolated nodes if needed\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "nodes_to_remove = [node for node in G.nodes() if G.in_degree(node) < 4]\n",
    "G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "# Find the top 20 nodes with the most incoming edges\n",
    "top_nodes = sorted(G.nodes(), key=lambda n: G.in_degree(n), reverse=True)[:20]\n",
    "\n",
    "# Convert paper IDs to titles for the top nodes\n",
    "titles_above_threshold = {}\n",
    "for paper_id in top_nodes:\n",
    "    title = get_paper_title(paper_id, api_key)\n",
    "    if title:\n",
    "        titles_above_threshold[paper_id] = title\n",
    "\n",
    "\n",
    "# Cap the maximum node size to prevent too large nodes\n",
    "max_size = 100000  # Maximum size for a node\n",
    "node_sizes = [min(G.in_degree(node) * 15, max_size) for node in G.nodes()]\n",
    "\n",
    "# Draw the graph with adjusted layout parameters\n",
    "plt.figure(figsize=(18, 18))  # Increased figure size for more space\n",
    "pos = nx.kamada_kawai_layout(G, dist=None, scale=1.5)  # Adjust 'scale' as needed\n",
    "nx.draw(G, pos, with_labels=False, node_size=node_sizes, node_color='skyblue', edge_color='gray', width=0.1)\n",
    "\n",
    "# Assign and label top nodes with numbers\n",
    "node_labels = {node: str(index + 1) for index, node in enumerate(top_nodes)}\n",
    "nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=12)\n",
    "\n",
    "# Create a smaller legend (number to title mapping)\n",
    "legend_labels = {str(index + 1): label for index, (node, label) in enumerate(titles_above_threshold.items())}\n",
    "plt.legend(legend_labels.items(), title=\"Top Node Titles\", loc='upper left', fontsize='x-small')\n",
    "\n",
    "plt.title(\"Graph of Paper References\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
