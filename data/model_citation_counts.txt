GPT-3 (14): ['Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations', 'Unveiling the potential of large language models in generating semantic and cross-language clones', 'On Codex Prompt Engineering for OCL Generation: An Empirical Study', 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity', 'Towards Equitable Representation in Text-to-Image Synthesis Models with the Cross-Cultural Understanding Benchmark (CCUB) Dataset', 'Generating medically-accurate summaries of patient-provider dialogue: A multi-stage approach using large language models', 'Taken out of context: On measuring situational awareness in LLMs', 'Larger language models do in-context learning differently', 'Using Large Language Models to Generate Engaging Captions for Data Visualizations', 'ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction', 'Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators', 'ChatGPT for PLC/DCS Control Logic Generation', 'Boosting In-Context Learning with Factual Knowledge', 'CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors']
GPT-4 (14): ['Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification', 'ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games', 'Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students', 'Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning', '"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models', 'Adversarial Demonstration Attacks on Large Language Models', 'ChatGPT for PLC/DCS Control Logic Generation', 'Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive Synthesis using Large Language Models and Satisfiability Solving', 'SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering Dataset for Scientific Graphs', 'A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models', 'ChatGPT opens a new door for bioinformatics', 'A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT', 'Flows: Building Blocks of Reasoning and Collaborating AI', 'Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning']
InstructGPT (4): ['Larger language models do in-context learning differently', 'Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors', 'Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts', 'GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models']
Codex (1): ['On Codex Prompt Engineering for OCL Generation: An Empirical Study']
BLOOMZ (1): ['Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis']
LLaMA (1): ["Two Timin': Repairing Smart Contracts With A Two-Layered Approach"]
Codellama (1): ['LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation']
LLaVA (1): ['SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering Dataset for Scientific Graphs']
CODEGEN (1): ['Learning Performance-Improving Code Edits']
SynthIE (1): ['Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction']
FLAN (4): ['Larger language models do in-context learning differently', 'Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification', 'Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation', 'Revisiting Relation Extraction in the era of Large Language Models']
BERT (2): ['Transfer Learning for Power Outage Detection Task with Limited Training Data', 'RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning']
BioBERT (1): ['Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification']
FinBERT (1): ['Transforming Sentiment Analysis in the Financial Domain with ChatGPT']
GatorTron (1): ['Model Tuning or Prompt Tuning? A Study of Large Language Models for Clinical Concept and Relation Extraction']
BART (1): ['Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-temporal Reasoning']
DreamFusion (2): ['ATT3D: Amortized Text-to-3D Object Synthesis', 'Scalable 3D Captioning with Pretrained Models']
CLIP (2): ['Noise2Music: Text-conditioned Music Generation with Diffusion Models', 'Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models']
CoCoOp (2): ['Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts', 'Read-only Prompt Optimization for Vision-Language Few-shot Learning']
BLIP-2 (3): ['ChatGPT as a mapping assistant: A novel method to enrich maps with generative AI and content derived from street-level photographs', 'RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension', 'SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering Dataset for Scientific Graphs']
Vision Transformer (2): ['Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer', 'Zero-Shot and Few-Shot Video Question Answering with Multi-Modal Prompts']
Flamingo (1): ['A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models']
YOLOv5m (1): ['Exploring the Effectiveness of Dataset Synthesis: An application of Apple Detection in Orchards']
CLIPSeg (1): ['PEACE: Prompt Engineering Automation for CLIPSeg Enhancement in Aerial Robotics']
XMem (1): ['Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models']
